{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CH07 합성곱 신경망 (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| apply_filter.py | lena_gray.png 파일에 필터를 적용합니다. |  |  |\n",
    "| gradient_check.py | SimpleCovNet이 기울기를 올바로 계산하는지 확인합니다. |  |  |\n",
    "| params.pkl | 미리 학습된 가중치 값들입니다. |  |  |\n",
    "| simple_convnet.py | “Convolution-ReLU-Pooling-Affine-ReLU-Affine-Softmax” 순으로 흐르는 단순한 합성곱 신경망(CNN)입니다. | 7.5 CNN 구현하기 | 251 |\n",
    "| train_convnet.py | SimpleConvNet으로 MNIST 데이터셋을 학습합니다. | 7.5 CNN 구현하기 | 254 |\n",
    "| visualize_filter.py | 합성곱 1번째 층의 가중치를 학습 전과 후로 나눠 시각화해봅니다. 이미 학습된 가중치 값(params.pkl)을 읽어서 사용하므로 학습 과정은 생략됩니다. | 7.6.1 1번째 층의 가중치 시각화하기 | 254 |\n",
    "\n",
    "## 7장 합성곱 신경망(CNN)\n",
    "이번 장의 주제는 합성곱 신경망(convolutional neural network, CNN)입니다. CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용되는데, 특히 이미지 인식 분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로 하죠. 이번 장에서는 CNN의 메커니즘을 자세히 설명하고 이를 파이썬으로 구현해보겠습니다.\n",
    "\n",
    "*옮긴이_ 합성곱은 공학과 물리학에서 널리 쓰이는 수학적 개념으로, 간단히 정의해보면 다음과 같습니다.\n",
    "“두 함수 중 하나를 반전(reverse), 이동(shift)시켜가며 나머지 함수와의 곱을 연이어 적분한다.”\n",
    "합성곱 신경망을 영어 발음 그대로 ‘컨벌루션 신경망’으로도 많이 씁니다만, 위 정의와 이번 장에서 설명할 동작 원리를 이해하고 나면 ‘합성곱 신경망’이란 용어가 더 직관적으로 다가올 수도 있을 겁니다.*\n",
    "\n",
    "## 목차\n",
    "```\n",
    "7.1 전체 구조 \n",
    "7.2 합성곱 계층 \n",
    "__7.2.1 완전연결 계층의 문제점 \n",
    "__7.2.2 합성곱 연산 \n",
    "__7.2.3 패딩 \n",
    "__7.2.4 스트라이드 \n",
    "__7.2.5 3차원 데이터의 합성곱 연산 \n",
    "__7.2.6 블록으로 생각하기 \n",
    "__7.2.7 배치 처리 \n",
    "7.3 풀링 계층 \n",
    "__7.3.1 풀링 계층의 특징 \n",
    "7.4 합성곱/풀링 계층 구현하기 \n",
    "__7.4.1 4차원 배열 \n",
    "__7.4.2 im2col로 데이터 전개하기 \n",
    "__7.4.3 합성곱 계층 구현하기 \n",
    "__7.4.4 풀링 계층 구현하기 \n",
    "7.5 CNN 구현하기 \n",
    "7.6 CNN 시각화하기 \n",
    "__7.6.1 1번째 층의 가중치 시각화하기 \n",
    "__7.6.2 층 깊이에 따른 추출 정보 변화 \n",
    "7.7 대표적인 CNN \n",
    "__7.7.1 LeNet \n",
    "__7.7.2 AlexNet \n",
    "```\n",
    "\n",
    "## 이번 장에서 배운 내용\n",
    "* CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가한다.\n",
    "* 합성곱 계층과 풀링 계층은 im2col (이미지를 행렬로 전개하는 함수)을 이용하면 간단하고 효율적으로 구현할 수 있다.\n",
    "* CNN을 시각화해보면 계층이 깊어질수록 고급 정보가 추출되는 모습을 확인할 수 있다.\n",
    "* 대표적인 CNN에는 LeNet과 AlexNet이 있다.\n",
    "* 딥러닝의 발전에는 빅 데이터와 GPU가 크게 기여했다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 합성곱/풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.5488135 , 0.71518937, 0.60276338, 0.54488318, 0.4236548 ,\n",
       "        0.64589411, 0.43758721, 0.891773  , 0.96366276, 0.38344152,\n",
       "        0.79172504, 0.52889492, 0.56804456, 0.92559664, 0.07103606,\n",
       "        0.0871293 , 0.0202184 , 0.83261985, 0.77815675, 0.87001215,\n",
       "        0.97861834, 0.79915856, 0.46147936, 0.78052918, 0.11827443,\n",
       "        0.63992102, 0.14335329, 0.94466892],\n",
       "       [0.52184832, 0.41466194, 0.26455561, 0.77423369, 0.45615033,\n",
       "        0.56843395, 0.0187898 , 0.6176355 , 0.61209572, 0.616934  ,\n",
       "        0.94374808, 0.6818203 , 0.3595079 , 0.43703195, 0.6976312 ,\n",
       "        0.06022547, 0.66676672, 0.67063787, 0.21038256, 0.1289263 ,\n",
       "        0.31542835, 0.36371077, 0.57019677, 0.43860151, 0.98837384,\n",
       "        0.10204481, 0.20887676, 0.16130952],\n",
       "       [0.65310833, 0.2532916 , 0.46631077, 0.24442559, 0.15896958,\n",
       "        0.11037514, 0.65632959, 0.13818295, 0.19658236, 0.36872517,\n",
       "        0.82099323, 0.09710128, 0.83794491, 0.09609841, 0.97645947,\n",
       "        0.4686512 , 0.97676109, 0.60484552, 0.73926358, 0.03918779,\n",
       "        0.28280696, 0.12019656, 0.2961402 , 0.11872772, 0.31798318,\n",
       "        0.41426299, 0.0641475 , 0.69247212],\n",
       "       [0.56660145, 0.26538949, 0.52324805, 0.09394051, 0.5759465 ,\n",
       "        0.9292962 , 0.31856895, 0.66741038, 0.13179786, 0.7163272 ,\n",
       "        0.28940609, 0.18319136, 0.58651293, 0.02010755, 0.82894003,\n",
       "        0.00469548, 0.67781654, 0.27000797, 0.73519402, 0.96218855,\n",
       "        0.24875314, 0.57615733, 0.59204193, 0.57225191, 0.22308163,\n",
       "        0.95274901, 0.44712538, 0.84640867],\n",
       "       [0.69947928, 0.29743695, 0.81379782, 0.39650574, 0.8811032 ,\n",
       "        0.58127287, 0.88173536, 0.69253159, 0.72525428, 0.50132438,\n",
       "        0.95608363, 0.6439902 , 0.42385505, 0.60639321, 0.0191932 ,\n",
       "        0.30157482, 0.66017354, 0.29007761, 0.61801543, 0.4287687 ,\n",
       "        0.13547406, 0.29828233, 0.56996491, 0.59087276, 0.57432525,\n",
       "        0.65320082, 0.65210327, 0.43141844],\n",
       "       [0.8965466 , 0.36756187, 0.43586493, 0.89192336, 0.80619399,\n",
       "        0.70388858, 0.10022689, 0.91948261, 0.7142413 , 0.99884701,\n",
       "        0.1494483 , 0.86812606, 0.16249293, 0.61555956, 0.12381998,\n",
       "        0.84800823, 0.80731896, 0.56910074, 0.4071833 , 0.069167  ,\n",
       "        0.69742877, 0.45354268, 0.7220556 , 0.86638233, 0.97552151,\n",
       "        0.85580334, 0.01171408, 0.35997806],\n",
       "       [0.72999056, 0.17162968, 0.52103661, 0.05433799, 0.19999652,\n",
       "        0.01852179, 0.7936977 , 0.22392469, 0.34535168, 0.92808129,\n",
       "        0.7044144 , 0.03183893, 0.16469416, 0.6214784 , 0.57722859,\n",
       "        0.23789282, 0.934214  , 0.61396596, 0.5356328 , 0.58990998,\n",
       "        0.73012203, 0.311945  , 0.39822106, 0.20984375, 0.18619301,\n",
       "        0.94437239, 0.7395508 , 0.49045881],\n",
       "       [0.22741463, 0.25435648, 0.05802916, 0.43441663, 0.31179588,\n",
       "        0.69634349, 0.37775184, 0.17960368, 0.02467873, 0.06724963,\n",
       "        0.67939277, 0.45369684, 0.53657921, 0.89667129, 0.99033895,\n",
       "        0.21689698, 0.6630782 , 0.26332238, 0.020651  , 0.75837865,\n",
       "        0.32001715, 0.38346389, 0.58831711, 0.83104846, 0.62898184,\n",
       "        0.87265066, 0.27354203, 0.79804683],\n",
       "       [0.18563594, 0.95279166, 0.68748828, 0.21550768, 0.94737059,\n",
       "        0.73085581, 0.25394164, 0.21331198, 0.51820071, 0.02566272,\n",
       "        0.20747008, 0.42468547, 0.37416998, 0.46357542, 0.27762871,\n",
       "        0.58678435, 0.86385561, 0.11753186, 0.51737911, 0.13206811,\n",
       "        0.71685968, 0.3960597 , 0.56542131, 0.18327984, 0.14484776,\n",
       "        0.48805628, 0.35561274, 0.94043195],\n",
       "       [0.76532525, 0.74866362, 0.90371974, 0.08342244, 0.55219247,\n",
       "        0.58447607, 0.96193638, 0.29214753, 0.24082878, 0.10029394,\n",
       "        0.01642963, 0.92952932, 0.66991655, 0.78515291, 0.28173011,\n",
       "        0.58641017, 0.06395527, 0.4856276 , 0.97749514, 0.87650525,\n",
       "        0.33815895, 0.96157015, 0.23170163, 0.94931882, 0.9413777 ,\n",
       "        0.79920259, 0.63044794, 0.87428797],\n",
       "       [0.29302028, 0.84894356, 0.61787669, 0.01323686, 0.34723352,\n",
       "        0.14814086, 0.98182939, 0.47837031, 0.49739137, 0.63947252,\n",
       "        0.36858461, 0.13690027, 0.82211773, 0.18984791, 0.51131898,\n",
       "        0.22431703, 0.09784448, 0.86219152, 0.97291949, 0.96083466,\n",
       "        0.9065555 , 0.77404733, 0.33314515, 0.08110139, 0.40724117,\n",
       "        0.23223414, 0.13248763, 0.05342718],\n",
       "       [0.72559436, 0.01142746, 0.77058075, 0.14694665, 0.07952208,\n",
       "        0.08960303, 0.67204781, 0.24536721, 0.42053947, 0.55736879,\n",
       "        0.86055117, 0.72704426, 0.27032791, 0.1314828 , 0.05537432,\n",
       "        0.30159863, 0.26211815, 0.45614057, 0.68328134, 0.69562545,\n",
       "        0.28351885, 0.37992696, 0.18115096, 0.78854551, 0.05684808,\n",
       "        0.69699724, 0.7786954 , 0.77740756],\n",
       "       [0.25942256, 0.37381314, 0.58759964, 0.2728219 , 0.3708528 ,\n",
       "        0.19705428, 0.45985588, 0.0446123 , 0.79979588, 0.07695645,\n",
       "        0.51883515, 0.3068101 , 0.57754295, 0.95943334, 0.64557024,\n",
       "        0.03536244, 0.43040244, 0.51001685, 0.53617749, 0.68139251,\n",
       "        0.2775961 , 0.12886057, 0.39267568, 0.95640572, 0.18713089,\n",
       "        0.90398395, 0.54380595, 0.45691142],\n",
       "       [0.88204141, 0.45860396, 0.72416764, 0.39902532, 0.90404439,\n",
       "        0.69002502, 0.69962205, 0.3277204 , 0.75677864, 0.63606106,\n",
       "        0.24002027, 0.16053882, 0.79639147, 0.9591666 , 0.45813883,\n",
       "        0.59098417, 0.85772264, 0.45722345, 0.95187448, 0.57575116,\n",
       "        0.82076712, 0.90884372, 0.81552382, 0.15941446, 0.62889844,\n",
       "        0.39843426, 0.06271295, 0.42403225],\n",
       "       [0.25868407, 0.84903831, 0.03330463, 0.95898272, 0.35536885,\n",
       "        0.35670689, 0.0163285 , 0.18523233, 0.4012595 , 0.92929142,\n",
       "        0.09961493, 0.94530153, 0.86948853, 0.4541624 , 0.32670088,\n",
       "        0.23274413, 0.61446471, 0.03307459, 0.01560606, 0.42879572,\n",
       "        0.06807407, 0.25194099, 0.22116092, 0.25319119, 0.13105523,\n",
       "        0.01203622, 0.1154843 , 0.61848026],\n",
       "       [0.97425621, 0.990345  , 0.4090541 , 0.16295443, 0.63876176,\n",
       "        0.49030535, 0.98940978, 0.06530421, 0.78323444, 0.2883985 ,\n",
       "        0.24141862, 0.66250457, 0.24606318, 0.66585912, 0.51730852,\n",
       "        0.42408899, 0.55468781, 0.28705152, 0.70657471, 0.41485687,\n",
       "        0.36054556, 0.82865691, 0.92496691, 0.04600731, 0.23262699,\n",
       "        0.34851937, 0.81496648, 0.98549143],\n",
       "       [0.9689717 , 0.90494835, 0.29655627, 0.99201124, 0.24942004,\n",
       "        0.10590615, 0.95095261, 0.23342026, 0.68976827, 0.05835636,\n",
       "        0.7307091 , 0.88172021, 0.2724369 , 0.3790569 , 0.37429618,\n",
       "        0.74878826, 0.23780724, 0.1718531 , 0.44929165, 0.30446841,\n",
       "        0.83918912, 0.23774183, 0.50238946, 0.9425836 , 0.6339977 ,\n",
       "        0.86728941, 0.94020969, 0.75076486],\n",
       "       [0.69957506, 0.96796557, 0.99440079, 0.45182168, 0.07086978,\n",
       "        0.29279403, 0.15235471, 0.41748637, 0.13128933, 0.6041178 ,\n",
       "        0.38280806, 0.89538588, 0.96779467, 0.5468849 , 0.27482357,\n",
       "        0.59223042, 0.89676116, 0.40673335, 0.55207828, 0.27165277,\n",
       "        0.45544415, 0.40171354, 0.24841347, 0.50586638, 0.31038083,\n",
       "        0.37303486, 0.52497044, 0.75059502],\n",
       "       [0.33350747, 0.92415877, 0.86231855, 0.0486903 , 0.25364252,\n",
       "        0.44613551, 0.10462789, 0.34847599, 0.74009753, 0.68051448,\n",
       "        0.62238443, 0.7105284 , 0.20492369, 0.34169811, 0.67624248,\n",
       "        0.87923476, 0.54367805, 0.28269965, 0.03023526, 0.71033683,\n",
       "        0.0078841 , 0.37267907, 0.53053721, 0.92211146, 0.08949455,\n",
       "        0.40594232, 0.0243132 , 0.34261098],\n",
       "       [0.62223106, 0.27906795, 0.20974995, 0.11570323, 0.57714024,\n",
       "        0.69527001, 0.67195714, 0.94886102, 0.00270321, 0.64719665,\n",
       "        0.60039224, 0.58873961, 0.96277032, 0.01687167, 0.69648243,\n",
       "        0.81367865, 0.5098072 , 0.33396487, 0.79084016, 0.09724293,\n",
       "        0.44203564, 0.51995237, 0.69395641, 0.09088573, 0.2277595 ,\n",
       "        0.41030156, 0.62329467, 0.88696078],\n",
       "       [0.61882617, 0.13346147, 0.98058013, 0.87178573, 0.50272076,\n",
       "        0.92234798, 0.54138079, 0.92330607, 0.82989737, 0.96828641,\n",
       "        0.91978281, 0.03603382, 0.174772  , 0.38913468, 0.9521427 ,\n",
       "        0.30002892, 0.16046764, 0.88630467, 0.44639442, 0.90787559,\n",
       "        0.16023047, 0.66111751, 0.44026375, 0.07648677, 0.69646314,\n",
       "        0.24739876, 0.03961552, 0.0599443 ],\n",
       "       [0.06107854, 0.90773296, 0.73988392, 0.89806236, 0.67258231,\n",
       "        0.52893993, 0.30444636, 0.99796225, 0.36218906, 0.47064895,\n",
       "        0.37824517, 0.97952693, 0.17465839, 0.327988  , 0.68034867,\n",
       "        0.06320762, 0.60724937, 0.4776465 , 0.28399998, 0.23841328,\n",
       "        0.51451274, 0.36792758, 0.45651989, 0.33747738, 0.97049369,\n",
       "        0.13343943, 0.09680395, 0.34339173],\n",
       "       [0.5910269 , 0.65917647, 0.39725675, 0.99927799, 0.351893  ,\n",
       "        0.72140667, 0.63758269, 0.81305386, 0.97622566, 0.88979366,\n",
       "        0.76456197, 0.69824848, 0.33549817, 0.14768558, 0.062636  ,\n",
       "        0.2419017 , 0.43228148, 0.52199627, 0.77308355, 0.95874092,\n",
       "        0.11732048, 0.10700414, 0.58969472, 0.74539807, 0.84815038,\n",
       "        0.93583208, 0.98342624, 0.39980169],\n",
       "       [0.38033518, 0.14780868, 0.68493444, 0.65676196, 0.8620626 ,\n",
       "        0.09725799, 0.49777691, 0.58108193, 0.24155704, 0.16902541,\n",
       "        0.85958084, 0.05853492, 0.4706209 , 0.115834  , 0.45705876,\n",
       "        0.97996233, 0.42370635, 0.85712492, 0.11731556, 0.27125208,\n",
       "        0.40379274, 0.39981214, 0.67138348, 0.34471813, 0.71376687,\n",
       "        0.6391869 , 0.39916115, 0.43176013],\n",
       "       [0.6145277 , 0.07004219, 0.82240674, 0.65342116, 0.72634246,\n",
       "        0.536923  , 0.11047711, 0.40503561, 0.40537358, 0.32104299,\n",
       "        0.02995032, 0.73725424, 0.10978446, 0.60630813, 0.7032175 ,\n",
       "        0.63478632, 0.95914225, 0.10329816, 0.86716716, 0.02919023,\n",
       "        0.53491685, 0.40424362, 0.52418386, 0.36509988, 0.19056691,\n",
       "        0.0191229 , 0.51814981, 0.84277686],\n",
       "       [0.37321596, 0.22286382, 0.080532  , 0.08531092, 0.22139645,\n",
       "        0.10001406, 0.2650397 , 0.06614946, 0.06560487, 0.85627618,\n",
       "        0.16212026, 0.55968241, 0.77345554, 0.45640957, 0.15336888,\n",
       "        0.19959614, 0.43298421, 0.52823409, 0.34944029, 0.7814796 ,\n",
       "        0.75102165, 0.92721181, 0.02895255, 0.89569129, 0.39256879,\n",
       "        0.8783725 , 0.69078478, 0.98734876],\n",
       "       [0.75928245, 0.36454463, 0.50106317, 0.37638916, 0.36491184,\n",
       "        0.2609045 , 0.4959703 , 0.68173995, 0.27734027, 0.52437981,\n",
       "        0.11738029, 0.15984529, 0.04680635, 0.97073144, 0.00386035,\n",
       "        0.17857997, 0.61286675, 0.0813696 , 0.8818965 , 0.71962016,\n",
       "        0.96638997, 0.50763555, 0.30040368, 0.54950057, 0.93081872,\n",
       "        0.52076144, 0.26720703, 0.87739879],\n",
       "       [0.37191875, 0.00138335, 0.24768502, 0.31823351, 0.85877747,\n",
       "        0.45850317, 0.44458729, 0.33610227, 0.88067812, 0.94502678,\n",
       "        0.99189033, 0.37674127, 0.96614745, 0.79187957, 0.67568915,\n",
       "        0.24488948, 0.21645726, 0.16604782, 0.92275661, 0.29407666,\n",
       "        0.45309425, 0.49395783, 0.7781716 , 0.84423496, 0.1390727 ,\n",
       "        0.42690436, 0.84285489, 0.81803331]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "x = np.random.rand(10, 1, 28, 28) # 높이 28, 너비 28, 채널 1개, 데이터 10개\n",
    "display(x.shape)\n",
    "display(x[0, 0]) # 첫번째 데이터의 첫 채널의 공간 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4.2 im2col로 데이터 전개하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common/util.py\n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(1, 3, 7, 7) # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape) # (9, 75)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # (데이터 수, 채널 수, 높이, 너비)\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape) # (90, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 계층 구현: common.layers.py\n",
    "\n",
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        # 중간 데이터（backward 시 사용）\n",
    "        self.x = None   \n",
    "        self.col = None\n",
    "        self.col_W = None\n",
    "        \n",
    "        # 가중치와 편향 매개변수의 기울기\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = 1 + int((H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = 1 + int((W + 2*self.pad - FW) / self.stride)\n",
    "\n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T\n",
    "\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.col = col\n",
    "        self.col_W = col_W\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
    "\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        self.dW = np.dot(self.col.T, dout)\n",
    "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
    "\n",
    "        dcol = np.dot(dout, self.col_W.T)\n",
    "        dx = col2im(dcol, self.x.shape, FH, FW, self.stride, self.pad)\n",
    "\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링 계층 구현하기: common/layers.py\n",
    "\n",
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "        self.x = None\n",
    "        self.arg_max = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h*self.pool_w)\n",
    "\n",
    "        arg_max = np.argmax(col, axis=1)\n",
    "        out = np.max(col, axis=1)\n",
    "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "\n",
    "        self.x = x\n",
    "        self.arg_max = arg_max\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = dout.transpose(0, 2, 3, 1)\n",
    "        \n",
    "        pool_size = self.pool_h * self.pool_w\n",
    "        dmax = np.zeros((dout.size, pool_size))\n",
    "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
    "        dmax = dmax.reshape(dout.shape + (pool_size,)) \n",
    "        \n",
    "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
    "        dx = col2im(dcol, self.x.shape, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 CNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ch07/simple_convnet.py\n",
    "\n",
    "from src.common.gradient import numerical_gradient\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleNet으로 MNIST 데이터셋 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2995566840985933\n",
      "=== epoch:1, train acc:0.132, test acc:0.145 ===\n",
      "train loss:2.297908807243491\n",
      "train loss:2.2939922540397273\n",
      "train loss:2.288061046314952\n",
      "train loss:2.278024085624977\n",
      "train loss:2.266714798190005\n",
      "train loss:2.2637797922543452\n",
      "train loss:2.235382244407729\n",
      "train loss:2.207015492268314\n",
      "train loss:2.2028362483781563\n",
      "train loss:2.183082514364516\n",
      "train loss:2.153369697191434\n",
      "train loss:2.108686218693852\n",
      "train loss:2.007267649709703\n",
      "train loss:2.0232236188334682\n",
      "train loss:1.961979461408567\n",
      "train loss:1.8945062217073192\n",
      "train loss:1.781074928354131\n",
      "train loss:1.6910554027195954\n",
      "train loss:1.5658614364162113\n",
      "train loss:1.5381739006064954\n",
      "train loss:1.5282891571001627\n",
      "train loss:1.3227602529628388\n",
      "train loss:1.3697570816049096\n",
      "train loss:1.182368655855534\n",
      "train loss:1.1362564500858423\n",
      "train loss:1.1974196853725905\n",
      "train loss:1.1119998566052036\n",
      "train loss:1.0353910345113149\n",
      "train loss:0.9346453202063159\n",
      "train loss:0.9750670991993208\n",
      "train loss:0.8055751629547637\n",
      "train loss:0.8775109057166545\n",
      "train loss:0.7595418622571022\n",
      "train loss:0.7059539109113925\n",
      "train loss:0.7113964147649748\n",
      "train loss:0.8601947100147916\n",
      "train loss:0.9258013417722993\n",
      "train loss:0.6752636844347946\n",
      "train loss:0.6868118053683391\n",
      "train loss:0.7536043448534522\n",
      "train loss:0.7067055623282218\n",
      "train loss:0.6433469718550893\n",
      "train loss:0.6985374944370096\n",
      "train loss:0.7463220414460533\n",
      "train loss:0.6915565762932626\n",
      "train loss:0.5321845685914064\n",
      "train loss:0.5594577226981451\n",
      "train loss:0.6319501613965403\n",
      "train loss:0.5954041372482246\n",
      "train loss:0.6767663474530946\n",
      "train loss:0.498918480998366\n",
      "train loss:0.6994855841559707\n",
      "train loss:0.6528471292293428\n",
      "train loss:0.5108017621595751\n",
      "train loss:0.6326784318041856\n",
      "train loss:0.49479878346366485\n",
      "train loss:0.4540210265196023\n",
      "train loss:0.4776392819297343\n",
      "train loss:0.40197307235138796\n",
      "train loss:0.5713037889435836\n",
      "train loss:0.47745841879065515\n",
      "train loss:0.46619875580113024\n",
      "train loss:0.4637753078381674\n",
      "train loss:0.36030390023319714\n",
      "train loss:0.5239195692037529\n",
      "train loss:0.5344694952737631\n",
      "train loss:0.38668156027543454\n",
      "train loss:0.42369537301645466\n",
      "train loss:0.3226108338838881\n",
      "train loss:0.4192585341400251\n",
      "train loss:0.34979293130915656\n",
      "train loss:0.33614530886716004\n",
      "train loss:0.31622756682085407\n",
      "train loss:0.4281083873633357\n",
      "train loss:0.6112098710738634\n",
      "train loss:0.46131486602435634\n",
      "train loss:0.4044547290942333\n",
      "train loss:0.4388412658100031\n",
      "train loss:0.3417235171693154\n",
      "train loss:0.48963947657827156\n",
      "train loss:0.29384565341271374\n",
      "train loss:0.49634459239146134\n",
      "train loss:0.3337099762365638\n",
      "train loss:0.41213425339797355\n",
      "train loss:0.37826562785206846\n",
      "train loss:0.6246812431048936\n",
      "train loss:0.3220989643721194\n",
      "train loss:0.32392326402739097\n",
      "train loss:0.29310452754657457\n",
      "train loss:0.42410285382254614\n",
      "train loss:0.33932035443991176\n",
      "train loss:0.5122207307685465\n",
      "train loss:0.32209963398827557\n",
      "train loss:0.47295556394201704\n",
      "train loss:0.41457967607459295\n",
      "train loss:0.44412554093645595\n",
      "train loss:0.37940501775338875\n",
      "train loss:0.30835498498119324\n",
      "train loss:0.24601003081299835\n",
      "train loss:0.5492193726248699\n",
      "train loss:0.33638281004970483\n",
      "train loss:0.31700422316180155\n",
      "train loss:0.45459433900919954\n",
      "train loss:0.3553857688025285\n",
      "train loss:0.29926374905119585\n",
      "train loss:0.331860961161535\n",
      "train loss:0.29752759541398766\n",
      "train loss:0.3497665935518136\n",
      "train loss:0.3989909274901009\n",
      "train loss:0.5492216960591176\n",
      "train loss:0.6109797862666835\n",
      "train loss:0.3786735684353012\n",
      "train loss:0.2642433360602594\n",
      "train loss:0.2728441835112664\n",
      "train loss:0.3007034160247816\n",
      "train loss:0.5749201093816879\n",
      "train loss:0.43981932325917567\n",
      "train loss:0.5948507167335824\n",
      "train loss:0.5053599548652837\n",
      "train loss:0.46800541967574605\n",
      "train loss:0.27990804049517515\n",
      "train loss:0.36979736242722816\n",
      "train loss:0.35331059657024433\n",
      "train loss:0.31410119879497783\n",
      "train loss:0.3586510420231122\n",
      "train loss:0.24604214828004323\n",
      "train loss:0.3791896490224454\n",
      "train loss:0.4414944204974385\n",
      "train loss:0.26605549080152663\n",
      "train loss:0.38845637283111684\n",
      "train loss:0.44394983200519794\n",
      "train loss:0.29164989267411234\n",
      "train loss:0.43157351598211924\n",
      "train loss:0.44987138329908843\n",
      "train loss:0.4265454737368205\n",
      "train loss:0.38332100822650533\n",
      "train loss:0.4153604037126653\n",
      "train loss:0.43392274258841523\n",
      "train loss:0.33593658599289644\n",
      "train loss:0.362793489409859\n",
      "train loss:0.3438991751379965\n",
      "train loss:0.32891007807430045\n",
      "train loss:0.3781849083574982\n",
      "train loss:0.3310997345850407\n",
      "train loss:0.457051300854348\n",
      "train loss:0.35446801131431166\n",
      "train loss:0.3578075331893511\n",
      "train loss:0.6041690864767152\n",
      "train loss:0.35166699549476677\n",
      "train loss:0.3021884955301264\n",
      "train loss:0.2811877442638338\n",
      "train loss:0.2943878822309459\n",
      "train loss:0.3346174309421874\n",
      "train loss:0.3343436569724762\n",
      "train loss:0.42266770782932694\n",
      "train loss:0.32367552141647077\n",
      "train loss:0.33208575924255634\n",
      "train loss:0.3143454020116335\n",
      "train loss:0.35461562050684314\n",
      "train loss:0.19865619994657713\n",
      "train loss:0.412324751948794\n",
      "train loss:0.3385631004940565\n",
      "train loss:0.2692587312508643\n",
      "train loss:0.25819608288262813\n",
      "train loss:0.41720476204062673\n",
      "train loss:0.3537813346657001\n",
      "train loss:0.2973740710359129\n",
      "train loss:0.22723814320839508\n",
      "train loss:0.25759256858326723\n",
      "train loss:0.3330319848459035\n",
      "train loss:0.159848889542496\n",
      "train loss:0.3489825062214672\n",
      "train loss:0.32061422339305856\n",
      "train loss:0.30761197110999133\n",
      "train loss:0.34737142048927244\n",
      "train loss:0.26854204482226074\n",
      "train loss:0.40936770891868607\n",
      "train loss:0.31457800583642986\n",
      "train loss:0.21307762510863146\n",
      "train loss:0.23464648476919503\n",
      "train loss:0.3203579975874123\n",
      "train loss:0.3990358663198139\n",
      "train loss:0.36201247761457045\n",
      "train loss:0.5125023857899664\n",
      "train loss:0.39462114205959176\n",
      "train loss:0.24306425125108444\n",
      "train loss:0.3176598124341307\n",
      "train loss:0.3311005785453742\n",
      "train loss:0.45769226961510134\n",
      "train loss:0.26727433776077447\n",
      "train loss:0.25130030935346187\n",
      "train loss:0.3830105421364997\n",
      "train loss:0.22481466571442837\n",
      "train loss:0.29747844548728103\n",
      "train loss:0.38381089768948184\n",
      "train loss:0.2476632441725017\n",
      "train loss:0.28832067962367053\n",
      "train loss:0.3566764466731015\n",
      "train loss:0.32603404430883887\n",
      "train loss:0.24548156596671497\n",
      "train loss:0.2537184385013227\n",
      "train loss:0.31919256871774726\n",
      "train loss:0.21286814448360702\n",
      "train loss:0.23947525254897728\n",
      "train loss:0.2764072411953056\n",
      "train loss:0.2730327371174743\n",
      "train loss:0.19226470559460954\n",
      "train loss:0.20706928445665448\n",
      "train loss:0.2702952913563962\n",
      "train loss:0.3430039985482706\n",
      "train loss:0.3196125737960189\n",
      "train loss:0.21833355346612227\n",
      "train loss:0.37376214295836674\n",
      "train loss:0.23518289757198027\n",
      "train loss:0.2248797939071741\n",
      "train loss:0.3665485120288591\n",
      "train loss:0.31451417697032663\n",
      "train loss:0.24594747032661388\n",
      "train loss:0.21270531379335522\n",
      "train loss:0.17260116736460232\n",
      "train loss:0.2860482668320756\n",
      "train loss:0.32884955069933136\n",
      "train loss:0.20869820475728293\n",
      "train loss:0.18691755307091124\n",
      "train loss:0.17164969359993715\n",
      "train loss:0.2262479082026836\n",
      "train loss:0.1821082537524293\n",
      "train loss:0.2523277375514206\n",
      "train loss:0.17067271907566975\n",
      "train loss:0.14290102501886814\n",
      "train loss:0.2570743248686206\n",
      "train loss:0.3972950548910448\n",
      "train loss:0.20446141329723846\n",
      "train loss:0.28280369753359896\n",
      "train loss:0.37452893205143234\n",
      "train loss:0.34572450936437077\n",
      "train loss:0.15702298087153702\n",
      "train loss:0.2244470988712454\n",
      "train loss:0.20657802196108738\n",
      "train loss:0.30304643609752085\n",
      "train loss:0.24213428647825566\n",
      "train loss:0.3349087127823752\n",
      "train loss:0.2264410334400341\n",
      "train loss:0.2617582518310913\n",
      "train loss:0.2968097963179779\n",
      "train loss:0.32108816313961497\n",
      "train loss:0.2849906079970826\n",
      "train loss:0.16808300834768578\n",
      "train loss:0.32537219250878713\n",
      "train loss:0.17415330105754248\n",
      "train loss:0.20484869278062307\n",
      "train loss:0.24387641243370622\n",
      "train loss:0.24613789448576262\n",
      "train loss:0.2615132663953363\n",
      "train loss:0.14516496000392057\n",
      "train loss:0.42232696500821976\n",
      "train loss:0.1674252934301387\n",
      "train loss:0.210579866945044\n",
      "train loss:0.3152973928429888\n",
      "train loss:0.22145096887843108\n",
      "train loss:0.20732553654980698\n",
      "train loss:0.3273357856185521\n",
      "train loss:0.2041454252956554\n",
      "train loss:0.20220981132670718\n",
      "train loss:0.28761468538186497\n",
      "train loss:0.5182444660954154\n",
      "train loss:0.22567166249607634\n",
      "train loss:0.22733021875345258\n",
      "train loss:0.30857388997727747\n",
      "train loss:0.29256967925275146\n",
      "train loss:0.3361005260647424\n",
      "train loss:0.11401970803546595\n",
      "train loss:0.2374768783534935\n",
      "train loss:0.2726826606609857\n",
      "train loss:0.20239026086032472\n",
      "train loss:0.15579962089262428\n",
      "train loss:0.3261017934849804\n",
      "train loss:0.4045096856043383\n",
      "train loss:0.1527265512011859\n",
      "train loss:0.263790277072631\n",
      "train loss:0.16094449387159418\n",
      "train loss:0.17212391908889496\n",
      "train loss:0.2130266270343974\n",
      "train loss:0.13355373503119067\n",
      "train loss:0.2749737387100312\n",
      "train loss:0.1753784281028918\n",
      "train loss:0.20739987940904883\n",
      "train loss:0.2491818451764629\n",
      "train loss:0.29675074144917274\n",
      "train loss:0.2592120180940779\n",
      "train loss:0.1737090823243691\n",
      "train loss:0.262203412151551\n",
      "train loss:0.4167878105834005\n",
      "train loss:0.4017698060405392\n",
      "train loss:0.3531097801839018\n",
      "train loss:0.1499275931668725\n",
      "train loss:0.34851704790418203\n",
      "train loss:0.2090567369556042\n",
      "train loss:0.14749853439740712\n",
      "train loss:0.3075687035977991\n",
      "train loss:0.20954047932484698\n",
      "train loss:0.22478280155510913\n",
      "train loss:0.1712115856967284\n",
      "train loss:0.09658523237061545\n",
      "train loss:0.2301206831525384\n",
      "train loss:0.3474485533900388\n",
      "train loss:0.18220002950917155\n",
      "train loss:0.19015858819193723\n",
      "train loss:0.2867171015936474\n",
      "train loss:0.14390419203298802\n",
      "train loss:0.19793146609098158\n",
      "train loss:0.24048706587782323\n",
      "train loss:0.253185293349042\n",
      "train loss:0.23388641852536454\n",
      "train loss:0.22598861583544458\n",
      "train loss:0.2204626323034812\n",
      "train loss:0.31812115399829277\n",
      "train loss:0.21094067544724504\n",
      "train loss:0.28066741935140277\n",
      "train loss:0.1144714850284351\n",
      "train loss:0.14539545593936445\n",
      "train loss:0.08690249150150085\n",
      "train loss:0.1443670260106134\n",
      "train loss:0.22934819774430162\n",
      "train loss:0.10596000887847604\n",
      "train loss:0.29362374353010706\n",
      "train loss:0.32740108155506403\n",
      "train loss:0.1657777697244493\n",
      "train loss:0.13398070947395896\n",
      "train loss:0.24952924782917685\n",
      "train loss:0.1779385834520236\n",
      "train loss:0.18258169888117767\n",
      "train loss:0.10914471764708365\n",
      "train loss:0.24797260450269726\n",
      "train loss:0.2562057140563794\n",
      "train loss:0.17530693155583407\n",
      "train loss:0.3243504415853835\n",
      "train loss:0.1308602154699406\n",
      "train loss:0.15867691440675413\n",
      "train loss:0.212039843321191\n",
      "train loss:0.14616241948057515\n",
      "train loss:0.14062155184370448\n",
      "train loss:0.21134635057159268\n",
      "train loss:0.4244603053570036\n",
      "train loss:0.19677927278072851\n",
      "train loss:0.18848540505066708\n",
      "train loss:0.25599290858214535\n",
      "train loss:0.15081611618437607\n",
      "train loss:0.1471008959431699\n",
      "train loss:0.21409707902033367\n",
      "train loss:0.21747919056694331\n",
      "train loss:0.2777982825074543\n",
      "train loss:0.28149568714319123\n",
      "train loss:0.1335340250490391\n",
      "train loss:0.2590847312728515\n",
      "train loss:0.13433104758736447\n",
      "train loss:0.17831386124547915\n",
      "train loss:0.19750014720985415\n",
      "train loss:0.19162391878192456\n",
      "train loss:0.18617166384756476\n",
      "train loss:0.19816221360297653\n",
      "train loss:0.2413829929557545\n",
      "train loss:0.1688620892057936\n",
      "train loss:0.13692363059910664\n",
      "train loss:0.2628618550426418\n",
      "train loss:0.31444876703294444\n",
      "train loss:0.13188394997457412\n",
      "train loss:0.2227508144941881\n",
      "train loss:0.1530055389562245\n",
      "train loss:0.09849631932003762\n",
      "train loss:0.1075791690932097\n",
      "train loss:0.09812310348840839\n",
      "train loss:0.20073805185920182\n",
      "train loss:0.18369318032206927\n",
      "train loss:0.17744898666788486\n",
      "train loss:0.18468742031661814\n",
      "train loss:0.19222768568806237\n",
      "train loss:0.142973864835637\n",
      "train loss:0.16998254461399648\n",
      "train loss:0.15511983475491684\n",
      "train loss:0.22373533604053972\n",
      "train loss:0.17860714231741542\n",
      "train loss:0.1862121392159777\n",
      "train loss:0.20126480988523507\n",
      "train loss:0.12648148367667608\n",
      "train loss:0.14577136881761069\n",
      "train loss:0.0935382326892163\n",
      "train loss:0.17086016530995835\n",
      "train loss:0.24457846461743685\n",
      "train loss:0.20925316909603264\n",
      "train loss:0.2144796376050283\n",
      "train loss:0.16914276895786146\n",
      "train loss:0.08889563020175065\n",
      "train loss:0.17600152315803588\n",
      "train loss:0.09983960054371238\n",
      "train loss:0.15517529547947903\n",
      "train loss:0.15982000506945837\n",
      "train loss:0.23788987915822662\n",
      "train loss:0.3223617399316013\n",
      "train loss:0.17725568387720414\n",
      "train loss:0.16331492035852382\n",
      "train loss:0.18617489428293257\n",
      "train loss:0.10744862232727671\n",
      "train loss:0.09849137090157745\n",
      "train loss:0.2898788847135803\n",
      "train loss:0.16644940075505243\n",
      "train loss:0.0695651789380914\n",
      "train loss:0.10597082507633429\n",
      "train loss:0.09673043519706657\n",
      "train loss:0.07129697616920529\n",
      "train loss:0.1247032323665361\n",
      "train loss:0.21305020147430467\n",
      "train loss:0.2422328826054664\n",
      "train loss:0.20745356144895943\n",
      "train loss:0.12368760150502603\n",
      "train loss:0.12422296159013316\n",
      "train loss:0.21515340568796554\n",
      "train loss:0.17296164095964237\n",
      "train loss:0.14517030923229013\n",
      "train loss:0.3664248774256539\n",
      "train loss:0.2341609927800971\n",
      "train loss:0.2256772038011743\n",
      "train loss:0.16010898821456607\n",
      "train loss:0.2214870167335029\n",
      "train loss:0.23449060982640701\n",
      "train loss:0.11259472036066191\n",
      "train loss:0.14644329044726112\n",
      "train loss:0.2185925565390191\n",
      "train loss:0.2689847206162229\n",
      "train loss:0.1571754848857397\n",
      "train loss:0.14420183152199015\n",
      "train loss:0.1545493978113074\n",
      "train loss:0.09013385878077415\n",
      "train loss:0.17856045550400168\n",
      "train loss:0.19575933324384057\n",
      "train loss:0.12446351069295922\n",
      "train loss:0.11796700268478906\n",
      "train loss:0.19835144340028546\n",
      "train loss:0.2029935198051089\n",
      "train loss:0.1259402300007552\n",
      "train loss:0.16208592390870213\n",
      "train loss:0.19321541811522672\n",
      "train loss:0.19997355740207656\n",
      "train loss:0.12293283268883382\n",
      "train loss:0.11397629241008632\n",
      "train loss:0.15890015929236187\n",
      "train loss:0.11641478769735142\n",
      "train loss:0.18076075732719685\n",
      "train loss:0.20902746774531938\n",
      "train loss:0.1595946384146262\n",
      "train loss:0.14838801658305475\n",
      "train loss:0.19041827359634067\n",
      "train loss:0.16997048711035734\n",
      "train loss:0.1529094777788281\n",
      "train loss:0.19473195306479604\n",
      "train loss:0.22959061417803941\n",
      "train loss:0.14874670987506097\n",
      "train loss:0.17273095233861915\n",
      "train loss:0.07691743257908304\n",
      "train loss:0.19621090643349107\n",
      "train loss:0.15024278925344212\n",
      "train loss:0.08445500642234358\n",
      "train loss:0.15214326721283594\n",
      "train loss:0.09067400136883283\n",
      "train loss:0.11845427197295433\n",
      "train loss:0.07960215893782446\n",
      "train loss:0.1386814127058429\n",
      "train loss:0.14351412781956208\n",
      "train loss:0.1190321202595366\n",
      "train loss:0.10273694925837097\n",
      "train loss:0.20217687460537495\n",
      "train loss:0.17687653973757322\n",
      "train loss:0.11353848291851383\n",
      "train loss:0.11963140990806292\n",
      "train loss:0.15765876246240204\n",
      "train loss:0.21609074787310292\n",
      "train loss:0.22011653797901407\n",
      "train loss:0.07928046329348333\n",
      "train loss:0.08758726053274629\n",
      "train loss:0.12605265381149805\n",
      "train loss:0.17045175875942217\n",
      "train loss:0.08515230154192474\n",
      "train loss:0.20811932312240658\n",
      "train loss:0.08804395581153213\n",
      "train loss:0.23616594458299742\n",
      "train loss:0.11480588959625664\n",
      "train loss:0.13705901416112104\n",
      "train loss:0.05164482010946337\n",
      "train loss:0.10403098945064153\n",
      "train loss:0.17710111000726506\n",
      "train loss:0.24883466502582322\n",
      "train loss:0.18034532030528705\n",
      "train loss:0.16563211597429583\n",
      "train loss:0.2417659810556039\n",
      "train loss:0.2062880528420952\n",
      "train loss:0.11889120795044779\n",
      "train loss:0.06384318314076959\n",
      "train loss:0.07444023816161077\n",
      "train loss:0.32295789920382967\n",
      "train loss:0.21766072719471388\n",
      "train loss:0.1466806330722054\n",
      "train loss:0.18390603115898185\n",
      "train loss:0.07213564715462882\n",
      "train loss:0.127373930632669\n",
      "train loss:0.16727968281333436\n",
      "train loss:0.09540316437435291\n",
      "train loss:0.12907940945880006\n",
      "train loss:0.09105871916466718\n",
      "train loss:0.14842522204307454\n",
      "train loss:0.18479863027811685\n",
      "train loss:0.12529391445179172\n",
      "train loss:0.14221451920082676\n",
      "train loss:0.16938823529021999\n",
      "train loss:0.1357668086735926\n",
      "train loss:0.09349350101098544\n",
      "train loss:0.19281995062649646\n",
      "train loss:0.15086961116616573\n",
      "train loss:0.06415910443466041\n",
      "train loss:0.08800997648541413\n",
      "train loss:0.16143605808417114\n",
      "train loss:0.1244913454504663\n",
      "train loss:0.10793890839196787\n",
      "train loss:0.11863233055873643\n",
      "train loss:0.28539426700600934\n",
      "train loss:0.12898241003297561\n",
      "train loss:0.21830897596902205\n",
      "train loss:0.10690078991480259\n",
      "train loss:0.11594597023237992\n",
      "train loss:0.14669918924145095\n",
      "train loss:0.12470546432416343\n",
      "train loss:0.08924264520874381\n",
      "train loss:0.12701295619142383\n",
      "train loss:0.09861124317006738\n",
      "train loss:0.2368683971619842\n",
      "train loss:0.09359427101373743\n",
      "train loss:0.13332166038506488\n",
      "train loss:0.06141960756935897\n",
      "train loss:0.06693089853180165\n",
      "train loss:0.11364979132955749\n",
      "train loss:0.17880331226656365\n",
      "train loss:0.11135132067079972\n",
      "train loss:0.04894909550192474\n",
      "train loss:0.15996293232009848\n",
      "train loss:0.13119802000139727\n",
      "train loss:0.1188460257364484\n",
      "train loss:0.15992207424651628\n",
      "train loss:0.15121431125151147\n",
      "train loss:0.13228081113738166\n",
      "train loss:0.054844719381967805\n",
      "train loss:0.17568361057225576\n",
      "train loss:0.14744625852141216\n",
      "train loss:0.1899723674497244\n",
      "train loss:0.18460233063166823\n",
      "train loss:0.03850892870640366\n",
      "train loss:0.05719903544396605\n",
      "train loss:0.3242067913803418\n",
      "train loss:0.13223417956088288\n",
      "train loss:0.21183550995740166\n",
      "train loss:0.08552938016612265\n",
      "train loss:0.08305997240395463\n",
      "train loss:0.13979213085447298\n",
      "train loss:0.12305499661364182\n",
      "train loss:0.1933042046484155\n",
      "train loss:0.13043611869809582\n",
      "train loss:0.09500861346027731\n",
      "train loss:0.14916380871682836\n",
      "train loss:0.10770548130704133\n",
      "train loss:0.20505873074439787\n",
      "train loss:0.1274708853615025\n",
      "train loss:0.13548189161665533\n",
      "train loss:0.09546270154695456\n",
      "train loss:0.11686602282735459\n",
      "train loss:0.1329443728140509\n",
      "train loss:0.04670570411447775\n",
      "train loss:0.18088237355607728\n",
      "train loss:0.09694534314900594\n",
      "train loss:0.07588345373184542\n",
      "train loss:0.1301570969870577\n",
      "train loss:0.13365382854507366\n",
      "train loss:0.22462718676012774\n",
      "train loss:0.07686649666390574\n",
      "train loss:0.07254980898409218\n",
      "train loss:0.1342934999030391\n",
      "train loss:0.13957591395004865\n",
      "train loss:0.15151063920170724\n",
      "train loss:0.04109217785589764\n",
      "train loss:0.12092873905729899\n",
      "train loss:0.13844901699148918\n",
      "train loss:0.08794990750565888\n",
      "train loss:0.06892144733231924\n",
      "train loss:0.11484565858065952\n",
      "train loss:0.12642861112161904\n",
      "train loss:0.09558172516222056\n",
      "train loss:0.09606161557473236\n",
      "train loss:0.16378053502885817\n",
      "train loss:0.1286846321668909\n",
      "train loss:0.09728970342043933\n",
      "train loss:0.0914610105943304\n",
      "train loss:0.16146587192600217\n",
      "train loss:0.09429663745130061\n",
      "=== epoch:2, train acc:0.963, test acc:0.959 ===\n",
      "train loss:0.15463201403936325\n",
      "train loss:0.15974197703224172\n",
      "train loss:0.09144407563728238\n",
      "train loss:0.08992899632455316\n",
      "train loss:0.05556583168917004\n",
      "train loss:0.11085095639598092\n",
      "train loss:0.1731490454689441\n",
      "train loss:0.11098159950701865\n",
      "train loss:0.11359673890805168\n",
      "train loss:0.0765625557936611\n",
      "train loss:0.1384956018462741\n",
      "train loss:0.12534880401523615\n",
      "train loss:0.08117161973112073\n",
      "train loss:0.12158354541895187\n",
      "train loss:0.0853887455550259\n",
      "train loss:0.16606090969439743\n",
      "train loss:0.08996562843950454\n",
      "train loss:0.045327671286026903\n",
      "train loss:0.11163473465042552\n",
      "train loss:0.18849473004483386\n",
      "train loss:0.05371411085601116\n",
      "train loss:0.05336086582178793\n",
      "train loss:0.08338760470068873\n",
      "train loss:0.03498954952387923\n",
      "train loss:0.14949182304535483\n",
      "train loss:0.06173291761673446\n",
      "train loss:0.15244488247987928\n",
      "train loss:0.08667188795124123\n",
      "train loss:0.17264721153072163\n",
      "train loss:0.07521656493899284\n",
      "train loss:0.14994227948755878\n",
      "train loss:0.07701120176454433\n",
      "train loss:0.08479929603495334\n",
      "train loss:0.044333433840971145\n",
      "train loss:0.14502013177567666\n",
      "train loss:0.10068191975714419\n",
      "train loss:0.07336771295722734\n",
      "train loss:0.11247734485503477\n",
      "train loss:0.1278275677286715\n",
      "train loss:0.1002315465058036\n",
      "train loss:0.09606040970769722\n",
      "train loss:0.09870467276102923\n",
      "train loss:0.0740552909162341\n",
      "train loss:0.07287737527165866\n",
      "train loss:0.057554833267517376\n",
      "train loss:0.17683118408071508\n",
      "train loss:0.17159899805806517\n",
      "train loss:0.2114468719446418\n",
      "train loss:0.12561887521809076\n",
      "train loss:0.13374703791290946\n",
      "train loss:0.13352041617099542\n",
      "train loss:0.12042596881999802\n",
      "train loss:0.16232592916045996\n",
      "train loss:0.12097183057591698\n",
      "train loss:0.11481652188413832\n",
      "train loss:0.0798373757452127\n",
      "train loss:0.13149837463656414\n",
      "train loss:0.18474586305704768\n",
      "train loss:0.14680146979087613\n",
      "train loss:0.08708854788174653\n",
      "train loss:0.07700315868398516\n",
      "train loss:0.11475720889377165\n",
      "train loss:0.06105802102873606\n",
      "train loss:0.12606494188316175\n",
      "train loss:0.08385377564558393\n",
      "train loss:0.20281279052634027\n",
      "train loss:0.254862033130472\n",
      "train loss:0.06912365458988505\n",
      "train loss:0.06530345220849897\n",
      "train loss:0.10246607990650151\n",
      "train loss:0.19385228800895157\n",
      "train loss:0.05158664743700259\n",
      "train loss:0.09960402955619845\n",
      "train loss:0.04632950090952974\n",
      "train loss:0.11129175944005361\n",
      "train loss:0.11302913145172477\n",
      "train loss:0.12836543660959873\n",
      "train loss:0.22127877581210817\n",
      "train loss:0.03731716432502159\n",
      "train loss:0.13426118690604602\n",
      "train loss:0.04803586922808019\n",
      "train loss:0.060983350178179574\n",
      "train loss:0.09555009308301832\n",
      "train loss:0.08547651779930224\n",
      "train loss:0.05942074714747643\n",
      "train loss:0.13376475290388634\n",
      "train loss:0.0898161568280045\n",
      "train loss:0.053691855890719765\n",
      "train loss:0.1138050406356519\n",
      "train loss:0.11347806886834652\n",
      "train loss:0.15585181426496397\n",
      "train loss:0.12212673498274013\n",
      "train loss:0.10727043069747907\n",
      "train loss:0.09624558665017256\n",
      "train loss:0.04260894945426072\n",
      "train loss:0.11812501232740108\n",
      "train loss:0.2969171759017772\n",
      "train loss:0.04821040405844114\n",
      "train loss:0.11312756119176039\n",
      "train loss:0.11820207157794746\n",
      "train loss:0.08963685269449159\n",
      "train loss:0.0867068060468525\n",
      "train loss:0.0495415290997843\n",
      "train loss:0.17004173595590683\n",
      "train loss:0.14531293674032347\n",
      "train loss:0.11542515412386908\n",
      "train loss:0.080478317590024\n",
      "train loss:0.04001708764529877\n",
      "train loss:0.0646672335827544\n",
      "train loss:0.12106930712744976\n",
      "train loss:0.15032206863327244\n",
      "train loss:0.05809629566662089\n",
      "train loss:0.09140434735975578\n",
      "train loss:0.1322897251681709\n",
      "train loss:0.07086062517093308\n",
      "train loss:0.18039211784366735\n",
      "train loss:0.09130149724094812\n",
      "train loss:0.05060253958103268\n",
      "train loss:0.067634126864506\n",
      "train loss:0.17851404379399471\n",
      "train loss:0.04903244157276537\n",
      "train loss:0.16188846280377076\n",
      "train loss:0.13480902115539656\n",
      "train loss:0.09063354345963022\n",
      "train loss:0.07038459326042151\n",
      "train loss:0.08943722470868959\n",
      "train loss:0.07533152766610648\n",
      "train loss:0.14507934764453498\n",
      "train loss:0.07269509542606953\n",
      "train loss:0.12290844593768302\n",
      "train loss:0.09719521549502685\n",
      "train loss:0.14611226555605344\n",
      "train loss:0.11316480239487081\n",
      "train loss:0.13001889185198479\n",
      "train loss:0.05308307105360292\n",
      "train loss:0.07732259921097026\n",
      "train loss:0.07475521098652509\n",
      "train loss:0.052767315369035374\n",
      "train loss:0.055522651473406875\n",
      "train loss:0.05539386432514655\n",
      "train loss:0.1098921608210556\n",
      "train loss:0.07466414567522418\n",
      "train loss:0.056945743921721845\n",
      "train loss:0.06893084269496405\n",
      "train loss:0.0823619360531765\n",
      "train loss:0.09527745625360805\n",
      "train loss:0.0716774507982886\n",
      "train loss:0.07577705052921897\n",
      "train loss:0.03737945477034898\n",
      "train loss:0.10065008744221232\n",
      "train loss:0.09119919851222949\n",
      "train loss:0.0321712723578562\n",
      "train loss:0.06407224459116533\n",
      "train loss:0.09930556827217644\n",
      "train loss:0.22719969732914883\n",
      "train loss:0.0889164408793794\n",
      "train loss:0.08283332688616221\n",
      "train loss:0.03769358032785656\n",
      "train loss:0.044670455573511104\n",
      "train loss:0.08208689558709698\n",
      "train loss:0.07167993232228877\n",
      "train loss:0.14362488199349605\n",
      "train loss:0.03366248544474492\n",
      "train loss:0.062103420595347875\n",
      "train loss:0.08403661824597625\n",
      "train loss:0.05472870765108666\n",
      "train loss:0.05570060992966317\n",
      "train loss:0.06938384091473142\n",
      "train loss:0.05759820340766333\n",
      "train loss:0.03570392974130277\n",
      "train loss:0.0735296542871667\n",
      "train loss:0.07488949687170601\n",
      "train loss:0.13216767028072282\n",
      "train loss:0.05399535733881407\n",
      "train loss:0.05799645053829284\n",
      "train loss:0.05412451940908624\n",
      "train loss:0.0527793682615673\n",
      "train loss:0.11808777280769153\n",
      "train loss:0.11676567681986125\n",
      "train loss:0.09181959089672669\n",
      "train loss:0.17659858914617976\n",
      "train loss:0.10819024546193214\n",
      "train loss:0.04578112736414373\n",
      "train loss:0.11121037637386538\n",
      "train loss:0.05284733404539833\n",
      "train loss:0.08678241070014345\n",
      "train loss:0.09531605030832133\n",
      "train loss:0.06942555841065859\n",
      "train loss:0.08819672615946195\n",
      "train loss:0.06294948015631217\n",
      "train loss:0.14584801460094382\n",
      "train loss:0.06392160809220561\n",
      "train loss:0.033353560948454264\n",
      "train loss:0.109353608072849\n",
      "train loss:0.05861471625923799\n",
      "train loss:0.07656922155656702\n",
      "train loss:0.059492347076696574\n",
      "train loss:0.05655844191494475\n",
      "train loss:0.08475848580254584\n",
      "train loss:0.1196013403369757\n",
      "train loss:0.06966760870844994\n",
      "train loss:0.11329463222515156\n",
      "train loss:0.10514619549378136\n",
      "train loss:0.060484822248202716\n",
      "train loss:0.06894840900584215\n",
      "train loss:0.06087999655324088\n",
      "train loss:0.10228394253831649\n",
      "train loss:0.12828601007236684\n",
      "train loss:0.10668939203619067\n",
      "train loss:0.09732864483549429\n",
      "train loss:0.09360409915130725\n",
      "train loss:0.054769114721922606\n",
      "train loss:0.0946604755405494\n",
      "train loss:0.10432181382351294\n",
      "train loss:0.16770414459298458\n",
      "train loss:0.11911266897187892\n",
      "train loss:0.11607300793637115\n",
      "train loss:0.0735073152640182\n",
      "train loss:0.15877338304925556\n",
      "train loss:0.049343655757282515\n",
      "train loss:0.04887061167263213\n",
      "train loss:0.09927445863280633\n",
      "train loss:0.04571604225493728\n",
      "train loss:0.034056837271529326\n",
      "train loss:0.1743809819073957\n",
      "train loss:0.07846267424451313\n",
      "train loss:0.20646093605547777\n",
      "train loss:0.12073555955846882\n",
      "train loss:0.07586265726437538\n",
      "train loss:0.04717038815843553\n",
      "train loss:0.14640045811180386\n",
      "train loss:0.01807970866772651\n",
      "train loss:0.14061555133714745\n",
      "train loss:0.1230429294852306\n",
      "train loss:0.051434192283658774\n",
      "train loss:0.16618395958129653\n",
      "train loss:0.1327267197211232\n",
      "train loss:0.16777438567568523\n",
      "train loss:0.05837016667050318\n",
      "train loss:0.09603918633255809\n",
      "train loss:0.08482977493271149\n",
      "train loss:0.16565082441062223\n",
      "train loss:0.14119578683738493\n",
      "train loss:0.05156114079556396\n",
      "train loss:0.12945460524439686\n",
      "train loss:0.10251965166121568\n",
      "train loss:0.04033864800352061\n",
      "train loss:0.11749286929082255\n",
      "train loss:0.1735214806174798\n",
      "train loss:0.06364501082040788\n",
      "train loss:0.05327714149197879\n",
      "train loss:0.09776877058902325\n",
      "train loss:0.08359003257110753\n",
      "train loss:0.11412924258480034\n",
      "train loss:0.08574712562359683\n",
      "train loss:0.08458406668631731\n",
      "train loss:0.08156667920857805\n",
      "train loss:0.1838270769736999\n",
      "train loss:0.06042515293826563\n",
      "train loss:0.039791639739917936\n",
      "train loss:0.06191028174494439\n",
      "train loss:0.0527780590637161\n",
      "train loss:0.13897022812039292\n",
      "train loss:0.05810157970288096\n",
      "train loss:0.10563832783108992\n",
      "train loss:0.06196688910052289\n",
      "train loss:0.11743110920954497\n",
      "train loss:0.02699863793488806\n",
      "train loss:0.19937943492157892\n",
      "train loss:0.11456068398288764\n",
      "train loss:0.05498559261519613\n",
      "train loss:0.1847778406737137\n",
      "train loss:0.08610579070522043\n",
      "train loss:0.12169590933527226\n",
      "train loss:0.21788364877348795\n",
      "train loss:0.023808164770252674\n",
      "train loss:0.04591276130917946\n",
      "train loss:0.09554611254689953\n",
      "train loss:0.14350388245863466\n",
      "train loss:0.10300401183426743\n",
      "train loss:0.10494024091378053\n",
      "train loss:0.04605784640318315\n",
      "train loss:0.03839476949400664\n",
      "train loss:0.17279468264962983\n",
      "train loss:0.05653927104473219\n",
      "train loss:0.05882832904353684\n",
      "train loss:0.0858226741870099\n",
      "train loss:0.06542851189602715\n",
      "train loss:0.10151249397793674\n",
      "train loss:0.061880281840598295\n",
      "train loss:0.06227869282889855\n",
      "train loss:0.10160837049846298\n",
      "train loss:0.029135484036338283\n",
      "train loss:0.055460270883307274\n",
      "train loss:0.11594577896324951\n",
      "train loss:0.11496619403070746\n",
      "train loss:0.10419200188528936\n",
      "train loss:0.08532962529523141\n",
      "train loss:0.10686226985904523\n",
      "train loss:0.06028091726062037\n",
      "train loss:0.08956813121017998\n",
      "train loss:0.08580330129640917\n",
      "train loss:0.07551897531808587\n",
      "train loss:0.03935457815722793\n",
      "train loss:0.05136191347124809\n",
      "train loss:0.16977899384735098\n",
      "train loss:0.040405295936019145\n",
      "train loss:0.03420409384487694\n",
      "train loss:0.07238268968166761\n",
      "train loss:0.06992721682356018\n",
      "train loss:0.05284269939723134\n",
      "train loss:0.13427692758823992\n",
      "train loss:0.04984125328935574\n",
      "train loss:0.09485809555822103\n",
      "train loss:0.19111093876936958\n",
      "train loss:0.051479715658137415\n",
      "train loss:0.09614015125083569\n",
      "train loss:0.03642371787560885\n",
      "train loss:0.06076801469763243\n",
      "train loss:0.11129030377657083\n",
      "train loss:0.08555562649020969\n",
      "train loss:0.11130037065496336\n",
      "train loss:0.13283902888179655\n",
      "train loss:0.08915622453087137\n",
      "train loss:0.03773412997000546\n",
      "train loss:0.06596181443266558\n",
      "train loss:0.046674894941634584\n",
      "train loss:0.11891302735688919\n",
      "train loss:0.06452583410833795\n",
      "train loss:0.09919477892264406\n",
      "train loss:0.07838168252321678\n",
      "train loss:0.1585680677796394\n",
      "train loss:0.04739149056690467\n",
      "train loss:0.07397393105555765\n",
      "train loss:0.05157637825799328\n",
      "train loss:0.10200228190942046\n",
      "train loss:0.09858810331998434\n",
      "train loss:0.043716790089183416\n",
      "train loss:0.05072765072757693\n",
      "train loss:0.09103533991336624\n",
      "train loss:0.057565261628806194\n",
      "train loss:0.14426362772951337\n",
      "train loss:0.08127834334913073\n",
      "train loss:0.06511168834635148\n",
      "train loss:0.07594386117245917\n",
      "train loss:0.05408971318832791\n",
      "train loss:0.14843662111973013\n",
      "train loss:0.16008430675648644\n",
      "train loss:0.08477340444421971\n",
      "train loss:0.03141303652600899\n",
      "train loss:0.05192488843655003\n",
      "train loss:0.07417425669839353\n",
      "train loss:0.06928137567822616\n",
      "train loss:0.10093646438724592\n",
      "train loss:0.09475904527406566\n",
      "train loss:0.0795484825256797\n",
      "train loss:0.08438918778143922\n",
      "train loss:0.14827275244220736\n",
      "train loss:0.06650359645624965\n",
      "train loss:0.09369744578689858\n",
      "train loss:0.07784776129824363\n",
      "train loss:0.025625268676127008\n",
      "train loss:0.10033949786477452\n",
      "train loss:0.031692025305623595\n",
      "train loss:0.05302506736088916\n",
      "train loss:0.12027286087063738\n",
      "train loss:0.05473902395751632\n",
      "train loss:0.14093847698479636\n",
      "train loss:0.038855130401244324\n",
      "train loss:0.08670479584941869\n",
      "train loss:0.09479407687420797\n",
      "train loss:0.058983860427799614\n",
      "train loss:0.0905137948280374\n",
      "train loss:0.07623619817806783\n",
      "train loss:0.03708796871472639\n",
      "train loss:0.08833032758646071\n",
      "train loss:0.044139113430729474\n",
      "train loss:0.10890978408005812\n",
      "train loss:0.047794340147654685\n",
      "train loss:0.06198656519314644\n",
      "train loss:0.06596138286892539\n",
      "train loss:0.14692483042878587\n",
      "train loss:0.10684723906724\n",
      "train loss:0.03659469168773897\n",
      "train loss:0.0922108733792082\n",
      "train loss:0.12373207327742909\n",
      "train loss:0.07351759528728491\n",
      "train loss:0.0487233595074644\n",
      "train loss:0.03287548353032164\n",
      "train loss:0.0605585774576893\n",
      "train loss:0.11637996287009987\n",
      "train loss:0.0934884372901773\n",
      "train loss:0.02856816042509374\n",
      "train loss:0.04533598093911031\n",
      "train loss:0.09072418863664622\n",
      "train loss:0.038000165040614084\n",
      "train loss:0.03845572424435012\n",
      "train loss:0.04908431287229824\n",
      "train loss:0.05439438799010925\n",
      "train loss:0.05754372759264117\n",
      "train loss:0.05827017941398209\n",
      "train loss:0.08015214814558418\n",
      "train loss:0.1010054845703231\n",
      "train loss:0.08897196753995446\n",
      "train loss:0.12488382000396715\n",
      "train loss:0.09513896195792043\n",
      "train loss:0.015910640155814525\n",
      "train loss:0.025057402250854247\n",
      "train loss:0.06415900845385183\n",
      "train loss:0.030632508078131258\n",
      "train loss:0.021382156623913448\n",
      "train loss:0.07075462478993534\n",
      "train loss:0.10951231631996101\n",
      "train loss:0.049051555836248574\n",
      "train loss:0.0609759005474372\n",
      "train loss:0.020181134572429336\n",
      "train loss:0.13667043532418538\n",
      "train loss:0.07664079429213742\n",
      "train loss:0.03202725402206191\n",
      "train loss:0.015525968100751394\n",
      "train loss:0.025993991005692316\n",
      "train loss:0.08240642448621935\n",
      "train loss:0.04142424570703815\n",
      "train loss:0.02849327542669632\n",
      "train loss:0.052677421275928206\n",
      "train loss:0.07572240610140557\n",
      "train loss:0.09711027148251451\n",
      "train loss:0.06952284759299916\n",
      "train loss:0.053145949699113376\n",
      "train loss:0.10394551638614581\n",
      "train loss:0.08046898170748493\n",
      "train loss:0.03129162785285764\n",
      "train loss:0.07438960034517607\n",
      "train loss:0.21673424279186537\n",
      "train loss:0.055386383140589315\n",
      "train loss:0.1666128004455019\n",
      "train loss:0.1087317569577787\n",
      "train loss:0.038805311085899914\n",
      "train loss:0.10648399637399439\n",
      "train loss:0.03335786620929315\n",
      "train loss:0.03084419636725398\n",
      "train loss:0.04270125431729511\n",
      "train loss:0.07623988199813661\n",
      "train loss:0.05516420466573635\n",
      "train loss:0.10998738589108507\n",
      "train loss:0.05025775380292979\n",
      "train loss:0.06652656223460665\n",
      "train loss:0.04708000378308477\n",
      "train loss:0.05104911776214\n",
      "train loss:0.09532857300606512\n",
      "train loss:0.06929037905395916\n",
      "train loss:0.035211994545766054\n",
      "train loss:0.07219943088220608\n",
      "train loss:0.0993839202435056\n",
      "train loss:0.04249158968467046\n",
      "train loss:0.04818724658796064\n",
      "train loss:0.05997564014476007\n",
      "train loss:0.0692951897287828\n",
      "train loss:0.018105310386321107\n",
      "train loss:0.07636406883734072\n",
      "train loss:0.062436425777899575\n",
      "train loss:0.03698917232350216\n",
      "train loss:0.076843268391152\n",
      "train loss:0.01607003806489358\n",
      "train loss:0.17688289571695578\n",
      "train loss:0.017224134434536048\n",
      "train loss:0.02793498518683078\n",
      "train loss:0.09580750017627379\n",
      "train loss:0.030210886993697988\n",
      "train loss:0.137347432346752\n",
      "train loss:0.10684980945160506\n",
      "train loss:0.029627146510105246\n",
      "train loss:0.04198437741669285\n",
      "train loss:0.19761516852704658\n",
      "train loss:0.03336021828239752\n",
      "train loss:0.15460734705803256\n",
      "train loss:0.0272780684817088\n",
      "train loss:0.20276699615576585\n",
      "train loss:0.07042414424726404\n",
      "train loss:0.03744947029549648\n",
      "train loss:0.07765569844506881\n",
      "train loss:0.04720203700836274\n",
      "train loss:0.09948243747858351\n",
      "train loss:0.08877341433253902\n",
      "train loss:0.07634236981613715\n",
      "train loss:0.06880429802718975\n",
      "train loss:0.0601491760553399\n",
      "train loss:0.09067734691282102\n",
      "train loss:0.12481970514309944\n",
      "train loss:0.09127050726781341\n",
      "train loss:0.16123605888168896\n",
      "train loss:0.05271942396010959\n",
      "train loss:0.09333304164953848\n",
      "train loss:0.08302270765593628\n",
      "train loss:0.05636319064134195\n",
      "train loss:0.10983459016779967\n",
      "train loss:0.10775934416337982\n",
      "train loss:0.12788607272427824\n",
      "train loss:0.0393555403773612\n",
      "train loss:0.03562409742259613\n",
      "train loss:0.06208293091665567\n",
      "train loss:0.046401744097026576\n",
      "train loss:0.21137015634562584\n",
      "train loss:0.033928913235471585\n",
      "train loss:0.04713822933927411\n",
      "train loss:0.018157585976173767\n",
      "train loss:0.08837877512580002\n",
      "train loss:0.07800611490093144\n",
      "train loss:0.07761743666677672\n",
      "train loss:0.052938348541917674\n",
      "train loss:0.027234512432472366\n",
      "train loss:0.11446996753747396\n",
      "train loss:0.0610303481419914\n",
      "train loss:0.04271097169587049\n",
      "train loss:0.03535782231985527\n",
      "train loss:0.049784685856077114\n",
      "train loss:0.05760641786283561\n",
      "train loss:0.08954236829817189\n",
      "train loss:0.11750711839924087\n",
      "train loss:0.05423752827720738\n",
      "train loss:0.06689099661889325\n",
      "train loss:0.037324814548200184\n",
      "train loss:0.07598285075296315\n",
      "train loss:0.05268349436370383\n",
      "train loss:0.02594478934371664\n",
      "train loss:0.08757837695115532\n",
      "train loss:0.06678551879284708\n",
      "train loss:0.02932869440891044\n",
      "train loss:0.07894575513879154\n",
      "train loss:0.028574136797471637\n",
      "train loss:0.08250560224479252\n",
      "train loss:0.11544735177227482\n",
      "train loss:0.03833671149774391\n",
      "train loss:0.06805757301180072\n",
      "train loss:0.11121816028060309\n",
      "train loss:0.0391701534164884\n",
      "train loss:0.07568833819992847\n",
      "train loss:0.10111032316033476\n",
      "train loss:0.04775621376373973\n",
      "train loss:0.044027259783746844\n",
      "train loss:0.02524499683936814\n",
      "train loss:0.10366622820314285\n",
      "train loss:0.07365563623269206\n",
      "train loss:0.09349976860052961\n",
      "train loss:0.0427200544132537\n",
      "train loss:0.10453339095143831\n",
      "train loss:0.07651248086195869\n",
      "train loss:0.04786576691444127\n",
      "train loss:0.03140822514826761\n",
      "train loss:0.09546723844775502\n",
      "train loss:0.05612905386186256\n",
      "train loss:0.04182036585354882\n",
      "train loss:0.09507066548074895\n",
      "train loss:0.04381384186869894\n",
      "train loss:0.04583691112344081\n",
      "train loss:0.04752216409333712\n",
      "train loss:0.0797140009615735\n",
      "train loss:0.05878642237829225\n",
      "train loss:0.0644604312421713\n",
      "train loss:0.056489923365598785\n",
      "train loss:0.1282934830206886\n",
      "train loss:0.048933874424780054\n",
      "train loss:0.02589989321135942\n",
      "train loss:0.05649218633413193\n",
      "train loss:0.12614951410159683\n",
      "train loss:0.04826885174018145\n",
      "train loss:0.14504539691177226\n",
      "train loss:0.08602692148094108\n",
      "train loss:0.03389418694185767\n",
      "train loss:0.03815435157951772\n",
      "train loss:0.0395327815649093\n",
      "train loss:0.08668172706525129\n",
      "train loss:0.03083866014725917\n",
      "train loss:0.015433004033305265\n",
      "train loss:0.05638959806854868\n",
      "train loss:0.048295466435589275\n",
      "train loss:0.0444841454037582\n",
      "train loss:0.08129726693223419\n",
      "train loss:0.07068832179745678\n",
      "train loss:0.026095204617235752\n",
      "train loss:0.04887114881374324\n",
      "train loss:0.11230047888684103\n",
      "train loss:0.019256174419999942\n",
      "train loss:0.08463181402679971\n",
      "train loss:0.020124660161643465\n",
      "train loss:0.012219578434137119\n",
      "train loss:0.022950167645655356\n",
      "train loss:0.0703799928616401\n",
      "train loss:0.07144692663851179\n",
      "train loss:0.09775621142952769\n",
      "train loss:0.03198276783616261\n",
      "train loss:0.07651167344661665\n",
      "train loss:0.05583241124737831\n",
      "train loss:0.07115238215658755\n",
      "train loss:0.09115967897060345\n",
      "train loss:0.08622673711252085\n",
      "train loss:0.05047197789972275\n",
      "train loss:0.14767346879451518\n",
      "train loss:0.08157332269541609\n",
      "train loss:0.03334031292986958\n",
      "=== epoch:3, train acc:0.974, test acc:0.97 ===\n",
      "train loss:0.10975248869839144\n",
      "train loss:0.06412067638791559\n",
      "train loss:0.13001129833205224\n",
      "train loss:0.0432158971464926\n",
      "train loss:0.06453230847832349\n",
      "train loss:0.054357133818450046\n",
      "train loss:0.059282547311237915\n",
      "train loss:0.04247814207920777\n",
      "train loss:0.02675999545614406\n",
      "train loss:0.014799383567417423\n",
      "train loss:0.05998363948930813\n",
      "train loss:0.017336342135213016\n",
      "train loss:0.020741950772879294\n",
      "train loss:0.07525614509341491\n",
      "train loss:0.04116672935910153\n",
      "train loss:0.05778187101588678\n",
      "train loss:0.03369194435765723\n",
      "train loss:0.023142361775764363\n",
      "train loss:0.028780982011329392\n",
      "train loss:0.025638918290998083\n",
      "train loss:0.09027232934724577\n",
      "train loss:0.1077808719294509\n",
      "train loss:0.03616950985614551\n",
      "train loss:0.01591127345307042\n",
      "train loss:0.05262531607706177\n",
      "train loss:0.08091115860304601\n",
      "train loss:0.021909138306745922\n",
      "train loss:0.1008145097504714\n",
      "train loss:0.04658526612174686\n",
      "train loss:0.06782717872317756\n",
      "train loss:0.08012822774806833\n",
      "train loss:0.047708495224364746\n",
      "train loss:0.04570507501577912\n",
      "train loss:0.10897580720925357\n",
      "train loss:0.05493402589638607\n",
      "train loss:0.11067352361832654\n",
      "train loss:0.025321848533779168\n",
      "train loss:0.06377843304752606\n",
      "train loss:0.015290247825720683\n",
      "train loss:0.037310720746568035\n",
      "train loss:0.02514495260084023\n",
      "train loss:0.03273028850735229\n",
      "train loss:0.037062241454170516\n",
      "train loss:0.014108109928215797\n",
      "train loss:0.055616175511066096\n",
      "train loss:0.09122378829900449\n",
      "train loss:0.026237976714874753\n",
      "train loss:0.01772630240405849\n",
      "train loss:0.10951014824797463\n",
      "train loss:0.03774033034139845\n",
      "train loss:0.03782390533106907\n",
      "train loss:0.027285378151868277\n",
      "train loss:0.06731356723397465\n",
      "train loss:0.012356104104606979\n",
      "train loss:0.03148791645485724\n",
      "train loss:0.1402118077758253\n",
      "train loss:0.029006241852667185\n",
      "train loss:0.03151220686033766\n",
      "train loss:0.045593352970913215\n",
      "train loss:0.04596842501990156\n",
      "train loss:0.04088784800109521\n",
      "train loss:0.054031740214373514\n",
      "train loss:0.06859371240602191\n",
      "train loss:0.12598194475481966\n",
      "train loss:0.11063759232801271\n",
      "train loss:0.06614084695421835\n",
      "train loss:0.04316463879077335\n",
      "train loss:0.05945125078062649\n",
      "train loss:0.022434943715039273\n",
      "train loss:0.030370412163421477\n",
      "train loss:0.07070872645534296\n",
      "train loss:0.04963125547259633\n",
      "train loss:0.057091746224699084\n",
      "train loss:0.08918538998081178\n",
      "train loss:0.10575305185622298\n",
      "train loss:0.031183340424558777\n",
      "train loss:0.08598592854051773\n",
      "train loss:0.0996635947902111\n",
      "train loss:0.07782911477677668\n",
      "train loss:0.1015889355493335\n",
      "train loss:0.11741228319878387\n",
      "train loss:0.07773518633964825\n",
      "train loss:0.04262502003273732\n",
      "train loss:0.05225676049128904\n",
      "train loss:0.01064266062341478\n",
      "train loss:0.07964590660683837\n",
      "train loss:0.07420210194252624\n",
      "train loss:0.09988077478441644\n",
      "train loss:0.05449326531601692\n",
      "train loss:0.035697284549615946\n",
      "train loss:0.06973169470438123\n",
      "train loss:0.054002727032866266\n",
      "train loss:0.0312893989595234\n",
      "train loss:0.06470643491358558\n",
      "train loss:0.09291296554724361\n",
      "train loss:0.10617646761411743\n",
      "train loss:0.020100496977364987\n",
      "train loss:0.13214117493899313\n",
      "train loss:0.13785714930150594\n",
      "train loss:0.06999637113231148\n",
      "train loss:0.04051924469545039\n",
      "train loss:0.09629738800489043\n",
      "train loss:0.10114718762982361\n",
      "train loss:0.0827045825156321\n",
      "train loss:0.026001644597251832\n",
      "train loss:0.04372598254590044\n",
      "train loss:0.0332054033563772\n",
      "train loss:0.06866944624436434\n",
      "train loss:0.020890706983098802\n",
      "train loss:0.06615300821495175\n",
      "train loss:0.058945036332005325\n",
      "train loss:0.02737031174116222\n",
      "train loss:0.16156441044938977\n",
      "train loss:0.04266295390073684\n",
      "train loss:0.12692943810601917\n",
      "train loss:0.12565255192860925\n",
      "train loss:0.08666023982535492\n",
      "train loss:0.09399230200058295\n",
      "train loss:0.03816386595789965\n",
      "train loss:0.05139872169044656\n",
      "train loss:0.0381484455957079\n",
      "train loss:0.05326770002076594\n",
      "train loss:0.0690874357571335\n",
      "train loss:0.0711393360006904\n",
      "train loss:0.10004398575319157\n",
      "train loss:0.01736804178207\n",
      "train loss:0.09066139273193129\n",
      "train loss:0.03445278404793201\n",
      "train loss:0.041738813083653306\n",
      "train loss:0.025700115083790595\n",
      "train loss:0.06256751656608887\n",
      "train loss:0.07836392224216765\n",
      "train loss:0.07032874772615082\n",
      "train loss:0.03705235660984114\n",
      "train loss:0.10261805954024357\n",
      "train loss:0.08300399963435158\n",
      "train loss:0.07917013032593759\n",
      "train loss:0.04135608846815231\n",
      "train loss:0.04747809057883817\n",
      "train loss:0.038934018948217144\n",
      "train loss:0.011340245304938674\n",
      "train loss:0.03841152661098531\n",
      "train loss:0.025313367340172373\n",
      "train loss:0.12406996096923603\n",
      "train loss:0.031583652318049917\n",
      "train loss:0.013475979430002599\n",
      "train loss:0.028245548055961082\n",
      "train loss:0.033725391060945346\n",
      "train loss:0.058867451519166655\n",
      "train loss:0.0346073173440458\n",
      "train loss:0.032001123293393594\n",
      "train loss:0.020778163105114423\n",
      "train loss:0.024262631930347965\n",
      "train loss:0.044663001085704895\n",
      "train loss:0.10417530451831328\n",
      "train loss:0.05973607839441909\n",
      "train loss:0.029442047348973602\n",
      "train loss:0.22156157083138653\n",
      "train loss:0.0229698445931544\n",
      "train loss:0.039938570206018875\n",
      "train loss:0.037568876400239815\n",
      "train loss:0.04713854888154295\n",
      "train loss:0.046037629182167944\n",
      "train loss:0.05281221381065999\n",
      "train loss:0.15386604481845834\n",
      "train loss:0.03758412047135937\n",
      "train loss:0.06378799711244322\n",
      "train loss:0.03246750237897928\n",
      "train loss:0.09285342410383628\n",
      "train loss:0.03709263288748868\n",
      "train loss:0.07862864774412266\n",
      "train loss:0.04924609191623367\n",
      "train loss:0.070972266840364\n",
      "train loss:0.17172360796569386\n",
      "train loss:0.058470801864336265\n",
      "train loss:0.0872678893382313\n",
      "train loss:0.05200002828500864\n",
      "train loss:0.041001733673533526\n",
      "train loss:0.03596916605144721\n",
      "train loss:0.0138342520295116\n",
      "train loss:0.05651820467167111\n",
      "train loss:0.1161140443406175\n",
      "train loss:0.11093027815961685\n",
      "train loss:0.060701093455155626\n",
      "train loss:0.04352977009738319\n",
      "train loss:0.029687291612496326\n",
      "train loss:0.05482259015543245\n",
      "train loss:0.10759430032998724\n",
      "train loss:0.026750747471682223\n",
      "train loss:0.08939475171317915\n",
      "train loss:0.03124963819796207\n",
      "train loss:0.03859751429178526\n",
      "train loss:0.02970754911073092\n",
      "train loss:0.051340027490207794\n",
      "train loss:0.0510294315267141\n",
      "train loss:0.06536306201299466\n",
      "train loss:0.0893205672095535\n",
      "train loss:0.037650678242299826\n",
      "train loss:0.07778282904636834\n",
      "train loss:0.039791393429453474\n",
      "train loss:0.03858564755342087\n",
      "train loss:0.10349416071817379\n",
      "train loss:0.013691399331203143\n",
      "train loss:0.013926926906166464\n",
      "train loss:0.017317902677219787\n",
      "train loss:0.10766965805285553\n",
      "train loss:0.07963582073897946\n",
      "train loss:0.04468258076098405\n",
      "train loss:0.07696687640652523\n",
      "train loss:0.054925005658054894\n",
      "train loss:0.02364526732025545\n",
      "train loss:0.03615298950185599\n",
      "train loss:0.033164446596099496\n",
      "train loss:0.0613250792533899\n",
      "train loss:0.048980462178338756\n",
      "train loss:0.08457064269548475\n",
      "train loss:0.03699004659079142\n",
      "train loss:0.015402435438052284\n",
      "train loss:0.027041285491021815\n",
      "train loss:0.04443865626752009\n",
      "train loss:0.12616837303967743\n",
      "train loss:0.05058410870814708\n",
      "train loss:0.1461322529708595\n",
      "train loss:0.07619452565929692\n",
      "train loss:0.045141227192609774\n",
      "train loss:0.014414437942891186\n",
      "train loss:0.016410716931870507\n",
      "train loss:0.04058000478557006\n",
      "train loss:0.04479201233987164\n",
      "train loss:0.045822282588252355\n",
      "train loss:0.06916540170255046\n",
      "train loss:0.06915069333363844\n",
      "train loss:0.016232695900167408\n",
      "train loss:0.029607981856533207\n",
      "train loss:0.042808809156098804\n",
      "train loss:0.03004236178062518\n",
      "train loss:0.21336759949330006\n",
      "train loss:0.05925894215373189\n",
      "train loss:0.05498621061820033\n",
      "train loss:0.046566956248375736\n",
      "train loss:0.0666037319275579\n",
      "train loss:0.09395682859668261\n",
      "train loss:0.05200838742788072\n",
      "train loss:0.08865449465961044\n",
      "train loss:0.06874987657346442\n",
      "train loss:0.03104739379072126\n",
      "train loss:0.046635073575083015\n",
      "train loss:0.0521219130418043\n",
      "train loss:0.05022097048668556\n",
      "train loss:0.05275477820459901\n",
      "train loss:0.09544473719783797\n",
      "train loss:0.08536062015859874\n",
      "train loss:0.07965364941090854\n",
      "train loss:0.04968545994080551\n",
      "train loss:0.1167750200843356\n",
      "train loss:0.07758794292357282\n",
      "train loss:0.03514278569129088\n",
      "train loss:0.030954388770872417\n",
      "train loss:0.07038706319077494\n",
      "train loss:0.03207831556560246\n",
      "train loss:0.023718749341355122\n",
      "train loss:0.06902132620694533\n",
      "train loss:0.04241227363654001\n",
      "train loss:0.031495778567932384\n",
      "train loss:0.01460997565873258\n",
      "train loss:0.027576748231248355\n",
      "train loss:0.1325992533749805\n",
      "train loss:0.04743434622031908\n",
      "train loss:0.1289891127306868\n",
      "train loss:0.01734236748000819\n",
      "train loss:0.05012319212569402\n",
      "train loss:0.061283263902455774\n",
      "train loss:0.10055118490167697\n",
      "train loss:0.1252598927599669\n",
      "train loss:0.08208592399998216\n",
      "train loss:0.04294138172833369\n",
      "train loss:0.05712202503201264\n",
      "train loss:0.08006721331154244\n",
      "train loss:0.040344416248985576\n",
      "train loss:0.03903345210012412\n",
      "train loss:0.04022782756334554\n",
      "train loss:0.07015233852803815\n",
      "train loss:0.0532025920706059\n",
      "train loss:0.17030846804552374\n",
      "train loss:0.058860687278307545\n",
      "train loss:0.06132203379079362\n",
      "train loss:0.034969952033470426\n",
      "train loss:0.03633751381094249\n",
      "train loss:0.03377978381632809\n",
      "train loss:0.0480006082599023\n",
      "train loss:0.07101532984402337\n",
      "train loss:0.05566195162129589\n",
      "train loss:0.04339793148418156\n",
      "train loss:0.07384534093032291\n",
      "train loss:0.0620374839124135\n",
      "train loss:0.04514846694308426\n",
      "train loss:0.07440423706950913\n",
      "train loss:0.01632966197672006\n",
      "train loss:0.046515472713823704\n",
      "train loss:0.05558576301339392\n",
      "train loss:0.023314016396876074\n",
      "train loss:0.0291676211330366\n",
      "train loss:0.06643131237414109\n",
      "train loss:0.03811940358719227\n",
      "train loss:0.04232224874381542\n",
      "train loss:0.031176234598286934\n",
      "train loss:0.020574718220760003\n",
      "train loss:0.012971762932806488\n",
      "train loss:0.06804409608508993\n",
      "train loss:0.06334208609841786\n",
      "train loss:0.019416700136270358\n",
      "train loss:0.12713086459092998\n",
      "train loss:0.039295794477781955\n",
      "train loss:0.05936587323825954\n",
      "train loss:0.07976397779798643\n",
      "train loss:0.10639482271439371\n",
      "train loss:0.010750682231829995\n",
      "train loss:0.08394868389605216\n",
      "train loss:0.05072946880043465\n",
      "train loss:0.040308136564468654\n",
      "train loss:0.031007614639571527\n",
      "train loss:0.047245711141301126\n",
      "train loss:0.012981527672079963\n",
      "train loss:0.026426281292741747\n",
      "train loss:0.04003113394543517\n",
      "train loss:0.026151568814215643\n",
      "train loss:0.05401012169965716\n",
      "train loss:0.05063186097250604\n",
      "train loss:0.044332841081824566\n",
      "train loss:0.05549381564855259\n",
      "train loss:0.017610454031323566\n",
      "train loss:0.02758897108565547\n",
      "train loss:0.03825974060646933\n",
      "train loss:0.02370226455617484\n",
      "train loss:0.06389286319253581\n",
      "train loss:0.05008065489408982\n",
      "train loss:0.05843202329488409\n",
      "train loss:0.06522983185955292\n",
      "train loss:0.056931518663744775\n",
      "train loss:0.023933229047516907\n",
      "train loss:0.05444852601386099\n",
      "train loss:0.05037832231168255\n",
      "train loss:0.08349532132797555\n",
      "train loss:0.07183618204952304\n",
      "train loss:0.10481754086334917\n",
      "train loss:0.056658489171539414\n",
      "train loss:0.03812765930769811\n",
      "train loss:0.06980220489161901\n",
      "train loss:0.04316848683721752\n",
      "train loss:0.03900972452306138\n",
      "train loss:0.059299035634453254\n",
      "train loss:0.03589093665774177\n",
      "train loss:0.0936136591011009\n",
      "train loss:0.02535910005960333\n",
      "train loss:0.13055279812868065\n",
      "train loss:0.018556279611964533\n",
      "train loss:0.051246197104719\n",
      "train loss:0.01163497095690226\n",
      "train loss:0.030265869643271853\n",
      "train loss:0.0583665041424071\n",
      "train loss:0.14289746253556473\n",
      "train loss:0.0651265144559247\n",
      "train loss:0.11017965941860716\n",
      "train loss:0.02127261351696\n",
      "train loss:0.013394160738868385\n",
      "train loss:0.015463555979145425\n",
      "train loss:0.044069803773008925\n",
      "train loss:0.04640171290565979\n",
      "train loss:0.06173530417294662\n",
      "train loss:0.027038564158970102\n",
      "train loss:0.029983733326094223\n",
      "train loss:0.0245379625659026\n",
      "train loss:0.10717817267563921\n",
      "train loss:0.02704978201718143\n",
      "train loss:0.02114367828709586\n",
      "train loss:0.021277631458787253\n",
      "train loss:0.02997534686690993\n",
      "train loss:0.062270747226436024\n",
      "train loss:0.06376651851665849\n",
      "train loss:0.02301443981278768\n",
      "train loss:0.018297020441570937\n",
      "train loss:0.08379567969208318\n",
      "train loss:0.05362294614110251\n",
      "train loss:0.06412610923232683\n",
      "train loss:0.06056415688441767\n",
      "train loss:0.08730460019194779\n",
      "train loss:0.046385150453819565\n",
      "train loss:0.029259592579294117\n",
      "train loss:0.03733660342856206\n",
      "train loss:0.029475943779303494\n",
      "train loss:0.06442057342601722\n",
      "train loss:0.04015903313671906\n",
      "train loss:0.0757334519571427\n",
      "train loss:0.06293939923144727\n",
      "train loss:0.04943089710996448\n",
      "train loss:0.08284342454869732\n",
      "train loss:0.042935368567392336\n",
      "train loss:0.015992780822995115\n",
      "train loss:0.02045004618721344\n",
      "train loss:0.0336375488837866\n",
      "train loss:0.025687681278770687\n",
      "train loss:0.07271861586326589\n",
      "train loss:0.02400270010432602\n",
      "train loss:0.013380451342274653\n",
      "train loss:0.07677719808384166\n",
      "train loss:0.013728841130757405\n",
      "train loss:0.09714834964910275\n",
      "train loss:0.04771898692480314\n",
      "train loss:0.010458725030210003\n",
      "train loss:0.04415912251864574\n",
      "train loss:0.06055981607671096\n",
      "train loss:0.11414122584530861\n",
      "train loss:0.007850821703304686\n",
      "train loss:0.0174318558071867\n",
      "train loss:0.023504263134204992\n",
      "train loss:0.055456035471890396\n",
      "train loss:0.048730240522130826\n",
      "train loss:0.07106126901838562\n",
      "train loss:0.02543337869804764\n",
      "train loss:0.06514279189248483\n",
      "train loss:0.06917508660054833\n",
      "train loss:0.08924183745109301\n",
      "train loss:0.01699308654145885\n",
      "train loss:0.038701274026708934\n",
      "train loss:0.03151289702135753\n",
      "train loss:0.005427211051482702\n",
      "train loss:0.03376112763718861\n",
      "train loss:0.04436378089247413\n",
      "train loss:0.027530887893928945\n",
      "train loss:0.0712936088127761\n",
      "train loss:0.05111049890824291\n",
      "train loss:0.0246851220651288\n",
      "train loss:0.01613446881249672\n",
      "train loss:0.1165935257957656\n",
      "train loss:0.055654059904060735\n",
      "train loss:0.05663096787845465\n",
      "train loss:0.054810226743082585\n",
      "train loss:0.042498498366750355\n",
      "train loss:0.01114927872919484\n",
      "train loss:0.01990334620481159\n",
      "train loss:0.035573688710866275\n",
      "train loss:0.008012653664935495\n",
      "train loss:0.07047280804592723\n",
      "train loss:0.017529026301584406\n",
      "train loss:0.016328630676433142\n",
      "train loss:0.04361754435695811\n",
      "train loss:0.018676799901614714\n",
      "train loss:0.08317167174617147\n",
      "train loss:0.09047000818421058\n",
      "train loss:0.03699249323924303\n",
      "train loss:0.039873983591613794\n",
      "train loss:0.009186390728620233\n",
      "train loss:0.031773109615419806\n",
      "train loss:0.029262462006551818\n",
      "train loss:0.11744904197076889\n",
      "train loss:0.023611212987352206\n",
      "train loss:0.13355849413060086\n",
      "train loss:0.05280014459807899\n",
      "train loss:0.02310567246446216\n",
      "train loss:0.1472617414399824\n",
      "train loss:0.07396254283167417\n",
      "train loss:0.03501510226344148\n",
      "train loss:0.020112801299183834\n",
      "train loss:0.06968034217528192\n",
      "train loss:0.1497321221332962\n",
      "train loss:0.02498561933684242\n",
      "train loss:0.03947177524004161\n",
      "train loss:0.17398079619210985\n",
      "train loss:0.1286879373866481\n",
      "train loss:0.01767080904203132\n",
      "train loss:0.09217114870675902\n",
      "train loss:0.045482918734481875\n",
      "train loss:0.07033311079880403\n",
      "train loss:0.04394907537442676\n",
      "train loss:0.014273429888290213\n",
      "train loss:0.02402246444763707\n",
      "train loss:0.023030814058835173\n",
      "train loss:0.0484476171259318\n",
      "train loss:0.03707579477970504\n",
      "train loss:0.11251768688677156\n",
      "train loss:0.021300319555482294\n",
      "train loss:0.12692790630877548\n",
      "train loss:0.060307557283148225\n",
      "train loss:0.027215368757876886\n",
      "train loss:0.0261464524446442\n",
      "train loss:0.03351477901028888\n",
      "train loss:0.03607333798303785\n",
      "train loss:0.018815847225725345\n",
      "train loss:0.05223893862025809\n",
      "train loss:0.05874771582166442\n",
      "train loss:0.04397301967729665\n",
      "train loss:0.11499408132134356\n",
      "train loss:0.030628945022038293\n",
      "train loss:0.021737311427054807\n",
      "train loss:0.047829235708011106\n",
      "train loss:0.05327484029357168\n",
      "train loss:0.032891795405076474\n",
      "train loss:0.05397390776987538\n",
      "train loss:0.1595659776292402\n",
      "train loss:0.039329772748782875\n",
      "train loss:0.02673764548396932\n",
      "train loss:0.05212079975716117\n",
      "train loss:0.019880647492117688\n",
      "train loss:0.03297674841127122\n",
      "train loss:0.01862409897078759\n",
      "train loss:0.05105934912010026\n",
      "train loss:0.029413331628043556\n",
      "train loss:0.04322263671059479\n",
      "train loss:0.04231997212226877\n",
      "train loss:0.07852997432924966\n",
      "train loss:0.07088607359092673\n",
      "train loss:0.03847687780893685\n",
      "train loss:0.033416954813265703\n",
      "train loss:0.027239071049305993\n",
      "train loss:0.017483186499312957\n",
      "train loss:0.04040484148306841\n",
      "train loss:0.020957439495212053\n",
      "train loss:0.012988443970507826\n",
      "train loss:0.02654929240420982\n",
      "train loss:0.01903654679335399\n",
      "train loss:0.011011275594061778\n",
      "train loss:0.011186573963763134\n",
      "train loss:0.061834342148912015\n",
      "train loss:0.08792417558497774\n",
      "train loss:0.022652142269048645\n",
      "train loss:0.07959669765219797\n",
      "train loss:0.0170655769557468\n",
      "train loss:0.029399706200652596\n",
      "train loss:0.042402278484941804\n",
      "train loss:0.026209958869723823\n",
      "train loss:0.05486600948854384\n",
      "train loss:0.1369999972896518\n",
      "train loss:0.11476413363185527\n",
      "train loss:0.03535341719212647\n",
      "train loss:0.10638135759232803\n",
      "train loss:0.028348698155996152\n",
      "train loss:0.05309118331402472\n",
      "train loss:0.02471292619752792\n",
      "train loss:0.014655523580843382\n",
      "train loss:0.04515496514015732\n",
      "train loss:0.01882396369524046\n",
      "train loss:0.033889410810318876\n",
      "train loss:0.021701426252720046\n",
      "train loss:0.05115468663274088\n",
      "train loss:0.174595701864357\n",
      "train loss:0.021491599214202087\n",
      "train loss:0.09119972806803357\n",
      "train loss:0.017562741035769876\n",
      "train loss:0.08263510745162865\n",
      "train loss:0.10656573366486008\n",
      "train loss:0.029210100972259886\n",
      "train loss:0.02963461991548468\n",
      "train loss:0.09630761178272251\n",
      "train loss:0.04046086625757995\n",
      "train loss:0.048423762149093934\n",
      "train loss:0.011712450247806972\n",
      "train loss:0.07567612433817787\n",
      "train loss:0.060672383442091124\n",
      "train loss:0.13171571772227575\n",
      "train loss:0.04588218592223213\n",
      "train loss:0.025771514326790017\n",
      "train loss:0.0424519205061929\n",
      "train loss:0.1137918373674375\n",
      "train loss:0.08413529656334207\n",
      "train loss:0.02339428990509883\n",
      "train loss:0.07554550636123088\n",
      "train loss:0.08953555492588613\n",
      "train loss:0.045696356697347035\n",
      "train loss:0.037374217067721496\n",
      "train loss:0.06942108521972949\n",
      "train loss:0.035020978377608786\n",
      "train loss:0.028689532361755567\n",
      "train loss:0.010074196772214914\n",
      "train loss:0.023470614646142383\n",
      "train loss:0.019452475016558182\n",
      "train loss:0.02041673673784243\n",
      "train loss:0.06619928770458106\n",
      "train loss:0.07467597152659361\n",
      "train loss:0.03276806984375674\n",
      "train loss:0.11175489866137638\n",
      "train loss:0.0061302590406364125\n",
      "train loss:0.08555695731497423\n",
      "train loss:0.02106679321095966\n",
      "train loss:0.02180877399877768\n",
      "train loss:0.025719421140335513\n",
      "train loss:0.06233951055152444\n",
      "train loss:0.03246157970454124\n",
      "train loss:0.024000256264842618\n",
      "train loss:0.06913887004739473\n",
      "train loss:0.11288989517138609\n",
      "train loss:0.0380345855624171\n",
      "train loss:0.06681036642710089\n",
      "train loss:0.07528701417442821\n",
      "train loss:0.03219578477612975\n",
      "train loss:0.06511078498824376\n",
      "train loss:0.019311397375666173\n",
      "train loss:0.12257618244917179\n",
      "train loss:0.01461800979591989\n",
      "train loss:0.0371766775053989\n",
      "train loss:0.07664482890033854\n",
      "=== epoch:4, train acc:0.98, test acc:0.988 ===\n",
      "train loss:0.021465853688701856\n",
      "train loss:0.11741747270729343\n",
      "train loss:0.06799800839461295\n",
      "train loss:0.07283257074544099\n",
      "train loss:0.07868189185076957\n",
      "train loss:0.02123100764310585\n",
      "train loss:0.06920440938892936\n",
      "train loss:0.020288877039192833\n",
      "train loss:0.05235208112637396\n",
      "train loss:0.022027827982965018\n",
      "train loss:0.022612238437212658\n",
      "train loss:0.014410442484074453\n",
      "train loss:0.035500240783056004\n",
      "train loss:0.011944819501762348\n",
      "train loss:0.06236702005685707\n",
      "train loss:0.02782028394812177\n",
      "train loss:0.028343895881565793\n",
      "train loss:0.06599102264236235\n",
      "train loss:0.02788518566788685\n",
      "train loss:0.13194011765414257\n",
      "train loss:0.08943297378572926\n",
      "train loss:0.018338865516802524\n",
      "train loss:0.02871268316751304\n",
      "train loss:0.05033814444084071\n",
      "train loss:0.012907982403800226\n",
      "train loss:0.03193669635874961\n",
      "train loss:0.022540206596055035\n",
      "train loss:0.0225551455490714\n",
      "train loss:0.055612316226813806\n",
      "train loss:0.06470771532318109\n",
      "train loss:0.06091870125554902\n",
      "train loss:0.01947053547258609\n",
      "train loss:0.07034593219428466\n",
      "train loss:0.035520475233187875\n",
      "train loss:0.1779713182527908\n",
      "train loss:0.05038876429783756\n",
      "train loss:0.020374069871759094\n",
      "train loss:0.10660748070660638\n",
      "train loss:0.033090518414278985\n",
      "train loss:0.06103323638908567\n",
      "train loss:0.057905065871510814\n",
      "train loss:0.03907888878087781\n",
      "train loss:0.0723470094113822\n",
      "train loss:0.018652347655796736\n",
      "train loss:0.030600011536149045\n",
      "train loss:0.03203447233986405\n",
      "train loss:0.03386901835092295\n",
      "train loss:0.03336775437569949\n",
      "train loss:0.08440187614279558\n",
      "train loss:0.027961555267705746\n",
      "train loss:0.11413036955645994\n",
      "train loss:0.028524392590255566\n",
      "train loss:0.09424060241480245\n",
      "train loss:0.01717425727479091\n",
      "train loss:0.10902127218671798\n",
      "train loss:0.08987500805918282\n",
      "train loss:0.03852338715022219\n",
      "train loss:0.05153663765649406\n",
      "train loss:0.025327729892426366\n",
      "train loss:0.018858550275708725\n",
      "train loss:0.05233682179648429\n",
      "train loss:0.017252549919843634\n",
      "train loss:0.055534738672327034\n",
      "train loss:0.014216168717137354\n",
      "train loss:0.021528959834142856\n",
      "train loss:0.018012750120500166\n",
      "train loss:0.03716375882130798\n",
      "train loss:0.015963473998389505\n",
      "train loss:0.0672089653814088\n",
      "train loss:0.028314829465870696\n",
      "train loss:0.01923290206267455\n",
      "train loss:0.023634640638873678\n",
      "train loss:0.035755369185695274\n",
      "train loss:0.006339977984951703\n",
      "train loss:0.03903128058351069\n",
      "train loss:0.025583881569793493\n",
      "train loss:0.012167083595464454\n",
      "train loss:0.022455992600922806\n",
      "train loss:0.01632529892446003\n",
      "train loss:0.15612886229798817\n",
      "train loss:0.026898293790714307\n",
      "train loss:0.024064236523918675\n",
      "train loss:0.02963974366613826\n",
      "train loss:0.014205198286996816\n",
      "train loss:0.018428973064734462\n",
      "train loss:0.047212337736161514\n",
      "train loss:0.018531867691958262\n",
      "train loss:0.02000526518336785\n",
      "train loss:0.0371101744951064\n",
      "train loss:0.06751981621139157\n",
      "train loss:0.06254856087944884\n",
      "train loss:0.06945531701838925\n",
      "train loss:0.0698557554113874\n",
      "train loss:0.05032927212561795\n",
      "train loss:0.03599197423924028\n",
      "train loss:0.05359118502179861\n",
      "train loss:0.03370513943363535\n",
      "train loss:0.0354218832863957\n",
      "train loss:0.008334879260534717\n",
      "train loss:0.032015433562041486\n",
      "train loss:0.04690382924337585\n",
      "train loss:0.032292218663567726\n",
      "train loss:0.0449052280674005\n",
      "train loss:0.07295870119641369\n",
      "train loss:0.0755288277392994\n",
      "train loss:0.022115759066967312\n",
      "train loss:0.029466675617606863\n",
      "train loss:0.03352327185419662\n",
      "train loss:0.058435241273766494\n",
      "train loss:0.05022072273188202\n",
      "train loss:0.19417207249937019\n",
      "train loss:0.01117215416132774\n",
      "train loss:0.026896369634298877\n",
      "train loss:0.03696687371835324\n",
      "train loss:0.012031092134858493\n",
      "train loss:0.04021886072640401\n",
      "train loss:0.040159436818609624\n",
      "train loss:0.017899486177342827\n",
      "train loss:0.03643250534342071\n",
      "train loss:0.017385257090165255\n",
      "train loss:0.06945060609113243\n",
      "train loss:0.012359686788785495\n",
      "train loss:0.03154992562561948\n",
      "train loss:0.09368710785637942\n",
      "train loss:0.021612993775813813\n",
      "train loss:0.029138226818008657\n",
      "train loss:0.04604256358015817\n",
      "train loss:0.039715027863310125\n",
      "train loss:0.027727638082561894\n",
      "train loss:0.05632378220874272\n",
      "train loss:0.18037321806779308\n",
      "train loss:0.02958571777290806\n",
      "train loss:0.04918487452175662\n",
      "train loss:0.014379428197431827\n",
      "train loss:0.01819298080682986\n",
      "train loss:0.08287532375328434\n",
      "train loss:0.04685584956281986\n",
      "train loss:0.03154935844421988\n",
      "train loss:0.1404961872814713\n",
      "train loss:0.036267154164669885\n",
      "train loss:0.07996244523969374\n",
      "train loss:0.07358527010994817\n",
      "train loss:0.018425834264532114\n",
      "train loss:0.019803199649183003\n",
      "train loss:0.028184700710144513\n",
      "train loss:0.0669537474992681\n",
      "train loss:0.024351681772628544\n",
      "train loss:0.015751564549613965\n",
      "train loss:0.01740978010332928\n",
      "train loss:0.025179091259352394\n",
      "train loss:0.04412769421066279\n",
      "train loss:0.0616040785131592\n",
      "train loss:0.03194677795622341\n",
      "train loss:0.01906628992568098\n",
      "train loss:0.05837687211406128\n",
      "train loss:0.043005009191902796\n",
      "train loss:0.02203420510911468\n",
      "train loss:0.0623925509612438\n",
      "train loss:0.01039620793071547\n",
      "train loss:0.027497929689077362\n",
      "train loss:0.022381146968698865\n",
      "train loss:0.02116049594445094\n",
      "train loss:0.02443367558301665\n",
      "train loss:0.016945784539562445\n",
      "train loss:0.04177648408853738\n",
      "train loss:0.08690570231484097\n",
      "train loss:0.029764710457047712\n",
      "train loss:0.04738193772616917\n",
      "train loss:0.060763976481707976\n",
      "train loss:0.026686517272339866\n",
      "train loss:0.05768861628278934\n",
      "train loss:0.01662123903775936\n",
      "train loss:0.018349166235886366\n",
      "train loss:0.1128026838980635\n",
      "train loss:0.048983262782969154\n",
      "train loss:0.008672225031320197\n",
      "train loss:0.029056983882402097\n",
      "train loss:0.03824124804132866\n",
      "train loss:0.08267887465340866\n",
      "train loss:0.05274284858052481\n",
      "train loss:0.03246399891661365\n",
      "train loss:0.07951512172361719\n",
      "train loss:0.040284100608652194\n",
      "train loss:0.013596236871491417\n",
      "train loss:0.011266370586392687\n",
      "train loss:0.018584991101604446\n",
      "train loss:0.029683735474662905\n",
      "train loss:0.013833992506017006\n",
      "train loss:0.05216963136631918\n",
      "train loss:0.04002948124204665\n",
      "train loss:0.01754492021019466\n",
      "train loss:0.03731933498260582\n",
      "train loss:0.02812464978021015\n",
      "train loss:0.019023445604732347\n",
      "train loss:0.045622463256660604\n",
      "train loss:0.05247262956306099\n",
      "train loss:0.01843379344170001\n",
      "train loss:0.028451548840968028\n",
      "train loss:0.07016956849293068\n",
      "train loss:0.041130061719187705\n",
      "train loss:0.022344084514946908\n",
      "train loss:0.014532442519793179\n",
      "train loss:0.02117440713795945\n",
      "train loss:0.029752563981653844\n",
      "train loss:0.02606121698919501\n",
      "train loss:0.030043306559678386\n",
      "train loss:0.024827483456814917\n",
      "train loss:0.023056913711256795\n",
      "train loss:0.01400224844879105\n",
      "train loss:0.007745651247650889\n",
      "train loss:0.03666734325393676\n",
      "train loss:0.0533587452549569\n",
      "train loss:0.03332093681077127\n",
      "train loss:0.021045082236963553\n",
      "train loss:0.04362002741162005\n",
      "train loss:0.053387128759030865\n",
      "train loss:0.014104236678990674\n",
      "train loss:0.03855675723304721\n",
      "train loss:0.03506685646260951\n",
      "train loss:0.017447019966978308\n",
      "train loss:0.040057945011604895\n",
      "train loss:0.03648054572239557\n",
      "train loss:0.03824615305595744\n",
      "train loss:0.023361053456790307\n",
      "train loss:0.013413332072504724\n",
      "train loss:0.04212365074297917\n",
      "train loss:0.031721815907981635\n",
      "train loss:0.017660167829178765\n",
      "train loss:0.07920446821274742\n",
      "train loss:0.039041762825908786\n",
      "train loss:0.012307427634633989\n",
      "train loss:0.037476243627231155\n",
      "train loss:0.010523653039878327\n",
      "train loss:0.02294166591802333\n",
      "train loss:0.019229331248611294\n",
      "train loss:0.029211094565811453\n",
      "train loss:0.058140883261469135\n",
      "train loss:0.026381694572477632\n",
      "train loss:0.008352235403908706\n",
      "train loss:0.08467368240463091\n",
      "train loss:0.015120934681556883\n",
      "train loss:0.027069236619189294\n",
      "train loss:0.0660555179035242\n",
      "train loss:0.022829404165622357\n",
      "train loss:0.033399724558110806\n",
      "train loss:0.017431118396136154\n",
      "train loss:0.021475879454626586\n",
      "train loss:0.026807600344762796\n",
      "train loss:0.0799751090187256\n",
      "train loss:0.04476362672351142\n",
      "train loss:0.03374905718995527\n",
      "train loss:0.015022684560422049\n",
      "train loss:0.051025647979433125\n",
      "train loss:0.05266589718588846\n",
      "train loss:0.01690445706421301\n",
      "train loss:0.029007656912921908\n",
      "train loss:0.10026715326444681\n",
      "train loss:0.01699809006588789\n",
      "train loss:0.050449363008498914\n",
      "train loss:0.07416859556500648\n",
      "train loss:0.017466890852646542\n",
      "train loss:0.028624351019641656\n",
      "train loss:0.0496790083530617\n",
      "train loss:0.012336761739686475\n",
      "train loss:0.024164590467767196\n",
      "train loss:0.02174851494021569\n",
      "train loss:0.017396511764637943\n",
      "train loss:0.03315830135215058\n",
      "train loss:0.029988668087209874\n",
      "train loss:0.04543698439413591\n",
      "train loss:0.03730694994593733\n",
      "train loss:0.017201543727298783\n",
      "train loss:0.07299830000395822\n",
      "train loss:0.02377200246847874\n",
      "train loss:0.04422349900892017\n",
      "train loss:0.024463165055681767\n",
      "train loss:0.032485923967890205\n",
      "train loss:0.09200140353536644\n",
      "train loss:0.012580770970253723\n",
      "train loss:0.007479249622767249\n",
      "train loss:0.06591960795370119\n",
      "train loss:0.03220269308886639\n",
      "train loss:0.04595751606108655\n",
      "train loss:0.011252596230865386\n",
      "train loss:0.020365388776753583\n",
      "train loss:0.021021440796335902\n",
      "train loss:0.01659205261013451\n",
      "train loss:0.01797341417927914\n",
      "train loss:0.059550253830123745\n",
      "train loss:0.061360986983478354\n",
      "train loss:0.031038044391151737\n",
      "train loss:0.0841745104873122\n",
      "train loss:0.026970460597675158\n",
      "train loss:0.05439411020278921\n",
      "train loss:0.07155768587861618\n",
      "train loss:0.04554390110843766\n",
      "train loss:0.025571744008978547\n",
      "train loss:0.04838747566653726\n",
      "train loss:0.05097463624163319\n",
      "train loss:0.015350167612726815\n",
      "train loss:0.04842902132248305\n",
      "train loss:0.015533173744330482\n",
      "train loss:0.17098600454305263\n",
      "train loss:0.01938562771049025\n",
      "train loss:0.15846383631387748\n",
      "train loss:0.11296583828809835\n",
      "train loss:0.031821608825443576\n",
      "train loss:0.004027246462229911\n",
      "train loss:0.06607342774421011\n",
      "train loss:0.016233676780027483\n",
      "train loss:0.1009201659018615\n",
      "train loss:0.08004303604648054\n",
      "train loss:0.03015443382511039\n",
      "train loss:0.07949546825039128\n",
      "train loss:0.038945150930378175\n",
      "train loss:0.07264701019003933\n",
      "train loss:0.02907158018775243\n",
      "train loss:0.04982398450902162\n",
      "train loss:0.0527325158745478\n",
      "train loss:0.0372539484737599\n",
      "train loss:0.05574881320630268\n",
      "train loss:0.02331466582421154\n",
      "train loss:0.015676806527321806\n",
      "train loss:0.08389159343587181\n",
      "train loss:0.02560763370945876\n",
      "train loss:0.012694570891192863\n",
      "train loss:0.026153439123416757\n",
      "train loss:0.007768707742926294\n",
      "train loss:0.0803130667039008\n",
      "train loss:0.0200410487308194\n",
      "train loss:0.023333900066848462\n",
      "train loss:0.05540074242619226\n",
      "train loss:0.024696820365595062\n",
      "train loss:0.016008386992436726\n",
      "train loss:0.06925897952590944\n",
      "train loss:0.027973041414089655\n",
      "train loss:0.09352534118097333\n",
      "train loss:0.0055437045128502475\n",
      "train loss:0.044120426501420916\n",
      "train loss:0.07086792176303804\n",
      "train loss:0.012469249944554056\n",
      "train loss:0.025355988435439288\n",
      "train loss:0.01433296929425319\n",
      "train loss:0.053392321589800715\n",
      "train loss:0.051778769940045606\n",
      "train loss:0.03853146613752337\n",
      "train loss:0.025481269441457902\n",
      "train loss:0.03992617309860452\n",
      "train loss:0.009392116848177381\n",
      "train loss:0.025460317202777617\n",
      "train loss:0.011074193103641154\n",
      "train loss:0.0285723437217519\n",
      "train loss:0.03241467957377549\n",
      "train loss:0.04527215668595166\n",
      "train loss:0.04453530730043055\n",
      "train loss:0.011342677435732884\n",
      "train loss:0.016471171172331968\n",
      "train loss:0.025584601926026834\n",
      "train loss:0.04397167765688014\n",
      "train loss:0.034593646633945686\n",
      "train loss:0.051481811089413985\n",
      "train loss:0.017546641009477816\n",
      "train loss:0.03766060627101946\n",
      "train loss:0.022746078456827787\n",
      "train loss:0.04296907283361786\n",
      "train loss:0.008573224030983036\n",
      "train loss:0.021546313497313424\n",
      "train loss:0.03130202742699682\n",
      "train loss:0.016396105166510102\n",
      "train loss:0.03228484870138325\n",
      "train loss:0.026019850845401656\n",
      "train loss:0.013961283504480814\n",
      "train loss:0.016101161350430913\n",
      "train loss:0.016975906727585588\n",
      "train loss:0.03989524462064145\n",
      "train loss:0.057487588593274436\n",
      "train loss:0.022064800630761314\n",
      "train loss:0.01001670362035358\n",
      "train loss:0.008854748115299698\n",
      "train loss:0.0413791105568281\n",
      "train loss:0.02350870812521921\n",
      "train loss:0.005863653440135429\n",
      "train loss:0.037515294011460046\n",
      "train loss:0.006265201239555335\n",
      "train loss:0.038805577696671485\n",
      "train loss:0.09265002425692838\n",
      "train loss:0.06040408417000643\n",
      "train loss:0.020818340335422302\n",
      "train loss:0.0405062342493193\n",
      "train loss:0.0519509679104615\n",
      "train loss:0.07824915737518298\n",
      "train loss:0.007389152544262792\n",
      "train loss:0.018088464416337924\n",
      "train loss:0.019749088221575624\n",
      "train loss:0.009003674163649894\n",
      "train loss:0.017066542432761546\n",
      "train loss:0.006686698588985522\n",
      "train loss:0.031103923165017977\n",
      "train loss:0.04300317439797748\n",
      "train loss:0.03230160876028847\n",
      "train loss:0.02195606872575589\n",
      "train loss:0.009138382995933402\n",
      "train loss:0.025423224540178268\n",
      "train loss:0.02102899212030037\n",
      "train loss:0.12881742541731384\n",
      "train loss:0.03800734527542909\n",
      "train loss:0.030033064984416206\n",
      "train loss:0.01629653581153448\n",
      "train loss:0.008237234891218241\n",
      "train loss:0.012827374896601285\n",
      "train loss:0.08367722370183815\n",
      "train loss:0.009200024911042649\n",
      "train loss:0.03482861384075355\n",
      "train loss:0.020549983656543914\n",
      "train loss:0.04142808593892169\n",
      "train loss:0.05436651098681446\n",
      "train loss:0.03096880498049225\n",
      "train loss:0.08361343896554416\n",
      "train loss:0.011541167382320063\n",
      "train loss:0.0324235212904633\n",
      "train loss:0.010236835708167127\n",
      "train loss:0.05924422913100841\n",
      "train loss:0.015884095700895388\n",
      "train loss:0.01475466647704076\n",
      "train loss:0.09411748705999048\n",
      "train loss:0.07207995770249619\n",
      "train loss:0.1001324221476822\n",
      "train loss:0.0625971843594297\n",
      "train loss:0.0345456698703396\n",
      "train loss:0.05006521902279982\n",
      "train loss:0.04189825379241356\n",
      "train loss:0.09231735083918392\n",
      "train loss:0.015925105509900762\n",
      "train loss:0.026266239280081826\n",
      "train loss:0.025031634860703908\n",
      "train loss:0.004946779990634567\n",
      "train loss:0.032076485497321894\n",
      "train loss:0.09867587448103926\n",
      "train loss:0.036459598684183574\n",
      "train loss:0.009221693668619834\n",
      "train loss:0.007954137727049379\n",
      "train loss:0.022822875914855295\n",
      "train loss:0.023295355268349856\n",
      "train loss:0.016167325783983447\n",
      "train loss:0.018290835188779525\n",
      "train loss:0.10701529190352847\n",
      "train loss:0.008820535588237357\n",
      "train loss:0.049525203045551344\n",
      "train loss:0.019280144019112943\n",
      "train loss:0.1011033459275025\n",
      "train loss:0.046960094654476814\n",
      "train loss:0.040094277191932155\n",
      "train loss:0.04198644579893221\n",
      "train loss:0.05320394058492697\n",
      "train loss:0.04770737638369039\n",
      "train loss:0.027515610261149\n",
      "train loss:0.09533512288027428\n",
      "train loss:0.05271317021045657\n",
      "train loss:0.018462267905238878\n",
      "train loss:0.009763942711736456\n",
      "train loss:0.026700981798281558\n",
      "train loss:0.031147482271591725\n",
      "train loss:0.040105247554367895\n",
      "train loss:0.013404307490009393\n",
      "train loss:0.028093446794046125\n",
      "train loss:0.007699755428787758\n",
      "train loss:0.048621546674793306\n",
      "train loss:0.015116247335343109\n",
      "train loss:0.047123523096867334\n",
      "train loss:0.04323893807019052\n",
      "train loss:0.023758917390382703\n",
      "train loss:0.05061696281387383\n",
      "train loss:0.014803376810590407\n",
      "train loss:0.07204416994263371\n",
      "train loss:0.03128596700468761\n",
      "train loss:0.010709835749992696\n",
      "train loss:0.016374864665724034\n",
      "train loss:0.021995124035834403\n",
      "train loss:0.015479376595282004\n",
      "train loss:0.026368748535809946\n",
      "train loss:0.03032160965989763\n",
      "train loss:0.0054336237987319715\n",
      "train loss:0.01930599750247464\n",
      "train loss:0.022567631314805922\n",
      "train loss:0.04784703842388989\n",
      "train loss:0.010212542833001907\n",
      "train loss:0.03674038397388431\n",
      "train loss:0.034314347355503386\n",
      "train loss:0.04134728526023954\n",
      "train loss:0.05241659039503342\n",
      "train loss:0.029939010632147024\n",
      "train loss:0.027527664980947848\n",
      "train loss:0.08055355862293187\n",
      "train loss:0.026490247771429276\n",
      "train loss:0.05812942133377521\n",
      "train loss:0.014478390411794571\n",
      "train loss:0.022310012415111227\n",
      "train loss:0.01356112123061659\n",
      "train loss:0.030567068013580598\n",
      "train loss:0.01798852174706852\n",
      "train loss:0.111013535689072\n",
      "train loss:0.02271327547801535\n",
      "train loss:0.15215470654162114\n",
      "train loss:0.03219329993810503\n",
      "train loss:0.014393376420673325\n",
      "train loss:0.06859024406747177\n",
      "train loss:0.04052739736659343\n",
      "train loss:0.05946403776001491\n",
      "train loss:0.021429832367030083\n",
      "train loss:0.036296086802075724\n",
      "train loss:0.03576745265482342\n",
      "train loss:0.02367143497585979\n",
      "train loss:0.006008260745709835\n",
      "train loss:0.016512693390114314\n",
      "train loss:0.05778405222365988\n",
      "train loss:0.06991913089147651\n",
      "train loss:0.05938307381546915\n",
      "train loss:0.06614311961807436\n",
      "train loss:0.07314491088537838\n",
      "train loss:0.05877711618226423\n",
      "train loss:0.020645158659966693\n",
      "train loss:0.07728735244105596\n",
      "train loss:0.02522149857557015\n",
      "train loss:0.07196940315768935\n",
      "train loss:0.04667049870426657\n",
      "train loss:0.05381479308729744\n",
      "train loss:0.09455922470613805\n",
      "train loss:0.01722806386315213\n",
      "train loss:0.0127294453604508\n",
      "train loss:0.08820966770330566\n",
      "train loss:0.007814811328628588\n",
      "train loss:0.025870814524293996\n",
      "train loss:0.018962061256282862\n",
      "train loss:0.041669227468513856\n",
      "train loss:0.07554044179813081\n",
      "train loss:0.026095153793997215\n",
      "train loss:0.009378060660600719\n",
      "train loss:0.07019786289178052\n",
      "train loss:0.03363437211085804\n",
      "train loss:0.006980571704035797\n",
      "train loss:0.022802198192181482\n",
      "train loss:0.008850350032495265\n",
      "train loss:0.02998250233960707\n",
      "train loss:0.03971659274860739\n",
      "train loss:0.08799045387851628\n",
      "train loss:0.03301637500777795\n",
      "train loss:0.002747288356319389\n",
      "train loss:0.05208260294271642\n",
      "train loss:0.0058148199917682246\n",
      "train loss:0.045701574944566704\n",
      "train loss:0.03855326039215857\n",
      "train loss:0.017028488470540958\n",
      "train loss:0.05468356742340628\n",
      "train loss:0.009320398808608606\n",
      "train loss:0.010790526102890023\n",
      "train loss:0.020355220026854113\n",
      "train loss:0.012766550259467218\n",
      "train loss:0.08442447058280282\n",
      "train loss:0.03319396370899183\n",
      "train loss:0.08102175452206957\n",
      "train loss:0.03501794058006669\n",
      "train loss:0.056073875952953205\n",
      "train loss:0.011230246360721308\n",
      "train loss:0.0034139279161799502\n",
      "train loss:0.02743752098646873\n",
      "train loss:0.017099446353982577\n",
      "train loss:0.04615313546969119\n",
      "train loss:0.010612583160251559\n",
      "train loss:0.03924191454509861\n",
      "train loss:0.05219918002229132\n",
      "train loss:0.023547663372536224\n",
      "train loss:0.00870317288749799\n",
      "train loss:0.032557255553602525\n",
      "train loss:0.03187706733227427\n",
      "train loss:0.015203779353844865\n",
      "train loss:0.03008900764262539\n",
      "train loss:0.011667164520261704\n",
      "train loss:0.03668085479052518\n",
      "train loss:0.011480915376634678\n",
      "train loss:0.017530318280961608\n",
      "train loss:0.02186868826530979\n",
      "train loss:0.019745089119171208\n",
      "train loss:0.08034072037252539\n",
      "train loss:0.011234644042977941\n",
      "train loss:0.01958595823586084\n",
      "train loss:0.06230708150509642\n",
      "train loss:0.010361083702362472\n",
      "train loss:0.04093883046519392\n",
      "train loss:0.020355790467547506\n",
      "train loss:0.044377700557234716\n",
      "train loss:0.024043602239672134\n",
      "train loss:0.14623375130596603\n",
      "train loss:0.01339016635189581\n",
      "train loss:0.049130048565553024\n",
      "train loss:0.016433114512290497\n",
      "train loss:0.07969182472125463\n",
      "train loss:0.02042395222894228\n",
      "train loss:0.0396935249763716\n",
      "train loss:0.02539527613292427\n",
      "train loss:0.01816926919663118\n",
      "=== epoch:5, train acc:0.982, test acc:0.987 ===\n",
      "train loss:0.04220273172513184\n",
      "train loss:0.026345865709001957\n",
      "train loss:0.0457285145991049\n",
      "train loss:0.021745367595151794\n",
      "train loss:0.025359819010031433\n",
      "train loss:0.023216054161940974\n",
      "train loss:0.0135004965476515\n",
      "train loss:0.040652722389406225\n",
      "train loss:0.020692435490312886\n",
      "train loss:0.021118531737095183\n",
      "train loss:0.016851196523970585\n",
      "train loss:0.03606475958262179\n",
      "train loss:0.03429491219834041\n",
      "train loss:0.01055030981616759\n",
      "train loss:0.06647181880358372\n",
      "train loss:0.045874791830838306\n",
      "train loss:0.03835053143691476\n",
      "train loss:0.014033225449630007\n",
      "train loss:0.029188508198885472\n",
      "train loss:0.02609801368334544\n",
      "train loss:0.11606895722482191\n",
      "train loss:0.0106919100541781\n",
      "train loss:0.0129032612960674\n",
      "train loss:0.008462282115005503\n",
      "train loss:0.004815805214913582\n",
      "train loss:0.030534273538257786\n",
      "train loss:0.008189898493246589\n",
      "train loss:0.01085913216732764\n",
      "train loss:0.010954695959675322\n",
      "train loss:0.011928096694911867\n",
      "train loss:0.023715499705137262\n",
      "train loss:0.07734147234269047\n",
      "train loss:0.017235374839810812\n",
      "train loss:0.0878149595719906\n",
      "train loss:0.02230655938151822\n",
      "train loss:0.05352262283530401\n",
      "train loss:0.04536566742620513\n",
      "train loss:0.03509095652461983\n",
      "train loss:0.051418125220974886\n",
      "train loss:0.040044999769480547\n",
      "train loss:0.08813390736264813\n",
      "train loss:0.01958022353074274\n",
      "train loss:0.09625639096896373\n",
      "train loss:0.03700914539162094\n",
      "train loss:0.016900591996008102\n",
      "train loss:0.04225863371126257\n",
      "train loss:0.046764910892589225\n",
      "train loss:0.02135309056938866\n",
      "train loss:0.032844066764414266\n",
      "train loss:0.01641585963145444\n",
      "train loss:0.010001033725600503\n",
      "train loss:0.036379193519160816\n",
      "train loss:0.027469784804715642\n",
      "train loss:0.027487294607191983\n",
      "train loss:0.007478147018301784\n",
      "train loss:0.03406594864959207\n",
      "train loss:0.0337796854404122\n",
      "train loss:0.016053489365055566\n",
      "train loss:0.07639820016765161\n",
      "train loss:0.009484228868386835\n",
      "train loss:0.1052086475081365\n",
      "train loss:0.017565931469131733\n",
      "train loss:0.015833851051356738\n",
      "train loss:0.04130898721294063\n",
      "train loss:0.06529453556489245\n",
      "train loss:0.02938189835944121\n",
      "train loss:0.09462069978427479\n",
      "train loss:0.0049321419181011196\n",
      "train loss:0.015571142741494617\n",
      "train loss:0.04010782958019407\n",
      "train loss:0.024712343232868705\n",
      "train loss:0.04342413106014595\n",
      "train loss:0.008225779072111323\n",
      "train loss:0.008188895414151355\n",
      "train loss:0.012514840044105609\n",
      "train loss:0.03417290484091948\n",
      "train loss:0.047216985319357925\n",
      "train loss:0.05114964569748055\n",
      "train loss:0.03665973684365142\n",
      "train loss:0.007391133526271964\n",
      "train loss:0.008963885452297638\n",
      "train loss:0.020391356385602976\n",
      "train loss:0.008997246773594304\n",
      "train loss:0.054192432665662434\n",
      "train loss:0.018856930208226916\n",
      "train loss:0.022406231474655737\n",
      "train loss:0.06943927582829529\n",
      "train loss:0.058598809703632744\n",
      "train loss:0.04238774530360621\n",
      "train loss:0.009614011387155508\n",
      "train loss:0.017225060713018277\n",
      "train loss:0.03162094152725525\n",
      "train loss:0.016959166748369347\n",
      "train loss:0.021957751052144883\n",
      "train loss:0.06128215349219187\n",
      "train loss:0.07057451881828966\n",
      "train loss:0.019624814887983327\n",
      "train loss:0.025948627398830665\n",
      "train loss:0.029914546741783524\n",
      "train loss:0.028396433276864187\n",
      "train loss:0.030350703240291238\n",
      "train loss:0.1409331318613817\n",
      "train loss:0.03810338123707051\n",
      "train loss:0.023233322757542113\n",
      "train loss:0.06625607032492782\n",
      "train loss:0.058969773467901644\n",
      "train loss:0.022094841053463578\n",
      "train loss:0.03166623169341944\n",
      "train loss:0.04261093361591677\n",
      "train loss:0.0815970435776902\n",
      "train loss:0.027352967289982325\n",
      "train loss:0.00950847061109847\n",
      "train loss:0.08520887274941405\n",
      "train loss:0.028282990700800443\n",
      "train loss:0.012241556091486335\n",
      "train loss:0.01322156023669594\n",
      "train loss:0.16094976063258243\n",
      "train loss:0.018221847162788168\n",
      "train loss:0.05277974431877862\n",
      "train loss:0.018005873555120015\n",
      "train loss:0.05051347881322706\n",
      "train loss:0.04458144540541097\n",
      "train loss:0.010317219709751378\n",
      "train loss:0.015346030808191396\n",
      "train loss:0.012655205586880533\n",
      "train loss:0.08853996321991758\n",
      "train loss:0.01113169843763568\n",
      "train loss:0.023432603820857784\n",
      "train loss:0.06471474453521472\n",
      "train loss:0.02934638048619959\n",
      "train loss:0.011719499664563234\n",
      "train loss:0.004740653745631981\n",
      "train loss:0.031712310640589686\n",
      "train loss:0.0545565846655086\n",
      "train loss:0.008736006459155683\n",
      "train loss:0.03755505421853296\n",
      "train loss:0.011203129889741698\n",
      "train loss:0.012777563064056013\n",
      "train loss:0.006435930436143881\n",
      "train loss:0.035460933489856086\n",
      "train loss:0.08933415447168215\n",
      "train loss:0.01140148961927713\n",
      "train loss:0.0451746901583339\n",
      "train loss:0.011870815507469774\n",
      "train loss:0.06369650389213248\n",
      "train loss:0.06020036321806841\n",
      "train loss:0.008245546013803477\n",
      "train loss:0.07421373945784833\n",
      "train loss:0.028179197916775412\n",
      "train loss:0.011457461541263729\n",
      "train loss:0.03163284049014449\n",
      "train loss:0.023813296476814252\n",
      "train loss:0.008536252178666022\n",
      "train loss:0.022845159667863456\n",
      "train loss:0.007016117724080993\n",
      "train loss:0.009150520747838451\n",
      "train loss:0.008514487788731588\n",
      "train loss:0.020684740477613314\n",
      "train loss:0.0077178535570924245\n",
      "train loss:0.012820212425295635\n",
      "train loss:0.008573061160770336\n",
      "train loss:0.013435513613269605\n",
      "train loss:0.052396582191626774\n",
      "train loss:0.021722718767487922\n",
      "train loss:0.00940297623061818\n",
      "train loss:0.00924952882640268\n",
      "train loss:0.02689798093062265\n",
      "train loss:0.06052178787949194\n",
      "train loss:0.01085463563443802\n",
      "train loss:0.012699203006219944\n",
      "train loss:0.013660236908179023\n",
      "train loss:0.007169717155041972\n",
      "train loss:0.02904713788206462\n",
      "train loss:0.0164289647081698\n",
      "train loss:0.028608532813060316\n",
      "train loss:0.009036524865458471\n",
      "train loss:0.1387354482284039\n",
      "train loss:0.01167141406235037\n",
      "train loss:0.07551800756809322\n",
      "train loss:0.005619894326818342\n",
      "train loss:0.00876700208188961\n",
      "train loss:0.06154877558735115\n",
      "train loss:0.07121080861088794\n",
      "train loss:0.004250311739330204\n",
      "train loss:0.010464675806482648\n",
      "train loss:0.01807470857429309\n",
      "train loss:0.017203113073375024\n",
      "train loss:0.006840322999939987\n",
      "train loss:0.04631882101436833\n",
      "train loss:0.01337957948552221\n",
      "train loss:0.0090434538488499\n",
      "train loss:0.08973535133755632\n",
      "train loss:0.03261074416135282\n",
      "train loss:0.009045407242739906\n",
      "train loss:0.06113740505299921\n",
      "train loss:0.009989812060392612\n",
      "train loss:0.029241835521327846\n",
      "train loss:0.028646213161748407\n",
      "train loss:0.05608814456917601\n",
      "train loss:0.027810887725781937\n",
      "train loss:0.06342607434876531\n",
      "train loss:0.0709019602408285\n",
      "train loss:0.02107906350297882\n",
      "train loss:0.037533686552077124\n",
      "train loss:0.019011004866877977\n",
      "train loss:0.06358821346198479\n",
      "train loss:0.01412617346875954\n",
      "train loss:0.017371227585104978\n",
      "train loss:0.050234464181091634\n",
      "train loss:0.026093508767511025\n",
      "train loss:0.04343532944808023\n",
      "train loss:0.021439420788164822\n",
      "train loss:0.03527063483269887\n",
      "train loss:0.022603402149561896\n",
      "train loss:0.019087281603128423\n",
      "train loss:0.012050778704106193\n",
      "train loss:0.06643074839745707\n",
      "train loss:0.015181957274310319\n",
      "train loss:0.04620571986754692\n",
      "train loss:0.0371014071789725\n",
      "train loss:0.02590274449524042\n",
      "train loss:0.03741773606689769\n",
      "train loss:0.06646672878325399\n",
      "train loss:0.03609452289138529\n",
      "train loss:0.0096152100329398\n",
      "train loss:0.03965579084986237\n",
      "train loss:0.030379375856607348\n",
      "train loss:0.1370190333434501\n",
      "train loss:0.08558733458893637\n",
      "train loss:0.014723995680801672\n",
      "train loss:0.02153777290770266\n",
      "train loss:0.00617722840385058\n",
      "train loss:0.059319638369060235\n",
      "train loss:0.014319740921859092\n",
      "train loss:0.004947829458124897\n",
      "train loss:0.026894095818090876\n",
      "train loss:0.007020050527751311\n",
      "train loss:0.014052391547069377\n",
      "train loss:0.020439115565406462\n",
      "train loss:0.01480946568310742\n",
      "train loss:0.012467159672185934\n",
      "train loss:0.03413842494230873\n",
      "train loss:0.0139298768174049\n",
      "train loss:0.016549039528851724\n",
      "train loss:0.026276933404469273\n",
      "train loss:0.02150956333826152\n",
      "train loss:0.024951499180349505\n",
      "train loss:0.005820420183142051\n",
      "train loss:0.010076790595615635\n",
      "train loss:0.039311717897750356\n",
      "train loss:0.00978699368988602\n",
      "train loss:0.05755640624979584\n",
      "train loss:0.044581739559224086\n",
      "train loss:0.04450224993861902\n",
      "train loss:0.0567159207355249\n",
      "train loss:0.012095079229460737\n",
      "train loss:0.04613027807833066\n",
      "train loss:0.045215088734733094\n",
      "train loss:0.07239482335675416\n",
      "train loss:0.07766319253345431\n",
      "train loss:0.03415692255163792\n",
      "train loss:0.022781038265013716\n",
      "train loss:0.085894151794053\n",
      "train loss:0.02478771194194079\n",
      "train loss:0.010746912749270168\n",
      "train loss:0.013778149095168231\n",
      "train loss:0.012406179049240535\n",
      "train loss:0.05911662415455133\n",
      "train loss:0.005822698200608619\n",
      "train loss:0.02910169892275829\n",
      "train loss:0.15830027061783933\n",
      "train loss:0.048027242609840474\n",
      "train loss:0.025141403815072044\n",
      "train loss:0.07763351880562201\n",
      "train loss:0.009766210315318057\n",
      "train loss:0.019682830818179647\n",
      "train loss:0.006134450385846955\n",
      "train loss:0.015425824532262582\n",
      "train loss:0.005086690789619775\n",
      "train loss:0.01045298350591855\n",
      "train loss:0.012251327018955628\n",
      "train loss:0.015405062359669812\n",
      "train loss:0.00807327091105959\n",
      "train loss:0.02673530354710114\n",
      "train loss:0.02703025470025072\n",
      "train loss:0.08992480921138452\n",
      "train loss:0.005872527113317732\n",
      "train loss:0.005546416572622211\n",
      "train loss:0.02078376038815637\n",
      "train loss:0.018598119161915675\n",
      "train loss:0.0038757512885734344\n",
      "train loss:0.017145581192935546\n",
      "train loss:0.005685694111557462\n",
      "train loss:0.01334546671129886\n",
      "train loss:0.013002285305220816\n",
      "train loss:0.03328990920212103\n",
      "train loss:0.07731982263059649\n",
      "train loss:0.016586348130703744\n",
      "train loss:0.054057131759771095\n",
      "train loss:0.02619453381418424\n",
      "train loss:0.11698831291022806\n",
      "train loss:0.0050776598240528355\n",
      "train loss:0.014143782546654262\n",
      "train loss:0.01278277049124407\n",
      "train loss:0.023888499926927653\n",
      "train loss:0.032373827282845755\n",
      "train loss:0.008296747484411513\n",
      "train loss:0.02142406578939053\n",
      "train loss:0.012172143290541983\n",
      "train loss:0.055600161362693266\n",
      "train loss:0.03289998121793508\n",
      "train loss:0.05778546156191721\n",
      "train loss:0.01776926385817533\n",
      "train loss:0.01883696181981929\n",
      "train loss:0.005128577811623343\n",
      "train loss:0.02514656079138551\n",
      "train loss:0.02777887624409393\n",
      "train loss:0.029350570110519746\n",
      "train loss:0.025065052561007866\n",
      "train loss:0.022705832798396525\n",
      "train loss:0.017183251682271906\n",
      "train loss:0.09932338246116984\n",
      "train loss:0.01175324522743713\n",
      "train loss:0.020418744905402283\n",
      "train loss:0.0035364686434914234\n",
      "train loss:0.016637308187689243\n",
      "train loss:0.02068696719194959\n",
      "train loss:0.011561929658297778\n",
      "train loss:0.024997850987025054\n",
      "train loss:0.0026493200026651603\n",
      "train loss:0.015412754744699539\n",
      "train loss:0.0650664925081001\n",
      "train loss:0.016335477919369387\n",
      "train loss:0.028510459029888392\n",
      "train loss:0.06629195444836662\n",
      "train loss:0.015143382155112328\n",
      "train loss:0.019979949205604863\n",
      "train loss:0.03135129771857318\n",
      "train loss:0.02754001477882956\n",
      "train loss:0.055783768384732306\n",
      "train loss:0.006423528419164427\n",
      "train loss:0.059110558294075\n",
      "train loss:0.03486907435562393\n",
      "train loss:0.022449472086398744\n",
      "train loss:0.027671033175313327\n",
      "train loss:0.01276610454717334\n",
      "train loss:0.04613603068650453\n",
      "train loss:0.01810960637094902\n",
      "train loss:0.04020711043321131\n",
      "train loss:0.009355684667014419\n",
      "train loss:0.006879435125550746\n",
      "train loss:0.04011984006486184\n",
      "train loss:0.016955944080278458\n",
      "train loss:0.019695366963281027\n",
      "train loss:0.013602472509265629\n",
      "train loss:0.039370409167751884\n",
      "train loss:0.03536048812882312\n",
      "train loss:0.0708802200973848\n",
      "train loss:0.025934735245144315\n",
      "train loss:0.03755080994491093\n",
      "train loss:0.014306358852058393\n",
      "train loss:0.015057280163259783\n",
      "train loss:0.011765097008013868\n",
      "train loss:0.00573113023135558\n",
      "train loss:0.044064176986125976\n",
      "train loss:0.023192419489167868\n",
      "train loss:0.03626687200391531\n",
      "train loss:0.07016146163850726\n",
      "train loss:0.019240238398300916\n",
      "train loss:0.03291623625428453\n",
      "train loss:0.11328937077030318\n",
      "train loss:0.08191801140812492\n",
      "train loss:0.03107863350339086\n",
      "train loss:0.03544554673451923\n",
      "train loss:0.015611420597484146\n",
      "train loss:0.03936045651551184\n",
      "train loss:0.04498330082972902\n",
      "train loss:0.04691876795435264\n",
      "train loss:0.10889505469497328\n",
      "train loss:0.011000564256610789\n",
      "train loss:0.09862807728113623\n",
      "train loss:0.012047878722312317\n",
      "train loss:0.017097120644379574\n",
      "train loss:0.04733034246636512\n",
      "train loss:0.01972035291227837\n",
      "train loss:0.047721105989749046\n",
      "train loss:0.03851974874002887\n",
      "train loss:0.0167563647167002\n",
      "train loss:0.014799812097390728\n",
      "train loss:0.04277109933686378\n",
      "train loss:0.014440357095782756\n",
      "train loss:0.025913708394989698\n",
      "train loss:0.03462873054011832\n",
      "train loss:0.017221642458066923\n",
      "train loss:0.021568402392436813\n",
      "train loss:0.0700338849513067\n",
      "train loss:0.036457794755310385\n",
      "train loss:0.04285836503169966\n",
      "train loss:0.008453762387304357\n",
      "train loss:0.004676418575796996\n",
      "train loss:0.02440995978889215\n",
      "train loss:0.05382865329050428\n",
      "train loss:0.01939543569526072\n",
      "train loss:0.014422928962980421\n",
      "train loss:0.04250874539920648\n",
      "train loss:0.046335234983984785\n",
      "train loss:0.1382954310219079\n",
      "train loss:0.04419033461718497\n",
      "train loss:0.018809318256456112\n",
      "train loss:0.03394731370543056\n",
      "train loss:0.02402780102165834\n",
      "train loss:0.025382064552635628\n",
      "train loss:0.014567055524507579\n",
      "train loss:0.021033920312450508\n",
      "train loss:0.0882307440783966\n",
      "train loss:0.02001004833951698\n",
      "train loss:0.004880366729847867\n",
      "train loss:0.018108550787735666\n",
      "train loss:0.015204571441045898\n",
      "train loss:0.0859867629922674\n",
      "train loss:0.031844421070730426\n",
      "train loss:0.05732314648198076\n",
      "train loss:0.05769593524127092\n",
      "train loss:0.02741976059410354\n",
      "train loss:0.00992955350738064\n",
      "train loss:0.06384375827264566\n",
      "train loss:0.04189960919791178\n",
      "train loss:0.010797765451460738\n",
      "train loss:0.01769444425755943\n",
      "train loss:0.020512314456156457\n",
      "train loss:0.009059269627720676\n",
      "train loss:0.03614722713574688\n",
      "train loss:0.018033544884706907\n",
      "train loss:0.05332028083801736\n",
      "train loss:0.020936444710091495\n",
      "train loss:0.00987715941131078\n",
      "train loss:0.0055002476368524325\n",
      "train loss:0.007165861565820496\n",
      "train loss:0.012899560712648733\n",
      "train loss:0.04878001058398268\n",
      "train loss:0.012754599532972793\n",
      "train loss:0.01032822566568576\n",
      "train loss:0.00823439498260263\n",
      "train loss:0.011848191810018767\n",
      "train loss:0.06994227707327505\n",
      "train loss:0.013880625870600016\n",
      "train loss:0.02327905953391772\n",
      "train loss:0.02987691504412412\n",
      "train loss:0.01537153216964228\n",
      "train loss:0.03402277615033364\n",
      "train loss:0.018747073474981515\n",
      "train loss:0.008586601748541695\n",
      "train loss:0.05414464981264261\n",
      "train loss:0.019204074377984517\n",
      "train loss:0.034683324536251725\n",
      "train loss:0.051850287071953154\n",
      "train loss:0.06404855207698086\n",
      "train loss:0.02767454585534679\n",
      "train loss:0.13073238452803818\n",
      "train loss:0.009872930594556864\n",
      "train loss:0.0689386188220684\n",
      "train loss:0.046508037269987694\n",
      "train loss:0.0253689867112904\n",
      "train loss:0.08361225222670977\n",
      "train loss:0.0099499620212656\n",
      "train loss:0.0029177524380971766\n",
      "train loss:0.023961491711018655\n",
      "train loss:0.03330420402672075\n",
      "train loss:0.027422274238605736\n",
      "train loss:0.04654128593079571\n",
      "train loss:0.031241280661442404\n",
      "train loss:0.029974951595347417\n",
      "train loss:0.07880555845887745\n",
      "train loss:0.049345070515369696\n",
      "train loss:0.008013711653108118\n",
      "train loss:0.014560233657729578\n",
      "train loss:0.056645053501651804\n",
      "train loss:0.03900552384715111\n",
      "train loss:0.026140849642747575\n",
      "train loss:0.015559672824572041\n",
      "train loss:0.06313837266679473\n",
      "train loss:0.0187166617817755\n",
      "train loss:0.06709078476750814\n",
      "train loss:0.09412948404761334\n",
      "train loss:0.023447604535938745\n",
      "train loss:0.01573537069405291\n",
      "train loss:0.05840063686899064\n",
      "train loss:0.05904288226848245\n",
      "train loss:0.013694037434235142\n",
      "train loss:0.018441153206763122\n",
      "train loss:0.009782858584904191\n",
      "train loss:0.016091332251347602\n",
      "train loss:0.023594890856483076\n",
      "train loss:0.01781325259567847\n",
      "train loss:0.02734681948571368\n",
      "train loss:0.010412044184316212\n",
      "train loss:0.030029492051485914\n",
      "train loss:0.028570961282237274\n",
      "train loss:0.06256920178108834\n",
      "train loss:0.008286765560749676\n",
      "train loss:0.015156356234859726\n",
      "train loss:0.04638908075052831\n",
      "train loss:0.044740904659073676\n",
      "train loss:0.04512625459341688\n",
      "train loss:0.018205295663261206\n",
      "train loss:0.03233735270730291\n",
      "train loss:0.019766379942236244\n",
      "train loss:0.02044920860420326\n",
      "train loss:0.004100930104027412\n",
      "train loss:0.01811733361344213\n",
      "train loss:0.016376250771189687\n",
      "train loss:0.01695039408859455\n",
      "train loss:0.02593651827151842\n",
      "train loss:0.013443427752712192\n",
      "train loss:0.03533755866754271\n",
      "train loss:0.01976743318191943\n",
      "train loss:0.006516433762536641\n",
      "train loss:0.02612022631358854\n",
      "train loss:0.025774443235017444\n",
      "train loss:0.06748198260325766\n",
      "train loss:0.018580245085174977\n",
      "train loss:0.038359293120231355\n",
      "train loss:0.031563317633584186\n",
      "train loss:0.003994243960751776\n",
      "train loss:0.011379299311057937\n",
      "train loss:0.015405851712802916\n",
      "train loss:0.07331066103443605\n",
      "train loss:0.04803229620061062\n",
      "train loss:0.003043228535789218\n",
      "train loss:0.042560566112573105\n",
      "train loss:0.03345104834582506\n",
      "train loss:0.02198092087915461\n",
      "train loss:0.01922779754008586\n",
      "train loss:0.03835453097669943\n",
      "train loss:0.027678681580254768\n",
      "train loss:0.022377678468778903\n",
      "train loss:0.02362279197537918\n",
      "train loss:0.028243721511652976\n",
      "train loss:0.010500707281565205\n",
      "train loss:0.017134247655475863\n",
      "train loss:0.01013335332594425\n",
      "train loss:0.012432567350084798\n",
      "train loss:0.00288007387569751\n",
      "train loss:0.004002264702608533\n",
      "train loss:0.008976667236094223\n",
      "train loss:0.003999846804271692\n",
      "train loss:0.011913700579802533\n",
      "train loss:0.017088551667644922\n",
      "train loss:0.011505581833582886\n",
      "train loss:0.009621423853453161\n",
      "train loss:0.009721128074274114\n",
      "train loss:0.007280281886023485\n",
      "train loss:0.01117272590644561\n",
      "train loss:0.026921468789821677\n",
      "train loss:0.04999050252578301\n",
      "train loss:0.05453225819680828\n",
      "train loss:0.023643201500549185\n",
      "train loss:0.01726830219007718\n",
      "train loss:0.028240076472605277\n",
      "train loss:0.03526093230739255\n",
      "train loss:0.06723920459509931\n",
      "train loss:0.01179540976199335\n",
      "train loss:0.016740617198469566\n",
      "train loss:0.015182394028684433\n",
      "train loss:0.03155584146782049\n",
      "train loss:0.010918344474021529\n",
      "train loss:0.02655881605817021\n",
      "train loss:0.05236230412194284\n",
      "train loss:0.08545883258516943\n",
      "train loss:0.013567187732180437\n",
      "train loss:0.015387494004964197\n",
      "train loss:0.007609787762899216\n",
      "train loss:0.0035515287979123156\n",
      "train loss:0.020186425288652964\n",
      "train loss:0.014831361890964886\n",
      "train loss:0.020798892775122247\n",
      "train loss:0.012183678695299288\n",
      "train loss:0.028160203016895136\n",
      "train loss:0.00983004453303917\n",
      "train loss:0.061109584406279345\n",
      "train loss:0.024798836180857983\n",
      "train loss:0.05019849321321313\n",
      "train loss:0.014513247903227404\n",
      "train loss:0.0251257497465039\n",
      "train loss:0.05806133223942139\n",
      "train loss:0.020844250136351182\n",
      "train loss:0.016509280748085674\n",
      "train loss:0.01748905934680405\n",
      "train loss:0.012139644445656428\n",
      "train loss:0.0767475719840799\n",
      "train loss:0.007136235880571055\n",
      "train loss:0.005905297729179385\n",
      "train loss:0.04181534417484769\n",
      "train loss:0.017407684508577062\n",
      "train loss:0.024523981880265566\n",
      "train loss:0.04108613214389893\n",
      "train loss:0.027710045943938014\n",
      "train loss:0.01628211157604855\n",
      "train loss:0.014723239896792533\n",
      "train loss:0.018788904786093172\n",
      "=== epoch:6, train acc:0.989, test acc:0.987 ===\n",
      "train loss:0.015777217783938938\n",
      "train loss:0.007433824262040503\n",
      "train loss:0.07091809878393242\n",
      "train loss:0.011022735508526026\n",
      "train loss:0.012444468134741135\n",
      "train loss:0.02540662173467195\n",
      "train loss:0.0023369309884130494\n",
      "train loss:0.04877285037059838\n",
      "train loss:0.161569453921661\n",
      "train loss:0.022117237503482268\n",
      "train loss:0.00897107300410042\n",
      "train loss:0.022162768771263747\n",
      "train loss:0.013228264149436031\n",
      "train loss:0.06681684265207194\n",
      "train loss:0.012978160523921563\n",
      "train loss:0.004714840946252427\n",
      "train loss:0.04345124420813156\n",
      "train loss:0.02043201783216854\n",
      "train loss:0.014046062123496857\n",
      "train loss:0.050470980967523976\n",
      "train loss:0.015844942411304266\n",
      "train loss:0.022212326162572526\n",
      "train loss:0.0350306760334128\n",
      "train loss:0.03080037985098506\n",
      "train loss:0.09272425176173567\n",
      "train loss:0.006063531372734549\n",
      "train loss:0.014904900602817926\n",
      "train loss:0.04233145589483359\n",
      "train loss:0.027572591378331776\n",
      "train loss:0.0062478959029980494\n",
      "train loss:0.015769388650018572\n",
      "train loss:0.015490000907667478\n",
      "train loss:0.07239658581197374\n",
      "train loss:0.006465290404020434\n",
      "train loss:0.02587551558835188\n",
      "train loss:0.006107262397726506\n",
      "train loss:0.008064482471396245\n",
      "train loss:0.06068628285518916\n",
      "train loss:0.022284111881116765\n",
      "train loss:0.03415482026272551\n",
      "train loss:0.016565360743346177\n",
      "train loss:0.028543489895092346\n",
      "train loss:0.015891294442419112\n",
      "train loss:0.01556272557268433\n",
      "train loss:0.043557434142828984\n",
      "train loss:0.033829969201607975\n",
      "train loss:0.06373811307539902\n",
      "train loss:0.020850295957909448\n",
      "train loss:0.005271999953756466\n",
      "train loss:0.024023412358313723\n",
      "train loss:0.15418806529710116\n",
      "train loss:0.012069931147814872\n",
      "train loss:0.05360074127516018\n",
      "train loss:0.030647376702544128\n",
      "train loss:0.003765901690328409\n",
      "train loss:0.03208757148183422\n",
      "train loss:0.02905958853581002\n",
      "train loss:0.030678994377467267\n",
      "train loss:0.023690705154508763\n",
      "train loss:0.018909830872546288\n",
      "train loss:0.02856695194940552\n",
      "train loss:0.0352809471662715\n",
      "train loss:0.006927461930437195\n",
      "train loss:0.017663199188763766\n",
      "train loss:0.008230012378913782\n",
      "train loss:0.05896200045070931\n",
      "train loss:0.05811257572255833\n",
      "train loss:0.05350766138317224\n",
      "train loss:0.04187529079302551\n",
      "train loss:0.03073509007915073\n",
      "train loss:0.014526880448245343\n",
      "train loss:0.007229251976512366\n",
      "train loss:0.013147210145514489\n",
      "train loss:0.06023059139509539\n",
      "train loss:0.008306362807921314\n",
      "train loss:0.012498788505039361\n",
      "train loss:0.021274602107692706\n",
      "train loss:0.007472495100032467\n",
      "train loss:0.006524592076608841\n",
      "train loss:0.021431723787688414\n",
      "train loss:0.02137091164203048\n",
      "train loss:0.02187823317264887\n",
      "train loss:0.007833781675539171\n",
      "train loss:0.006764164703255811\n",
      "train loss:0.010694522800793369\n",
      "train loss:0.0060471775270684825\n",
      "train loss:0.11111284608499744\n",
      "train loss:0.014551010621187101\n",
      "train loss:0.018297163662334314\n",
      "train loss:0.013068674175407613\n",
      "train loss:0.003688035478038425\n",
      "train loss:0.005168802705190996\n",
      "train loss:0.008456125707476413\n",
      "train loss:0.030469198578689877\n",
      "train loss:0.01467148460542834\n",
      "train loss:0.08080795885625962\n",
      "train loss:0.026032019318494904\n",
      "train loss:0.002267141952962815\n",
      "train loss:0.00892926465465155\n",
      "train loss:0.002510146909049678\n",
      "train loss:0.023511533422934258\n",
      "train loss:0.0030445352357136002\n",
      "train loss:0.02106716086715886\n",
      "train loss:0.013346407641572631\n",
      "train loss:0.025474499980930782\n",
      "train loss:0.031472232083695435\n",
      "train loss:0.007196248091183441\n",
      "train loss:0.03455915108810241\n",
      "train loss:0.03905326178684255\n",
      "train loss:0.016507117458111377\n",
      "train loss:0.019777603803148067\n",
      "train loss:0.015339674482496577\n",
      "train loss:0.017780140188883096\n",
      "train loss:0.04096258983431328\n",
      "train loss:0.011632987560370149\n",
      "train loss:0.0948819140329842\n",
      "train loss:0.005861617038016481\n",
      "train loss:0.03815080422816299\n",
      "train loss:0.06532757857029091\n",
      "train loss:0.014413928387578968\n",
      "train loss:0.06334173102882047\n",
      "train loss:0.023972489972264845\n",
      "train loss:0.009349620549228416\n",
      "train loss:0.04361007784242688\n",
      "train loss:0.03884182594519305\n",
      "train loss:0.009095253551690788\n",
      "train loss:0.09484714551710377\n",
      "train loss:0.016374003187608697\n",
      "train loss:0.03296125868714331\n",
      "train loss:0.011769350690016868\n",
      "train loss:0.046754998230345964\n",
      "train loss:0.006434603545890944\n",
      "train loss:0.06810847795023457\n",
      "train loss:0.019567973681520773\n",
      "train loss:0.02186308121829192\n",
      "train loss:0.003477796381919045\n",
      "train loss:0.01897458881255555\n",
      "train loss:0.10954378820662235\n",
      "train loss:0.011163398306609652\n",
      "train loss:0.06640263590062345\n",
      "train loss:0.017256690086471644\n",
      "train loss:0.02462720369874756\n",
      "train loss:0.05391672476315477\n",
      "train loss:0.04497316621284828\n",
      "train loss:0.03377427769476543\n",
      "train loss:0.02173627990263954\n",
      "train loss:0.03461870434586666\n",
      "train loss:0.021137281330779963\n",
      "train loss:0.015445714200832168\n",
      "train loss:0.009199953198136802\n",
      "train loss:0.053073241596745556\n",
      "train loss:0.012793586227588465\n",
      "train loss:0.011911415577451661\n",
      "train loss:0.03204561618840227\n",
      "train loss:0.011466023907754695\n",
      "train loss:0.035326246518323744\n",
      "train loss:0.006303157209021177\n",
      "train loss:0.016645608923604373\n",
      "train loss:0.01450468920162169\n",
      "train loss:0.014674420952964532\n",
      "train loss:0.008041848309372678\n",
      "train loss:0.030342515818543456\n",
      "train loss:0.020810560084729205\n",
      "train loss:0.03587553955301244\n",
      "train loss:0.020736694070070998\n",
      "train loss:0.009056729638787396\n",
      "train loss:0.012806398213307929\n",
      "train loss:0.034290762845268906\n",
      "train loss:0.012624739205395124\n",
      "train loss:0.01199227554703425\n",
      "train loss:0.0017139728424594217\n",
      "train loss:0.0022610078455755685\n",
      "train loss:0.04080568395879043\n",
      "train loss:0.00724407100656767\n",
      "train loss:0.016596250601552242\n",
      "train loss:0.07662958289365301\n",
      "train loss:0.05148527520170245\n",
      "train loss:0.00583255471830849\n",
      "train loss:0.0059737766002189085\n",
      "train loss:0.011594460270686995\n",
      "train loss:0.02962639488576013\n",
      "train loss:0.015108133512285002\n",
      "train loss:0.023242176032750594\n",
      "train loss:0.0261496286459268\n",
      "train loss:0.0178857270127874\n",
      "train loss:0.06982642512661189\n",
      "train loss:0.010941331340882172\n",
      "train loss:0.024482737844857664\n",
      "train loss:0.02002466088347605\n",
      "train loss:0.0244200308173424\n",
      "train loss:0.033331744296264836\n",
      "train loss:0.023814504628780032\n",
      "train loss:0.0428932006011588\n",
      "train loss:0.04457957618069051\n",
      "train loss:0.002544330938876953\n",
      "train loss:0.018384343764795696\n",
      "train loss:0.004395316315290695\n",
      "train loss:0.006880871340230417\n",
      "train loss:0.006281374125218413\n",
      "train loss:0.09761513781974646\n",
      "train loss:0.012935103287050866\n",
      "train loss:0.011826078827439522\n",
      "train loss:0.00786447814135533\n",
      "train loss:0.0023368488668483907\n",
      "train loss:0.04225750106580255\n",
      "train loss:0.05373750576505505\n",
      "train loss:0.007201466546383526\n",
      "train loss:0.0069716827869764275\n",
      "train loss:0.049367903645759006\n",
      "train loss:0.0057450874697619805\n",
      "train loss:0.04442914395947286\n",
      "train loss:0.00416192454113799\n",
      "train loss:0.06430118803319486\n",
      "train loss:0.05123235624913686\n",
      "train loss:0.008666476367424075\n",
      "train loss:0.04398245821365415\n",
      "train loss:0.004218478581123036\n",
      "train loss:0.015294880807835629\n",
      "train loss:0.004004217176474208\n",
      "train loss:0.010591739163532028\n",
      "train loss:0.013575443248162495\n",
      "train loss:0.048931850787251714\n",
      "train loss:0.01630813223791118\n",
      "train loss:0.03112253361332011\n",
      "train loss:0.028580109804162715\n",
      "train loss:0.052190207130824874\n",
      "train loss:0.01377281578154645\n",
      "train loss:0.046037770366386684\n",
      "train loss:0.007629304886059474\n",
      "train loss:0.018213154938473183\n",
      "train loss:0.003521783443206081\n",
      "train loss:0.024310235189079286\n",
      "train loss:0.016150806288679247\n",
      "train loss:0.0058791974365097095\n",
      "train loss:0.02271582271829908\n",
      "train loss:0.011591617114464074\n",
      "train loss:0.04286824375922046\n",
      "train loss:0.007804239939477373\n",
      "train loss:0.011589930231265424\n",
      "train loss:0.02029879196046399\n",
      "train loss:0.07149777134965657\n",
      "train loss:0.012778622965336661\n",
      "train loss:0.04508112413608559\n",
      "train loss:0.02499469802820109\n",
      "train loss:0.005383458947664565\n",
      "train loss:0.009587638329575609\n",
      "train loss:0.047579082668674694\n",
      "train loss:0.017231392126467064\n",
      "train loss:0.005563222362243681\n",
      "train loss:0.006573940595261441\n",
      "train loss:0.008834548208111517\n",
      "train loss:0.00666595963369837\n",
      "train loss:0.013484505508373254\n",
      "train loss:0.01019911235921014\n",
      "train loss:0.07251257722114846\n",
      "train loss:0.009510612720746332\n",
      "train loss:0.050646783229141554\n",
      "train loss:0.032853121782724135\n",
      "train loss:0.011027121032728342\n",
      "train loss:0.00478620392243602\n",
      "train loss:0.01303476699579306\n",
      "train loss:0.053989094965318375\n",
      "train loss:0.009646382746591018\n",
      "train loss:0.02737074326897103\n",
      "train loss:0.03894491188738993\n",
      "train loss:0.012399758742805089\n",
      "train loss:0.007008398105433116\n",
      "train loss:0.04673125149846371\n",
      "train loss:0.010226114582731595\n",
      "train loss:0.0073298415551433386\n",
      "train loss:0.014302867781435046\n",
      "train loss:0.00541507166990777\n",
      "train loss:0.03392287407896773\n",
      "train loss:0.01644112185208913\n",
      "train loss:0.060882652953435146\n",
      "train loss:0.09307056013284287\n",
      "train loss:0.03772946415495063\n",
      "train loss:0.015962622843304592\n",
      "train loss:0.04440802506904323\n",
      "train loss:0.004473130937889311\n",
      "train loss:0.062112469436641504\n",
      "train loss:0.00961369744041005\n",
      "train loss:0.0039897164442805125\n",
      "train loss:0.03128873246644198\n",
      "train loss:0.011553725359501547\n",
      "train loss:0.00639326834365414\n",
      "train loss:0.01751301376201608\n",
      "train loss:0.019768444487292522\n",
      "train loss:0.020568634383314733\n",
      "train loss:0.037407225826702445\n",
      "train loss:0.053343924536512335\n",
      "train loss:0.007595869656977885\n",
      "train loss:0.030221756761493284\n",
      "train loss:0.03274283531127828\n",
      "train loss:0.018909762332172144\n",
      "train loss:0.022062974966427396\n",
      "train loss:0.030611722162601645\n",
      "train loss:0.008912554711268178\n",
      "train loss:0.011973018059476077\n",
      "train loss:0.011235773050178834\n",
      "train loss:0.006220016384008572\n",
      "train loss:0.008211500384934156\n",
      "train loss:0.017739853572092526\n",
      "train loss:0.005741318880931091\n",
      "train loss:0.014931309572875034\n",
      "train loss:0.025515619740967065\n",
      "train loss:0.03342776947422403\n",
      "train loss:0.02896327659440125\n",
      "train loss:0.00783374658199912\n",
      "train loss:0.00690723867561346\n",
      "train loss:0.0046122469340912535\n",
      "train loss:0.03011022441259311\n",
      "train loss:0.003180136827265384\n",
      "train loss:0.024423882244766767\n",
      "train loss:0.05085393093618355\n",
      "train loss:0.006880149954097336\n",
      "train loss:0.08556184139471253\n",
      "train loss:0.01453333816543997\n",
      "train loss:0.014681451291310375\n",
      "train loss:0.02848643965033629\n",
      "train loss:0.008012732761178172\n",
      "train loss:0.023020400382408237\n",
      "train loss:0.011743335364095091\n",
      "train loss:0.006915035600336777\n",
      "train loss:0.025568892162372986\n",
      "train loss:0.047996225122119276\n",
      "train loss:0.01901388305494794\n",
      "train loss:0.021809472167935395\n",
      "train loss:0.01194020440825272\n",
      "train loss:0.01475078462790855\n",
      "train loss:0.005341931916705052\n",
      "train loss:0.03697202970692356\n",
      "train loss:0.01829981223901038\n",
      "train loss:0.06353914586051303\n",
      "train loss:0.05463823861963364\n",
      "train loss:0.004391740007187397\n",
      "train loss:0.001962572308598036\n",
      "train loss:0.06642499513811347\n",
      "train loss:0.03841103172163842\n",
      "train loss:0.0117212121000164\n",
      "train loss:0.09187341361140262\n",
      "train loss:0.07670703422481247\n",
      "train loss:0.006087575710811719\n",
      "train loss:0.017027163028861696\n",
      "train loss:0.04983883602561932\n",
      "train loss:0.03350026447548849\n",
      "train loss:0.01910049825578042\n",
      "train loss:0.03912347325937886\n",
      "train loss:0.011192627647979701\n",
      "train loss:0.007877859541845724\n",
      "train loss:0.012774626405995994\n",
      "train loss:0.04610510652637114\n",
      "train loss:0.006154982419124325\n",
      "train loss:0.03580152865074743\n",
      "train loss:0.00890921505278819\n",
      "train loss:0.00775723355888761\n",
      "train loss:0.023887000084763077\n",
      "train loss:0.014601718694374963\n",
      "train loss:0.02342758317650822\n",
      "train loss:0.09038014656347765\n",
      "train loss:0.060906395836364015\n",
      "train loss:0.015925709514431074\n",
      "train loss:0.009825849970190901\n",
      "train loss:0.003710420567404951\n",
      "train loss:0.014959184331688424\n",
      "train loss:0.023035046334596066\n",
      "train loss:0.013514130054525586\n",
      "train loss:0.01042840029270021\n",
      "train loss:0.010887467925571716\n",
      "train loss:0.023312906559396086\n",
      "train loss:0.016107460253866775\n",
      "train loss:0.0604222319383389\n",
      "train loss:0.01706573770263071\n",
      "train loss:0.03148766201093947\n",
      "train loss:0.006494259668964247\n",
      "train loss:0.008089608459114586\n",
      "train loss:0.01010376690976847\n",
      "train loss:0.03133485016494211\n",
      "train loss:0.005005364936085547\n",
      "train loss:0.06564703960166793\n",
      "train loss:0.04184620272455287\n",
      "train loss:0.03664677936065352\n",
      "train loss:0.030768339221650426\n",
      "train loss:0.002824696846476179\n",
      "train loss:0.030762488668573753\n",
      "train loss:0.01809418060758182\n",
      "train loss:0.060334728297170924\n",
      "train loss:0.03288825109168752\n",
      "train loss:0.017302268230791888\n",
      "train loss:0.004170505113699081\n",
      "train loss:0.033440917116832974\n",
      "train loss:0.006183882704772192\n",
      "train loss:0.009037448193679973\n",
      "train loss:0.07893305785650034\n",
      "train loss:0.023810082960226703\n",
      "train loss:0.00904282399963485\n",
      "train loss:0.15562355721421825\n",
      "train loss:0.014644212361650333\n",
      "train loss:0.006703909868493393\n",
      "train loss:0.034871964663530035\n",
      "train loss:0.053414925725847925\n",
      "train loss:0.013188831406461633\n",
      "train loss:0.04258345419069978\n",
      "train loss:0.03232917339170331\n",
      "train loss:0.018191686912287345\n",
      "train loss:0.059561273350405244\n",
      "train loss:0.009093351413455283\n",
      "train loss:0.0186869908097353\n",
      "train loss:0.007505699706019767\n",
      "train loss:0.004638141788970175\n",
      "train loss:0.020646826498033333\n",
      "train loss:0.026126959659767825\n",
      "train loss:0.04042229176687163\n",
      "train loss:0.014421874605256442\n",
      "train loss:0.03169108417484909\n",
      "train loss:0.008061768643760105\n",
      "train loss:0.018454220013742556\n",
      "train loss:0.03670521496083614\n",
      "train loss:0.01951903187387881\n",
      "train loss:0.018165415138032305\n",
      "train loss:0.052040821882484226\n",
      "train loss:0.0076380685526006645\n",
      "train loss:0.016294235390757618\n",
      "train loss:0.00969895003722605\n",
      "train loss:0.04135490191675898\n",
      "train loss:0.047236966059735756\n",
      "train loss:0.04740832601503757\n",
      "train loss:0.016229775963239264\n",
      "train loss:0.011838894308750278\n",
      "train loss:0.007283732277854326\n",
      "train loss:0.007204682212505169\n",
      "train loss:0.020243231834432593\n",
      "train loss:0.056136799257683875\n",
      "train loss:0.026797013449617567\n",
      "train loss:0.0987143622907159\n",
      "train loss:0.03036382165181262\n",
      "train loss:0.00659898974852819\n",
      "train loss:0.01912737994681569\n",
      "train loss:0.007542348292504667\n",
      "train loss:0.03116401690399895\n",
      "train loss:0.04705684193295326\n",
      "train loss:0.005825839747035656\n",
      "train loss:0.019474085301872716\n",
      "train loss:0.06495550165049739\n",
      "train loss:0.11062379599765562\n",
      "train loss:0.02570870940456214\n",
      "train loss:0.050851489630430284\n",
      "train loss:0.09143843177703039\n",
      "train loss:0.015207032632741811\n",
      "train loss:0.04159404226549219\n",
      "train loss:0.05190753491055312\n",
      "train loss:0.012421946695610602\n",
      "train loss:0.007627195161844645\n",
      "train loss:0.02116861477595148\n",
      "train loss:0.008475065808906342\n",
      "train loss:0.0033014502420812947\n",
      "train loss:0.012375982565514915\n",
      "train loss:0.030163700871805154\n",
      "train loss:0.029143882212162162\n",
      "train loss:0.011146825932304413\n",
      "train loss:0.003998289444149122\n",
      "train loss:0.018587714953892717\n",
      "train loss:0.014722479936521825\n",
      "train loss:0.027329576855632923\n",
      "train loss:0.03697437243789108\n",
      "train loss:0.03579325323664296\n",
      "train loss:0.011068598412477475\n",
      "train loss:0.016706528242889197\n",
      "train loss:0.040110937574344314\n",
      "train loss:0.10053142278620701\n",
      "train loss:0.007468053166904286\n",
      "train loss:0.004721602575173384\n",
      "train loss:0.023445842436885852\n",
      "train loss:0.01889726272226829\n",
      "train loss:0.008514263781688056\n",
      "train loss:0.013220219610989247\n",
      "train loss:0.01928720323077522\n",
      "train loss:0.047379864725123205\n",
      "train loss:0.012131003559300826\n",
      "train loss:0.02088636645573405\n",
      "train loss:0.03685100869572887\n",
      "train loss:0.004320443056071463\n",
      "train loss:0.012779970331625267\n",
      "train loss:0.05196786965257992\n",
      "train loss:0.00220475902428724\n",
      "train loss:0.011147563314581155\n",
      "train loss:0.013634085973792051\n",
      "train loss:0.025311837482646853\n",
      "train loss:0.021289254685858326\n",
      "train loss:0.006791195263026358\n",
      "train loss:0.018139496821088626\n",
      "train loss:0.01541522593874531\n",
      "train loss:0.028700250642407773\n",
      "train loss:0.018738489534987506\n",
      "train loss:0.017749142284799766\n",
      "train loss:0.04019125904929368\n",
      "train loss:0.029030361243712992\n",
      "train loss:0.017470089154782452\n",
      "train loss:0.026965968220618\n",
      "train loss:0.011772254949405642\n",
      "train loss:0.028763447967445902\n",
      "train loss:0.0036984290739607317\n",
      "train loss:0.0027098305304983357\n",
      "train loss:0.05773902011537875\n",
      "train loss:0.00780544725162889\n",
      "train loss:0.03864599572678111\n",
      "train loss:0.0027465931719983495\n",
      "train loss:0.011235991631541067\n",
      "train loss:0.007260174296807589\n",
      "train loss:0.0250644879230386\n",
      "train loss:0.05739414880775232\n",
      "train loss:0.003973331191660226\n",
      "train loss:0.0041755776076389944\n",
      "train loss:0.011187760860534577\n",
      "train loss:0.00938453599857253\n",
      "train loss:0.010214556321736356\n",
      "train loss:0.004127578220055358\n",
      "train loss:0.009304621773399385\n",
      "train loss:0.00764355995044413\n",
      "train loss:0.01629404780758894\n",
      "train loss:0.020201923054942526\n",
      "train loss:0.01973495456750815\n",
      "train loss:0.013603741695049283\n",
      "train loss:0.01726372479584523\n",
      "train loss:0.008644326354561764\n",
      "train loss:0.030537489048668688\n",
      "train loss:0.004579268686513389\n",
      "train loss:0.0251788516735053\n",
      "train loss:0.01109235042085883\n",
      "train loss:0.0075822491565889025\n",
      "train loss:0.0291711319651155\n",
      "train loss:0.023765918634791765\n",
      "train loss:0.007454365368624414\n",
      "train loss:0.024800042417793697\n",
      "train loss:0.025314831071472504\n",
      "train loss:0.029076772934078156\n",
      "train loss:0.012004424982537279\n",
      "train loss:0.010725260086364203\n",
      "train loss:0.04287662083221214\n",
      "train loss:0.03119508314663901\n",
      "train loss:0.039616447701255914\n",
      "train loss:0.02561812624669186\n",
      "train loss:0.023706406640600548\n",
      "train loss:0.007180589902205924\n",
      "train loss:0.0013465722298894825\n",
      "train loss:0.031138280759797833\n",
      "train loss:0.057665348855485174\n",
      "train loss:0.019736390019459135\n",
      "train loss:0.045215916509838916\n",
      "train loss:0.016775530062845243\n",
      "train loss:0.011361156200494119\n",
      "train loss:0.021169477038166278\n",
      "train loss:0.018119369048066027\n",
      "train loss:0.005735884072303267\n",
      "train loss:0.0036860218754521256\n",
      "train loss:0.02092621081459901\n",
      "train loss:0.009690896486249927\n",
      "train loss:0.04346967066864735\n",
      "train loss:0.01326509685410493\n",
      "train loss:0.003735871137127832\n",
      "train loss:0.0262095205866018\n",
      "train loss:0.00469282695456828\n",
      "train loss:0.068270536406575\n",
      "train loss:0.014217294223431116\n",
      "train loss:0.02757665007464714\n",
      "train loss:0.008080215080756643\n",
      "train loss:0.01813988480373435\n",
      "train loss:0.0077727185019157985\n",
      "train loss:0.007437160623902206\n",
      "train loss:0.005963279923176128\n",
      "train loss:0.07526607290625481\n",
      "train loss:0.03196771420253895\n",
      "train loss:0.01152401608417347\n",
      "train loss:0.007024320474009087\n",
      "train loss:0.004391605372976587\n",
      "train loss:0.017889392703233007\n",
      "train loss:0.0026290115159931173\n",
      "train loss:0.015886533087703398\n",
      "train loss:0.007578200966810047\n",
      "train loss:0.02788755302800938\n",
      "train loss:0.010933401733208128\n",
      "train loss:0.015469594897650357\n",
      "train loss:0.01180078824870104\n",
      "train loss:0.014729516292474376\n",
      "train loss:0.015645365353012933\n",
      "train loss:0.022526897141840016\n",
      "train loss:0.005991185348699759\n",
      "train loss:0.004884047555042532\n",
      "train loss:0.004644828063322269\n",
      "train loss:0.04852559467622946\n",
      "train loss:0.006434911389398332\n",
      "train loss:0.009898710872926762\n",
      "train loss:0.02992939451899095\n",
      "train loss:0.008604708678591578\n",
      "train loss:0.004020690245459398\n",
      "train loss:0.004769258260405086\n",
      "train loss:0.022869998709201766\n",
      "train loss:0.01684099042356916\n",
      "train loss:0.011745287785467072\n",
      "train loss:0.005625034176180155\n",
      "=== epoch:7, train acc:0.989, test acc:0.986 ===\n",
      "train loss:0.04182606843264833\n",
      "train loss:0.0022737113000174764\n",
      "train loss:0.02353100719795349\n",
      "train loss:0.002554211064026341\n",
      "train loss:0.002803340590733114\n",
      "train loss:0.08444152350404675\n",
      "train loss:0.013151517651463057\n",
      "train loss:0.045372219139010045\n",
      "train loss:0.012809170529028174\n",
      "train loss:0.004031342482409799\n",
      "train loss:0.04300123458212972\n",
      "train loss:0.005134537591236475\n",
      "train loss:0.0035939292309309858\n",
      "train loss:0.009865158694241198\n",
      "train loss:0.008789997779763695\n",
      "train loss:0.006514047739621172\n",
      "train loss:0.029377418074974616\n",
      "train loss:0.01798538506672648\n",
      "train loss:0.033099895588617576\n",
      "train loss:0.025112050158386863\n",
      "train loss:0.0036392139659288314\n",
      "train loss:0.006627648627430872\n",
      "train loss:0.004489489568341868\n",
      "train loss:0.008450461186658036\n",
      "train loss:0.016683902782964933\n",
      "train loss:0.009182663385251246\n",
      "train loss:0.020565345052303122\n",
      "train loss:0.005706773213948521\n",
      "train loss:0.012630536521249647\n",
      "train loss:0.00865984006561169\n",
      "train loss:0.035195376456161255\n",
      "train loss:0.0031267356861941586\n",
      "train loss:0.0625796622157194\n",
      "train loss:0.03295057151883522\n",
      "train loss:0.01867053387670688\n",
      "train loss:0.0017468878126605369\n",
      "train loss:0.01635933489874576\n",
      "train loss:0.008015621459153027\n",
      "train loss:0.043199854191908554\n",
      "train loss:0.028506500578227484\n",
      "train loss:0.011105317064662786\n",
      "train loss:0.02069096527667762\n",
      "train loss:0.0041560696858622395\n",
      "train loss:0.011852780960818616\n",
      "train loss:0.014717242813222928\n",
      "train loss:0.00803370715631549\n",
      "train loss:0.003271365132749002\n",
      "train loss:0.023349758017792276\n",
      "train loss:0.034010947090567914\n",
      "train loss:0.0074900581460383975\n",
      "train loss:0.0009770500582991445\n",
      "train loss:0.00481975254593818\n",
      "train loss:0.0374707331576655\n",
      "train loss:0.011719289902339008\n",
      "train loss:0.01890959717285183\n",
      "train loss:0.005370227652924641\n",
      "train loss:0.007033637730316396\n",
      "train loss:0.01715873843248354\n",
      "train loss:0.043053819605437374\n",
      "train loss:0.0028182315811782137\n",
      "train loss:0.013759471313812317\n",
      "train loss:0.08985952941136292\n",
      "train loss:0.004511229336536202\n",
      "train loss:0.005676681819355704\n",
      "train loss:0.010683642029592967\n",
      "train loss:0.006102460732868009\n",
      "train loss:0.004343929434984328\n",
      "train loss:0.006163814902852868\n",
      "train loss:0.030560620341350164\n",
      "train loss:0.02399562139448093\n",
      "train loss:0.009303101371931643\n",
      "train loss:0.01030328613667685\n",
      "train loss:0.019965297919470316\n",
      "train loss:0.008182440047912817\n",
      "train loss:0.002071644302227168\n",
      "train loss:0.007563968282689226\n",
      "train loss:0.009336795277307219\n",
      "train loss:0.021088218809882084\n",
      "train loss:0.014857072619566885\n",
      "train loss:0.014870449373211237\n",
      "train loss:0.013321493884664087\n",
      "train loss:0.047403743281161335\n",
      "train loss:0.016897944222580424\n",
      "train loss:0.0055132753596549245\n",
      "train loss:0.006484224672913102\n",
      "train loss:0.002210815461539254\n",
      "train loss:0.011748291585579457\n",
      "train loss:0.025599263451884045\n",
      "train loss:0.017820437131418208\n",
      "train loss:0.10983129326098634\n",
      "train loss:0.013308715020782786\n",
      "train loss:0.026926955400118212\n",
      "train loss:0.016634938472452558\n",
      "train loss:0.014632595342259181\n",
      "train loss:0.00550268319873721\n",
      "train loss:0.07178534632166762\n",
      "train loss:0.01718588807390927\n",
      "train loss:0.0077239204804347384\n",
      "train loss:0.0337631321115792\n",
      "train loss:0.004062357374827057\n",
      "train loss:0.00418258495449737\n",
      "train loss:0.04786496053165847\n",
      "train loss:0.014008842895180465\n",
      "train loss:0.035859218794201085\n",
      "train loss:0.005007391623673519\n",
      "train loss:0.009119315596040846\n",
      "train loss:0.013739606082940892\n",
      "train loss:0.034801622589209866\n",
      "train loss:0.00509699387850587\n",
      "train loss:0.010014680222699364\n",
      "train loss:0.031287468830334536\n",
      "train loss:0.06449435884663851\n",
      "train loss:0.008101968092061767\n",
      "train loss:0.03359702299584904\n",
      "train loss:0.008285389796213495\n",
      "train loss:0.014480457183165324\n",
      "train loss:0.027748176358589755\n",
      "train loss:0.02172325629947687\n",
      "train loss:0.01033235278629165\n",
      "train loss:0.0036876750262986873\n",
      "train loss:0.04118022730866267\n",
      "train loss:0.007089027882886729\n",
      "train loss:0.044041849975426414\n",
      "train loss:0.013357553280821716\n",
      "train loss:0.05646434175790385\n",
      "train loss:0.05877240592256272\n",
      "train loss:0.010544425109833411\n",
      "train loss:0.01350605558172969\n",
      "train loss:0.003425759854636338\n",
      "train loss:0.05982523911146046\n",
      "train loss:0.006379414355894325\n",
      "train loss:0.043596332072154326\n",
      "train loss:0.015021380113677714\n",
      "train loss:0.023304540145936737\n",
      "train loss:0.016242754165820147\n",
      "train loss:0.0455525883861441\n",
      "train loss:0.011968822984873326\n",
      "train loss:0.010258264543631617\n",
      "train loss:0.013788080689865496\n",
      "train loss:0.002695030719545538\n",
      "train loss:0.015998118087675775\n",
      "train loss:0.0038013494194705853\n",
      "train loss:0.029434592666743007\n",
      "train loss:0.022575640648109272\n",
      "train loss:0.017221965557429057\n",
      "train loss:0.00647088271454828\n",
      "train loss:0.012456606725471267\n",
      "train loss:0.0030694295547368257\n",
      "train loss:0.006691680332484629\n",
      "train loss:0.00660417546480916\n",
      "train loss:0.034206660176841194\n",
      "train loss:0.015458340669496275\n",
      "train loss:0.00824064779517383\n",
      "train loss:0.0067062138034593675\n",
      "train loss:0.0067684471192769845\n",
      "train loss:0.004979990746910882\n",
      "train loss:0.0033237813684104268\n",
      "train loss:0.012068142808338402\n",
      "train loss:0.007901966710586496\n",
      "train loss:0.012881107721457119\n",
      "train loss:0.011963946532985839\n",
      "train loss:0.0020230031914306983\n",
      "train loss:0.022374955629336366\n",
      "train loss:0.014404021788546653\n",
      "train loss:0.006899390479995157\n",
      "train loss:0.008472945703859645\n",
      "train loss:0.027121319783395638\n",
      "train loss:0.0022251724162350105\n",
      "train loss:0.012159841019393783\n",
      "train loss:0.0157368868519394\n",
      "train loss:0.004411666026765653\n",
      "train loss:0.004890742127484006\n",
      "train loss:0.020050619603562757\n",
      "train loss:0.0019242531661897233\n",
      "train loss:0.0017307114602679826\n",
      "train loss:0.002156128866871283\n",
      "train loss:0.02408151725394081\n",
      "train loss:0.002969891038367086\n",
      "train loss:0.004347575709657158\n",
      "train loss:0.01116058157476093\n",
      "train loss:0.006217093579345182\n",
      "train loss:0.0019871883704123397\n",
      "train loss:0.011266009430179596\n",
      "train loss:0.023666860606142183\n",
      "train loss:0.0266524024779914\n",
      "train loss:0.006765621987687853\n",
      "train loss:0.035425528577844624\n",
      "train loss:0.003175907513833942\n",
      "train loss:0.019518932131981546\n",
      "train loss:0.028083530654540025\n",
      "train loss:0.02461530301489523\n",
      "train loss:0.006720899482226597\n",
      "train loss:0.007668522582075986\n",
      "train loss:0.014306693641904058\n",
      "train loss:0.011117670843130175\n",
      "train loss:0.020805630994273745\n",
      "train loss:0.0026755554930848325\n",
      "train loss:0.007681273002583133\n",
      "train loss:0.013846282578212892\n",
      "train loss:0.026646161359874028\n",
      "train loss:0.0037991035050097873\n",
      "train loss:0.0024511778264964773\n",
      "train loss:0.0041212305762649585\n",
      "train loss:0.006632384516685269\n",
      "train loss:0.00710172507910877\n",
      "train loss:0.0038274440772420983\n",
      "train loss:0.007565310511632681\n",
      "train loss:0.004301291170351695\n",
      "train loss:0.006710689274419459\n",
      "train loss:0.0037128790845836657\n",
      "train loss:0.030824861936028493\n",
      "train loss:0.053161263295494955\n",
      "train loss:0.016857959887450806\n",
      "train loss:0.005052747180388501\n",
      "train loss:0.014526275588093267\n",
      "train loss:0.02437786192872485\n",
      "train loss:0.004573542271530713\n",
      "train loss:0.028050763686360947\n",
      "train loss:0.004334847332826393\n",
      "train loss:0.024708724437401176\n",
      "train loss:0.006530301174046738\n",
      "train loss:0.012763583791373743\n",
      "train loss:0.038359462508218416\n",
      "train loss:0.005536985812628724\n",
      "train loss:0.024902928743146865\n",
      "train loss:0.01798968023392976\n",
      "train loss:0.006717568061091976\n",
      "train loss:0.041524712875645006\n",
      "train loss:0.014174805464615699\n",
      "train loss:0.08214060443125414\n",
      "train loss:0.011099982302255925\n",
      "train loss:0.02853246373989361\n",
      "train loss:0.06841509449019982\n",
      "train loss:0.014573414996174837\n",
      "train loss:0.017775571367675883\n",
      "train loss:0.040948592108103296\n",
      "train loss:0.020540353962579933\n",
      "train loss:0.017886509952558294\n",
      "train loss:0.03946523658352129\n",
      "train loss:0.0794544286536893\n",
      "train loss:0.023903755099576797\n",
      "train loss:0.0037793757919300465\n",
      "train loss:0.006487057370222491\n",
      "train loss:0.009976850678432915\n",
      "train loss:0.010545584014255599\n",
      "train loss:0.014212017890532556\n",
      "train loss:0.006245002882679908\n",
      "train loss:0.07405732766203203\n",
      "train loss:0.008865393117530821\n",
      "train loss:0.02448770468563568\n",
      "train loss:0.02125566163781547\n",
      "train loss:0.006794083530283477\n",
      "train loss:0.01615528418083523\n",
      "train loss:0.009778062728163757\n",
      "train loss:0.021522829130101003\n",
      "train loss:0.017379455619446326\n",
      "train loss:0.008228956531759129\n",
      "train loss:0.056084578384555835\n",
      "train loss:0.01903360320670383\n",
      "train loss:0.01677889170592637\n",
      "train loss:0.019381910778800325\n",
      "train loss:0.007898733650514146\n",
      "train loss:0.01648740165156367\n",
      "train loss:0.011107361116229564\n",
      "train loss:0.019780029250383007\n",
      "train loss:0.022560865309241285\n",
      "train loss:0.019312364245530147\n",
      "train loss:0.006873629747205068\n",
      "train loss:0.004227110386200563\n",
      "train loss:0.018998075931993166\n",
      "train loss:0.01675191523984748\n",
      "train loss:0.024882644716701745\n",
      "train loss:0.004570803186447226\n",
      "train loss:0.013471945181496128\n",
      "train loss:0.025502276895895713\n",
      "train loss:0.014220156837328732\n",
      "train loss:0.007587313365368184\n",
      "train loss:0.015855933253502864\n",
      "train loss:0.005182347184381688\n",
      "train loss:0.08194562801232225\n",
      "train loss:0.006125638817555234\n",
      "train loss:0.014148702135876547\n",
      "train loss:0.02366397337280727\n",
      "train loss:0.0203874546642622\n",
      "train loss:0.00845587298768415\n",
      "train loss:0.021809773949863383\n",
      "train loss:0.011894606927407785\n",
      "train loss:0.025459649535208195\n",
      "train loss:0.011182256289930512\n",
      "train loss:0.07249498581885186\n",
      "train loss:0.021272469348293393\n",
      "train loss:0.011232878175948022\n",
      "train loss:0.010507709661638094\n",
      "train loss:0.06663992893425964\n",
      "train loss:0.047327226069747846\n",
      "train loss:0.010529979350381816\n",
      "train loss:0.005467247534567058\n",
      "train loss:0.004918882023916355\n",
      "train loss:0.006384141939505535\n",
      "train loss:0.014253820184176395\n",
      "train loss:0.004720418285093916\n",
      "train loss:0.005376294700919048\n",
      "train loss:0.012727097476622802\n",
      "train loss:0.015160028263718841\n",
      "train loss:0.035411123650329605\n",
      "train loss:0.0061254220991788875\n",
      "train loss:0.02493778586849455\n",
      "train loss:0.059123924552427994\n",
      "train loss:0.0069067211021472084\n",
      "train loss:0.006131105490351469\n",
      "train loss:0.02239400156210871\n",
      "train loss:0.0023332221329354194\n",
      "train loss:0.018939219073644552\n",
      "train loss:0.0060566745983320295\n",
      "train loss:0.013920728087321532\n",
      "train loss:0.014499213878544779\n",
      "train loss:0.011649798044773663\n",
      "train loss:0.01456353011386842\n",
      "train loss:0.014976026536840714\n",
      "train loss:0.04310099205120027\n",
      "train loss:0.006010728476636382\n",
      "train loss:0.004619622838825109\n",
      "train loss:0.007977801103699155\n",
      "train loss:0.013768134037991571\n",
      "train loss:0.030099947182386844\n",
      "train loss:0.004788767766842352\n",
      "train loss:0.023770736743366015\n",
      "train loss:0.02238371751373613\n",
      "train loss:0.03251102836032136\n",
      "train loss:0.01625103744841996\n",
      "train loss:0.010533445296566614\n",
      "train loss:0.04686202462765559\n",
      "train loss:0.03251623771664776\n",
      "train loss:0.007101316098878276\n",
      "train loss:0.034077139196237095\n",
      "train loss:0.0009671022070543712\n",
      "train loss:0.013711504359728278\n",
      "train loss:0.010160798398489412\n",
      "train loss:0.017736796259893925\n",
      "train loss:0.008338509997493195\n",
      "train loss:0.0005381982203233037\n",
      "train loss:0.01370125831152329\n",
      "train loss:0.004546814265015537\n",
      "train loss:0.012379898416385341\n",
      "train loss:0.008640035602362253\n",
      "train loss:0.0029936312342312456\n",
      "train loss:0.019018048331685355\n",
      "train loss:0.049539890048313905\n",
      "train loss:0.010308720890805693\n",
      "train loss:0.013485775799302808\n",
      "train loss:0.012376845907497158\n",
      "train loss:0.015919246360573906\n",
      "train loss:0.01174383831455216\n",
      "train loss:0.009942958538737686\n",
      "train loss:0.06724633569124794\n",
      "train loss:0.020567032712005603\n",
      "train loss:0.002486450858920578\n",
      "train loss:0.008811894211544487\n",
      "train loss:0.019118023749490228\n",
      "train loss:0.009388361687297321\n",
      "train loss:0.006455523661309017\n",
      "train loss:0.04772064431744039\n",
      "train loss:0.027429791440403167\n",
      "train loss:0.009511183167426444\n",
      "train loss:0.03095394283612287\n",
      "train loss:0.012726934258369784\n",
      "train loss:0.010150346162303203\n",
      "train loss:0.0018391617050943381\n",
      "train loss:0.10182390479480867\n",
      "train loss:0.009100424491360238\n",
      "train loss:0.03410064321168058\n",
      "train loss:0.00591569506563398\n",
      "train loss:0.05108466877986921\n",
      "train loss:0.0075819794325856435\n",
      "train loss:0.009395032623902346\n",
      "train loss:0.005534131939670281\n",
      "train loss:0.020943930331488402\n",
      "train loss:0.009932520895141796\n",
      "train loss:0.0050374285139472095\n",
      "train loss:0.008122848044623616\n",
      "train loss:0.039012186971954896\n",
      "train loss:0.011851916036948174\n",
      "train loss:0.004037644671988948\n",
      "train loss:0.03677274237975532\n",
      "train loss:0.0055681302988889615\n",
      "train loss:0.031454810384710624\n",
      "train loss:0.005579620726972601\n",
      "train loss:0.006555536073604012\n",
      "train loss:0.02148315013854336\n",
      "train loss:0.021252855987128984\n",
      "train loss:0.005205265020067054\n",
      "train loss:0.004806635027792432\n",
      "train loss:0.06478838505552742\n",
      "train loss:0.03232301251619291\n",
      "train loss:0.027094284321711713\n",
      "train loss:0.0032630983932706646\n",
      "train loss:0.008542197021890647\n",
      "train loss:0.007668845558123388\n",
      "train loss:0.01155236194336031\n",
      "train loss:0.006583846588059978\n",
      "train loss:0.02924603814760079\n",
      "train loss:0.010839629427944532\n",
      "train loss:0.0026739260774517127\n",
      "train loss:0.03321105316920058\n",
      "train loss:0.016584830677673818\n",
      "train loss:0.018260239982208853\n",
      "train loss:0.08443840292928595\n",
      "train loss:0.004757835375350312\n",
      "train loss:0.008253651815639104\n",
      "train loss:0.008491941195438156\n",
      "train loss:0.006981644175170718\n",
      "train loss:0.009937558668308\n",
      "train loss:0.03628490083067668\n",
      "train loss:0.03514998185590687\n",
      "train loss:0.002374438940859797\n",
      "train loss:0.0028581068216039594\n",
      "train loss:0.003288585525201375\n",
      "train loss:0.010433884523964577\n",
      "train loss:0.03693693102278545\n",
      "train loss:0.0007389707108024443\n",
      "train loss:0.004577514113783534\n",
      "train loss:0.003218691867159329\n",
      "train loss:0.020341655484944356\n",
      "train loss:0.008210632313725227\n",
      "train loss:0.016164893344503873\n",
      "train loss:0.001690111266921107\n",
      "train loss:0.010235329402045237\n",
      "train loss:0.005716035129057831\n",
      "train loss:0.02460803145742932\n",
      "train loss:0.0024251236851987527\n",
      "train loss:0.03200688214877795\n",
      "train loss:0.012664559509511675\n",
      "train loss:0.006999926511785775\n",
      "train loss:0.0022572563718805793\n",
      "train loss:0.06139752575175345\n",
      "train loss:0.02224122296246004\n",
      "train loss:0.018520860275714913\n",
      "train loss:0.018567254495259474\n",
      "train loss:0.006045846322939013\n",
      "train loss:0.004524518226532982\n",
      "train loss:0.020251832316394013\n",
      "train loss:0.007351308474174546\n",
      "train loss:0.01380582201679976\n",
      "train loss:0.017667964742430063\n",
      "train loss:0.014572379535727147\n",
      "train loss:0.008257845162559528\n",
      "train loss:0.015252343788782626\n",
      "train loss:0.005456954536530884\n",
      "train loss:0.014705082115909223\n",
      "train loss:0.010673367087358603\n",
      "train loss:0.0034861172877009377\n",
      "train loss:0.010691025186812628\n",
      "train loss:0.010764562704633733\n",
      "train loss:0.0045943549107809924\n",
      "train loss:0.04719190707532584\n",
      "train loss:0.0058749849742703066\n",
      "train loss:0.00430724332156585\n",
      "train loss:0.012777938262727167\n",
      "train loss:0.022216699361054464\n",
      "train loss:0.0072912603857935585\n",
      "train loss:0.00809737955762903\n",
      "train loss:0.03544110594537625\n",
      "train loss:0.015977428158040194\n",
      "train loss:0.02440757955093702\n",
      "train loss:0.019005312379869327\n",
      "train loss:0.00439698346648223\n",
      "train loss:0.011550669761854124\n",
      "train loss:0.0025430024482616153\n",
      "train loss:0.028378148304764202\n",
      "train loss:0.004636260065545306\n",
      "train loss:0.011061558227725936\n",
      "train loss:0.027953398162606793\n",
      "train loss:0.0033444348560090487\n",
      "train loss:0.003202919639585084\n",
      "train loss:0.07279052970992071\n",
      "train loss:0.007108872113238846\n",
      "train loss:0.019126293451848887\n",
      "train loss:0.019856198868743926\n",
      "train loss:0.03125081786567409\n",
      "train loss:0.026266832390689245\n",
      "train loss:0.01912160459443184\n",
      "train loss:0.004600896067261547\n",
      "train loss:0.007088742216068423\n",
      "train loss:0.004898403168121288\n",
      "train loss:0.015138284983838521\n",
      "train loss:0.015367405124786754\n",
      "train loss:0.01909353191169919\n",
      "train loss:0.029974474122731683\n",
      "train loss:0.032693148559813645\n",
      "train loss:0.02076426949355241\n",
      "train loss:0.011131353128556357\n",
      "train loss:0.00752304154594344\n",
      "train loss:0.0023832488780744674\n",
      "train loss:0.020253858571230923\n",
      "train loss:0.004670035742352183\n",
      "train loss:0.011092098738133391\n",
      "train loss:0.01694044750547622\n",
      "train loss:0.013001948474857144\n",
      "train loss:0.01219220091106868\n",
      "train loss:0.0033146959252278725\n",
      "train loss:0.04842353767681774\n",
      "train loss:0.008270228942935007\n",
      "train loss:0.06862546641525143\n",
      "train loss:0.0066242972275886184\n",
      "train loss:0.00368634156613226\n",
      "train loss:0.009067608207586677\n",
      "train loss:0.00787298608632311\n",
      "train loss:0.0016015098845032336\n",
      "train loss:0.01666081373314919\n",
      "train loss:0.0639523334337491\n",
      "train loss:0.008390476712118537\n",
      "train loss:0.008039211158789885\n",
      "train loss:0.011132282316853016\n",
      "train loss:0.007550049674813103\n",
      "train loss:0.007817693492961901\n",
      "train loss:0.0006835116931396849\n",
      "train loss:0.02864023264429502\n",
      "train loss:0.015854058149793147\n",
      "train loss:0.0012319892563728623\n",
      "train loss:0.022553202406018755\n",
      "train loss:0.014014823368166087\n",
      "train loss:0.002849710757780086\n",
      "train loss:0.06734890560900535\n",
      "train loss:0.01673887856185155\n",
      "train loss:0.015180912431112456\n",
      "train loss:0.016292550853353592\n",
      "train loss:0.07287195019112708\n",
      "train loss:0.064801623668626\n",
      "train loss:0.06585617578057978\n",
      "train loss:0.0343936535464563\n",
      "train loss:0.009939325227344517\n",
      "train loss:0.06671913227867571\n",
      "train loss:0.011894543808012295\n",
      "train loss:0.027109218814233803\n",
      "train loss:0.03467261864545397\n",
      "train loss:0.010830763789503244\n",
      "train loss:0.011401793621236452\n",
      "train loss:0.019470287938776955\n",
      "train loss:0.016022051356071213\n",
      "train loss:0.01810814334615505\n",
      "train loss:0.005062354065220665\n",
      "train loss:0.01322765431368952\n",
      "train loss:0.02723475711913145\n",
      "train loss:0.06845647369164898\n",
      "train loss:0.0070419019490740465\n",
      "train loss:0.028127264196145436\n",
      "train loss:0.004533696990496829\n",
      "train loss:0.0037390339565796225\n",
      "train loss:0.00806136939579262\n",
      "train loss:0.04147582147104524\n",
      "train loss:0.01336736840907654\n",
      "train loss:0.0013876548197516393\n",
      "train loss:0.003303808480644787\n",
      "train loss:0.008077881919322915\n",
      "train loss:0.006843444757226583\n",
      "train loss:0.0038650439816100834\n",
      "train loss:0.004886852016012302\n",
      "train loss:0.03418773616011395\n",
      "train loss:0.005286766979712969\n",
      "train loss:0.00500684679256965\n",
      "train loss:0.04445950187261414\n",
      "train loss:0.01063094228292992\n",
      "train loss:0.014815239881733205\n",
      "train loss:0.010775728172263646\n",
      "train loss:0.0052935010599504066\n",
      "train loss:0.01296569246811735\n",
      "train loss:0.03860326507709363\n",
      "train loss:0.005257194205792036\n",
      "train loss:0.01781910760013933\n",
      "train loss:0.002466537897280062\n",
      "train loss:0.020820662549869744\n",
      "train loss:0.03415942223020971\n",
      "train loss:0.029391293060580213\n",
      "train loss:0.004508339930306376\n",
      "train loss:0.005318687784008166\n",
      "train loss:0.008749193467808126\n",
      "train loss:0.011314503780405112\n",
      "train loss:0.00286787041574947\n",
      "train loss:0.050829143125349134\n",
      "train loss:0.0070727803404908385\n",
      "train loss:0.01241084152571216\n",
      "train loss:0.005011255045707065\n",
      "train loss:0.014263559876600525\n",
      "train loss:0.008564910378660518\n",
      "train loss:0.01725199797090424\n",
      "train loss:0.009035515627607103\n",
      "train loss:0.01039303539118979\n",
      "train loss:0.016826932518353172\n",
      "train loss:0.005433338940486585\n",
      "train loss:0.014810646589992822\n",
      "train loss:0.005160509926387421\n",
      "train loss:0.00619569216469446\n",
      "train loss:0.03128452822079173\n",
      "train loss:0.006016914638941821\n",
      "train loss:0.005865898889155249\n",
      "train loss:0.007734373892158086\n",
      "train loss:0.006264813050411905\n",
      "train loss:0.06815051274310097\n",
      "train loss:0.017692449058631942\n",
      "train loss:0.01039754115914331\n",
      "=== epoch:8, train acc:0.993, test acc:0.99 ===\n",
      "train loss:0.003355563037147459\n",
      "train loss:0.026747035525262423\n",
      "train loss:0.0035400804855051987\n",
      "train loss:0.004102918767854141\n",
      "train loss:0.0071318671280653\n",
      "train loss:0.009509265477164153\n",
      "train loss:0.018469382735852025\n",
      "train loss:0.009577229632220732\n",
      "train loss:0.0044367817585967044\n",
      "train loss:0.0061431104313996844\n",
      "train loss:0.007636651443348484\n",
      "train loss:0.023813021979929818\n",
      "train loss:0.01670637892877547\n",
      "train loss:0.010193822014814669\n",
      "train loss:0.026469563385471986\n",
      "train loss:0.029145687969180566\n",
      "train loss:0.011442107427391424\n",
      "train loss:0.001554159313579413\n",
      "train loss:0.01080799929136053\n",
      "train loss:0.0037933312472227844\n",
      "train loss:0.009853588561142606\n",
      "train loss:0.022731091940129757\n",
      "train loss:0.004779478181433692\n",
      "train loss:0.007523455144155581\n",
      "train loss:0.005310974114579576\n",
      "train loss:0.04035865669231655\n",
      "train loss:0.012047841318416123\n",
      "train loss:0.0036564180929295697\n",
      "train loss:0.006280677802087944\n",
      "train loss:0.024301732701713607\n",
      "train loss:0.003651036856273656\n",
      "train loss:0.003919919783000483\n",
      "train loss:0.00795739915977638\n",
      "train loss:0.021300689705400475\n",
      "train loss:0.023694922677728734\n",
      "train loss:0.009259904335960445\n",
      "train loss:0.006438010955052618\n",
      "train loss:0.00756945469902491\n",
      "train loss:0.007069568499103096\n",
      "train loss:0.014087478456422822\n",
      "train loss:0.015035950050113107\n",
      "train loss:0.010315063348661778\n",
      "train loss:0.0067782700112900395\n",
      "train loss:0.015500413053453843\n",
      "train loss:0.01941638618775278\n",
      "train loss:0.0023053838208988557\n",
      "train loss:0.0011999960539855654\n",
      "train loss:0.02607270810504098\n",
      "train loss:0.00938320693817413\n",
      "train loss:0.0036401594458838338\n",
      "train loss:0.05702849087385497\n",
      "train loss:0.0038372768632310493\n",
      "train loss:0.02390513940394634\n",
      "train loss:0.0026167284417020036\n",
      "train loss:0.005801955426616133\n",
      "train loss:0.034402379978117806\n",
      "train loss:0.0038181302413164975\n",
      "train loss:0.012070174445249089\n",
      "train loss:0.0023400975493990195\n",
      "train loss:0.001540429965823324\n",
      "train loss:0.08395097311899549\n",
      "train loss:0.026932507509429014\n",
      "train loss:0.024350519198455482\n",
      "train loss:0.01523684079937937\n",
      "train loss:0.03446707874669761\n",
      "train loss:0.01689167741126147\n",
      "train loss:0.011487352913370547\n",
      "train loss:0.046072712421629955\n",
      "train loss:0.006836687429364793\n",
      "train loss:0.036538018606244185\n",
      "train loss:0.00429193075183387\n",
      "train loss:0.015882512172398583\n",
      "train loss:0.006527104452642069\n",
      "train loss:0.007260743613783107\n",
      "train loss:0.001506477962155603\n",
      "train loss:0.026930702121884625\n",
      "train loss:0.02082059237687254\n",
      "train loss:0.022810314559385383\n",
      "train loss:0.007861968671298476\n",
      "train loss:0.008508203496506423\n",
      "train loss:0.03043768324945533\n",
      "train loss:0.012668365478478433\n",
      "train loss:0.006310720351176822\n",
      "train loss:0.0037749005900596833\n",
      "train loss:0.013597790278736789\n",
      "train loss:0.0020770224223906207\n",
      "train loss:0.011006681695723672\n",
      "train loss:0.008287564703960627\n",
      "train loss:0.02606542681123338\n",
      "train loss:0.006932089065833344\n",
      "train loss:0.007354079203448748\n",
      "train loss:0.0646701526402793\n",
      "train loss:0.004886510951801851\n",
      "train loss:0.015446806213986307\n",
      "train loss:0.014888064957911016\n",
      "train loss:0.019697008428311763\n",
      "train loss:0.007544402996570038\n",
      "train loss:0.00834639370117867\n",
      "train loss:0.0027444545818203856\n",
      "train loss:0.013970494216038767\n",
      "train loss:0.007610540463853471\n",
      "train loss:0.006464990778959969\n",
      "train loss:0.012520905091285079\n",
      "train loss:0.006045933475285763\n",
      "train loss:0.01628467626671714\n",
      "train loss:0.010713843707919744\n",
      "train loss:0.026795285497833814\n",
      "train loss:0.024744868548765828\n",
      "train loss:0.00626773877232968\n",
      "train loss:0.001886210756617017\n",
      "train loss:0.004681147735925046\n",
      "train loss:0.007662107683455608\n",
      "train loss:0.009168306558884261\n",
      "train loss:0.015882062135962747\n",
      "train loss:0.0034384250114162743\n",
      "train loss:0.005414469776076252\n",
      "train loss:0.010700049243765051\n",
      "train loss:0.007851317222988282\n",
      "train loss:0.004175982102411432\n",
      "train loss:0.01113849288906181\n",
      "train loss:0.033260055976950614\n",
      "train loss:0.03538136096314343\n",
      "train loss:0.003499312332937986\n",
      "train loss:0.0573650759039975\n",
      "train loss:0.001633592960384516\n",
      "train loss:0.027860197915872863\n",
      "train loss:0.014649815533208653\n",
      "train loss:0.00802582160065665\n",
      "train loss:0.005182663852837817\n",
      "train loss:0.0027057540064062\n",
      "train loss:0.03783414728067223\n",
      "train loss:0.0023141130175309576\n",
      "train loss:0.015577272859324304\n",
      "train loss:0.09654084550963903\n",
      "train loss:0.005627608649250684\n",
      "train loss:0.005414525478951359\n",
      "train loss:0.00699979514665146\n",
      "train loss:0.01916986549255692\n",
      "train loss:0.009344463508353041\n",
      "train loss:0.00824307431136869\n",
      "train loss:0.008693715062454596\n",
      "train loss:0.007357628796464406\n",
      "train loss:0.0030940524695218592\n",
      "train loss:0.00519736479980259\n",
      "train loss:0.017827772394638355\n",
      "train loss:0.017579312259629904\n",
      "train loss:0.018487985554940793\n",
      "train loss:0.005469769786645762\n",
      "train loss:0.009748712925598918\n",
      "train loss:0.011022907428763835\n",
      "train loss:0.007778349132694108\n",
      "train loss:0.005342161751588957\n",
      "train loss:0.05227291507011765\n",
      "train loss:0.06120601908093452\n",
      "train loss:0.01184622972715616\n",
      "train loss:0.004128592667398171\n",
      "train loss:0.046637769690587666\n",
      "train loss:0.006382130988649834\n",
      "train loss:0.03982253484123055\n",
      "train loss:0.006568166644311066\n",
      "train loss:0.00820447315145277\n",
      "train loss:0.01823087733817412\n",
      "train loss:0.009239848323928268\n",
      "train loss:0.0017493421029492768\n",
      "train loss:0.006632562357075508\n",
      "train loss:0.0024065151517101598\n",
      "train loss:0.009450501315917332\n",
      "train loss:0.011541362657380934\n",
      "train loss:0.006532166838569134\n",
      "train loss:0.0035771733896027696\n",
      "train loss:0.01881922608926694\n",
      "train loss:0.012426090957359033\n",
      "train loss:0.004364124200164198\n",
      "train loss:0.0032465762522686896\n",
      "train loss:0.08104550876360442\n",
      "train loss:0.019862502495211543\n",
      "train loss:0.00477512731381461\n",
      "train loss:0.03554772416624624\n",
      "train loss:0.013790368000561645\n",
      "train loss:0.03009177809213891\n",
      "train loss:0.02380120810412313\n",
      "train loss:0.014818669580592055\n",
      "train loss:0.010308784113838964\n",
      "train loss:0.01714022148583195\n",
      "train loss:0.01546481650209994\n",
      "train loss:0.017557161986891792\n",
      "train loss:0.0031070167335102627\n",
      "train loss:0.0032948137713669223\n",
      "train loss:0.002408315063521393\n",
      "train loss:0.0021711246938388743\n",
      "train loss:0.019265030590026475\n",
      "train loss:0.0026867656495731455\n",
      "train loss:0.004528549009032427\n",
      "train loss:0.09273925921377449\n",
      "train loss:0.0009185924482388899\n",
      "train loss:0.06398339224793057\n",
      "train loss:0.012003114439264493\n",
      "train loss:0.0030684395307779035\n",
      "train loss:0.007404703506160827\n",
      "train loss:0.01346397912202443\n",
      "train loss:0.03936058402615235\n",
      "train loss:0.002554373089230721\n",
      "train loss:0.02925079827701625\n",
      "train loss:0.003878820573198522\n",
      "train loss:0.07976050169780423\n",
      "train loss:0.0031865698543804876\n",
      "train loss:0.006508363161834725\n",
      "train loss:0.005660787215359699\n",
      "train loss:0.011569682795229732\n",
      "train loss:0.014113716063606079\n",
      "train loss:0.027470874222798702\n",
      "train loss:0.012261325095942204\n",
      "train loss:0.013908181673992482\n",
      "train loss:0.0028725411003031947\n",
      "train loss:0.047753759702836074\n",
      "train loss:0.011464389320019207\n",
      "train loss:0.0064525593069776795\n",
      "train loss:0.016045810540130757\n",
      "train loss:0.0008618331775071622\n",
      "train loss:0.016047505981615785\n",
      "train loss:0.0033682456966459572\n",
      "train loss:0.03132432035490495\n",
      "train loss:0.007095467476725088\n",
      "train loss:0.025823028979106\n",
      "train loss:0.015534154931980076\n",
      "train loss:0.007238769811996294\n",
      "train loss:0.10004925048503704\n",
      "train loss:0.04145194145944711\n",
      "train loss:0.007027608020794119\n",
      "train loss:0.0013532436156139238\n",
      "train loss:0.005285260396770011\n",
      "train loss:0.023769469719536668\n",
      "train loss:0.005334372901068336\n",
      "train loss:0.003042643678523466\n",
      "train loss:0.012578403092723577\n",
      "train loss:0.0034904242843544274\n",
      "train loss:0.0035816656844182564\n",
      "train loss:0.018200699885683787\n",
      "train loss:0.01350118524518474\n",
      "train loss:0.019900484286314\n",
      "train loss:0.0055993003704048585\n",
      "train loss:0.005346066001823977\n",
      "train loss:0.0035444840987406013\n",
      "train loss:0.012727718158973339\n",
      "train loss:0.00803031203155962\n",
      "train loss:0.01226679479095057\n",
      "train loss:0.008064943051130454\n",
      "train loss:0.00826895954875342\n",
      "train loss:0.016918139623346273\n",
      "train loss:0.005757556740507355\n",
      "train loss:0.010806353916676788\n",
      "train loss:0.01294301904343095\n",
      "train loss:0.01253560709716818\n",
      "train loss:0.0015135702079467422\n",
      "train loss:0.01011412955319034\n",
      "train loss:0.018338623981429145\n",
      "train loss:0.01962103730889282\n",
      "train loss:0.008386287084748872\n",
      "train loss:0.029404805290056908\n",
      "train loss:0.003833321911078065\n",
      "train loss:0.005564909023778316\n",
      "train loss:0.002690110863420857\n",
      "train loss:0.054483887031266685\n",
      "train loss:0.0021783931812762933\n",
      "train loss:0.009653519874658324\n",
      "train loss:0.0006819602940718029\n",
      "train loss:0.002565770045149898\n",
      "train loss:0.01119468970229284\n",
      "train loss:0.014887669784633364\n",
      "train loss:0.02237844249026558\n",
      "train loss:0.005240405248817224\n",
      "train loss:0.005229799735307113\n",
      "train loss:0.046586881433899024\n",
      "train loss:0.040872755070423164\n",
      "train loss:0.0015923615811024943\n",
      "train loss:0.019492264645667844\n",
      "train loss:0.06180734341211804\n",
      "train loss:0.04545215511337815\n",
      "train loss:0.0059767810769423245\n",
      "train loss:0.021518708322466898\n",
      "train loss:0.010621892402836336\n",
      "train loss:0.0555103650484909\n",
      "train loss:0.008904353117089803\n",
      "train loss:0.006874058951067574\n",
      "train loss:0.004410385843120769\n",
      "train loss:0.012383702772133189\n",
      "train loss:0.0025368050185258723\n",
      "train loss:0.017317211941629856\n",
      "train loss:0.059008469822133806\n",
      "train loss:0.0017985252172513998\n",
      "train loss:0.003785162554074564\n",
      "train loss:0.01405382400946089\n",
      "train loss:0.008261328441836826\n",
      "train loss:0.029505488178426676\n",
      "train loss:0.005948891919154353\n",
      "train loss:0.0034024779854473206\n",
      "train loss:0.0033958987021006563\n",
      "train loss:0.01632935607604167\n",
      "train loss:0.009686637369412056\n",
      "train loss:0.00878693516522185\n",
      "train loss:0.030699447511761156\n",
      "train loss:0.0016750069079163757\n",
      "train loss:0.007923121665503652\n",
      "train loss:0.02555388099656498\n",
      "train loss:0.004197763382375636\n",
      "train loss:0.004282289465325975\n",
      "train loss:0.002324989291414566\n",
      "train loss:0.007357520634644657\n",
      "train loss:0.0014815222511066718\n",
      "train loss:0.018490178026854855\n",
      "train loss:0.0037357127418369616\n",
      "train loss:0.004505391911569537\n",
      "train loss:0.01696399354487075\n",
      "train loss:0.0050990810302283095\n",
      "train loss:0.0021563887034738924\n",
      "train loss:0.03874449339253772\n",
      "train loss:0.01841018251865048\n",
      "train loss:0.023280206505646536\n",
      "train loss:0.003627239838572482\n",
      "train loss:0.01031378843301372\n",
      "train loss:0.005274067507550888\n",
      "train loss:0.02992818076292671\n",
      "train loss:0.01162943967147529\n",
      "train loss:0.012051449034456692\n",
      "train loss:0.012973632775827417\n",
      "train loss:0.0044999227058433\n",
      "train loss:0.007886394685172401\n",
      "train loss:0.01748262229758357\n",
      "train loss:0.009426304644776945\n",
      "train loss:0.010538733107861853\n",
      "train loss:0.004411826428407142\n",
      "train loss:0.00430026937359923\n",
      "train loss:0.020804691060951553\n",
      "train loss:0.015984930749352796\n",
      "train loss:0.02504504392861643\n",
      "train loss:0.0060910605524130265\n",
      "train loss:0.025090715455679112\n",
      "train loss:0.020114402611423977\n",
      "train loss:0.03232265674680953\n",
      "train loss:0.0014615620016539055\n",
      "train loss:0.006190458899600264\n",
      "train loss:0.008404049625600023\n",
      "train loss:0.004692845412668562\n",
      "train loss:0.0050480679826397255\n",
      "train loss:0.0026751429834221863\n",
      "train loss:0.0022310039350279627\n",
      "train loss:0.005041715395521898\n",
      "train loss:0.0008625600576310038\n",
      "train loss:0.0028908519201403184\n",
      "train loss:0.0040297305987599865\n",
      "train loss:0.004689828968892016\n",
      "train loss:0.008746100140574545\n",
      "train loss:0.01255784486637485\n",
      "train loss:0.011659152431403\n",
      "train loss:0.0032426688346721376\n",
      "train loss:0.0010540516154262042\n",
      "train loss:0.0033936952505880234\n",
      "train loss:0.01762169851575408\n",
      "train loss:0.005843207814664297\n",
      "train loss:0.011197380870971045\n",
      "train loss:0.009130286492901854\n",
      "train loss:0.0010830834226879733\n",
      "train loss:0.011306476605112343\n",
      "train loss:0.00659039073085989\n",
      "train loss:0.015576084687644192\n",
      "train loss:0.002686717735353267\n",
      "train loss:0.00854644470459524\n",
      "train loss:0.01253318972897537\n",
      "train loss:0.047560639882415136\n",
      "train loss:0.011752535334686058\n",
      "train loss:0.033664065445445465\n",
      "train loss:0.0022798622125163558\n",
      "train loss:0.004567851038880996\n",
      "train loss:0.0170615799197891\n",
      "train loss:0.007858909040595672\n",
      "train loss:0.0029924260861393455\n",
      "train loss:0.0043468870852881696\n",
      "train loss:0.011771135619697656\n",
      "train loss:0.004271726902170936\n",
      "train loss:0.05390016949965992\n",
      "train loss:0.0033539940507983684\n",
      "train loss:0.015346955758276833\n",
      "train loss:0.006491277037149503\n",
      "train loss:0.00936430717202892\n",
      "train loss:0.015987092965287233\n",
      "train loss:0.011166179349348004\n",
      "train loss:0.04519410565701645\n",
      "train loss:0.005236987477694898\n",
      "train loss:0.0045593640579190175\n",
      "train loss:0.0034707481149459946\n",
      "train loss:0.03448694027856667\n",
      "train loss:0.006558295117472931\n",
      "train loss:0.01047616560867335\n",
      "train loss:0.003916736430279133\n",
      "train loss:0.025646140687518085\n",
      "train loss:0.00880963938857858\n",
      "train loss:0.029499592151631237\n",
      "train loss:0.005344619689726121\n",
      "train loss:0.0107779421893353\n",
      "train loss:0.0038102989269024785\n",
      "train loss:0.009336771984419548\n",
      "train loss:0.004707861134846834\n",
      "train loss:0.002906482124702129\n",
      "train loss:0.005318030981797283\n",
      "train loss:0.0037654669513216476\n",
      "train loss:0.0030716988600254826\n",
      "train loss:0.0030811963485482667\n",
      "train loss:0.005823909379519789\n",
      "train loss:0.005480113928000058\n",
      "train loss:0.050172056758470716\n",
      "train loss:0.003873144074594571\n",
      "train loss:0.024628896997561385\n",
      "train loss:0.01007216925842047\n",
      "train loss:0.008432640677031512\n",
      "train loss:0.00987910410262726\n",
      "train loss:0.007692904725464954\n",
      "train loss:0.002995735804897341\n",
      "train loss:0.001250472381051847\n",
      "train loss:0.006649252379753002\n",
      "train loss:0.012372203513233046\n",
      "train loss:0.006001492773431479\n",
      "train loss:0.0077573327595638316\n",
      "train loss:0.00914759266906419\n",
      "train loss:0.021646888334600843\n",
      "train loss:0.006657132978080797\n",
      "train loss:0.004215671606211047\n",
      "train loss:0.0019074592754590534\n",
      "train loss:0.009318414976614526\n",
      "train loss:0.008952384634067471\n",
      "train loss:0.03728096122014944\n",
      "train loss:0.009606836584288837\n",
      "train loss:0.008345149734134303\n",
      "train loss:0.02451057404332592\n",
      "train loss:0.001232314998299116\n",
      "train loss:0.0022825219811006044\n",
      "train loss:0.0012058670529427032\n",
      "train loss:0.06602553296599335\n",
      "train loss:0.027459722450283486\n",
      "train loss:0.006915771919710015\n",
      "train loss:0.0029415934571469476\n",
      "train loss:0.001659928585500323\n",
      "train loss:0.0008716825931186406\n",
      "train loss:0.007955642609442325\n",
      "train loss:0.001974578784114951\n",
      "train loss:0.0011719456670602948\n",
      "train loss:0.006659092862910958\n",
      "train loss:0.02474772397163911\n",
      "train loss:0.02028434103307318\n",
      "train loss:0.0032637013688636782\n",
      "train loss:0.12429030103133164\n",
      "train loss:0.012127094304788841\n",
      "train loss:0.005424386880472084\n",
      "train loss:0.0030338625777958823\n",
      "train loss:0.0023968492078595364\n",
      "train loss:0.00911395047476427\n",
      "train loss:0.0013360289252055996\n",
      "train loss:0.004962100381091869\n",
      "train loss:0.005492876566794606\n",
      "train loss:0.014281519350648668\n",
      "train loss:0.001655440433961971\n",
      "train loss:0.006882175216154237\n",
      "train loss:0.00915077685627223\n",
      "train loss:0.007208677666394232\n",
      "train loss:0.00285026422419551\n",
      "train loss:0.0023028369287222744\n",
      "train loss:0.013550157348905753\n",
      "train loss:0.0456087519292693\n",
      "train loss:0.009478920438566124\n",
      "train loss:0.023002155354812398\n",
      "train loss:0.014404106438190824\n",
      "train loss:0.0024873357077528076\n",
      "train loss:0.0017339497408878554\n",
      "train loss:0.0035555025796078477\n",
      "train loss:0.011327711052572765\n",
      "train loss:0.0069848480514925785\n",
      "train loss:0.002076567257283757\n",
      "train loss:0.010828887195137537\n",
      "train loss:0.0017595582458391202\n",
      "train loss:0.016342430152480804\n",
      "train loss:0.019464563807863516\n",
      "train loss:0.00909602210893126\n",
      "train loss:0.004570317006991948\n",
      "train loss:0.012142791030803844\n",
      "train loss:0.02481732418731448\n",
      "train loss:0.003685122855849367\n",
      "train loss:0.001520983529131285\n",
      "train loss:0.038192950786664084\n",
      "train loss:0.0018961071997942761\n",
      "train loss:0.0046724598021714615\n",
      "train loss:0.003753994951708128\n",
      "train loss:0.044706587050027335\n",
      "train loss:0.011298388552020398\n",
      "train loss:0.008840830146006916\n",
      "train loss:0.00526396614069862\n",
      "train loss:0.01142931449720867\n",
      "train loss:0.0026397157747950106\n",
      "train loss:0.003759365760666786\n",
      "train loss:0.08013443275165347\n",
      "train loss:0.008053253422482221\n",
      "train loss:0.007907668715697501\n",
      "train loss:0.0044974762227202175\n",
      "train loss:0.010098858279425176\n",
      "train loss:0.009534365225757955\n",
      "train loss:0.006457578904287248\n",
      "train loss:0.013882653227493078\n",
      "train loss:0.006546537824219242\n",
      "train loss:0.008916148259917264\n",
      "train loss:0.05445442821833588\n",
      "train loss:0.00205223563345076\n",
      "train loss:0.010374962988398075\n",
      "train loss:0.0058261017275020935\n",
      "train loss:0.005898448351364857\n",
      "train loss:0.0019894874435520725\n",
      "train loss:0.0038274625041202714\n",
      "train loss:0.0031267821830284633\n",
      "train loss:0.0007758859535945646\n",
      "train loss:0.013730494992384904\n",
      "train loss:0.003542002902402509\n",
      "train loss:0.007496501339287472\n",
      "train loss:0.008327613583472055\n",
      "train loss:0.004157458370552067\n",
      "train loss:0.001059717252061132\n",
      "train loss:0.012630752826312826\n",
      "train loss:0.05104881764702588\n",
      "train loss:0.005667578154108523\n",
      "train loss:0.0021797521663723908\n",
      "train loss:0.010545906100512153\n",
      "train loss:0.002112400046624559\n",
      "train loss:0.008720824056579854\n",
      "train loss:0.008505482108545766\n",
      "train loss:0.009341569397164698\n",
      "train loss:0.0030104504528030134\n",
      "train loss:0.009132419505249586\n",
      "train loss:0.006793420465887956\n",
      "train loss:0.0027691963422648656\n",
      "train loss:0.003517262354071592\n",
      "train loss:0.01563004364736964\n",
      "train loss:0.004969777486128455\n",
      "train loss:0.0032268322005999206\n",
      "train loss:0.0016311281376236197\n",
      "train loss:0.004038998880501944\n",
      "train loss:0.022636888312509557\n",
      "train loss:0.030095944346335383\n",
      "train loss:0.0022123398604604262\n",
      "train loss:0.009692268990735555\n",
      "train loss:0.007697166842685495\n",
      "train loss:0.0071263746081977304\n",
      "train loss:0.007439500261484119\n",
      "train loss:0.006224838967152218\n",
      "train loss:0.000961145361820584\n",
      "train loss:0.0066302821377011555\n",
      "train loss:0.005806357701584873\n",
      "train loss:0.004536161621242694\n",
      "train loss:0.023272123557501353\n",
      "train loss:0.0040692122596423935\n",
      "train loss:0.010967852398090887\n",
      "train loss:0.014767992436000918\n",
      "train loss:0.006542476033279088\n",
      "train loss:0.004536816647804616\n",
      "train loss:0.004288812653724009\n",
      "train loss:0.019565146456523453\n",
      "train loss:0.03266142599778453\n",
      "train loss:0.011804072994861628\n",
      "train loss:0.0021752183077229557\n",
      "train loss:0.01492407943910071\n",
      "train loss:0.0312543021353333\n",
      "train loss:0.023109447303739462\n",
      "train loss:0.006232689822841855\n",
      "train loss:0.010664499832602243\n",
      "train loss:0.05573229257388327\n",
      "train loss:0.034486825610600784\n",
      "train loss:0.00517021252189359\n",
      "train loss:0.018862020418232758\n",
      "train loss:0.005318145172412962\n",
      "train loss:0.00811557874332367\n",
      "train loss:0.021951158287477516\n",
      "train loss:0.005772541426142571\n",
      "train loss:0.009988352376029276\n",
      "train loss:0.005186730330285868\n",
      "train loss:0.04085679535020281\n",
      "train loss:0.01754730367326892\n",
      "train loss:0.01668509142667309\n",
      "train loss:0.025255452980299912\n",
      "train loss:0.008749109423893864\n",
      "train loss:0.0032513456598191725\n",
      "train loss:0.0031293641735768334\n",
      "train loss:0.007849256870319763\n",
      "train loss:0.010628728132941316\n",
      "train loss:0.008905439554238826\n",
      "train loss:0.0025998010184693308\n",
      "train loss:0.006162140351177751\n",
      "train loss:0.0019938146038209243\n",
      "train loss:0.02661120520266542\n",
      "train loss:0.00926212650152266\n",
      "train loss:0.007412489346529838\n",
      "train loss:0.00747466464140129\n",
      "train loss:0.019856001674527033\n",
      "train loss:0.02451007870356261\n",
      "train loss:0.012338063509838704\n",
      "train loss:0.010424876738142172\n",
      "=== epoch:9, train acc:0.992, test acc:0.987 ===\n",
      "train loss:0.017526263946982264\n",
      "train loss:0.019421199773180048\n",
      "train loss:0.007628940170983085\n",
      "train loss:0.008715157317921657\n",
      "train loss:0.0015877644204667213\n",
      "train loss:0.007038716959194284\n",
      "train loss:0.0028542271425915765\n",
      "train loss:0.003994897379439088\n",
      "train loss:0.007854328355315155\n",
      "train loss:0.01386291959710826\n",
      "train loss:0.005290306869634247\n",
      "train loss:0.008475498386713924\n",
      "train loss:0.010728817870169115\n",
      "train loss:0.0033006933493009904\n",
      "train loss:0.032435349829768215\n",
      "train loss:0.007780320420567624\n",
      "train loss:0.0011336025146504642\n",
      "train loss:0.0035919816935781916\n",
      "train loss:0.005063523211688023\n",
      "train loss:0.00927986509051287\n",
      "train loss:0.0008500892313124572\n",
      "train loss:0.006225823405636167\n",
      "train loss:0.011312654406254508\n",
      "train loss:0.009345422639060632\n",
      "train loss:0.003391966759853042\n",
      "train loss:0.023505250041163078\n",
      "train loss:0.003306933131858373\n",
      "train loss:0.0014880908925408007\n",
      "train loss:0.0033440012828506306\n",
      "train loss:0.016563951517370407\n",
      "train loss:0.01853183354998062\n",
      "train loss:0.008195183442248096\n",
      "train loss:0.005895124061362465\n",
      "train loss:0.0009116071911000157\n",
      "train loss:0.012195717109845319\n",
      "train loss:0.01650004234954068\n",
      "train loss:0.005942602198352437\n",
      "train loss:0.003043969503640884\n",
      "train loss:0.002856639177668655\n",
      "train loss:0.005366153706262593\n",
      "train loss:0.006010423460076065\n",
      "train loss:0.06678671898454201\n",
      "train loss:0.0008661658592454498\n",
      "train loss:0.010076913896641266\n",
      "train loss:0.024032848203316505\n",
      "train loss:0.0032251965896499114\n",
      "train loss:0.03547257756730454\n",
      "train loss:0.0017084956582801253\n",
      "train loss:0.01205760555068815\n",
      "train loss:0.027231198475787657\n",
      "train loss:0.012127843169302094\n",
      "train loss:0.012667644560379695\n",
      "train loss:0.027333956090217132\n",
      "train loss:0.013643565454228446\n",
      "train loss:0.025526712788908626\n",
      "train loss:0.002734856222958531\n",
      "train loss:0.016941570773908576\n",
      "train loss:0.0010400206384444915\n",
      "train loss:0.00928021351529188\n",
      "train loss:0.008380267220691451\n",
      "train loss:0.009275365509090423\n",
      "train loss:0.005254268545558178\n",
      "train loss:0.010664116223571676\n",
      "train loss:0.020851839269899437\n",
      "train loss:0.025870311723301623\n",
      "train loss:0.017461056874265576\n",
      "train loss:0.014585984225472377\n",
      "train loss:0.00466972087206369\n",
      "train loss:0.0031724713611805283\n",
      "train loss:0.003737625439382232\n",
      "train loss:0.011178317201442488\n",
      "train loss:0.0031290719586138443\n",
      "train loss:0.002586526733047416\n",
      "train loss:0.0064394347048941794\n",
      "train loss:0.004873039829690822\n",
      "train loss:0.006792384085171707\n",
      "train loss:0.06120450790488305\n",
      "train loss:0.00892315065266407\n",
      "train loss:0.025565531174195154\n",
      "train loss:0.0016564645431995306\n",
      "train loss:0.014754685936021245\n",
      "train loss:0.0028438568224437326\n",
      "train loss:0.002352367478336131\n",
      "train loss:0.008577977478542907\n",
      "train loss:0.007924850736886448\n",
      "train loss:0.004431254951301612\n",
      "train loss:0.008882905614390549\n",
      "train loss:0.002195690135588788\n",
      "train loss:0.006945897571821816\n",
      "train loss:0.0032045105400840173\n",
      "train loss:0.04759435087389478\n",
      "train loss:0.0031972238342651955\n",
      "train loss:0.005112837733405618\n",
      "train loss:0.0075262292933664056\n",
      "train loss:0.0033499830757551807\n",
      "train loss:0.001122993042235535\n",
      "train loss:0.014677050225651156\n",
      "train loss:0.017086354734368876\n",
      "train loss:0.017324618568074795\n",
      "train loss:0.004488735429168558\n",
      "train loss:0.03676491991077187\n",
      "train loss:0.01165353075359242\n",
      "train loss:0.006318146001486764\n",
      "train loss:0.006328135935490805\n",
      "train loss:0.016692150931659436\n",
      "train loss:0.006065808836067234\n",
      "train loss:0.004314699010926569\n",
      "train loss:0.002896685884706606\n",
      "train loss:0.0038622128746143665\n",
      "train loss:0.009061200264745715\n",
      "train loss:0.0018433962864029768\n",
      "train loss:0.016191230121117478\n",
      "train loss:0.0020836318960559545\n",
      "train loss:0.020880772261752285\n",
      "train loss:0.04223231268819317\n",
      "train loss:0.042148677326460986\n",
      "train loss:0.004172825294388584\n",
      "train loss:0.004163677378828984\n",
      "train loss:0.009424544328935584\n",
      "train loss:0.0027208448818628363\n",
      "train loss:0.0072677321220650315\n",
      "train loss:0.0025040581685520473\n",
      "train loss:0.006350841254720571\n",
      "train loss:0.0123192384362455\n",
      "train loss:0.006006289465970618\n",
      "train loss:0.10599785986868084\n",
      "train loss:0.10269276613375712\n",
      "train loss:0.005490448947512529\n",
      "train loss:0.043580996332304306\n",
      "train loss:0.003522603184720989\n",
      "train loss:0.0011544966128661576\n",
      "train loss:0.004427032995904311\n",
      "train loss:0.008313226088106793\n",
      "train loss:0.01746360893612041\n",
      "train loss:0.002416498493335377\n",
      "train loss:0.004175700817775167\n",
      "train loss:0.024696827344786537\n",
      "train loss:0.007338266452689096\n",
      "train loss:0.002968852152615216\n",
      "train loss:0.0028391742756325032\n",
      "train loss:0.0006502702643273413\n",
      "train loss:0.008818819435133117\n",
      "train loss:0.006368740078810335\n",
      "train loss:0.03138952902430717\n",
      "train loss:0.023783478329652365\n",
      "train loss:0.00430035649457124\n",
      "train loss:0.02712463517318922\n",
      "train loss:0.017754896919144936\n",
      "train loss:0.01853583754050148\n",
      "train loss:0.013484827398070437\n",
      "train loss:0.0015047642563412772\n",
      "train loss:0.007262536207981175\n",
      "train loss:0.0038644204669669225\n",
      "train loss:0.00557355228474168\n",
      "train loss:0.0033760695764427206\n",
      "train loss:0.003416164140144253\n",
      "train loss:0.013373645459175075\n",
      "train loss:0.02462948283344337\n",
      "train loss:0.005232951157173794\n",
      "train loss:0.0033096735523014727\n",
      "train loss:0.0046285652568412335\n",
      "train loss:0.01385090466656837\n",
      "train loss:0.016800447192453646\n",
      "train loss:0.004925770161161668\n",
      "train loss:0.008982794300650455\n",
      "train loss:0.012040302028084456\n",
      "train loss:0.01778734442964792\n",
      "train loss:0.005902442499260421\n",
      "train loss:0.005268709198793397\n",
      "train loss:0.002385314063324463\n",
      "train loss:0.006080102014426767\n",
      "train loss:0.009984576686604112\n",
      "train loss:0.0024439617039743833\n",
      "train loss:0.1641021493696893\n",
      "train loss:0.006553293401857411\n",
      "train loss:0.023779458871179618\n",
      "train loss:0.014654270524787223\n",
      "train loss:0.0078129531499123\n",
      "train loss:0.014717901374266236\n",
      "train loss:0.017907457162119368\n",
      "train loss:0.06629221405821845\n",
      "train loss:0.0020970851999660613\n",
      "train loss:0.007895992117517148\n",
      "train loss:0.004961180004751604\n",
      "train loss:0.008592700661157315\n",
      "train loss:0.015969146659590025\n",
      "train loss:0.0029259801601125945\n",
      "train loss:0.004213162693320575\n",
      "train loss:0.004695789726837653\n",
      "train loss:0.002916427123170293\n",
      "train loss:0.009257179642312487\n",
      "train loss:0.01139643855279631\n",
      "train loss:0.005152780755238729\n",
      "train loss:0.016719549116207905\n",
      "train loss:0.004727477505116594\n",
      "train loss:0.0028267864040426283\n",
      "train loss:0.02806866133002328\n",
      "train loss:0.004995943059204861\n",
      "train loss:0.010813761653015974\n",
      "train loss:0.0027314996406999827\n",
      "train loss:0.003671017996768561\n",
      "train loss:0.00791347540856584\n",
      "train loss:0.0030794518801172204\n",
      "train loss:0.009159819521990655\n",
      "train loss:0.03219700663277644\n",
      "train loss:0.01324949356105038\n",
      "train loss:0.001990883848947347\n",
      "train loss:0.0016518332144166725\n",
      "train loss:0.0064097530612116285\n",
      "train loss:0.00982973206824865\n",
      "train loss:0.01822242660767874\n",
      "train loss:0.004679463938242961\n",
      "train loss:0.013324309835347683\n",
      "train loss:0.0016887890571340588\n",
      "train loss:0.003735831556617436\n",
      "train loss:0.023265687696118375\n",
      "train loss:0.0061581999191054095\n",
      "train loss:0.00839580374007232\n",
      "train loss:0.00581684163948153\n",
      "train loss:0.008471681281787708\n",
      "train loss:0.002472515830446785\n",
      "train loss:0.0015092567777036533\n",
      "train loss:0.0072543990653169835\n",
      "train loss:0.009410907952454136\n",
      "train loss:0.04480575584110584\n",
      "train loss:0.005119971591406691\n",
      "train loss:0.010280035195590677\n",
      "train loss:0.040821989585331765\n",
      "train loss:0.006459339616752286\n",
      "train loss:0.007256806977160307\n",
      "train loss:0.0136157509595423\n",
      "train loss:0.004144310369839244\n",
      "train loss:0.028402389905872565\n",
      "train loss:0.010062387238400361\n",
      "train loss:0.015427382590742103\n",
      "train loss:0.0008308870427164128\n",
      "train loss:0.011512926940246318\n",
      "train loss:0.00559999344225395\n",
      "train loss:0.011267218426796653\n",
      "train loss:0.007911376856960967\n",
      "train loss:0.0006871286232955225\n",
      "train loss:0.004586052949973927\n",
      "train loss:0.04910828981591649\n",
      "train loss:0.004163622585276681\n",
      "train loss:0.0028467092019702307\n",
      "train loss:0.02396288175511977\n",
      "train loss:0.011124788298394401\n",
      "train loss:0.0020752511778769083\n",
      "train loss:0.007951155239291246\n",
      "train loss:0.001961275006956068\n",
      "train loss:0.00394958455560887\n",
      "train loss:0.008560866650669267\n",
      "train loss:0.00078495575899072\n",
      "train loss:0.025100540880430375\n",
      "train loss:0.010139309691569256\n",
      "train loss:0.00022503284251408084\n",
      "train loss:0.002763140963665875\n",
      "train loss:0.0061364021623630475\n",
      "train loss:0.005207706869758073\n",
      "train loss:0.006886193065679408\n",
      "train loss:0.017114065767812228\n",
      "train loss:0.0016569681052085456\n",
      "train loss:0.0036096639933635745\n",
      "train loss:0.011001325041734941\n",
      "train loss:0.006774151312865376\n",
      "train loss:0.0032798365252266646\n",
      "train loss:0.028184374627611142\n",
      "train loss:0.003598018715867423\n",
      "train loss:0.006293177084262326\n",
      "train loss:0.002771575633076115\n",
      "train loss:0.017458519634473944\n",
      "train loss:0.002268761980184329\n",
      "train loss:0.007365958724754991\n",
      "train loss:0.015399195203825338\n",
      "train loss:0.003514416521589321\n",
      "train loss:0.02659082520550785\n",
      "train loss:0.0003990385795602245\n",
      "train loss:0.031356221730759\n",
      "train loss:0.00744332151366513\n",
      "train loss:0.025950229860664482\n",
      "train loss:0.0072938275718750665\n",
      "train loss:0.009706828743790889\n",
      "train loss:0.00630284202228939\n",
      "train loss:0.004047266430955225\n",
      "train loss:0.025255975061113007\n",
      "train loss:0.010692431357291319\n",
      "train loss:0.004212203602975867\n",
      "train loss:0.01170474718687712\n",
      "train loss:0.002356159724464889\n",
      "train loss:0.013200123848592928\n",
      "train loss:0.003174446727239177\n",
      "train loss:0.005021620094736523\n",
      "train loss:0.0036260992773584637\n",
      "train loss:0.009254774288708047\n",
      "train loss:0.02170664651979921\n",
      "train loss:0.008074995448018674\n",
      "train loss:0.017748098970839468\n",
      "train loss:0.033052925534512764\n",
      "train loss:0.003409508580790794\n",
      "train loss:0.014161668912650548\n",
      "train loss:0.00522633073876724\n",
      "train loss:0.015027483475660559\n",
      "train loss:0.014337586263461792\n",
      "train loss:0.010157258551215062\n",
      "train loss:0.004969729399906846\n",
      "train loss:0.011806625181204582\n",
      "train loss:0.011557674746944118\n",
      "train loss:0.0166151798466264\n",
      "train loss:0.0021189544981447335\n",
      "train loss:0.025924558935436243\n",
      "train loss:0.020358316609985678\n",
      "train loss:0.002341096538344011\n",
      "train loss:0.008505173079942658\n",
      "train loss:0.0017346446935608021\n",
      "train loss:0.018517539464362912\n",
      "train loss:0.006913114969814414\n",
      "train loss:0.005880867474279226\n",
      "train loss:0.018853124435272407\n",
      "train loss:0.0043418048530997335\n",
      "train loss:0.002599743813025724\n",
      "train loss:0.0023088928520398413\n",
      "train loss:0.0011929069209778687\n",
      "train loss:0.0046400587170999895\n",
      "train loss:0.0019524344983484424\n",
      "train loss:0.0031719664904409236\n",
      "train loss:0.004330267871818651\n",
      "train loss:0.0061488386492763196\n",
      "train loss:0.009157898798721427\n",
      "train loss:0.053002989625200364\n",
      "train loss:0.00500134278636228\n",
      "train loss:0.06493175902694923\n",
      "train loss:0.018018893215106736\n",
      "train loss:0.029958797091806155\n",
      "train loss:0.00817443007438999\n",
      "train loss:0.02196437827598351\n",
      "train loss:0.0024463580787723073\n",
      "train loss:0.00420979537811434\n",
      "train loss:0.005786472701457367\n",
      "train loss:0.010518501141564107\n",
      "train loss:0.0011901907212621774\n",
      "train loss:0.004546300320126212\n",
      "train loss:0.0034858363163727\n",
      "train loss:0.002660936269879224\n",
      "train loss:0.019855147416692226\n",
      "train loss:0.008375566055707499\n",
      "train loss:0.005411553139363185\n",
      "train loss:0.001686454581986127\n",
      "train loss:0.16730109802409607\n",
      "train loss:0.010588127476628765\n",
      "train loss:0.015820793035222505\n",
      "train loss:0.004609333741278797\n",
      "train loss:0.010557042320442108\n",
      "train loss:0.007085057414480498\n",
      "train loss:0.005323554707034206\n",
      "train loss:0.005295778982397318\n",
      "train loss:0.0030960215425133476\n",
      "train loss:0.0021496295849573977\n",
      "train loss:0.02024261490803715\n",
      "train loss:0.053736702654420876\n",
      "train loss:0.011641212490141358\n",
      "train loss:0.007425761311147884\n",
      "train loss:0.00113506421234241\n",
      "train loss:0.01117877674308187\n",
      "train loss:0.01677151083311997\n",
      "train loss:0.006669806891115203\n",
      "train loss:0.05622427639277138\n",
      "train loss:0.006725637224680756\n",
      "train loss:0.0033940540390034303\n",
      "train loss:0.0028805088876766804\n",
      "train loss:0.0052631938371621315\n",
      "train loss:0.02773629811079595\n",
      "train loss:0.0021913106095060495\n",
      "train loss:0.02794135558352601\n",
      "train loss:0.010730357459805846\n",
      "train loss:0.004057330290659132\n",
      "train loss:0.0032324795943573475\n",
      "train loss:0.0033202326227965307\n",
      "train loss:0.002312417275035562\n",
      "train loss:0.013497983817711647\n",
      "train loss:0.0018374617390110699\n",
      "train loss:0.003097630160167261\n",
      "train loss:0.014152858545693566\n",
      "train loss:0.007707255225562093\n",
      "train loss:0.02888997880860129\n",
      "train loss:0.014424072646496248\n",
      "train loss:0.005105407716273689\n",
      "train loss:0.023969033796553768\n",
      "train loss:0.01559351568196329\n",
      "train loss:0.005352787456333596\n",
      "train loss:0.011837335329107475\n",
      "train loss:0.009588295110889015\n",
      "train loss:0.001466950945007109\n",
      "train loss:0.004515896993594727\n",
      "train loss:0.0104473125287519\n",
      "train loss:0.009832041575879392\n",
      "train loss:0.008473400980588082\n",
      "train loss:0.007137451364989336\n",
      "train loss:0.004035779237115785\n",
      "train loss:0.0058026440962911175\n",
      "train loss:0.0012504399353599057\n",
      "train loss:0.0075958048156089\n",
      "train loss:0.0489343589584599\n",
      "train loss:0.017230574562436846\n",
      "train loss:0.017124120522809302\n",
      "train loss:0.005019587088270646\n",
      "train loss:0.006478121164798992\n",
      "train loss:0.007788394860563821\n",
      "train loss:0.02172969237728201\n",
      "train loss:0.005974607828595525\n",
      "train loss:0.0077550040598427135\n",
      "train loss:0.011245426577460298\n",
      "train loss:0.025788213099388627\n",
      "train loss:0.0014735016472218836\n",
      "train loss:0.0027051906707170085\n",
      "train loss:0.002032408774365403\n",
      "train loss:0.037031122046922535\n",
      "train loss:0.0018165904487664943\n",
      "train loss:0.007616838495402892\n",
      "train loss:0.018918396940167257\n",
      "train loss:0.00415308793685038\n",
      "train loss:0.03143653052872182\n",
      "train loss:0.0053093500663898945\n",
      "train loss:0.0015056859665194238\n",
      "train loss:0.00955256772370979\n",
      "train loss:0.019110783516580385\n",
      "train loss:0.005485311487095899\n",
      "train loss:0.0012082726598693157\n",
      "train loss:0.05038789146925244\n",
      "train loss:0.03608937689360723\n",
      "train loss:0.005359442173950024\n",
      "train loss:0.03735913115311361\n",
      "train loss:0.0038165024185200765\n",
      "train loss:0.009292979839130695\n",
      "train loss:0.011377075351873647\n",
      "train loss:0.05880638997634647\n",
      "train loss:0.005406198682819091\n",
      "train loss:0.016505398851623446\n",
      "train loss:0.005577432828267805\n",
      "train loss:0.01025157979696138\n",
      "train loss:0.012067018346625451\n",
      "train loss:0.00528478949226264\n",
      "train loss:0.0037048208132170074\n",
      "train loss:0.002513133242500005\n",
      "train loss:0.027897028257162903\n",
      "train loss:0.017468400175406386\n",
      "train loss:0.008541040191999721\n",
      "train loss:0.012856344252196004\n",
      "train loss:0.006703263281208911\n",
      "train loss:0.024643855802718807\n",
      "train loss:0.00047316674239031173\n",
      "train loss:0.006464429739931262\n",
      "train loss:0.027482987052821456\n",
      "train loss:0.0012565785316950076\n",
      "train loss:0.009316362108812594\n",
      "train loss:0.002932504029266722\n",
      "train loss:0.022529939476511635\n",
      "train loss:0.042566768698789205\n",
      "train loss:0.0025656775695209262\n",
      "train loss:0.007155761988682217\n",
      "train loss:0.017037597674056014\n",
      "train loss:0.0021885058077522595\n",
      "train loss:0.0040267647164295975\n",
      "train loss:0.006278156279653262\n",
      "train loss:0.01689615097217452\n",
      "train loss:0.03527705390618153\n",
      "train loss:0.0053400302593922845\n",
      "train loss:0.004073420713341599\n",
      "train loss:0.012254101807846534\n",
      "train loss:0.0036868654626804457\n",
      "train loss:0.00952417260264167\n",
      "train loss:0.005660900753368664\n",
      "train loss:0.0010984582702086615\n",
      "train loss:0.007261092166835509\n",
      "train loss:0.003488004936782543\n",
      "train loss:0.0003414531280923655\n",
      "train loss:0.0054498405581355205\n",
      "train loss:0.004180350231524843\n",
      "train loss:0.001411541367108483\n",
      "train loss:0.008981933886604884\n",
      "train loss:0.0009627725585265307\n",
      "train loss:0.0030601780148717668\n",
      "train loss:0.008222577094114988\n",
      "train loss:0.030151853783720383\n",
      "train loss:0.010315148571423256\n",
      "train loss:0.0063873147919471926\n",
      "train loss:0.009277978892031106\n",
      "train loss:0.003941118887332481\n",
      "train loss:0.02090356081990111\n",
      "train loss:0.002591258322573192\n",
      "train loss:0.006422675117407195\n",
      "train loss:0.07940671817155973\n",
      "train loss:0.012565355036924469\n",
      "train loss:0.003135861784218068\n",
      "train loss:0.011524906415041747\n",
      "train loss:0.0075145895190224885\n",
      "train loss:0.010602094134014233\n",
      "train loss:0.004339437506728695\n",
      "train loss:0.01942799783057829\n",
      "train loss:0.00799784107931054\n",
      "train loss:0.025656115373729586\n",
      "train loss:0.014576476389105347\n",
      "train loss:0.01576241141489019\n",
      "train loss:0.02259654548335653\n",
      "train loss:0.009886198488893667\n",
      "train loss:0.0008907838259562971\n",
      "train loss:0.0060478645506968\n",
      "train loss:0.0032172168159153598\n",
      "train loss:0.0002543274108437502\n",
      "train loss:0.004543860788738584\n",
      "train loss:0.003975719575715073\n",
      "train loss:0.012713740539876927\n",
      "train loss:0.01455345195611166\n",
      "train loss:0.01832034915982573\n",
      "train loss:0.002280112170671506\n",
      "train loss:0.002488266907296207\n",
      "train loss:0.0006597729473465934\n",
      "train loss:0.013725839457227395\n",
      "train loss:0.009313605219984897\n",
      "train loss:0.006130448346123336\n",
      "train loss:0.0010728416525992968\n",
      "train loss:0.005561393627270761\n",
      "train loss:0.011854230172284808\n",
      "train loss:0.010248588667294707\n",
      "train loss:0.010645714515564677\n",
      "train loss:0.006765919407276865\n",
      "train loss:0.027175829825934805\n",
      "train loss:0.007556775982138101\n",
      "train loss:0.00973992581799773\n",
      "train loss:0.029503689950519187\n",
      "train loss:0.0011883304201925485\n",
      "train loss:0.035329427100673466\n",
      "train loss:0.014324222831665546\n",
      "train loss:0.005102300973851514\n",
      "train loss:0.009456186648594687\n",
      "train loss:0.0022498424357867\n",
      "train loss:0.01189550416145627\n",
      "train loss:0.004993391554842062\n",
      "train loss:0.004998530044321041\n",
      "train loss:0.02031414112338035\n",
      "train loss:0.008438486815347274\n",
      "train loss:0.00467927362889689\n",
      "train loss:0.019721296939671385\n",
      "train loss:0.0036211492391559712\n",
      "train loss:0.0029499936639752872\n",
      "train loss:0.011016898265285669\n",
      "train loss:0.008997714878465289\n",
      "train loss:0.002241734478348636\n",
      "train loss:0.00662291600840663\n",
      "train loss:0.0034916730637859733\n",
      "train loss:0.00651003604082591\n",
      "train loss:0.016490027265424194\n",
      "train loss:0.0015341564877686697\n",
      "train loss:0.007046576100605203\n",
      "train loss:0.02292986897285474\n",
      "train loss:0.0037282236897588777\n",
      "train loss:0.01578011752553468\n",
      "train loss:0.004971379236573743\n",
      "train loss:0.023148528829763263\n",
      "train loss:0.005729636436378137\n",
      "train loss:0.008085184651397613\n",
      "train loss:0.0035357293466505377\n",
      "train loss:0.0008564731007255289\n",
      "train loss:0.0076793273051883855\n",
      "train loss:0.007327046212064258\n",
      "train loss:0.0006673623333023159\n",
      "train loss:0.00399214558796866\n",
      "train loss:0.004987559019913233\n",
      "train loss:0.005243457431308862\n",
      "train loss:0.001883401727369925\n",
      "train loss:0.007518905943118794\n",
      "train loss:0.0005177142762929247\n",
      "train loss:0.019228662490687352\n",
      "train loss:0.0357850360909144\n",
      "train loss:0.0038785363063640415\n",
      "train loss:0.007067846174510546\n",
      "train loss:0.0005136428093782184\n",
      "train loss:0.010192845018317204\n",
      "train loss:0.000431445037047627\n",
      "train loss:0.0030384698860792423\n",
      "train loss:0.0017316863568214533\n",
      "train loss:0.025212185696722154\n",
      "train loss:0.007329765466680117\n",
      "train loss:0.003354015604467178\n",
      "train loss:0.001182029841702287\n",
      "train loss:0.010067223636101361\n",
      "train loss:0.003682789062326612\n",
      "train loss:0.018342327243298803\n",
      "train loss:0.007960662208522788\n",
      "train loss:0.01102943888975203\n",
      "train loss:0.0005207185868221304\n",
      "train loss:0.006622187049777478\n",
      "train loss:0.008452088508668914\n",
      "train loss:0.0023470814263981243\n",
      "train loss:0.006192250012012131\n",
      "train loss:0.0034541694512247624\n",
      "train loss:0.008018781135988935\n",
      "train loss:0.01928958831545426\n",
      "train loss:0.0020550134644997174\n",
      "train loss:0.00037884509305107303\n",
      "train loss:0.0046277984678182674\n",
      "=== epoch:10, train acc:0.993, test acc:0.987 ===\n",
      "train loss:0.0038176930427058445\n",
      "train loss:0.0008383204904290515\n",
      "train loss:0.0023042633002020195\n",
      "train loss:0.0019522187891339105\n",
      "train loss:0.03329133966541073\n",
      "train loss:0.017202615336366273\n",
      "train loss:0.0013404859066016583\n",
      "train loss:0.0020364817829519512\n",
      "train loss:0.0028755051476743528\n",
      "train loss:0.007904615037226795\n",
      "train loss:0.0052302603193561115\n",
      "train loss:0.003240276728581009\n",
      "train loss:0.0019235970456899798\n",
      "train loss:0.0005442809874297309\n",
      "train loss:0.0036378949592296363\n",
      "train loss:0.0053483598476960605\n",
      "train loss:0.007649584428086415\n",
      "train loss:0.01969307676705257\n",
      "train loss:0.015505887622344495\n",
      "train loss:0.0011534601912251878\n",
      "train loss:0.003390105086206903\n",
      "train loss:0.005403319208063957\n",
      "train loss:0.0017520457952736237\n",
      "train loss:0.03152394870479533\n",
      "train loss:0.02102275694979041\n",
      "train loss:0.005512248030676557\n",
      "train loss:0.008671227089372277\n",
      "train loss:0.006637638023094274\n",
      "train loss:0.012453485796810288\n",
      "train loss:0.005850432981032203\n",
      "train loss:0.004630990704280124\n",
      "train loss:0.001186535008623081\n",
      "train loss:0.04616639566037139\n",
      "train loss:0.0024610400314932787\n",
      "train loss:0.002208773652092205\n",
      "train loss:0.0049599494409917335\n",
      "train loss:0.052045928840332135\n",
      "train loss:0.003454849225126701\n",
      "train loss:0.0036341326301710043\n",
      "train loss:0.005577442591538956\n",
      "train loss:0.0037666295617833113\n",
      "train loss:0.0036354616662567056\n",
      "train loss:0.0032015199086589973\n",
      "train loss:0.00418103871431397\n",
      "train loss:0.005511593333822545\n",
      "train loss:0.014255337629922336\n",
      "train loss:0.0017097586082835377\n",
      "train loss:0.0038313053026870943\n",
      "train loss:0.014095184221485667\n",
      "train loss:0.0034306545812153367\n",
      "train loss:0.0018117573594914574\n",
      "train loss:0.004452092760234346\n",
      "train loss:0.003915776476016911\n",
      "train loss:0.002060302407524648\n",
      "train loss:0.003544924462307405\n",
      "train loss:0.0033005453358938425\n",
      "train loss:0.004617142064286199\n",
      "train loss:0.014487268159272123\n",
      "train loss:0.02446927129775871\n",
      "train loss:0.0028480306700946036\n",
      "train loss:0.0058552732085859135\n",
      "train loss:0.009140255440210375\n",
      "train loss:0.0190372180215634\n",
      "train loss:0.008343656993796649\n",
      "train loss:0.03528785594298256\n",
      "train loss:0.013000116911643312\n",
      "train loss:0.0015348541582046072\n",
      "train loss:0.008437025722719507\n",
      "train loss:0.0043480116278876955\n",
      "train loss:0.01110784094944467\n",
      "train loss:0.008781449340910193\n",
      "train loss:0.006471945896325659\n",
      "train loss:0.002554663201051251\n",
      "train loss:0.0030308017503115443\n",
      "train loss:0.006765002406984687\n",
      "train loss:0.00042141832918495\n",
      "train loss:0.0031650192757579853\n",
      "train loss:0.008720742248121445\n",
      "train loss:0.0019101688391803234\n",
      "train loss:0.006323414606866633\n",
      "train loss:0.006892492909427661\n",
      "train loss:0.012630113071535918\n",
      "train loss:0.0015991142916249854\n",
      "train loss:0.007124650395877828\n",
      "train loss:0.031955526298734764\n",
      "train loss:0.006458829457935526\n",
      "train loss:0.006734185739527806\n",
      "train loss:0.0011114352375146972\n",
      "train loss:0.0073113838887724145\n",
      "train loss:0.00261516911375464\n",
      "train loss:0.002385778247257371\n",
      "train loss:0.012818786884571028\n",
      "train loss:0.007593084155661441\n",
      "train loss:0.00017205965738143804\n",
      "train loss:0.01275009147643487\n",
      "train loss:0.0019033850309791794\n",
      "train loss:0.007038647300514729\n",
      "train loss:0.003911965236355509\n",
      "train loss:0.003184678410106625\n",
      "train loss:0.0032515423027039713\n",
      "train loss:0.005215538920327468\n",
      "train loss:0.018278113663341644\n",
      "train loss:0.0008778834064550867\n",
      "train loss:0.003175452743553544\n",
      "train loss:0.0010194027545685793\n",
      "train loss:0.0041810154807796415\n",
      "train loss:0.04949736278690074\n",
      "train loss:0.003996825588974142\n",
      "train loss:0.0032669991233268527\n",
      "train loss:0.005056152438958441\n",
      "train loss:0.0183484968323659\n",
      "train loss:0.006052715283736424\n",
      "train loss:0.0002037059119857216\n",
      "train loss:0.009498591268688378\n",
      "train loss:0.06065535171429571\n",
      "train loss:0.005512578918974654\n",
      "train loss:0.0018607370999490177\n",
      "train loss:0.0029759139131635176\n",
      "train loss:0.009018312911599146\n",
      "train loss:0.007814342915204721\n",
      "train loss:0.005112644560410744\n",
      "train loss:0.0029232732327161594\n",
      "train loss:0.0050775827662715356\n",
      "train loss:0.007718088996140218\n",
      "train loss:0.002967067978392599\n",
      "train loss:0.024495464726981178\n",
      "train loss:0.013235614759393756\n",
      "train loss:0.009851351406799104\n",
      "train loss:0.06448730976199962\n",
      "train loss:0.004771379172864659\n",
      "train loss:0.005743286650388558\n",
      "train loss:0.0028898135013746425\n",
      "train loss:0.009880098964908636\n",
      "train loss:0.04315231322041622\n",
      "train loss:0.00568693087908309\n",
      "train loss:0.006175741903040199\n",
      "train loss:0.002312999091942168\n",
      "train loss:0.01438146303918062\n",
      "train loss:0.002001948373912551\n",
      "train loss:0.007331888330616761\n",
      "train loss:0.001549362686097592\n",
      "train loss:0.0011440630509933069\n",
      "train loss:0.009832192864534245\n",
      "train loss:0.005824398523230657\n",
      "train loss:0.021694251421343704\n",
      "train loss:0.001523581111648168\n",
      "train loss:0.025317563546872413\n",
      "train loss:0.006834306815910978\n",
      "train loss:0.007497908116310907\n",
      "train loss:0.0012000989515432972\n",
      "train loss:0.002760145943781251\n",
      "train loss:0.0025328477384580846\n",
      "train loss:0.0019399094824282762\n",
      "train loss:0.0034400830844816626\n",
      "train loss:0.006528545610794078\n",
      "train loss:0.007239493635411064\n",
      "train loss:0.0025671974868698376\n",
      "train loss:0.0023611631977569062\n",
      "train loss:0.007908997596548626\n",
      "train loss:0.0015531075197264999\n",
      "train loss:0.001877633714522268\n",
      "train loss:0.02716343935063334\n",
      "train loss:0.005790274461980126\n",
      "train loss:0.007246228856786044\n",
      "train loss:0.00302839350405032\n",
      "train loss:0.05606163205862358\n",
      "train loss:0.013654584248552233\n",
      "train loss:0.006897977959578242\n",
      "train loss:0.0023702980298437874\n",
      "train loss:0.03383718310082529\n",
      "train loss:0.005046256156333853\n",
      "train loss:0.004998464499408313\n",
      "train loss:0.008672798831263212\n",
      "train loss:0.0024261796237157033\n",
      "train loss:0.04772107229817788\n",
      "train loss:0.006884946659983543\n",
      "train loss:0.0016537681523390408\n",
      "train loss:0.000892202180622831\n",
      "train loss:0.15122146382112642\n",
      "train loss:0.11049811656123319\n",
      "train loss:0.01100549141173814\n",
      "train loss:0.004147510681483729\n",
      "train loss:0.007455721913974843\n",
      "train loss:0.007129077781441939\n",
      "train loss:0.0325660605325664\n",
      "train loss:0.028382752734157822\n",
      "train loss:0.010441786980107766\n",
      "train loss:0.0035995861120288707\n",
      "train loss:0.005504767789380689\n",
      "train loss:0.0053940278337698535\n",
      "train loss:0.005109577486641946\n",
      "train loss:0.008629535980263588\n",
      "train loss:0.006295220221212546\n",
      "train loss:0.008668938437949992\n",
      "train loss:0.007487405728249015\n",
      "train loss:0.004178989349452581\n",
      "train loss:0.016731706627132602\n",
      "train loss:0.0024527916157292915\n",
      "train loss:0.003389126877183428\n",
      "train loss:0.013069310671362995\n",
      "train loss:0.03128300677041054\n",
      "train loss:0.006290330133082628\n",
      "train loss:0.0024790186417829453\n",
      "train loss:0.0012690888264098763\n",
      "train loss:0.015517228628318105\n",
      "train loss:0.0018670292489815297\n",
      "train loss:0.008751299468430083\n",
      "train loss:0.013490754312031856\n",
      "train loss:0.02441001868815767\n",
      "train loss:0.00623809508967186\n",
      "train loss:0.005027139924081619\n",
      "train loss:0.0056845950075558645\n",
      "train loss:0.0047499355738916445\n",
      "train loss:0.024121297794020204\n",
      "train loss:0.0029086048929338397\n",
      "train loss:0.0050675539844832924\n",
      "train loss:0.003795316537006377\n",
      "train loss:0.0028207418775491656\n",
      "train loss:0.0025434052730169206\n",
      "train loss:0.007605986372015916\n",
      "train loss:0.0030292614480378166\n",
      "train loss:0.0016739593396214057\n",
      "train loss:0.0028563559064811055\n",
      "train loss:0.002837074832303185\n",
      "train loss:0.003657511602399016\n",
      "train loss:0.020221229463659295\n",
      "train loss:0.027349890686116433\n",
      "train loss:0.006720503526212488\n",
      "train loss:0.00457546657822451\n",
      "train loss:0.006261218840888103\n",
      "train loss:0.008140478708382849\n",
      "train loss:0.004347385502303409\n",
      "train loss:0.022840321109090574\n",
      "train loss:0.005421467963667846\n",
      "train loss:0.003257037531132293\n",
      "train loss:0.0036571316952759537\n",
      "train loss:0.021063707941332215\n",
      "train loss:0.0025755773848523318\n",
      "train loss:0.012741782357982168\n",
      "train loss:0.02190106750489967\n",
      "train loss:0.00899270869562992\n",
      "train loss:0.003310131847201706\n",
      "train loss:0.006639538147422004\n",
      "train loss:0.010101086499698857\n",
      "train loss:0.008510612065211734\n",
      "train loss:0.03533166948388902\n",
      "train loss:0.01742980312425469\n",
      "train loss:0.0010521179572087406\n",
      "train loss:0.0016205498102227318\n",
      "train loss:0.025812785412434976\n",
      "train loss:0.00790121772041885\n",
      "train loss:0.02839829290571795\n",
      "train loss:0.013452120125305358\n",
      "train loss:0.008043090949721643\n",
      "train loss:0.002490416730250961\n",
      "train loss:0.039589459624825636\n",
      "train loss:0.005082376081442492\n",
      "train loss:0.004751342302517417\n",
      "train loss:0.007071263284699519\n",
      "train loss:0.002491612806621606\n",
      "train loss:0.024375900675521284\n",
      "train loss:0.01672849100864053\n",
      "train loss:0.01535883715196694\n",
      "train loss:0.0014924046365515332\n",
      "train loss:0.008872199622008841\n",
      "train loss:0.09308191954791203\n",
      "train loss:0.004179650982811752\n",
      "train loss:0.008123232294410478\n",
      "train loss:0.0026510616782807056\n",
      "train loss:0.031058103385673115\n",
      "train loss:0.017642757002356447\n",
      "train loss:0.005313160781662567\n",
      "train loss:0.01550672723552044\n",
      "train loss:0.007837679695559124\n",
      "train loss:0.003227995859216391\n",
      "train loss:0.01201536354006279\n",
      "train loss:0.0023049661922901173\n",
      "train loss:0.003839144365874061\n",
      "train loss:0.010531890731336915\n",
      "train loss:0.015713119218251546\n",
      "train loss:0.0007208009795056632\n",
      "train loss:0.010030836872544533\n",
      "train loss:0.006222638784553743\n",
      "train loss:0.0018030293156407076\n",
      "train loss:0.01709738514486832\n",
      "train loss:0.01090033321782606\n",
      "train loss:0.0020172938709561478\n",
      "train loss:0.0011999972008336676\n",
      "train loss:0.002700854657202452\n",
      "train loss:0.0016655092982101288\n",
      "train loss:0.0011927960581904473\n",
      "train loss:0.0009673017492499919\n",
      "train loss:0.0014832847777031127\n",
      "train loss:0.002589676496542844\n",
      "train loss:0.0011640692913813004\n",
      "train loss:0.021786400992675953\n",
      "train loss:0.00798247242704603\n",
      "train loss:0.0018083575128668545\n",
      "train loss:0.021588837453329516\n",
      "train loss:0.011323354422336484\n",
      "train loss:0.0038072791927763142\n",
      "train loss:0.003426854429433054\n",
      "train loss:0.006327523329790914\n",
      "train loss:0.0020866046049063257\n",
      "train loss:0.003784037758716734\n",
      "train loss:0.0031079069823900696\n",
      "train loss:0.003142842960023106\n",
      "train loss:0.0007672198576249131\n",
      "train loss:0.00906787368116575\n",
      "train loss:0.006075267513694458\n",
      "train loss:0.025784266588835935\n",
      "train loss:0.01740455992501918\n",
      "train loss:0.01978253271348989\n",
      "train loss:0.0032760418760868536\n",
      "train loss:0.009253080577343491\n",
      "train loss:0.020489917746706433\n",
      "train loss:0.006824865951173906\n",
      "train loss:0.0032651813082777955\n",
      "train loss:0.001811149608827993\n",
      "train loss:0.0020389483726272637\n",
      "train loss:0.007022937138317324\n",
      "train loss:0.052714413576609366\n",
      "train loss:0.02188862117392237\n",
      "train loss:0.00553451759619212\n",
      "train loss:0.006949692121440504\n",
      "train loss:0.012993252202988416\n",
      "train loss:0.012878381264369004\n",
      "train loss:0.01685910019921928\n",
      "train loss:0.014070989127057447\n",
      "train loss:0.008874431052502522\n",
      "train loss:0.00607665193418299\n",
      "train loss:0.0026731812666039413\n",
      "train loss:0.008282651686013873\n",
      "train loss:0.002876380511564658\n",
      "train loss:0.0013941239993950562\n",
      "train loss:0.04612029938271961\n",
      "train loss:0.0024865073399795547\n",
      "train loss:0.008392952154216616\n",
      "train loss:0.020384857864389636\n",
      "train loss:0.010227064197836155\n",
      "train loss:0.0065075204586306536\n",
      "train loss:0.010020825347874993\n",
      "train loss:0.004572097906572068\n",
      "train loss:0.0007969532026904989\n",
      "train loss:0.008321052545496956\n",
      "train loss:0.029244953968378673\n",
      "train loss:0.01713132321862929\n",
      "train loss:0.004472474932908697\n",
      "train loss:0.004938301976599671\n",
      "train loss:0.004609641509102043\n",
      "train loss:0.008222437140859401\n",
      "train loss:0.015950758709009395\n",
      "train loss:0.05260421711726341\n",
      "train loss:0.0050770946729064735\n",
      "train loss:0.0023423992442048653\n",
      "train loss:0.0031713137577135024\n",
      "train loss:0.00812158682765949\n",
      "train loss:0.004750991358022427\n",
      "train loss:0.0050212605180942095\n",
      "train loss:0.006282713782579767\n",
      "train loss:0.020565049941438266\n",
      "train loss:0.009262810451035393\n",
      "train loss:0.003961937043548078\n",
      "train loss:0.0014440345956571465\n",
      "train loss:0.0022232156783477904\n",
      "train loss:0.0036990670707332724\n",
      "train loss:0.03001937483088447\n",
      "train loss:0.002509309341995924\n",
      "train loss:0.0021314799480484947\n",
      "train loss:0.017804305796216877\n",
      "train loss:0.010472569987743905\n",
      "train loss:0.005600580398289613\n",
      "train loss:0.00629398033569809\n",
      "train loss:0.00897272660979178\n",
      "train loss:0.006107299440337831\n",
      "train loss:0.0032020460945351163\n",
      "train loss:0.01075883916280206\n",
      "train loss:0.012879856218187848\n",
      "train loss:0.004606973294279462\n",
      "train loss:0.004729997046936805\n",
      "train loss:0.001788894333211059\n",
      "train loss:0.005913522976031006\n",
      "train loss:0.009673935930623094\n",
      "train loss:0.008988512438711955\n",
      "train loss:0.008785340726577499\n",
      "train loss:0.0023030830640948857\n",
      "train loss:0.001515247240780633\n",
      "train loss:0.002034601019897519\n",
      "train loss:0.003403865957725968\n",
      "train loss:0.008848240529224843\n",
      "train loss:0.023908693156951603\n",
      "train loss:0.006546894214173871\n",
      "train loss:0.010733129133046946\n",
      "train loss:0.0017237615480432166\n",
      "train loss:0.0027815677428184716\n",
      "train loss:0.0025913999422652995\n",
      "train loss:0.011447011438105361\n",
      "train loss:0.004318245002387379\n",
      "train loss:0.006134698651448688\n",
      "train loss:0.16346470542545175\n",
      "train loss:0.009145169520931456\n",
      "train loss:0.0048744024599780104\n",
      "train loss:0.00717033043947708\n",
      "train loss:0.004500569200792242\n",
      "train loss:0.0055448064505132484\n",
      "train loss:0.008457463454396522\n",
      "train loss:0.0013625750150406265\n",
      "train loss:0.009420639424308491\n",
      "train loss:0.0117462957572925\n",
      "train loss:0.0018457915848068634\n",
      "train loss:0.008505563113537529\n",
      "train loss:0.006068908814109544\n",
      "train loss:0.041343139456736594\n",
      "train loss:0.017981196336810747\n",
      "train loss:0.0013243637047204015\n",
      "train loss:0.0023748119189576154\n",
      "train loss:0.0061824175134425514\n",
      "train loss:0.003542968440771992\n",
      "train loss:0.010312484989976485\n",
      "train loss:0.003950245522081579\n",
      "train loss:0.005569984455134474\n",
      "train loss:0.0019259189140063643\n",
      "train loss:0.00438472998883145\n",
      "train loss:0.006419678469389518\n",
      "train loss:0.006170639868205201\n",
      "train loss:0.0044434890063210115\n",
      "train loss:0.006296930369254074\n",
      "train loss:0.009542482898403553\n",
      "train loss:0.0008105317856402834\n",
      "train loss:0.0031926893768411185\n",
      "train loss:0.008633772088989673\n",
      "train loss:0.014039538846539029\n",
      "train loss:0.0007477191644205807\n",
      "train loss:0.0011568510734141174\n",
      "train loss:0.015507975709823943\n",
      "train loss:0.002182772833710879\n",
      "train loss:0.006643082975563024\n",
      "train loss:0.0011223314528535661\n",
      "train loss:0.0030046773641123374\n",
      "train loss:0.001997975622701766\n",
      "train loss:0.007233447692188436\n",
      "train loss:0.002343200674783617\n",
      "train loss:0.005635001610528065\n",
      "train loss:0.010810589108539484\n",
      "train loss:0.00843363080223285\n",
      "train loss:0.01952082573667621\n",
      "train loss:0.013073452254136751\n",
      "train loss:0.014013216055087475\n",
      "train loss:0.0026224727052576256\n",
      "train loss:0.03513126904154305\n",
      "train loss:0.01036026430618414\n",
      "train loss:0.01608429890526665\n",
      "train loss:0.0015185055875487925\n",
      "train loss:0.007083468688387725\n",
      "train loss:0.029151560549192504\n",
      "train loss:0.00402499301085199\n",
      "train loss:0.004315681664654115\n",
      "train loss:0.001777467526371476\n",
      "train loss:0.0049050636897550745\n",
      "train loss:0.0017043102865181572\n",
      "train loss:0.0037980021086533016\n",
      "train loss:0.009574877259282246\n",
      "train loss:0.0037025430083566925\n",
      "train loss:0.0006938185331697269\n",
      "train loss:0.020348287689478304\n",
      "train loss:0.005915722041881119\n",
      "train loss:0.08220225915753751\n",
      "train loss:0.016216653464194812\n",
      "train loss:0.04274534733769248\n",
      "train loss:0.006979887993568697\n",
      "train loss:0.009594536645495075\n",
      "train loss:0.013913816984553937\n",
      "train loss:0.003726693711648469\n",
      "train loss:0.002349491858111225\n",
      "train loss:0.008825464057854171\n",
      "train loss:0.0019254356157405715\n",
      "train loss:0.0037593480633106944\n",
      "train loss:0.008812969333665776\n",
      "train loss:0.01500726432826971\n",
      "train loss:0.0012533771645006396\n",
      "train loss:0.01637038644469893\n",
      "train loss:0.036013088748546876\n",
      "train loss:0.022870171524157552\n",
      "train loss:0.0036344692298652427\n",
      "train loss:0.0031492119065391747\n",
      "train loss:0.005239987596830579\n",
      "train loss:0.01447932049937904\n",
      "train loss:0.005184922784063756\n",
      "train loss:0.009038916234395976\n",
      "train loss:0.00930915650344368\n",
      "train loss:0.001011007415094458\n",
      "train loss:0.006975288140226105\n",
      "train loss:0.008122910787815402\n",
      "train loss:0.003353514949833109\n",
      "train loss:0.004194275457565758\n",
      "train loss:0.0033300836959433426\n",
      "train loss:0.01623802691810626\n",
      "train loss:0.005651541529348025\n",
      "train loss:0.0015289423099001415\n",
      "train loss:0.012482038342807152\n",
      "train loss:0.008909296150317882\n",
      "train loss:0.023345230825925763\n",
      "train loss:0.01915984578390742\n",
      "train loss:0.00863432668115939\n",
      "train loss:0.0019115014264073794\n",
      "train loss:0.003656474152101637\n",
      "train loss:0.0024302261705979595\n",
      "train loss:0.0037992100440772786\n",
      "train loss:0.022309304489053973\n",
      "train loss:0.013137433038377897\n",
      "train loss:0.023866179426369483\n",
      "train loss:0.004261260703274467\n",
      "train loss:0.020009496881346518\n",
      "train loss:0.0036351004518796605\n",
      "train loss:0.012746449536551631\n",
      "train loss:0.013423457849272782\n",
      "train loss:0.018695898372478207\n",
      "train loss:0.013110049032926977\n",
      "train loss:0.01979984687999625\n",
      "train loss:0.012599188963527711\n",
      "train loss:0.01013240527236082\n",
      "train loss:0.0036497104566342673\n",
      "train loss:0.0007326187055913868\n",
      "train loss:0.0021421900091348187\n",
      "train loss:0.005546502127832711\n",
      "train loss:0.001520769031992307\n",
      "train loss:0.004167331670907906\n",
      "train loss:0.000711364560757104\n",
      "train loss:0.006505464663381325\n",
      "train loss:0.006694686567455675\n",
      "train loss:0.007077167210064\n",
      "train loss:0.018693438362611232\n",
      "train loss:0.012347367762575995\n",
      "train loss:0.010437461966365602\n",
      "train loss:0.006585974572101633\n",
      "train loss:0.0074984437550961415\n",
      "train loss:0.0008969778281516781\n",
      "train loss:0.009041281878834982\n",
      "train loss:0.003181186156268172\n",
      "train loss:0.00486805770470709\n",
      "train loss:0.010788339844610376\n",
      "train loss:0.0008590686173836064\n",
      "train loss:0.012409504767319161\n",
      "train loss:0.0016708943384700372\n",
      "train loss:0.006092736437161585\n",
      "train loss:0.0005891956808161587\n",
      "train loss:0.007192712117584135\n",
      "train loss:0.0031392050522728926\n",
      "train loss:0.008150516870194458\n",
      "train loss:0.021432059438127284\n",
      "train loss:0.0014312828768862907\n",
      "train loss:0.03252674793623363\n",
      "train loss:0.005725809549237948\n",
      "train loss:0.006044102599099158\n",
      "train loss:0.003172876426192983\n",
      "train loss:0.010084799134104563\n",
      "train loss:0.0016505650196445892\n",
      "train loss:0.012786055198040042\n",
      "train loss:0.03121347165188704\n",
      "train loss:0.00115097247271752\n",
      "train loss:0.0014154590314131312\n",
      "train loss:0.008163573095895485\n",
      "train loss:0.0051199949403425895\n",
      "train loss:0.016580416412833362\n",
      "train loss:0.003478203034046654\n",
      "train loss:0.029225945382086706\n",
      "train loss:0.022734375786214015\n",
      "train loss:0.010851149864173433\n",
      "train loss:0.0013290327121890338\n",
      "train loss:0.003229301139228287\n",
      "train loss:0.017047001318114915\n",
      "train loss:0.012993349415426405\n",
      "train loss:0.0022519669975849107\n",
      "train loss:0.0015228127479210126\n",
      "train loss:0.0035994261655210185\n",
      "train loss:0.020598525429543012\n",
      "train loss:0.04018169250301617\n",
      "train loss:0.0210795434113992\n",
      "train loss:0.004693944093531437\n",
      "train loss:0.004629635108722287\n",
      "train loss:0.0034088450021674426\n",
      "train loss:0.012279500787322907\n",
      "train loss:0.0014867375934611898\n",
      "train loss:0.00311038508451873\n",
      "train loss:0.005265454150520615\n",
      "train loss:0.0026891146186560867\n",
      "train loss:0.0037253666918494305\n",
      "train loss:0.00019241266791506786\n",
      "train loss:0.0066989838058083674\n",
      "train loss:0.0071800250341642335\n",
      "train loss:0.008692637860394993\n",
      "train loss:0.05398869600191418\n",
      "train loss:0.0029938955393262108\n",
      "train loss:0.0004408187598243712\n",
      "train loss:0.0036079938608725285\n",
      "train loss:0.007237718079479502\n",
      "train loss:0.007424454234281661\n",
      "train loss:0.0010197178598001554\n",
      "train loss:0.0033391042423850863\n",
      "train loss:0.0033631822083069864\n",
      "=== epoch:11, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.0032240991758307642\n",
      "train loss:0.00960385169418766\n",
      "train loss:0.0038268673184909557\n",
      "train loss:0.0003551464103806976\n",
      "train loss:0.0016378374820092334\n",
      "train loss:0.0009750957459519524\n",
      "train loss:0.0064441347511866665\n",
      "train loss:0.002018180001537218\n",
      "train loss:0.012904035560558722\n",
      "train loss:0.011004597615304847\n",
      "train loss:0.002487292381844624\n",
      "train loss:0.001672129250052367\n",
      "train loss:0.0018166548271599454\n",
      "train loss:0.009852730447932901\n",
      "train loss:0.021457401826472412\n",
      "train loss:0.0017591088072078092\n",
      "train loss:0.0039935128931135756\n",
      "train loss:0.0014266605248945698\n",
      "train loss:0.0010728716060047574\n",
      "train loss:0.027138448854606197\n",
      "train loss:0.0028694943363671488\n",
      "train loss:0.0019712495436545784\n",
      "train loss:0.0036540229919902623\n",
      "train loss:0.0062676205320468855\n",
      "train loss:0.012544737059818574\n",
      "train loss:0.0029296418495914694\n",
      "train loss:0.0029432331631912916\n",
      "train loss:0.00410111398368165\n",
      "train loss:0.009264287391889035\n",
      "train loss:0.0009683955695517857\n",
      "train loss:0.032365905440574876\n",
      "train loss:0.013702759198684633\n",
      "train loss:0.009557620777800393\n",
      "train loss:0.007082483080720828\n",
      "train loss:0.0016486372085611155\n",
      "train loss:0.0015382940047894136\n",
      "train loss:0.0011812093549294484\n",
      "train loss:0.004708473515922645\n",
      "train loss:0.006376326016436491\n",
      "train loss:0.005792468638530487\n",
      "train loss:0.033342488735913535\n",
      "train loss:0.0015666094904143615\n",
      "train loss:0.00046358066791101356\n",
      "train loss:0.004985842866319451\n",
      "train loss:0.004070641262868565\n",
      "train loss:0.0018098645616679465\n",
      "train loss:0.0012331256542061292\n",
      "train loss:0.0013238332496157642\n",
      "train loss:0.0003897510814590892\n",
      "train loss:0.01693828612624394\n",
      "train loss:0.005048009032778962\n",
      "train loss:0.008126426921584386\n",
      "train loss:0.002331032287288626\n",
      "train loss:0.0032446720734036973\n",
      "train loss:0.0052806478672649025\n",
      "train loss:0.004338651813018252\n",
      "train loss:0.010943015545028571\n",
      "train loss:0.0028140829022219294\n",
      "train loss:0.0029177137383389357\n",
      "train loss:0.001688676101114613\n",
      "train loss:0.002081877658579123\n",
      "train loss:0.005297343931997672\n",
      "train loss:0.01028813748929635\n",
      "train loss:0.028771126628709023\n",
      "train loss:0.0006312584975619393\n",
      "train loss:0.000928294982093044\n",
      "train loss:0.0029008532737082337\n",
      "train loss:0.039596091889187016\n",
      "train loss:0.0020471397805714732\n",
      "train loss:0.005204680445423034\n",
      "train loss:0.002099834197609562\n",
      "train loss:0.01452269906448836\n",
      "train loss:0.004099554419472398\n",
      "train loss:0.004037554969710578\n",
      "train loss:0.015480570737261787\n",
      "train loss:0.01847763017663777\n",
      "train loss:0.011017845361612768\n",
      "train loss:0.001921003522326616\n",
      "train loss:0.002816588750769516\n",
      "train loss:0.01034435326229872\n",
      "train loss:0.005232814110293048\n",
      "train loss:0.0008270342586316278\n",
      "train loss:0.0035285346511021447\n",
      "train loss:0.013753715217069777\n",
      "train loss:0.007694008207189977\n",
      "train loss:0.017980820767087617\n",
      "train loss:0.00426660044097223\n",
      "train loss:0.007228515383620142\n",
      "train loss:0.0036073649519878185\n",
      "train loss:0.004639023721000504\n",
      "train loss:0.008004422198689637\n",
      "train loss:0.0010106301029813858\n",
      "train loss:0.024909129537664044\n",
      "train loss:0.0026432221870796853\n",
      "train loss:0.0076266980847638265\n",
      "train loss:0.014853015163704351\n",
      "train loss:0.007935977608721867\n",
      "train loss:0.006274563600875074\n",
      "train loss:0.002156414605102716\n",
      "train loss:0.0032467279204995616\n",
      "train loss:0.007065481988832505\n",
      "train loss:0.0016344235024617181\n",
      "train loss:0.020375469112111678\n",
      "train loss:0.002512260211526598\n",
      "train loss:0.037710980929528286\n",
      "train loss:0.0018927646657093944\n",
      "train loss:0.018224937447928902\n",
      "train loss:0.009088655874584945\n",
      "train loss:0.01139011522431609\n",
      "train loss:0.005217712251470902\n",
      "train loss:0.007891030956058025\n",
      "train loss:0.020159942591690162\n",
      "train loss:0.012670007507659238\n",
      "train loss:0.006294257343335445\n",
      "train loss:0.0074552332885892665\n",
      "train loss:0.003007849536424177\n",
      "train loss:0.00279405872743644\n",
      "train loss:0.018575851599877524\n",
      "train loss:0.002227245090197964\n",
      "train loss:0.03914810629653524\n",
      "train loss:0.008081102320437114\n",
      "train loss:0.005182390341028641\n",
      "train loss:0.01944017446120833\n",
      "train loss:0.0029205219220786644\n",
      "train loss:0.0007444666551767229\n",
      "train loss:0.0071618639256120584\n",
      "train loss:0.0037955497633082994\n",
      "train loss:0.014111608318389994\n",
      "train loss:0.002373759458594171\n",
      "train loss:0.01006591484296768\n",
      "train loss:0.005893266786268133\n",
      "train loss:0.008417102238601449\n",
      "train loss:0.005833154053625146\n",
      "train loss:0.0024361606438762424\n",
      "train loss:0.006924383080518093\n",
      "train loss:0.018763913922442706\n",
      "train loss:0.004821497538611524\n",
      "train loss:0.0024090440913665085\n",
      "train loss:0.005144010669870957\n",
      "train loss:0.0024961034531036292\n",
      "train loss:0.00159957452123224\n",
      "train loss:0.0053545288758521745\n",
      "train loss:0.0030936806192320473\n",
      "train loss:0.009687488147473828\n",
      "train loss:0.007491290382181778\n",
      "train loss:0.003766922813054843\n",
      "train loss:0.0069563521227068315\n",
      "train loss:0.0004389499596715847\n",
      "train loss:0.0006530810176731797\n",
      "train loss:0.000800962548774412\n",
      "train loss:0.007967718017790332\n",
      "train loss:0.017284601384173422\n",
      "train loss:0.005920544360775992\n",
      "train loss:0.004003757181461084\n",
      "train loss:0.0033231303579715275\n",
      "train loss:0.0008715174934851676\n",
      "train loss:0.0018682497976838794\n",
      "train loss:0.008342384874298886\n",
      "train loss:0.029266268372529314\n",
      "train loss:0.006432935136449951\n",
      "train loss:0.0074540385091195725\n",
      "train loss:0.04194441688199209\n",
      "train loss:0.026562921451748517\n",
      "train loss:0.008516232859281577\n",
      "train loss:0.003895362948756859\n",
      "train loss:0.003694737024189243\n",
      "train loss:0.0011938783182174955\n",
      "train loss:0.0023692919998989583\n",
      "train loss:0.0066239776161889\n",
      "train loss:0.009243395045577417\n",
      "train loss:0.01996081838664923\n",
      "train loss:0.01532667665826831\n",
      "train loss:0.0010799958279371757\n",
      "train loss:0.00707435230139549\n",
      "train loss:0.016635282269087063\n",
      "train loss:0.007248388472117132\n",
      "train loss:0.0042265440383024355\n",
      "train loss:0.01500419220588358\n",
      "train loss:0.0033312425629284893\n",
      "train loss:0.010125241196196908\n",
      "train loss:0.001390075167718868\n",
      "train loss:0.017421840463200413\n",
      "train loss:0.007861528618642586\n",
      "train loss:0.03265185367514214\n",
      "train loss:0.0030748667039071404\n",
      "train loss:0.003966002749507212\n",
      "train loss:0.007931860617261201\n",
      "train loss:0.0022488103236101404\n",
      "train loss:0.017134811068291643\n",
      "train loss:0.0115744200974729\n",
      "train loss:0.003271858062792067\n",
      "train loss:0.012444568680565512\n",
      "train loss:0.005883677659105264\n",
      "train loss:0.011166115900130091\n",
      "train loss:0.008001830449257437\n",
      "train loss:0.004012962138463412\n",
      "train loss:0.005162719326035222\n",
      "train loss:0.007491379940492977\n",
      "train loss:0.006238133113567801\n",
      "train loss:0.03125096458100097\n",
      "train loss:0.002881430665794042\n",
      "train loss:0.0028116092689760342\n",
      "train loss:0.002078871432564248\n",
      "train loss:0.007605213618715297\n",
      "train loss:0.007334143665305727\n",
      "train loss:0.003740111809339171\n",
      "train loss:0.007542144366430348\n",
      "train loss:0.022945073213089032\n",
      "train loss:0.0091289232761108\n",
      "train loss:0.0036493570960437977\n",
      "train loss:0.002541268337204492\n",
      "train loss:0.0016499451033101576\n",
      "train loss:0.0009123090774282981\n",
      "train loss:0.0025987135595369674\n",
      "train loss:0.012300961972961402\n",
      "train loss:0.00665122620707181\n",
      "train loss:0.0009203664583108263\n",
      "train loss:0.0009688811042236232\n",
      "train loss:0.003965726427222028\n",
      "train loss:0.00498331630072515\n",
      "train loss:0.0010424499528616776\n",
      "train loss:0.0006167073528793159\n",
      "train loss:0.005672330074693469\n",
      "train loss:0.009752855277097518\n",
      "train loss:0.003535335329451821\n",
      "train loss:0.00434366410408642\n",
      "train loss:0.0005077334171455209\n",
      "train loss:0.004243424752207291\n",
      "train loss:0.0008966204216156237\n",
      "train loss:0.003713299005753406\n",
      "train loss:0.002472451242295531\n",
      "train loss:0.0007904930326734798\n",
      "train loss:0.011423413137511782\n",
      "train loss:0.0022771487798775667\n",
      "train loss:0.0027507333518837886\n",
      "train loss:0.002886873389671132\n",
      "train loss:0.006011707028031014\n",
      "train loss:0.001129408523852861\n",
      "train loss:0.0008925635845340954\n",
      "train loss:0.006810174335161239\n",
      "train loss:0.002574461984046969\n",
      "train loss:0.00130381589334499\n",
      "train loss:0.003006879599828598\n",
      "train loss:0.0012245700394481103\n",
      "train loss:0.009426664390820766\n",
      "train loss:0.008959601202805794\n",
      "train loss:0.0021371673677590673\n",
      "train loss:0.0008813738998986887\n",
      "train loss:0.006393669866079024\n",
      "train loss:0.00020734197569540782\n",
      "train loss:0.002060124757151598\n",
      "train loss:0.009516262286866717\n",
      "train loss:0.005369459541150066\n",
      "train loss:0.013743830778488843\n",
      "train loss:0.02855260899245728\n",
      "train loss:0.003936705917843619\n",
      "train loss:0.0011276801030554733\n",
      "train loss:0.0028665127588146278\n",
      "train loss:0.009454335023519533\n",
      "train loss:0.001011142966233231\n",
      "train loss:0.003444710056285577\n",
      "train loss:0.0031684393170424248\n",
      "train loss:0.007224428257959754\n",
      "train loss:0.007773064289796579\n",
      "train loss:0.004758592351420749\n",
      "train loss:0.002104989891504471\n",
      "train loss:0.019878312056064818\n",
      "train loss:0.0007881401962854869\n",
      "train loss:0.008134855318462517\n",
      "train loss:0.001034782088253278\n",
      "train loss:0.002157012558002903\n",
      "train loss:0.0006134458285641353\n",
      "train loss:0.001958078580160731\n",
      "train loss:0.005245840842333083\n",
      "train loss:0.009915362517836866\n",
      "train loss:0.0007211439597032917\n",
      "train loss:0.00040039424744970096\n",
      "train loss:0.0026237106082477374\n",
      "train loss:0.0042025028074058135\n",
      "train loss:0.0014882935217154737\n",
      "train loss:0.0033356034525381696\n",
      "train loss:0.010293202707002085\n",
      "train loss:0.02699165218797568\n",
      "train loss:0.006186025717848714\n",
      "train loss:0.003063803207501227\n",
      "train loss:0.0026920724494389607\n",
      "train loss:0.001516217231231888\n",
      "train loss:0.011691990601407957\n",
      "train loss:0.015985237427191754\n",
      "train loss:0.0075124431589383015\n",
      "train loss:0.004850606170833612\n",
      "train loss:0.015759652795358674\n",
      "train loss:0.0033350676762157233\n",
      "train loss:0.01877857833977449\n",
      "train loss:0.000525364589299584\n",
      "train loss:0.002482944726034361\n",
      "train loss:0.0015147019069715107\n",
      "train loss:0.006068640537225192\n",
      "train loss:0.0023295255665363715\n",
      "train loss:0.0038654875382029916\n",
      "train loss:0.002185636843965106\n",
      "train loss:0.0018576625849101467\n",
      "train loss:0.00113758742958292\n",
      "train loss:0.011394002793756821\n",
      "train loss:0.003053847264519654\n",
      "train loss:0.004904029818360093\n",
      "train loss:0.006281616360031086\n",
      "train loss:0.0017705648077919068\n",
      "train loss:0.005458970956914542\n",
      "train loss:0.008077655455223317\n",
      "train loss:0.003761318903721435\n",
      "train loss:0.0016214075484772064\n",
      "train loss:0.0019927765120929973\n",
      "train loss:0.00023290671952063023\n",
      "train loss:0.005294683763514925\n",
      "train loss:0.00024075529759834505\n",
      "train loss:0.005679340574328638\n",
      "train loss:0.037840758504318533\n",
      "train loss:0.0038291826841216035\n",
      "train loss:0.019817754859070284\n",
      "train loss:0.00019643268595293876\n",
      "train loss:0.0010811678187388572\n",
      "train loss:0.0008144839755830746\n",
      "train loss:0.005736792884803988\n",
      "train loss:0.0012773634010276075\n",
      "train loss:0.008253920985733623\n",
      "train loss:0.0018901522756574326\n",
      "train loss:0.002329082357982622\n",
      "train loss:0.0011088141726471534\n",
      "train loss:0.0007486373095510475\n",
      "train loss:0.009408570420241574\n",
      "train loss:0.001354841013952673\n",
      "train loss:0.0026968318105285638\n",
      "train loss:0.003699562586146683\n",
      "train loss:0.002643746901664128\n",
      "train loss:0.05108829415638669\n",
      "train loss:0.0021598552020735107\n",
      "train loss:0.0028458732457302383\n",
      "train loss:0.0057103233325631695\n",
      "train loss:0.00466288619650455\n",
      "train loss:0.00478052806027413\n",
      "train loss:0.001995078528335126\n",
      "train loss:0.00886042330110886\n",
      "train loss:0.0011790143238172982\n",
      "train loss:0.09589251314738491\n",
      "train loss:0.006467516773480378\n",
      "train loss:0.0016475603292575875\n",
      "train loss:0.0033128020454301784\n",
      "train loss:0.011735555372709568\n",
      "train loss:0.06535094203240317\n",
      "train loss:0.00039344080883005247\n",
      "train loss:0.006203427843098717\n",
      "train loss:0.006148454843501893\n",
      "train loss:0.00410279001701785\n",
      "train loss:0.00012039616053809695\n",
      "train loss:0.007938609462989112\n",
      "train loss:0.010041442985778854\n",
      "train loss:0.014641951591044531\n",
      "train loss:0.005762709522004354\n",
      "train loss:0.0035968342174487592\n",
      "train loss:0.008171010332069328\n",
      "train loss:0.01233793432311775\n",
      "train loss:0.004655728791643518\n",
      "train loss:0.007840788298612074\n",
      "train loss:0.010490436970598227\n",
      "train loss:0.0034678159968474587\n",
      "train loss:0.00797677158582377\n",
      "train loss:0.006775439278284503\n",
      "train loss:0.005336582630075826\n",
      "train loss:0.01179311848190913\n",
      "train loss:0.0013200977688400477\n",
      "train loss:0.010183108706734395\n",
      "train loss:0.02940157365146218\n",
      "train loss:0.013036102572282202\n",
      "train loss:0.001307312448658617\n",
      "train loss:0.008324615635725507\n",
      "train loss:0.005375081035173684\n",
      "train loss:0.028362883053971392\n",
      "train loss:0.018191176022720336\n",
      "train loss:0.0049042271438830025\n",
      "train loss:0.0009267294830412243\n",
      "train loss:0.006558897461762037\n",
      "train loss:0.004265004486726283\n",
      "train loss:0.010124370599310116\n",
      "train loss:0.0049411842966617095\n",
      "train loss:0.0011173464421182274\n",
      "train loss:0.013354089351091482\n",
      "train loss:0.006478278170349981\n",
      "train loss:0.005469678010167527\n",
      "train loss:0.019201608909555235\n",
      "train loss:0.005935081246086636\n",
      "train loss:0.0077501750874706\n",
      "train loss:0.007278335641613956\n",
      "train loss:0.0014775488422326026\n",
      "train loss:0.008328985985531352\n",
      "train loss:0.0026422448569271657\n",
      "train loss:0.00260267676593497\n",
      "train loss:0.017869259531776763\n",
      "train loss:0.008949732277273475\n",
      "train loss:0.001222854142344595\n",
      "train loss:0.0006111253447428879\n",
      "train loss:0.0038949167884655485\n",
      "train loss:0.0017570658785611988\n",
      "train loss:0.015469597639424409\n",
      "train loss:0.0034249732662142355\n",
      "train loss:0.015873141515025283\n",
      "train loss:0.01323497516300317\n",
      "train loss:0.007666247691781277\n",
      "train loss:0.03745222131707593\n",
      "train loss:0.0034660919511686804\n",
      "train loss:0.0009414216253588019\n",
      "train loss:0.005665322168416887\n",
      "train loss:0.0010588371404657453\n",
      "train loss:0.003669743540967208\n",
      "train loss:0.02112204203637681\n",
      "train loss:0.0026247026795198788\n",
      "train loss:0.0002972120772966887\n",
      "train loss:0.02575913923117902\n",
      "train loss:0.003584497447376234\n",
      "train loss:0.007595029564811974\n",
      "train loss:0.007629226809318367\n",
      "train loss:0.0031988572126385715\n",
      "train loss:0.012123552550608915\n",
      "train loss:0.0016883117161006149\n",
      "train loss:0.0018221947475975206\n",
      "train loss:0.0033680913507030223\n",
      "train loss:0.00020036817825397108\n",
      "train loss:0.015642699653699785\n",
      "train loss:0.0017680563816081663\n",
      "train loss:0.006909020476343583\n",
      "train loss:0.018625273324034786\n",
      "train loss:0.001024362279587858\n",
      "train loss:0.0008814573934182709\n",
      "train loss:0.018074676018033968\n",
      "train loss:0.0023283042182589385\n",
      "train loss:0.0020203671915808422\n",
      "train loss:0.007779041649659956\n",
      "train loss:0.0024363554255989422\n",
      "train loss:0.0003532727616824846\n",
      "train loss:0.014837151059696083\n",
      "train loss:0.0042317646441080705\n",
      "train loss:0.0026472311332488437\n",
      "train loss:0.0024031579151194866\n",
      "train loss:0.002317017567345365\n",
      "train loss:0.004474342826095643\n",
      "train loss:0.002777838055743829\n",
      "train loss:0.010725239710893826\n",
      "train loss:0.002829780495069874\n",
      "train loss:0.01885838879978854\n",
      "train loss:0.003105626545516154\n",
      "train loss:0.002832547417905384\n",
      "train loss:0.0024355580998760627\n",
      "train loss:0.016493319891282682\n",
      "train loss:0.007127757911551659\n",
      "train loss:0.007654181753689853\n",
      "train loss:0.00472411376383522\n",
      "train loss:0.001597461642953784\n",
      "train loss:0.0009383895577378124\n",
      "train loss:0.003625484467344926\n",
      "train loss:0.0012388506464529156\n",
      "train loss:0.0030724226910033804\n",
      "train loss:0.004437290387364071\n",
      "train loss:0.0024225243506772903\n",
      "train loss:0.012100039238821922\n",
      "train loss:0.019427404266533072\n",
      "train loss:0.0013712377442410086\n",
      "train loss:0.0054415593900011515\n",
      "train loss:0.0003089126588449196\n",
      "train loss:0.008546837450964172\n",
      "train loss:0.003337376981907152\n",
      "train loss:0.0037655149936702864\n",
      "train loss:0.0024178843784478884\n",
      "train loss:0.01430208151888154\n",
      "train loss:0.007517420884116199\n",
      "train loss:0.006284679071375274\n",
      "train loss:0.00308598062917275\n",
      "train loss:0.005378865116937935\n",
      "train loss:0.0019057793071574113\n",
      "train loss:0.011900087587691073\n",
      "train loss:0.00033768973466426157\n",
      "train loss:0.001655945323077149\n",
      "train loss:0.00406352312514726\n",
      "train loss:0.0011066965143460335\n",
      "train loss:0.0023335368846591005\n",
      "train loss:0.0017456858726039948\n",
      "train loss:0.003543937370765867\n",
      "train loss:0.005276011014427883\n",
      "train loss:0.0024171833824904\n",
      "train loss:0.0025866423665317014\n",
      "train loss:0.00204628317908119\n",
      "train loss:0.0024309804565548166\n",
      "train loss:0.007022456716172769\n",
      "train loss:0.0035653601203914846\n",
      "train loss:0.0011459997099213298\n",
      "train loss:0.001190690501486816\n",
      "train loss:0.01323570087660534\n",
      "train loss:0.01677530091485008\n",
      "train loss:0.0021339492440975664\n",
      "train loss:0.0033048918846744235\n",
      "train loss:0.014244066728657922\n",
      "train loss:0.0026723996044378125\n",
      "train loss:0.0026229838812469697\n",
      "train loss:0.0011467002125173887\n",
      "train loss:0.004375245201700716\n",
      "train loss:0.0025357834168300143\n",
      "train loss:0.0018159932802436244\n",
      "train loss:0.008863107816407525\n",
      "train loss:0.0007801044994848258\n",
      "train loss:0.004651049355622313\n",
      "train loss:0.016015134324596295\n",
      "train loss:0.0008592124310341395\n",
      "train loss:0.013971407072490706\n",
      "train loss:0.013309198244422706\n",
      "train loss:0.006830239561749967\n",
      "train loss:0.0012054481755339737\n",
      "train loss:0.003131240768585544\n",
      "train loss:0.0024469299111061446\n",
      "train loss:0.005809596566264138\n",
      "train loss:0.00187459469083413\n",
      "train loss:0.005200161369208594\n",
      "train loss:0.02524076337369511\n",
      "train loss:0.00032157934535272\n",
      "train loss:0.003135453704359394\n",
      "train loss:0.0029914132296793797\n",
      "train loss:0.0016544659778941653\n",
      "train loss:0.01822602700311853\n",
      "train loss:0.005888457345148474\n",
      "train loss:0.0027162018239102613\n",
      "train loss:0.0035637006411918647\n",
      "train loss:0.011672531779307365\n",
      "train loss:0.0016951318103008341\n",
      "train loss:0.005508802287050877\n",
      "train loss:0.000228268822376782\n",
      "train loss:0.0519847373946896\n",
      "train loss:0.0010432660592114057\n",
      "train loss:0.00914637211808305\n",
      "train loss:0.0025195781699987696\n",
      "train loss:0.036078230063659775\n",
      "train loss:0.004447021569431971\n",
      "train loss:0.0042054624867204765\n",
      "train loss:0.007675582825906335\n",
      "train loss:0.0006237818916436324\n",
      "train loss:0.006670261351262297\n",
      "train loss:0.0007155210149116293\n",
      "train loss:0.007204686141799724\n",
      "train loss:0.008123256903042782\n",
      "train loss:0.0025179658859859877\n",
      "train loss:0.016920753735720814\n",
      "train loss:0.0054078419704426395\n",
      "train loss:0.0048208401137599536\n",
      "train loss:0.0011209586997354888\n",
      "train loss:0.0039961922068896495\n",
      "train loss:0.005049585965165313\n",
      "train loss:0.0012465628910541813\n",
      "train loss:0.014948867018966866\n",
      "train loss:0.0019835025341734\n",
      "train loss:0.0101526462103681\n",
      "train loss:0.002787569056853996\n",
      "train loss:0.00489363293342918\n",
      "train loss:0.020461963002836835\n",
      "train loss:0.0033261204124716694\n",
      "train loss:0.0021585779072138722\n",
      "train loss:0.004622101344826605\n",
      "train loss:0.0019441390435201975\n",
      "train loss:0.0009096518974194927\n",
      "train loss:0.01737492365007737\n",
      "train loss:0.002426211800603368\n",
      "train loss:0.0059644686233591105\n",
      "train loss:0.00900479017312223\n",
      "train loss:0.0021910434700913102\n",
      "train loss:0.0015336476579217667\n",
      "train loss:0.0034522485803006437\n",
      "train loss:0.02103436629014504\n",
      "train loss:0.035251352227519\n",
      "train loss:0.0011799085811740285\n",
      "train loss:0.019866919483024433\n",
      "train loss:0.005140579535365022\n",
      "train loss:0.06310073927868984\n",
      "train loss:0.0010232912235051566\n",
      "train loss:0.010088068776196883\n",
      "train loss:0.0027546641144933935\n",
      "train loss:0.005520557694576132\n",
      "train loss:0.001750793008529284\n",
      "train loss:0.0008429469150400529\n",
      "train loss:0.0038382828850831376\n",
      "train loss:0.005309467869000415\n",
      "train loss:0.00041096712913283483\n",
      "train loss:0.002415007924811134\n",
      "train loss:0.003797559420877803\n",
      "train loss:0.0017040827013514441\n",
      "train loss:0.007953924775850347\n",
      "train loss:0.05487061403575197\n",
      "train loss:0.0009222856833489178\n",
      "train loss:0.007608402202104736\n",
      "train loss:0.08163637130535309\n",
      "train loss:0.007875052802546507\n",
      "train loss:0.01838623503459188\n",
      "train loss:0.0012467585687891314\n",
      "train loss:0.0036345483344500506\n",
      "train loss:0.014064225918370372\n",
      "=== epoch:12, train acc:0.996, test acc:0.986 ===\n",
      "train loss:0.0036662555552932153\n",
      "train loss:0.014802981334697339\n",
      "train loss:0.0032182140078729935\n",
      "train loss:0.013335093844292968\n",
      "train loss:0.007653785694947338\n",
      "train loss:0.002577367052947459\n",
      "train loss:0.000391164030463177\n",
      "train loss:0.0013884321113323528\n",
      "train loss:0.004530088137437463\n",
      "train loss:0.00165585119528569\n",
      "train loss:0.0013191282428994837\n",
      "train loss:0.0026681004623276806\n",
      "train loss:0.0032852157072556236\n",
      "train loss:0.013157924840702535\n",
      "train loss:0.004220997871317717\n",
      "train loss:0.0023245534817305947\n",
      "train loss:0.010508897707973357\n",
      "train loss:0.03213191770622461\n",
      "train loss:0.005537499572559871\n",
      "train loss:0.003318031303150053\n",
      "train loss:0.0017870342021728783\n",
      "train loss:0.02987003028538264\n",
      "train loss:0.0010179648874245164\n",
      "train loss:0.00023367895575930684\n",
      "train loss:0.004087734792687553\n",
      "train loss:0.017068678758275054\n",
      "train loss:0.0033912287684679738\n",
      "train loss:0.0005757118282273797\n",
      "train loss:0.02281881484197759\n",
      "train loss:0.017382897387826536\n",
      "train loss:0.0012273342325862374\n",
      "train loss:0.004603778727373371\n",
      "train loss:0.0029882397361114467\n",
      "train loss:0.0012758262738621251\n",
      "train loss:0.0012862874210048292\n",
      "train loss:0.0018831611113852155\n",
      "train loss:0.038648217887690454\n",
      "train loss:0.005471265596405551\n",
      "train loss:0.015271635992327105\n",
      "train loss:0.0020782693731172335\n",
      "train loss:0.005035843324070045\n",
      "train loss:0.0065167534648121715\n",
      "train loss:0.00121683286606553\n",
      "train loss:0.0036655652631788103\n",
      "train loss:0.0043193862480436565\n",
      "train loss:0.0037246882909227523\n",
      "train loss:0.01606396338805843\n",
      "train loss:0.002913140907603808\n",
      "train loss:0.0032542882586558603\n",
      "train loss:0.005192499719558788\n",
      "train loss:0.006398152440691739\n",
      "train loss:0.008391661899299178\n",
      "train loss:0.002068064257068876\n",
      "train loss:0.009862665329882643\n",
      "train loss:0.0012969413408876604\n",
      "train loss:0.001647915800391501\n",
      "train loss:0.010429305083608866\n",
      "train loss:0.0011611683156691772\n",
      "train loss:0.007105400698889803\n",
      "train loss:0.014011777543625452\n",
      "train loss:0.007542557466807532\n",
      "train loss:0.0006721273040658835\n",
      "train loss:0.003239297945835606\n",
      "train loss:0.009049605057078719\n",
      "train loss:0.0037758666818187834\n",
      "train loss:0.0041059701835971345\n",
      "train loss:0.007308660942932951\n",
      "train loss:0.008392900845041107\n",
      "train loss:0.004503197756978263\n",
      "train loss:0.00777677032634149\n",
      "train loss:0.0004853610176668985\n",
      "train loss:0.0178429856199251\n",
      "train loss:0.002310537303847568\n",
      "train loss:0.006603010990848268\n",
      "train loss:0.0005535156511427821\n",
      "train loss:0.01831871508488904\n",
      "train loss:0.0029794445478312174\n",
      "train loss:0.014212213031833896\n",
      "train loss:0.011800522553681445\n",
      "train loss:0.016461303219409983\n",
      "train loss:0.0015252886878288849\n",
      "train loss:0.010382838696032097\n",
      "train loss:0.006201343808897123\n",
      "train loss:0.014305700203654695\n",
      "train loss:0.012984463948558587\n",
      "train loss:0.0024003261467007405\n",
      "train loss:0.023461511323214942\n",
      "train loss:0.0024081661995058084\n",
      "train loss:0.012173500900808383\n",
      "train loss:0.0037911089819386732\n",
      "train loss:0.0214722760675197\n",
      "train loss:0.00236984025006941\n",
      "train loss:0.007539702051602882\n",
      "train loss:0.016833132489653176\n",
      "train loss:0.005567472434947208\n",
      "train loss:0.0023753105159617176\n",
      "train loss:0.004863152960519875\n",
      "train loss:0.0014925367271961562\n",
      "train loss:0.008095468157307521\n",
      "train loss:0.00661602509977272\n",
      "train loss:0.007844975339227176\n",
      "train loss:0.007002080607032319\n",
      "train loss:0.01673679010498051\n",
      "train loss:0.004292357223627693\n",
      "train loss:0.0014841169015291325\n",
      "train loss:0.004750390256404895\n",
      "train loss:0.008280207461182843\n",
      "train loss:0.0025889882991663627\n",
      "train loss:0.0023290635546969946\n",
      "train loss:0.0038765481707751996\n",
      "train loss:0.020082213844641924\n",
      "train loss:0.004473869601003503\n",
      "train loss:0.0008702730021850258\n",
      "train loss:0.0005839535221770981\n",
      "train loss:0.04040241153583322\n",
      "train loss:0.008964292384053975\n",
      "train loss:0.002671238581910421\n",
      "train loss:0.0048007104560494115\n",
      "train loss:0.005950207680157494\n",
      "train loss:0.004603131661728263\n",
      "train loss:0.012437852832327399\n",
      "train loss:0.002354559988726244\n",
      "train loss:0.0010798152041619554\n",
      "train loss:0.002434046886506452\n",
      "train loss:0.005778339273728977\n",
      "train loss:0.006891875396526205\n",
      "train loss:0.0014044210691911768\n",
      "train loss:0.007119922908111132\n",
      "train loss:0.0023346758018901108\n",
      "train loss:0.004578166001025789\n",
      "train loss:0.001136334452303851\n",
      "train loss:0.01071182460540558\n",
      "train loss:0.005066121220894202\n",
      "train loss:0.02100272799071706\n",
      "train loss:0.0008613055990962628\n",
      "train loss:0.009973543837621229\n",
      "train loss:0.033001943010387974\n",
      "train loss:0.0020311878920384802\n",
      "train loss:0.011186316467235731\n",
      "train loss:0.0024323673794920124\n",
      "train loss:0.005366265122206523\n",
      "train loss:0.00774206930283009\n",
      "train loss:0.01093680882047013\n",
      "train loss:0.0036394524767462463\n",
      "train loss:0.00777176943701797\n",
      "train loss:0.011036683192095529\n",
      "train loss:8.112594632157844e-05\n",
      "train loss:0.007494742284242541\n",
      "train loss:0.0026460347016051527\n",
      "train loss:0.005071065219660513\n",
      "train loss:0.005176744738754465\n",
      "train loss:0.000859136072704251\n",
      "train loss:0.0032871161946339588\n",
      "train loss:0.0232276733161399\n",
      "train loss:0.006296715768958536\n",
      "train loss:0.008742566410074414\n",
      "train loss:0.00028765009150598207\n",
      "train loss:0.0028753818902995405\n",
      "train loss:0.018912525220985514\n",
      "train loss:0.0014084170024526055\n",
      "train loss:0.002335757801103039\n",
      "train loss:0.0028450180303068286\n",
      "train loss:0.0043614592577278805\n",
      "train loss:0.010161242705390143\n",
      "train loss:0.003340933350957543\n",
      "train loss:0.007837130997744194\n",
      "train loss:0.019669816434383754\n",
      "train loss:0.005490024442103011\n",
      "train loss:0.0028174835525068037\n",
      "train loss:0.0015279648698445047\n",
      "train loss:0.007500781848813587\n",
      "train loss:0.013952959372535044\n",
      "train loss:0.004805029995072165\n",
      "train loss:0.0020153914326123544\n",
      "train loss:0.0015078839686178984\n",
      "train loss:0.002776115755234836\n",
      "train loss:0.0019888191466499294\n",
      "train loss:0.005107157424305287\n",
      "train loss:0.0014951264427866791\n",
      "train loss:0.0012669215455995446\n",
      "train loss:0.001164600153895916\n",
      "train loss:0.0013286305169688995\n",
      "train loss:0.00440570214432406\n",
      "train loss:0.005166976340292015\n",
      "train loss:0.0007820692411729744\n",
      "train loss:0.0013818686189070379\n",
      "train loss:0.008955809710648962\n",
      "train loss:0.0010001116567428428\n",
      "train loss:0.10349588773142998\n",
      "train loss:0.024202537783169352\n",
      "train loss:0.00658817728421327\n",
      "train loss:0.0019993961138226497\n",
      "train loss:0.003694403895664848\n",
      "train loss:0.006885084838424712\n",
      "train loss:0.0034965282573488606\n",
      "train loss:0.038959650844588106\n",
      "train loss:0.025798465497731717\n",
      "train loss:0.002797226717424486\n",
      "train loss:0.0008982356314145092\n",
      "train loss:0.0043958970191804924\n",
      "train loss:0.0030968518455422645\n",
      "train loss:0.004111722416127301\n",
      "train loss:0.016233087930054003\n",
      "train loss:0.005140625307915164\n",
      "train loss:0.006512550053712397\n",
      "train loss:0.002648014666024283\n",
      "train loss:0.010603832109905906\n",
      "train loss:0.006508638109321917\n",
      "train loss:0.004936580904703806\n",
      "train loss:0.021265298269158253\n",
      "train loss:0.0017635853623591826\n",
      "train loss:0.004254912253523986\n",
      "train loss:0.00366849384260074\n",
      "train loss:0.005914229471294252\n",
      "train loss:0.008357121348761196\n",
      "train loss:0.030805569014509194\n",
      "train loss:0.0001892492399320694\n",
      "train loss:0.006991418934257965\n",
      "train loss:0.003887722856385271\n",
      "train loss:0.004981065489951356\n",
      "train loss:0.0027618479559920754\n",
      "train loss:0.00932851167978025\n",
      "train loss:0.002137696364745689\n",
      "train loss:0.0011627331122482795\n",
      "train loss:0.007523973812178192\n",
      "train loss:0.029248886409365363\n",
      "train loss:0.0021045798118561904\n",
      "train loss:0.005138456848051437\n",
      "train loss:0.002694980306397339\n",
      "train loss:0.0015335075210558863\n",
      "train loss:0.0005180583257005146\n",
      "train loss:0.010778268634539654\n",
      "train loss:0.003133224120863698\n",
      "train loss:0.00421840091597275\n",
      "train loss:0.012743113414672635\n",
      "train loss:0.0034823148258910914\n",
      "train loss:0.0013073184696152658\n",
      "train loss:0.0007306977876808935\n",
      "train loss:0.005714810574607079\n",
      "train loss:0.0003959521301777394\n",
      "train loss:0.007388280492356842\n",
      "train loss:0.0006557019187086565\n",
      "train loss:0.008337775139939142\n",
      "train loss:0.008711750556724006\n",
      "train loss:0.01233277196340625\n",
      "train loss:0.008219496206870158\n",
      "train loss:0.0041326737046697044\n",
      "train loss:0.012195772246614002\n",
      "train loss:0.017784157882786148\n",
      "train loss:0.015244373770602216\n",
      "train loss:0.011084060567047728\n",
      "train loss:0.006392247597553923\n",
      "train loss:0.0022002633810904782\n",
      "train loss:8.837470994997293e-05\n",
      "train loss:0.00684529376987527\n",
      "train loss:0.007399625111922883\n",
      "train loss:0.0025961452687727825\n",
      "train loss:0.0006636999697001378\n",
      "train loss:0.008024960204515024\n",
      "train loss:0.009057137091536226\n",
      "train loss:0.0012676451642034047\n",
      "train loss:0.0006716552927122997\n",
      "train loss:0.016198024026570196\n",
      "train loss:0.003377312165529471\n",
      "train loss:0.0059651484446391215\n",
      "train loss:0.0005467905666347899\n",
      "train loss:0.004929911827550238\n",
      "train loss:0.0011087545665361897\n",
      "train loss:0.010086880069668297\n",
      "train loss:0.007635614451340814\n",
      "train loss:0.0017067530394974863\n",
      "train loss:0.009049726704990988\n",
      "train loss:0.0026910577189142803\n",
      "train loss:0.004440356258342888\n",
      "train loss:0.004849320814068352\n",
      "train loss:0.0009307087284194192\n",
      "train loss:0.006279010118161525\n",
      "train loss:0.009062114847554594\n",
      "train loss:0.0047521455412818684\n",
      "train loss:0.003850296231469018\n",
      "train loss:0.00026725579146255114\n",
      "train loss:0.025962169363073547\n",
      "train loss:0.0056654102605367814\n",
      "train loss:0.00331684422101205\n",
      "train loss:0.002760439399206717\n",
      "train loss:0.0038778461643263823\n",
      "train loss:0.002684942329562112\n",
      "train loss:0.002277126643404417\n",
      "train loss:0.04471673015672657\n",
      "train loss:0.006128417649742575\n",
      "train loss:0.006068209119073782\n",
      "train loss:0.0677184719023405\n",
      "train loss:0.013743627461974326\n",
      "train loss:0.004433228294745797\n",
      "train loss:0.0005714567330466116\n",
      "train loss:0.0009126266653588382\n",
      "train loss:0.017044353308082495\n",
      "train loss:0.002723074323434077\n",
      "train loss:0.004409409075294044\n",
      "train loss:0.0012153679555162531\n",
      "train loss:0.008134092176401243\n",
      "train loss:0.01480624411275639\n",
      "train loss:0.006408732542105702\n",
      "train loss:0.003797401119309457\n",
      "train loss:0.005193267616777546\n",
      "train loss:0.008257119158922176\n",
      "train loss:0.00816226680053484\n",
      "train loss:0.0011961582689400617\n",
      "train loss:0.007040259390342367\n",
      "train loss:0.004932092435178475\n",
      "train loss:0.0006285112242876167\n",
      "train loss:0.0020331579131436786\n",
      "train loss:0.003117911357875857\n",
      "train loss:0.003085178796749137\n",
      "train loss:0.0031080065436696223\n",
      "train loss:0.00198787566633743\n",
      "train loss:0.003050548124452092\n",
      "train loss:0.0019436368573515345\n",
      "train loss:0.0054016477456859365\n",
      "train loss:0.0010248855355648667\n",
      "train loss:0.012060781648429872\n",
      "train loss:0.036199121295772546\n",
      "train loss:0.003257041055569737\n",
      "train loss:0.0018790704857753857\n",
      "train loss:0.0007364429600882267\n",
      "train loss:0.002890831331822167\n",
      "train loss:0.03290879551234482\n",
      "train loss:0.003520504597726428\n",
      "train loss:0.0018207948122135117\n",
      "train loss:0.0004080931003280769\n",
      "train loss:0.002930676604780163\n",
      "train loss:0.002169260910734845\n",
      "train loss:0.007599129554066838\n",
      "train loss:0.011317126488121922\n",
      "train loss:0.011351918434053943\n",
      "train loss:0.0019281325737061975\n",
      "train loss:0.00023706936411593607\n",
      "train loss:0.001099154675784865\n",
      "train loss:0.002445314360386233\n",
      "train loss:0.008786537595966752\n",
      "train loss:0.0004696579793060856\n",
      "train loss:0.0016609779308477746\n",
      "train loss:0.00418072519977549\n",
      "train loss:0.002877769591814394\n",
      "train loss:0.008516977008474702\n",
      "train loss:0.004420094167821737\n",
      "train loss:0.0016699506095305368\n",
      "train loss:0.0017662599330414718\n",
      "train loss:0.0065317026485991496\n",
      "train loss:0.002936338660753462\n",
      "train loss:0.0037891221805452274\n",
      "train loss:0.002859662216845549\n",
      "train loss:0.0032695574867261236\n",
      "train loss:0.0003104010223442204\n",
      "train loss:0.006098360876187937\n",
      "train loss:0.004422470694407169\n",
      "train loss:0.0025299123809934564\n",
      "train loss:0.0005086899964445176\n",
      "train loss:0.002887154746049695\n",
      "train loss:0.002070189245171387\n",
      "train loss:0.010404500731548598\n",
      "train loss:0.001991257877781949\n",
      "train loss:0.004717187486464205\n",
      "train loss:0.004189632694632274\n",
      "train loss:0.0026003803889464087\n",
      "train loss:0.003985667977877047\n",
      "train loss:0.0007576973711906031\n",
      "train loss:0.004411993655493562\n",
      "train loss:0.003952387526929359\n",
      "train loss:0.0026239571877705752\n",
      "train loss:0.0005974777408065097\n",
      "train loss:0.004557762813966317\n",
      "train loss:0.0005172320217358034\n",
      "train loss:0.0008204023737795894\n",
      "train loss:0.0011972105015012671\n",
      "train loss:0.003976367811219584\n",
      "train loss:0.003140330013617661\n",
      "train loss:0.002606424165999537\n",
      "train loss:0.0013951858846170458\n",
      "train loss:0.0480154419454683\n",
      "train loss:0.0039062071880939385\n",
      "train loss:0.005204639471389462\n",
      "train loss:0.0002800397426933611\n",
      "train loss:0.0006052820736308754\n",
      "train loss:0.06300060692880285\n",
      "train loss:0.0037672002584309503\n",
      "train loss:0.00011065337568712884\n",
      "train loss:0.0003114573177348997\n",
      "train loss:0.0005662177535807748\n",
      "train loss:0.001993997648635082\n",
      "train loss:0.000695142120348027\n",
      "train loss:0.005070800427753268\n",
      "train loss:0.002193423398173553\n",
      "train loss:0.004197944109437774\n",
      "train loss:0.006360073793802174\n",
      "train loss:0.005909477794234923\n",
      "train loss:0.00024324293726435257\n",
      "train loss:0.0004024597938126335\n",
      "train loss:0.001701710178698567\n",
      "train loss:0.0004900977718709335\n",
      "train loss:0.0011264695848780435\n",
      "train loss:0.004389376232898772\n",
      "train loss:0.01750829125525486\n",
      "train loss:0.0009277248992226114\n",
      "train loss:0.0010786953823006303\n",
      "train loss:0.0016967792551820938\n",
      "train loss:0.0007743528063217891\n",
      "train loss:0.005188042031926184\n",
      "train loss:0.003911855787513145\n",
      "train loss:0.0017669472350141146\n",
      "train loss:0.002835071111947638\n",
      "train loss:0.003914162806733018\n",
      "train loss:0.0004972212058589376\n",
      "train loss:0.00570276060094451\n",
      "train loss:0.007993552711200445\n",
      "train loss:0.003084898690000922\n",
      "train loss:0.002926481162471928\n",
      "train loss:0.004660802007639785\n",
      "train loss:0.0006357070229636924\n",
      "train loss:0.0019299527302690663\n",
      "train loss:0.011509354698766981\n",
      "train loss:0.0017515678163318755\n",
      "train loss:0.0002912909120475577\n",
      "train loss:0.0004540446394871376\n",
      "train loss:0.003037159992348667\n",
      "train loss:0.003203121529260618\n",
      "train loss:0.0012406586461208937\n",
      "train loss:0.0006480215320990801\n",
      "train loss:0.0005986893659724996\n",
      "train loss:0.0015996921379441194\n",
      "train loss:0.006160156637964888\n",
      "train loss:0.0007542816667248638\n",
      "train loss:0.0004476686121440393\n",
      "train loss:0.004155190319834705\n",
      "train loss:0.002543103937983156\n",
      "train loss:0.004536307142486961\n",
      "train loss:0.003491056022656403\n",
      "train loss:0.002204690003780251\n",
      "train loss:0.0026179547620100844\n",
      "train loss:0.007098859734160967\n",
      "train loss:0.00511727080406132\n",
      "train loss:0.002883587210094762\n",
      "train loss:0.00425796934760791\n",
      "train loss:0.0014925890983593358\n",
      "train loss:0.0005315807505376406\n",
      "train loss:0.000827695287855683\n",
      "train loss:0.025996159841733407\n",
      "train loss:0.0013923324185058682\n",
      "train loss:0.0026496040123642544\n",
      "train loss:0.00042072912259457675\n",
      "train loss:0.00021359594987682668\n",
      "train loss:0.0003720269596162049\n",
      "train loss:0.002116174593476932\n",
      "train loss:0.004709215949012523\n",
      "train loss:0.003286494345915637\n",
      "train loss:0.012760450810839796\n",
      "train loss:0.0068048595277034295\n",
      "train loss:0.007958665987021954\n",
      "train loss:0.004381664891296076\n",
      "train loss:0.0021623163582625326\n",
      "train loss:0.002888512373149993\n",
      "train loss:0.0021251200933775577\n",
      "train loss:0.0014312567805454188\n",
      "train loss:0.024259324164461436\n",
      "train loss:0.00029413469017802344\n",
      "train loss:0.005079013412710007\n",
      "train loss:0.000997813857269278\n",
      "train loss:0.0007772085920275694\n",
      "train loss:0.0022442180520540855\n",
      "train loss:0.001877902436172249\n",
      "train loss:0.005129274381252393\n",
      "train loss:0.014713146160712327\n",
      "train loss:0.017057781542916536\n",
      "train loss:0.004893244763527036\n",
      "train loss:0.002335954813555036\n",
      "train loss:0.026876164760067392\n",
      "train loss:0.0034427323896816637\n",
      "train loss:0.002612818794987962\n",
      "train loss:0.005121417636326938\n",
      "train loss:0.0016674114019402902\n",
      "train loss:0.02548296394176959\n",
      "train loss:0.011351708034485992\n",
      "train loss:0.032084232433149444\n",
      "train loss:0.00029463454147954257\n",
      "train loss:0.027236058340259467\n",
      "train loss:0.013886042341450435\n",
      "train loss:0.0022024441812979858\n",
      "train loss:0.004828703220646459\n",
      "train loss:0.0018151735978582074\n",
      "train loss:0.003148208958802115\n",
      "train loss:0.001879566305129626\n",
      "train loss:0.003450504083703563\n",
      "train loss:0.003863555404103794\n",
      "train loss:0.050734784717062296\n",
      "train loss:0.0026596567156770695\n",
      "train loss:0.032871714697974716\n",
      "train loss:0.003096735253166076\n",
      "train loss:0.0040803253994453935\n",
      "train loss:0.0025019949482663743\n",
      "train loss:0.003802175826237274\n",
      "train loss:0.0069888486820792305\n",
      "train loss:0.0004344229653677518\n",
      "train loss:0.0024624253104815973\n",
      "train loss:0.00305986732180372\n",
      "train loss:0.02931080730433215\n",
      "train loss:0.004799112906639889\n",
      "train loss:0.022489284137924326\n",
      "train loss:0.0017058164348139687\n",
      "train loss:0.0022433996798098804\n",
      "train loss:0.002342799746075858\n",
      "train loss:0.0013208995948155056\n",
      "train loss:0.0013203252337699904\n",
      "train loss:0.04371363114487689\n",
      "train loss:0.0012808724092303386\n",
      "train loss:0.007475280283065325\n",
      "train loss:0.031587094509567454\n",
      "train loss:0.00102716472169916\n",
      "train loss:0.007473160987945315\n",
      "train loss:0.001956897781677028\n",
      "train loss:0.000919855601553245\n",
      "train loss:0.0030200415099371288\n",
      "train loss:0.006833481990279467\n",
      "train loss:0.0015714301173784322\n",
      "train loss:0.003339391304231834\n",
      "train loss:0.012256264897856521\n",
      "train loss:0.001630207434425729\n",
      "train loss:0.005223305743208111\n",
      "train loss:0.06436918688312977\n",
      "train loss:0.0035086588646251375\n",
      "train loss:0.004735416901920724\n",
      "train loss:0.005367714805221543\n",
      "train loss:0.004994022021498517\n",
      "train loss:0.001703071481126556\n",
      "train loss:0.003763037401885758\n",
      "train loss:0.0012857217671391375\n",
      "train loss:0.00017000564748922853\n",
      "train loss:0.027253269773102863\n",
      "train loss:0.0029283807583251583\n",
      "train loss:0.004508528340764283\n",
      "train loss:0.006264069323083794\n",
      "train loss:0.003727543654545072\n",
      "train loss:0.0014747829993130884\n",
      "train loss:0.00013318220362905974\n",
      "train loss:0.0016026829015677111\n",
      "train loss:0.0014442211493823078\n",
      "train loss:0.014873071185251758\n",
      "train loss:0.003532574611375337\n",
      "train loss:0.0018548578638672424\n",
      "train loss:0.0041818900889113554\n",
      "train loss:0.003494355020054667\n",
      "train loss:0.0011637814584027617\n",
      "train loss:0.0007081456858314966\n",
      "train loss:0.00036401383232782846\n",
      "train loss:0.05456218766574843\n",
      "train loss:0.00241369623293277\n",
      "train loss:0.0466374677212825\n",
      "train loss:0.01369486015856509\n",
      "train loss:0.001295494391867254\n",
      "train loss:0.005182551198846745\n",
      "train loss:0.04220738477671976\n",
      "train loss:0.004729545282820943\n",
      "train loss:0.0008544661103676676\n",
      "train loss:0.007663504714606385\n",
      "train loss:0.000996079212182231\n",
      "train loss:0.03975485367880666\n",
      "train loss:0.001562497412612659\n",
      "train loss:0.010101486928380343\n",
      "train loss:0.0008653928820621456\n",
      "train loss:0.0001777137125432566\n",
      "train loss:0.002032040393818119\n",
      "train loss:0.011037223295103394\n",
      "train loss:0.0010290472615554775\n",
      "train loss:0.0002514368182392082\n",
      "train loss:0.007758019597301637\n",
      "train loss:0.0008322885291809174\n",
      "train loss:0.0008115586683867734\n",
      "train loss:0.03671156993680328\n",
      "train loss:0.008616809132678281\n",
      "train loss:0.0006140858562504523\n",
      "train loss:0.054577995214626515\n",
      "train loss:0.0004815620929151456\n",
      "train loss:0.005693430642058145\n",
      "train loss:0.0024286254303319196\n",
      "train loss:0.005152162615159491\n",
      "train loss:0.0022048556608491735\n",
      "train loss:0.00042441295880151934\n",
      "train loss:0.0010603533726338589\n",
      "train loss:0.00038443099186185134\n",
      "train loss:0.004415610754405128\n",
      "train loss:0.011611140957305865\n",
      "train loss:0.015983890769907902\n",
      "train loss:0.0041719971030837145\n",
      "train loss:0.0028326994837816\n",
      "train loss:0.006061879433675954\n",
      "train loss:0.002312654660302827\n",
      "train loss:0.001439975361540967\n",
      "train loss:0.000978941460886959\n",
      "train loss:0.005132133413483498\n",
      "train loss:0.003176387864285892\n",
      "train loss:0.006677826593141211\n",
      "=== epoch:13, train acc:0.997, test acc:0.986 ===\n",
      "train loss:0.012094596627339914\n",
      "train loss:0.008154862839647227\n",
      "train loss:0.007845877282525277\n",
      "train loss:0.008880462276301355\n",
      "train loss:0.001943842515640591\n",
      "train loss:0.003628364941902118\n",
      "train loss:0.004758097558447\n",
      "train loss:0.0012160650874158303\n",
      "train loss:0.004661996404056122\n",
      "train loss:0.004371872784984831\n",
      "train loss:0.004129546731550902\n",
      "train loss:0.0014959712195753902\n",
      "train loss:0.011044282834894099\n",
      "train loss:0.0022128422870526495\n",
      "train loss:0.009091448616261426\n",
      "train loss:0.00039036742279855964\n",
      "train loss:0.0007328132592106462\n",
      "train loss:0.011247493800411965\n",
      "train loss:0.0006529215223144614\n",
      "train loss:0.003821071267966161\n",
      "train loss:0.0038255992636101266\n",
      "train loss:0.0019430058814807825\n",
      "train loss:0.0024192156618464463\n",
      "train loss:0.0014590070621829446\n",
      "train loss:0.00618025265456293\n",
      "train loss:0.0029908891632147\n",
      "train loss:0.0015870080237080592\n",
      "train loss:0.0006801820877945311\n",
      "train loss:0.002486239954469624\n",
      "train loss:0.0027841658132544\n",
      "train loss:0.0035750934643602704\n",
      "train loss:0.005114700768903719\n",
      "train loss:0.007073086959786658\n",
      "train loss:0.0024897415217338776\n",
      "train loss:0.0062099219642432705\n",
      "train loss:0.0012714894234779814\n",
      "train loss:0.003122091987682297\n",
      "train loss:0.006661425619140984\n",
      "train loss:0.002242790071685705\n",
      "train loss:0.0016488545876171407\n",
      "train loss:0.00044374170564709435\n",
      "train loss:0.00048587155930940437\n",
      "train loss:0.0015129541337757057\n",
      "train loss:0.004368675661534194\n",
      "train loss:0.0032970312293025173\n",
      "train loss:0.005032598593967605\n",
      "train loss:0.005965360190323063\n",
      "train loss:0.0019301889086232552\n",
      "train loss:0.0002381441511049971\n",
      "train loss:0.00205026895167538\n",
      "train loss:0.004341320173086163\n",
      "train loss:0.0028698800822429867\n",
      "train loss:0.007325838303506915\n",
      "train loss:0.0005031756753345142\n",
      "train loss:0.0005010175474821567\n",
      "train loss:0.001763420675139094\n",
      "train loss:0.006438460495146808\n",
      "train loss:0.00016976771149263198\n",
      "train loss:0.003579371983267336\n",
      "train loss:0.0032308657075725516\n",
      "train loss:0.008340142923832684\n",
      "train loss:0.002505982780112861\n",
      "train loss:0.0026054467650499158\n",
      "train loss:0.003970360410819756\n",
      "train loss:0.0017134609790308\n",
      "train loss:0.0026140199757631625\n",
      "train loss:0.001331762805910617\n",
      "train loss:0.0011765817726001784\n",
      "train loss:0.014983245211085872\n",
      "train loss:0.0016180153804023808\n",
      "train loss:0.002665324891934417\n",
      "train loss:0.06152175512838501\n",
      "train loss:0.007902576491731707\n",
      "train loss:0.001547340869324755\n",
      "train loss:0.003363352231598374\n",
      "train loss:0.00621426891356224\n",
      "train loss:0.0023935453421166856\n",
      "train loss:0.0026030039788009223\n",
      "train loss:0.0013040307154123265\n",
      "train loss:0.0055125653781149305\n",
      "train loss:0.00806899784384659\n",
      "train loss:0.031604600332247816\n",
      "train loss:0.01066665871125709\n",
      "train loss:0.003141886098617066\n",
      "train loss:0.0007788652219878793\n",
      "train loss:0.0012550875037209116\n",
      "train loss:0.0038844614777729506\n",
      "train loss:0.0008956085548618659\n",
      "train loss:0.0010367931433107045\n",
      "train loss:0.0030961015382219848\n",
      "train loss:0.010261848695797911\n",
      "train loss:0.003084732709774315\n",
      "train loss:0.004065630753472836\n",
      "train loss:0.001213802016504169\n",
      "train loss:0.0020699883992629747\n",
      "train loss:0.007834910861883733\n",
      "train loss:0.009851261616306627\n",
      "train loss:0.006653749547307835\n",
      "train loss:0.012304413552657347\n",
      "train loss:0.0032316257767278896\n",
      "train loss:0.0021358680523527783\n",
      "train loss:0.00925604779652824\n",
      "train loss:0.001283948166644635\n",
      "train loss:0.00041659784030928217\n",
      "train loss:0.0019024601993705358\n",
      "train loss:0.0004253069821496494\n",
      "train loss:0.0012524359781282996\n",
      "train loss:0.003684784770425045\n",
      "train loss:0.003967225478215787\n",
      "train loss:0.00016479261729589797\n",
      "train loss:0.00030305634350986287\n",
      "train loss:0.05123020339532291\n",
      "train loss:0.002127748472927232\n",
      "train loss:0.08099096708630289\n",
      "train loss:0.0016361563715487496\n",
      "train loss:0.00039181011479866843\n",
      "train loss:0.0017612711958495556\n",
      "train loss:0.0014733696369653158\n",
      "train loss:0.0017141438285881558\n",
      "train loss:0.003012597303961501\n",
      "train loss:0.0003472809906118393\n",
      "train loss:0.012787773039753267\n",
      "train loss:0.03347850346097561\n",
      "train loss:0.021195370753083788\n",
      "train loss:0.007644426311618863\n",
      "train loss:0.0005670601820355778\n",
      "train loss:0.00020521341859376408\n",
      "train loss:0.0021277970774578343\n",
      "train loss:0.008483562919240222\n",
      "train loss:0.004611384582944853\n",
      "train loss:0.0043393959435823574\n",
      "train loss:0.10729302918978671\n",
      "train loss:0.0006505188761696609\n",
      "train loss:0.0017488452298151202\n",
      "train loss:0.004400068991226935\n",
      "train loss:0.001165506011951651\n",
      "train loss:0.007709319609033058\n",
      "train loss:0.0051715913899863875\n",
      "train loss:0.0005444076878091223\n",
      "train loss:0.004100048929446695\n",
      "train loss:0.0036075802694086672\n",
      "train loss:0.001429630257491979\n",
      "train loss:0.002503168787318688\n",
      "train loss:0.010053346864181838\n",
      "train loss:0.003677147641959539\n",
      "train loss:0.0004950843780118\n",
      "train loss:0.001198681679626683\n",
      "train loss:0.004120094350624838\n",
      "train loss:0.0006781376896034952\n",
      "train loss:0.0003792813129624009\n",
      "train loss:0.0023668380096026603\n",
      "train loss:0.006012122353744725\n",
      "train loss:0.0011748055025837302\n",
      "train loss:0.0013616527393563388\n",
      "train loss:0.020354462889295696\n",
      "train loss:0.0041068843859193745\n",
      "train loss:0.008832030436736802\n",
      "train loss:0.0006008240016651462\n",
      "train loss:0.0006993419080573826\n",
      "train loss:0.003224774262916306\n",
      "train loss:0.0028540526433158907\n",
      "train loss:0.00522239225653423\n",
      "train loss:0.00938514258060546\n",
      "train loss:0.0019164267547857152\n",
      "train loss:0.002675831024307825\n",
      "train loss:0.0012110970167915761\n",
      "train loss:0.0028832294850166433\n",
      "train loss:0.0004587260127245673\n",
      "train loss:0.001516089050533383\n",
      "train loss:0.001002000639411481\n",
      "train loss:0.04655716030547199\n",
      "train loss:0.004686325567959639\n",
      "train loss:0.00045587369368960053\n",
      "train loss:0.0029756007623122738\n",
      "train loss:0.0013647296251629094\n",
      "train loss:0.002278982515894222\n",
      "train loss:0.0020855649721670142\n",
      "train loss:0.00030395072331357954\n",
      "train loss:0.0032445168621623487\n",
      "train loss:0.00011415713527592954\n",
      "train loss:0.0013647907157976196\n",
      "train loss:0.002409455873668507\n",
      "train loss:0.004590266513271145\n",
      "train loss:0.002534038821081663\n",
      "train loss:0.01839638587016736\n",
      "train loss:0.0018126782616819175\n",
      "train loss:0.0003143521547090644\n",
      "train loss:0.010085195185544831\n",
      "train loss:0.0011101797263299185\n",
      "train loss:0.0004824116708959939\n",
      "train loss:0.005380675065447233\n",
      "train loss:0.04457606598428459\n",
      "train loss:0.001091093088957962\n",
      "train loss:0.012019625106358272\n",
      "train loss:0.0020153236554733105\n",
      "train loss:0.028421328878564685\n",
      "train loss:0.008565355086642417\n",
      "train loss:0.02198815315516849\n",
      "train loss:0.011822559511057786\n",
      "train loss:0.005345853734640506\n",
      "train loss:0.014501320026973758\n",
      "train loss:0.012302447218031325\n",
      "train loss:0.007183078380748767\n",
      "train loss:0.0034469259645974605\n",
      "train loss:0.0021502313611006583\n",
      "train loss:0.00979399657208431\n",
      "train loss:0.005134853208678011\n",
      "train loss:0.00489718457964238\n",
      "train loss:0.002179051914611209\n",
      "train loss:0.001072404308360167\n",
      "train loss:0.0029196433181764734\n",
      "train loss:0.005841577901440035\n",
      "train loss:0.003600899551061002\n",
      "train loss:0.005523619166517529\n",
      "train loss:0.0018646034054736105\n",
      "train loss:0.003951345078992124\n",
      "train loss:0.0010119262353334958\n",
      "train loss:0.0030406676016753727\n",
      "train loss:0.0015591507739252703\n",
      "train loss:0.00479762768096665\n",
      "train loss:0.001080236410903305\n",
      "train loss:0.001253044079483793\n",
      "train loss:0.006097140757912328\n",
      "train loss:0.002456197471762378\n",
      "train loss:0.004071945492962302\n",
      "train loss:0.0011833276541260368\n",
      "train loss:0.0013611806588321284\n",
      "train loss:0.002990494689002734\n",
      "train loss:0.0020754673388617873\n",
      "train loss:0.003733090309909475\n",
      "train loss:0.003397070221322934\n",
      "train loss:0.0013353123217260288\n",
      "train loss:0.009873569251106898\n",
      "train loss:0.0038390583834048953\n",
      "train loss:0.00476049530867103\n",
      "train loss:0.001337382952299844\n",
      "train loss:0.0033841547743532962\n",
      "train loss:0.002547980435641711\n",
      "train loss:0.009096757890670163\n",
      "train loss:0.0002506513137842246\n",
      "train loss:0.005346383001867832\n",
      "train loss:0.0070044303279272815\n",
      "train loss:0.003119648294887555\n",
      "train loss:0.006289026601920819\n",
      "train loss:0.0025162880222273014\n",
      "train loss:0.002368726134955041\n",
      "train loss:0.00643209810665053\n",
      "train loss:0.0020244704620644488\n",
      "train loss:0.0027559592034892806\n",
      "train loss:0.015272047936750154\n",
      "train loss:0.002696324291715259\n",
      "train loss:0.0009191218603304029\n",
      "train loss:0.0031172699051168506\n",
      "train loss:0.013634887830630646\n",
      "train loss:0.004681933997222694\n",
      "train loss:0.02628809933846094\n",
      "train loss:0.0005640148327693853\n",
      "train loss:0.00365508617932295\n",
      "train loss:0.015510977088135688\n",
      "train loss:0.00564785185659743\n",
      "train loss:0.0004422785784421179\n",
      "train loss:0.003916421949241961\n",
      "train loss:0.0015202801542098098\n",
      "train loss:0.0029651131058526714\n",
      "train loss:0.007171906404265203\n",
      "train loss:0.001806797860913848\n",
      "train loss:0.0013741493336267465\n",
      "train loss:0.004999987808711753\n",
      "train loss:0.004452822821002626\n",
      "train loss:0.004463417350020779\n",
      "train loss:0.004651152825990677\n",
      "train loss:0.0012240839834322778\n",
      "train loss:0.0003043497103066208\n",
      "train loss:0.00024082781408319524\n",
      "train loss:0.00230529834250066\n",
      "train loss:0.000574070247872977\n",
      "train loss:0.0009318385181198593\n",
      "train loss:0.0035612330031663266\n",
      "train loss:0.0008908478946344471\n",
      "train loss:0.007264030838290646\n",
      "train loss:0.002221202853288373\n",
      "train loss:0.0003683786755511655\n",
      "train loss:0.007494635410690278\n",
      "train loss:0.0023417534473924866\n",
      "train loss:0.0036421524902749253\n",
      "train loss:0.014123646332891104\n",
      "train loss:0.0014038758944654834\n",
      "train loss:0.005361926078244741\n",
      "train loss:0.0017999421855204034\n",
      "train loss:0.001972800481024689\n",
      "train loss:0.00804434160689651\n",
      "train loss:0.0008283513207722449\n",
      "train loss:0.0030329793412121647\n",
      "train loss:0.00398263381199485\n",
      "train loss:0.006619509103252633\n",
      "train loss:0.0006708445540890826\n",
      "train loss:0.00721760772080482\n",
      "train loss:0.0017844932035128427\n",
      "train loss:0.027503651349780632\n",
      "train loss:0.0065100747774864695\n",
      "train loss:0.004358013215760129\n",
      "train loss:0.009512206697249583\n",
      "train loss:0.001277166819749944\n",
      "train loss:0.0016922160786793333\n",
      "train loss:0.00311847523567988\n",
      "train loss:0.0015383315512263413\n",
      "train loss:0.0016090984272704636\n",
      "train loss:0.007802674620723318\n",
      "train loss:0.001989103635670258\n",
      "train loss:0.002012239693403189\n",
      "train loss:0.0008968162810616206\n",
      "train loss:0.006378969483385653\n",
      "train loss:0.0004291490237070499\n",
      "train loss:0.03683733227921671\n",
      "train loss:0.0005820362581260394\n",
      "train loss:0.00042136617356126297\n",
      "train loss:0.0030166180728417188\n",
      "train loss:0.01123727638746081\n",
      "train loss:0.0005446798335604334\n",
      "train loss:0.005326767724078209\n",
      "train loss:0.0005009016715235\n",
      "train loss:0.0005292622928376344\n",
      "train loss:0.001459525416168949\n",
      "train loss:0.008932924578706822\n",
      "train loss:0.00023464022223064064\n",
      "train loss:0.007713994396083981\n",
      "train loss:0.0017345894199387146\n",
      "train loss:0.006035726848168824\n",
      "train loss:0.007246760547249705\n",
      "train loss:0.00315240867413579\n",
      "train loss:0.0019324332189984052\n",
      "train loss:0.005460896145598463\n",
      "train loss:0.0028922906177733386\n",
      "train loss:0.0007043905729471174\n",
      "train loss:0.0030523375239805877\n",
      "train loss:0.0030967618082094893\n",
      "train loss:0.0005985606143291819\n",
      "train loss:0.0015081212221797432\n",
      "train loss:0.0013866193317179385\n",
      "train loss:0.0017347087184725089\n",
      "train loss:0.0009839069456551086\n",
      "train loss:0.0023618481698355165\n",
      "train loss:0.005905399106776046\n",
      "train loss:0.0009453390590224853\n",
      "train loss:0.003661809715865657\n",
      "train loss:0.0005903895791583548\n",
      "train loss:0.039043061605768925\n",
      "train loss:0.00020080089948881473\n",
      "train loss:0.0024748762784174206\n",
      "train loss:0.012922886837893761\n",
      "train loss:0.017890422775699678\n",
      "train loss:0.00039565358737460164\n",
      "train loss:0.0012879065496351166\n",
      "train loss:0.013197593444291727\n",
      "train loss:0.002124587965280381\n",
      "train loss:0.004294276190148716\n",
      "train loss:0.0017337099418179023\n",
      "train loss:0.004175352259547987\n",
      "train loss:0.0011355822343060524\n",
      "train loss:0.0012957785701785444\n",
      "train loss:0.009192289410921272\n",
      "train loss:0.0005977389037613897\n",
      "train loss:0.008221703481755313\n",
      "train loss:0.000612289365609459\n",
      "train loss:0.007836562242385537\n",
      "train loss:0.0008006199622396911\n",
      "train loss:0.003842226490813703\n",
      "train loss:0.0036102584804529737\n",
      "train loss:0.001808716268698331\n",
      "train loss:0.005529933768758808\n",
      "train loss:0.002830042648529995\n",
      "train loss:0.0014094523583258183\n",
      "train loss:0.007927412681814383\n",
      "train loss:0.0005486556515746784\n",
      "train loss:0.00300676543895115\n",
      "train loss:0.0009638894931181631\n",
      "train loss:0.005139261760365196\n",
      "train loss:0.0022996967370834923\n",
      "train loss:0.002346773683203011\n",
      "train loss:0.003959368352519905\n",
      "train loss:0.01771966210866405\n",
      "train loss:0.003138271001085679\n",
      "train loss:0.001335812071582304\n",
      "train loss:0.006257988228834565\n",
      "train loss:0.0016829763173526614\n",
      "train loss:0.013362817312531776\n",
      "train loss:0.0012322311913785984\n",
      "train loss:0.003799855551819254\n",
      "train loss:0.006135617792343925\n",
      "train loss:0.0033807028492367002\n",
      "train loss:0.005082070302123242\n",
      "train loss:0.0033894381833064623\n",
      "train loss:0.0002595016958803544\n",
      "train loss:0.0011366955779079661\n",
      "train loss:0.0017485310312454908\n",
      "train loss:0.00023579266963873026\n",
      "train loss:0.006194171671726681\n",
      "train loss:0.0021629313702207806\n",
      "train loss:0.022110822125553497\n",
      "train loss:0.001532125584431323\n",
      "train loss:0.0016758742595366146\n",
      "train loss:0.0036142574502604575\n",
      "train loss:0.012549717527268755\n",
      "train loss:0.001881864019984537\n",
      "train loss:0.011506334967706462\n",
      "train loss:0.0175481329554074\n",
      "train loss:0.0006314341327383562\n",
      "train loss:0.006062025919947917\n",
      "train loss:0.0007026103946757944\n",
      "train loss:0.0035152920111870263\n",
      "train loss:0.01447148927809891\n",
      "train loss:0.004266755941288121\n",
      "train loss:0.007141069324497557\n",
      "train loss:0.0023684167760967233\n",
      "train loss:0.004303941380196669\n",
      "train loss:0.0011737724813297035\n",
      "train loss:0.0011894960894500352\n",
      "train loss:0.0002931808704946837\n",
      "train loss:0.003035303605052211\n",
      "train loss:0.003978994332666008\n",
      "train loss:0.0008264469940771573\n",
      "train loss:0.00027765647286796813\n",
      "train loss:0.00424921483787451\n",
      "train loss:0.0021657749235872367\n",
      "train loss:0.0010856568469695353\n",
      "train loss:0.0050996708147987005\n",
      "train loss:0.002956473788954193\n",
      "train loss:0.002120168866633509\n",
      "train loss:0.0010197115228738809\n",
      "train loss:0.0002883230732299083\n",
      "train loss:0.0007848410620659523\n",
      "train loss:0.0007784048077935963\n",
      "train loss:0.0032008205081980614\n",
      "train loss:0.00215104558578343\n",
      "train loss:0.0005538579246130326\n",
      "train loss:0.0023516245898106765\n",
      "train loss:0.004315696670075708\n",
      "train loss:0.005906317244427139\n",
      "train loss:0.0026011444187862215\n",
      "train loss:0.0009122962411570138\n",
      "train loss:0.0019187704042081491\n",
      "train loss:0.004309410745275189\n",
      "train loss:0.00017612068137452184\n",
      "train loss:0.0017756494190626134\n",
      "train loss:0.0013624395930303815\n",
      "train loss:0.0013097382612184375\n",
      "train loss:0.0023796475024481\n",
      "train loss:0.0014783690505442086\n",
      "train loss:0.0007497268613747186\n",
      "train loss:0.002160011269157598\n",
      "train loss:0.003203502348189411\n",
      "train loss:0.003882286638818636\n",
      "train loss:0.0031521866473412136\n",
      "train loss:0.005961513987046401\n",
      "train loss:0.0027125000485996613\n",
      "train loss:0.00016115516955608273\n",
      "train loss:0.0028879169736621487\n",
      "train loss:0.003515103942458073\n",
      "train loss:0.0006148264533569841\n",
      "train loss:0.0015078922520051295\n",
      "train loss:0.004818086658326996\n",
      "train loss:0.00039734918919184174\n",
      "train loss:0.00013921951615653111\n",
      "train loss:0.004956797662114146\n",
      "train loss:0.0016222855880917086\n",
      "train loss:0.0007648285315864537\n",
      "train loss:0.0026857823332202863\n",
      "train loss:0.003977292859722083\n",
      "train loss:0.0010765752027522494\n",
      "train loss:0.003410183697295933\n",
      "train loss:0.007091013240956454\n",
      "train loss:0.002290879499776016\n",
      "train loss:0.015401716076273463\n",
      "train loss:0.0010338724937649284\n",
      "train loss:0.0017478369227931806\n",
      "train loss:0.00017732230108793442\n",
      "train loss:0.00040345243483067743\n",
      "train loss:0.004973013023559552\n",
      "train loss:0.0024346755975654714\n",
      "train loss:0.0017309107225142275\n",
      "train loss:0.012035984696102377\n",
      "train loss:0.0003262152960728088\n",
      "train loss:0.0008708940137229667\n",
      "train loss:0.006667601227928933\n",
      "train loss:0.003133570939115642\n",
      "train loss:0.00022672429845311737\n",
      "train loss:0.0034842731908075924\n",
      "train loss:0.00038157462736893824\n",
      "train loss:0.0035497112930712826\n",
      "train loss:0.008485634427315368\n",
      "train loss:0.003633487996080417\n",
      "train loss:0.006877265426508607\n",
      "train loss:0.002368671072157411\n",
      "train loss:0.004263680640285346\n",
      "train loss:0.01652693584068199\n",
      "train loss:0.007299557461798917\n",
      "train loss:0.00442534455041908\n",
      "train loss:0.0013649407293981858\n",
      "train loss:0.0041006948134927\n",
      "train loss:0.005470533443138528\n",
      "train loss:0.0011823068336324128\n",
      "train loss:0.0023434208459998064\n",
      "train loss:0.005353985247532279\n",
      "train loss:0.002244811070525485\n",
      "train loss:0.014879284261958519\n",
      "train loss:0.005332662744506188\n",
      "train loss:0.008191429712556111\n",
      "train loss:0.001447128547163844\n",
      "train loss:0.0004204882070102208\n",
      "train loss:0.006906655182161678\n",
      "train loss:0.002538711290224255\n",
      "train loss:0.004054759900429321\n",
      "train loss:0.004611189569219173\n",
      "train loss:0.001643313681537972\n",
      "train loss:0.01087996889251528\n",
      "train loss:0.0011389798384656767\n",
      "train loss:0.008233459990644171\n",
      "train loss:0.00032452075385221347\n",
      "train loss:0.006422110015801916\n",
      "train loss:0.009543956905521367\n",
      "train loss:0.0008770998677307183\n",
      "train loss:0.002940271265793742\n",
      "train loss:0.0008325340097210973\n",
      "train loss:0.0009199473579895759\n",
      "train loss:0.0007915865871206629\n",
      "train loss:0.001686624787887539\n",
      "train loss:0.004089310384557973\n",
      "train loss:0.010313214180033059\n",
      "train loss:0.005139001839869933\n",
      "train loss:0.009052328739043594\n",
      "train loss:0.00025229416651540695\n",
      "train loss:0.0007844090293177767\n",
      "train loss:0.0008553952609425511\n",
      "train loss:0.018097699184700236\n",
      "train loss:0.0025526867842480534\n",
      "train loss:0.0027741325773693367\n",
      "train loss:0.015873703904394104\n",
      "train loss:0.01222847412780856\n",
      "train loss:0.003688433505503318\n",
      "train loss:0.0037149439596942625\n",
      "train loss:0.0009650839313832106\n",
      "train loss:0.001966685802063756\n",
      "train loss:0.0023055536707775235\n",
      "train loss:0.00039139704583255984\n",
      "train loss:0.00750509239395122\n",
      "train loss:0.004889301806708396\n",
      "train loss:0.0012731556667765498\n",
      "train loss:0.017215425566250914\n",
      "train loss:0.004287684636430363\n",
      "train loss:0.005398910558179878\n",
      "train loss:0.0004962422046535721\n",
      "train loss:0.0008723123335502063\n",
      "train loss:0.0003146519765312427\n",
      "train loss:0.0012803172190620868\n",
      "train loss:0.001779248603026333\n",
      "train loss:0.0018200864862371684\n",
      "train loss:0.002693633039940657\n",
      "train loss:0.001296026823554091\n",
      "train loss:0.013721166491193825\n",
      "train loss:0.0018851134841620049\n",
      "train loss:0.010285716674484548\n",
      "train loss:0.003022535487499651\n",
      "train loss:0.002378316263187964\n",
      "train loss:0.001088937837791731\n",
      "train loss:0.005453664758052731\n",
      "train loss:0.023604661950515585\n",
      "train loss:0.0006584875828254126\n",
      "train loss:0.002259892885091743\n",
      "train loss:0.0056308249637487704\n",
      "train loss:0.0005017948970403115\n",
      "train loss:0.006986565473868134\n",
      "train loss:0.005454282023565194\n",
      "train loss:0.0015440385949755983\n",
      "train loss:0.0032793299795587216\n",
      "train loss:0.0018968683739819944\n",
      "train loss:0.007364581546444457\n",
      "train loss:0.0017170702968332175\n",
      "train loss:0.011027414028141677\n",
      "train loss:0.0031011959327871203\n",
      "train loss:0.0007369825459859782\n",
      "train loss:0.0008785197029530199\n",
      "train loss:0.0003988700615940706\n",
      "train loss:0.007027744225971636\n",
      "train loss:0.004701020971131811\n",
      "train loss:0.002774645360608315\n",
      "train loss:0.002781934115539873\n",
      "train loss:0.007151635928323789\n",
      "train loss:0.00589198452811955\n",
      "train loss:0.0016154110618000926\n",
      "train loss:0.0004924495974216392\n",
      "train loss:0.002320130886016376\n",
      "train loss:0.00016015388850384147\n",
      "train loss:0.0027852892234580427\n",
      "train loss:0.0032510295834553924\n",
      "train loss:0.0030427793619905983\n",
      "train loss:0.0022230226426705056\n",
      "train loss:0.003427429074221318\n",
      "train loss:0.007001486796753188\n",
      "train loss:0.006025735378095731\n",
      "train loss:0.004196895773770162\n",
      "=== epoch:14, train acc:0.996, test acc:0.986 ===\n",
      "train loss:0.0014459440607482638\n",
      "train loss:0.006866813750798521\n",
      "train loss:0.0017656039537492358\n",
      "train loss:0.002562698507231808\n",
      "train loss:0.0015859949619364988\n",
      "train loss:0.001511386724969556\n",
      "train loss:0.0029759836937146805\n",
      "train loss:0.00026066843665051385\n",
      "train loss:0.0005362401374855859\n",
      "train loss:0.008272294415135734\n",
      "train loss:0.0006185989906455542\n",
      "train loss:0.001480559225887671\n",
      "train loss:0.0010715442402965227\n",
      "train loss:0.004317799213785747\n",
      "train loss:0.008940115822486877\n",
      "train loss:0.0007713000026792419\n",
      "train loss:0.0015118086071666944\n",
      "train loss:0.0010210383292630408\n",
      "train loss:0.0025276663516738923\n",
      "train loss:0.0005670239330301199\n",
      "train loss:0.0030855882481131223\n",
      "train loss:0.00545944821400945\n",
      "train loss:0.005276764366926755\n",
      "train loss:0.004877445841488604\n",
      "train loss:0.0001961022471427639\n",
      "train loss:0.0016941778583633529\n",
      "train loss:0.0014834319054855838\n",
      "train loss:0.002856934170020402\n",
      "train loss:0.0033553189766972473\n",
      "train loss:0.0023744874295483186\n",
      "train loss:0.006379765036952481\n",
      "train loss:0.012416692869757176\n",
      "train loss:0.0016634538913450963\n",
      "train loss:0.0059905778432681875\n",
      "train loss:0.01020492732356641\n",
      "train loss:0.011259664794927465\n",
      "train loss:0.004466557523743695\n",
      "train loss:0.008879302973057014\n",
      "train loss:0.00225442892468374\n",
      "train loss:0.014174520318033988\n",
      "train loss:0.003137526130920927\n",
      "train loss:0.005106015996881199\n",
      "train loss:0.00035525469924633667\n",
      "train loss:0.003971999285621204\n",
      "train loss:0.002249991054026151\n",
      "train loss:0.0032629889392832316\n",
      "train loss:0.0028572865866348307\n",
      "train loss:0.0013033485622162822\n",
      "train loss:0.0009519529047806421\n",
      "train loss:0.0027539952141437964\n",
      "train loss:0.001565211620741575\n",
      "train loss:0.000904184256370373\n",
      "train loss:0.005603348247332053\n",
      "train loss:0.001619671293117899\n",
      "train loss:0.00711234083939602\n",
      "train loss:0.0017387643344247803\n",
      "train loss:0.0034207456195399404\n",
      "train loss:0.0009410924118588776\n",
      "train loss:0.004030252336866964\n",
      "train loss:0.0024232329849842903\n",
      "train loss:0.001659986492053669\n",
      "train loss:0.0026658418748451117\n",
      "train loss:0.004856870526586385\n",
      "train loss:0.0038344080383275296\n",
      "train loss:0.003017248959528866\n",
      "train loss:0.0010087354251617682\n",
      "train loss:0.006081218768140228\n",
      "train loss:0.004029636684553498\n",
      "train loss:0.003360411718786681\n",
      "train loss:0.00255073557036549\n",
      "train loss:0.00745523756442714\n",
      "train loss:0.0014194965130036518\n",
      "train loss:0.003964373616250438\n",
      "train loss:0.004478563839492262\n",
      "train loss:0.007075442930853173\n",
      "train loss:0.0006978474373928792\n",
      "train loss:0.0020412156903272935\n",
      "train loss:0.013224152293281808\n",
      "train loss:0.0006009195439754457\n",
      "train loss:0.005994280395801719\n",
      "train loss:0.0021308933946035504\n",
      "train loss:0.004644363461233715\n",
      "train loss:0.001483918854067575\n",
      "train loss:0.0009180779145849815\n",
      "train loss:0.0002550254709231\n",
      "train loss:0.015095491005367391\n",
      "train loss:0.003686398527079418\n",
      "train loss:0.004472291775071459\n",
      "train loss:0.003937233861329898\n",
      "train loss:0.000938384919927236\n",
      "train loss:0.0033429622484887496\n",
      "train loss:0.0005930952683067984\n",
      "train loss:0.00019282395463331118\n",
      "train loss:0.005774202469958974\n",
      "train loss:0.0005281127128128718\n",
      "train loss:0.004757216708643929\n",
      "train loss:0.008050750685872576\n",
      "train loss:0.000915673113560507\n",
      "train loss:0.001351981040649667\n",
      "train loss:0.015503387675748033\n",
      "train loss:0.001760183933863615\n",
      "train loss:0.002376417844726126\n",
      "train loss:0.006753413171163324\n",
      "train loss:0.0024388001247017924\n",
      "train loss:0.0005521806315480677\n",
      "train loss:0.002516183014173818\n",
      "train loss:0.006788139817329291\n",
      "train loss:0.00568665348693707\n",
      "train loss:0.005541170013141845\n",
      "train loss:0.004008179078876174\n",
      "train loss:0.0009985672736204272\n",
      "train loss:0.005192599831155841\n",
      "train loss:0.0012320091099449822\n",
      "train loss:0.0012846356093740338\n",
      "train loss:0.013160739431048975\n",
      "train loss:0.0007995720747623766\n",
      "train loss:0.0059356710963470935\n",
      "train loss:0.002875676715352677\n",
      "train loss:0.00040975442650572616\n",
      "train loss:0.0020313356480061045\n",
      "train loss:0.006199413081896211\n",
      "train loss:0.0022395740755493027\n",
      "train loss:0.0008409975067108088\n",
      "train loss:0.002228346385807853\n",
      "train loss:0.0005231807344731094\n",
      "train loss:0.004011040873578283\n",
      "train loss:0.004140987749386968\n",
      "train loss:0.0027879904256017884\n",
      "train loss:0.029295251111458125\n",
      "train loss:0.0004140164745090153\n",
      "train loss:0.006921458344737927\n",
      "train loss:0.009687843051716093\n",
      "train loss:0.006841569986180667\n",
      "train loss:0.004887400231264212\n",
      "train loss:0.053127265704546636\n",
      "train loss:0.001982242532004143\n",
      "train loss:0.0032031508989751978\n",
      "train loss:0.0005037998843154697\n",
      "train loss:0.0050720195436581685\n",
      "train loss:0.001982503179991769\n",
      "train loss:0.0017231003562031219\n",
      "train loss:0.008752781724304664\n",
      "train loss:0.009704077837756512\n",
      "train loss:0.0013215484690469888\n",
      "train loss:0.0031645747087572125\n",
      "train loss:0.0010048759471084421\n",
      "train loss:0.0030582814730202574\n",
      "train loss:0.0007900538707168602\n",
      "train loss:0.0018047326454066492\n",
      "train loss:0.003247386596002792\n",
      "train loss:0.009772653094830646\n",
      "train loss:0.014444588172156856\n",
      "train loss:0.007969891686146492\n",
      "train loss:0.0007941659433929102\n",
      "train loss:0.0006941819747207541\n",
      "train loss:0.008526544114214414\n",
      "train loss:0.0010675551090366334\n",
      "train loss:0.0028247456087015514\n",
      "train loss:0.0003498331728435283\n",
      "train loss:0.0009210711241039022\n",
      "train loss:0.004056251031271299\n",
      "train loss:0.0017710828144496336\n",
      "train loss:0.0006306251142698531\n",
      "train loss:0.00076242613981769\n",
      "train loss:0.0013827072069921812\n",
      "train loss:0.0005212936026123648\n",
      "train loss:8.359745148275117e-05\n",
      "train loss:0.0024326725022304142\n",
      "train loss:0.0006138568814312404\n",
      "train loss:0.0013498186278223046\n",
      "train loss:0.00431956423419191\n",
      "train loss:0.004785304416163319\n",
      "train loss:0.003685462632139234\n",
      "train loss:0.010373903533887096\n",
      "train loss:0.0012792038365205607\n",
      "train loss:0.0040593075292997514\n",
      "train loss:0.0011546552958973614\n",
      "train loss:0.06927027697730181\n",
      "train loss:0.003788648949031696\n",
      "train loss:0.0007577592518372607\n",
      "train loss:0.0006129699126176553\n",
      "train loss:0.0016318253009918377\n",
      "train loss:0.002333848500606026\n",
      "train loss:0.01790774739951397\n",
      "train loss:0.0006826581747439024\n",
      "train loss:0.02534809901351768\n",
      "train loss:0.0009792338014164466\n",
      "train loss:0.00048259875163471973\n",
      "train loss:0.0015683646586399907\n",
      "train loss:0.0014576974495307204\n",
      "train loss:0.01780545338890334\n",
      "train loss:0.0012534444805575554\n",
      "train loss:0.0026024117062351223\n",
      "train loss:0.0030856145492051063\n",
      "train loss:0.002000279457324887\n",
      "train loss:0.013619498787323919\n",
      "train loss:0.0025078883584429\n",
      "train loss:0.0010771147498479378\n",
      "train loss:0.003134257295229194\n",
      "train loss:0.002990126584977755\n",
      "train loss:0.0007099798828389551\n",
      "train loss:0.0006385331644876721\n",
      "train loss:0.0010529892007319125\n",
      "train loss:0.0005997596502412306\n",
      "train loss:0.0012586785553404384\n",
      "train loss:0.003218502601668769\n",
      "train loss:0.0011953075786783353\n",
      "train loss:0.003639989459928256\n",
      "train loss:0.0020703228198472555\n",
      "train loss:0.00816693730902593\n",
      "train loss:0.0014173375517349662\n",
      "train loss:0.011738398839560458\n",
      "train loss:0.0017422668181266412\n",
      "train loss:0.001363511549828548\n",
      "train loss:0.000954929712399341\n",
      "train loss:0.001965323442035006\n",
      "train loss:0.000892316601070944\n",
      "train loss:0.0016623531058879482\n",
      "train loss:0.003120244150002743\n",
      "train loss:0.0018600560297549083\n",
      "train loss:0.004785069477664489\n",
      "train loss:0.00026603051784993324\n",
      "train loss:0.004649742128427168\n",
      "train loss:0.0011563286133643871\n",
      "train loss:0.0004776894233816\n",
      "train loss:0.0006507602381775789\n",
      "train loss:0.0005919883200561952\n",
      "train loss:0.0031629730686025233\n",
      "train loss:0.0076337260521868585\n",
      "train loss:0.0015301712257922465\n",
      "train loss:0.002855926540137268\n",
      "train loss:0.0006775587932938491\n",
      "train loss:0.0010678288653571753\n",
      "train loss:0.0021817970728593332\n",
      "train loss:0.010625791986823823\n",
      "train loss:0.0009399528499258727\n",
      "train loss:8.778883863800932e-05\n",
      "train loss:0.000560441825416456\n",
      "train loss:0.0036385152967145194\n",
      "train loss:0.0012264552364380965\n",
      "train loss:0.0019965720700655873\n",
      "train loss:0.0030492333804796805\n",
      "train loss:0.0018811015219703754\n",
      "train loss:9.072996882062135e-05\n",
      "train loss:0.011028269906787947\n",
      "train loss:0.0014227086666694776\n",
      "train loss:0.0004034558380392982\n",
      "train loss:0.0019611908128915924\n",
      "train loss:0.0020580093930495716\n",
      "train loss:0.007553671708817635\n",
      "train loss:0.0010772177488912354\n",
      "train loss:0.0013180160419135583\n",
      "train loss:0.007199538438299874\n",
      "train loss:0.001416601600597023\n",
      "train loss:0.0001584580030982561\n",
      "train loss:0.000258672557056479\n",
      "train loss:0.0004953974691093925\n",
      "train loss:0.008336743356718992\n",
      "train loss:0.0015370939026523348\n",
      "train loss:0.0017607171148772977\n",
      "train loss:0.0016052598754877012\n",
      "train loss:0.0019885616067166958\n",
      "train loss:0.0010886691539148125\n",
      "train loss:0.003730891918560257\n",
      "train loss:0.0030221422257254438\n",
      "train loss:0.0010965073665544717\n",
      "train loss:0.011206091382017627\n",
      "train loss:0.0015764145389423675\n",
      "train loss:0.0007197703676171902\n",
      "train loss:0.0021438643474080256\n",
      "train loss:0.007113075694338666\n",
      "train loss:0.0007235805646098951\n",
      "train loss:0.0005717499506090531\n",
      "train loss:0.003430044799344589\n",
      "train loss:0.0021765788985697674\n",
      "train loss:0.002607793852277591\n",
      "train loss:0.000310490491915326\n",
      "train loss:0.004969668083566919\n",
      "train loss:0.004222668640182261\n",
      "train loss:0.0017166845875749874\n",
      "train loss:0.00116514976294362\n",
      "train loss:0.0017284988649741006\n",
      "train loss:0.0020285552290312094\n",
      "train loss:0.0033404770215523473\n",
      "train loss:0.000539833808034386\n",
      "train loss:0.00048730983228954507\n",
      "train loss:0.0007084129319522055\n",
      "train loss:0.010982241225810907\n",
      "train loss:0.0007536686854255556\n",
      "train loss:0.002614146973765675\n",
      "train loss:0.0024388442102092605\n",
      "train loss:0.002170509350530356\n",
      "train loss:0.002598298717986473\n",
      "train loss:0.004343533620095719\n",
      "train loss:0.002737851769775157\n",
      "train loss:0.000916062342119571\n",
      "train loss:0.0011859248364104197\n",
      "train loss:0.0010837832269215732\n",
      "train loss:0.0002817946740284682\n",
      "train loss:0.0026700369034422826\n",
      "train loss:0.00119188159510777\n",
      "train loss:0.001352585354066592\n",
      "train loss:0.0003792397241990254\n",
      "train loss:0.0012451061519064325\n",
      "train loss:0.000844240683227354\n",
      "train loss:0.0029961002101852622\n",
      "train loss:0.01750933978076105\n",
      "train loss:0.0017576316436968614\n",
      "train loss:0.00047347256594217643\n",
      "train loss:0.002245541730685893\n",
      "train loss:0.002074255641036413\n",
      "train loss:0.0013100326417326469\n",
      "train loss:0.0009492068490818328\n",
      "train loss:0.0033142115133329175\n",
      "train loss:0.012876828384534838\n",
      "train loss:0.0028552122899735107\n",
      "train loss:0.002860461903723617\n",
      "train loss:0.0016954565372323763\n",
      "train loss:0.005791813924306427\n",
      "train loss:0.00022672042812198315\n",
      "train loss:0.0017761340560809836\n",
      "train loss:0.00116603844907726\n",
      "train loss:0.005060895267191514\n",
      "train loss:0.000979201710235342\n",
      "train loss:0.0003007850490768175\n",
      "train loss:0.005492748942234977\n",
      "train loss:0.0013522996054514036\n",
      "train loss:0.00404109960571444\n",
      "train loss:0.0013283649614507262\n",
      "train loss:0.0020361687038754446\n",
      "train loss:0.0004969701763509904\n",
      "train loss:8.811761075689064e-05\n",
      "train loss:0.06356777822415866\n",
      "train loss:0.00016585664442585288\n",
      "train loss:0.0016689647769356298\n",
      "train loss:0.09478381756452013\n",
      "train loss:0.0008502430256728854\n",
      "train loss:0.00010742494996631786\n",
      "train loss:0.0009205544434010362\n",
      "train loss:0.0008246142997484786\n",
      "train loss:0.002856132620790069\n",
      "train loss:0.0015128461284853686\n",
      "train loss:0.008373258608527077\n",
      "train loss:0.0010150313796512384\n",
      "train loss:0.005023953288454324\n",
      "train loss:0.0012172707096856038\n",
      "train loss:0.002159885131146175\n",
      "train loss:0.012591104414442328\n",
      "train loss:0.007156959126521168\n",
      "train loss:0.013050772785485417\n",
      "train loss:0.0045449866398247635\n",
      "train loss:0.004721760969915037\n",
      "train loss:0.00048124035922347846\n",
      "train loss:0.0012634000436618647\n",
      "train loss:0.001851036532701173\n",
      "train loss:0.0028526792211472623\n",
      "train loss:0.005643257730074243\n",
      "train loss:0.011717673269330337\n",
      "train loss:0.009821537945238476\n",
      "train loss:0.007163870403586587\n",
      "train loss:9.960385290793018e-05\n",
      "train loss:0.003371669933544285\n",
      "train loss:0.016838609416665345\n",
      "train loss:0.0006492819232130665\n",
      "train loss:0.008448335011843467\n",
      "train loss:0.0025509850130622036\n",
      "train loss:0.001970511106051142\n",
      "train loss:0.0020458738019953006\n",
      "train loss:0.0010039355356465012\n",
      "train loss:0.0011282131649771974\n",
      "train loss:0.018959731151398224\n",
      "train loss:0.004943319733368158\n",
      "train loss:0.003198695905214861\n",
      "train loss:0.0056724705612021305\n",
      "train loss:0.004263501234424189\n",
      "train loss:0.0013057006834215226\n",
      "train loss:0.0024440291406417278\n",
      "train loss:0.006345632406335979\n",
      "train loss:0.002121886363183773\n",
      "train loss:0.0010606654063621628\n",
      "train loss:0.0072510697625811135\n",
      "train loss:0.0026891542886577483\n",
      "train loss:0.00044857192371262547\n",
      "train loss:0.07870348441350888\n",
      "train loss:0.001062679083811509\n",
      "train loss:0.0016890730869084012\n",
      "train loss:0.0012755035220528158\n",
      "train loss:0.00040286139186405175\n",
      "train loss:0.0015757236083896585\n",
      "train loss:7.747929519980787e-05\n",
      "train loss:0.023662627328947982\n",
      "train loss:0.0009432747270166298\n",
      "train loss:0.0008564212961567252\n",
      "train loss:0.001253762219945027\n",
      "train loss:0.00024144147648392866\n",
      "train loss:0.0010466548496062603\n",
      "train loss:0.01407065667328946\n",
      "train loss:0.0016957003008767912\n",
      "train loss:0.0020438736903069027\n",
      "train loss:0.0042516548117432044\n",
      "train loss:0.0006157602951284142\n",
      "train loss:0.002675909343445928\n",
      "train loss:0.0005676013806681405\n",
      "train loss:0.004041469768831556\n",
      "train loss:0.0017369976078169052\n",
      "train loss:0.0027529279116127333\n",
      "train loss:0.007054104543962966\n",
      "train loss:0.01625831236929033\n",
      "train loss:0.0004703901449009091\n",
      "train loss:0.0016663100171572468\n",
      "train loss:0.00022963945627363795\n",
      "train loss:0.0071320678412971125\n",
      "train loss:0.001857833226465412\n",
      "train loss:0.0014036078488047906\n",
      "train loss:0.005522409059198565\n",
      "train loss:0.0035851501303658852\n",
      "train loss:0.001738062377228295\n",
      "train loss:0.005356082539425107\n",
      "train loss:0.0005778133843580064\n",
      "train loss:0.004891080259221875\n",
      "train loss:0.004732732643714198\n",
      "train loss:0.006146839366200822\n",
      "train loss:0.004014579119069137\n",
      "train loss:0.0009058440011845036\n",
      "train loss:0.0002883895452254584\n",
      "train loss:0.007155952491054223\n",
      "train loss:0.004722139143815941\n",
      "train loss:0.001970461497279333\n",
      "train loss:0.00012913789976928903\n",
      "train loss:0.010584316999266534\n",
      "train loss:0.0004861277919358115\n",
      "train loss:0.00046817746556429015\n",
      "train loss:0.03146241156317933\n",
      "train loss:0.0021679278922689922\n",
      "train loss:0.0033099532720113813\n",
      "train loss:0.003428918543024832\n",
      "train loss:0.0024653803091710834\n",
      "train loss:0.0009651564043669725\n",
      "train loss:0.004330440668054609\n",
      "train loss:0.0008883467899164941\n",
      "train loss:0.006695765523931628\n",
      "train loss:0.009657917310289628\n",
      "train loss:0.004313936771471003\n",
      "train loss:0.0020762657919517267\n",
      "train loss:0.006191495683544113\n",
      "train loss:0.0038912942494591933\n",
      "train loss:0.0020843931189740723\n",
      "train loss:0.0037846749952826345\n",
      "train loss:0.002599945268664491\n",
      "train loss:0.0004954929379052688\n",
      "train loss:0.0030902394276879357\n",
      "train loss:0.0013767308700006107\n",
      "train loss:0.0006071838743540648\n",
      "train loss:0.004693954404353353\n",
      "train loss:0.007154842233624703\n",
      "train loss:0.0008732438127882129\n",
      "train loss:0.0006595250743177159\n",
      "train loss:0.0018820290494281457\n",
      "train loss:0.0011408013435237694\n",
      "train loss:0.000594131244282245\n",
      "train loss:0.00037178492716476863\n",
      "train loss:0.004633126238483647\n",
      "train loss:0.003306956290769962\n",
      "train loss:0.011574801880025283\n",
      "train loss:0.003965929242677355\n",
      "train loss:0.005718196765349678\n",
      "train loss:0.002628426690263236\n",
      "train loss:0.003709559441616188\n",
      "train loss:9.95635466976316e-05\n",
      "train loss:0.001351156725961001\n",
      "train loss:0.005086231955433393\n",
      "train loss:0.0015299113952790947\n",
      "train loss:0.0003036202484492679\n",
      "train loss:0.006317758567953571\n",
      "train loss:0.0008689761254850746\n",
      "train loss:0.00187171321342931\n",
      "train loss:2.07305220816221e-05\n",
      "train loss:0.009063162435018259\n",
      "train loss:0.006316475915419757\n",
      "train loss:0.0007060884076760349\n",
      "train loss:0.0023645240724705805\n",
      "train loss:0.00217774952601539\n",
      "train loss:0.00026011342584120444\n",
      "train loss:0.0027838315981653385\n",
      "train loss:0.005643096722481435\n",
      "train loss:0.004743301415831681\n",
      "train loss:0.008774241161067262\n",
      "train loss:0.002139983978479761\n",
      "train loss:0.006929652847089098\n",
      "train loss:0.0022895692542037912\n",
      "train loss:0.006567577020274658\n",
      "train loss:0.009088381667218927\n",
      "train loss:0.0016016107310049118\n",
      "train loss:0.0035668302206175386\n",
      "train loss:0.00036013702403705545\n",
      "train loss:0.007557589515035893\n",
      "train loss:0.0008652871564050033\n",
      "train loss:0.0004270389636651208\n",
      "train loss:0.013572410929879623\n",
      "train loss:0.0009166276108639069\n",
      "train loss:0.006911450599481217\n",
      "train loss:0.0051686050936569135\n",
      "train loss:0.00343235923649686\n",
      "train loss:0.00023654466263917963\n",
      "train loss:0.002496317481217129\n",
      "train loss:0.0017391533632516519\n",
      "train loss:0.0020096132359229933\n",
      "train loss:0.0026999696092252523\n",
      "train loss:0.0062252179405184035\n",
      "train loss:0.0016378855160475696\n",
      "train loss:0.0007959869072194108\n",
      "train loss:0.012773518372739923\n",
      "train loss:0.0036507601762803\n",
      "train loss:0.010384847447078203\n",
      "train loss:0.01131615071995788\n",
      "train loss:0.0023735106524166317\n",
      "train loss:0.000833757532935064\n",
      "train loss:0.001849456291447098\n",
      "train loss:0.0033966418319732535\n",
      "train loss:0.000927930103346625\n",
      "train loss:0.002018315079422166\n",
      "train loss:0.0006933530790324149\n",
      "train loss:0.017324130787505988\n",
      "train loss:0.0019338858145746458\n",
      "train loss:0.005563787429390079\n",
      "train loss:0.0026010077601081767\n",
      "train loss:0.004088575488813764\n",
      "train loss:0.00026420861574355715\n",
      "train loss:0.003542852188898761\n",
      "train loss:0.000861826733842966\n",
      "train loss:0.004127679515662277\n",
      "train loss:0.003266776385951938\n",
      "train loss:0.0020838927390049483\n",
      "train loss:0.0006026412409581694\n",
      "train loss:0.0002572780258656779\n",
      "train loss:0.003623461613504287\n",
      "train loss:0.0047024428146916954\n",
      "train loss:0.0022375663373033596\n",
      "train loss:0.00227562714922139\n",
      "train loss:0.0006500536726087368\n",
      "train loss:0.0005125812476060673\n",
      "train loss:0.0005303086747918908\n",
      "train loss:0.006955852683855108\n",
      "train loss:0.0002511984006814521\n",
      "train loss:0.01448810983434406\n",
      "train loss:0.002115767915824027\n",
      "train loss:0.0004604908879372643\n",
      "train loss:0.0030825795918956143\n",
      "train loss:0.0004867711254029307\n",
      "train loss:0.0029611495931614186\n",
      "train loss:0.00198236741101265\n",
      "train loss:0.0005356672589783903\n",
      "train loss:0.0022117675385696276\n",
      "train loss:0.0022816416760948668\n",
      "train loss:0.0020758330172664513\n",
      "train loss:0.0007596621593765371\n",
      "train loss:0.007568927228539277\n",
      "train loss:0.0004019553369214822\n",
      "train loss:0.0012167956827801964\n",
      "train loss:0.001959648315908943\n",
      "train loss:0.0028190702529821464\n",
      "train loss:0.0027730605530157755\n",
      "train loss:0.031750895760626924\n",
      "train loss:0.0021981043790645855\n",
      "train loss:0.0013707429421446955\n",
      "train loss:0.006426116531699005\n",
      "train loss:0.0013867009251910794\n",
      "train loss:0.001923234478747477\n",
      "train loss:0.00026914436643013507\n",
      "train loss:0.0006240372165662589\n",
      "train loss:0.004964874124661235\n",
      "train loss:0.0013104335994991387\n",
      "train loss:0.002955983357089667\n",
      "train loss:0.009961420231959301\n",
      "train loss:0.001216807182979958\n",
      "train loss:0.00014803465399365007\n",
      "train loss:0.003537705796507763\n",
      "train loss:0.0006115186338633609\n",
      "train loss:0.002523854711685671\n",
      "train loss:0.0016180428158261023\n",
      "train loss:0.0011653026809216988\n",
      "train loss:0.0017439906049666325\n",
      "train loss:0.022083714888895184\n",
      "train loss:0.00010716998912623882\n",
      "train loss:0.0003293469451454639\n",
      "train loss:0.006077263031383609\n",
      "train loss:0.04259545138452131\n",
      "train loss:0.00034507098686655587\n",
      "train loss:0.0005154725059442248\n",
      "train loss:0.009658106178188637\n",
      "train loss:0.0008528553128952677\n",
      "train loss:0.009818716457143089\n",
      "train loss:0.0028374741143421976\n",
      "train loss:0.002722775211604739\n",
      "train loss:0.0036059928713587817\n",
      "train loss:0.007165297571069252\n",
      "train loss:0.003523046121216543\n",
      "train loss:0.004090869515571128\n",
      "train loss:0.015053413683679899\n",
      "train loss:0.00642895611676489\n",
      "=== epoch:15, train acc:0.996, test acc:0.989 ===\n",
      "train loss:0.0021760538208755297\n",
      "train loss:0.0004286285132105232\n",
      "train loss:0.0014706066708905002\n",
      "train loss:0.0007778176037769406\n",
      "train loss:0.005854724073103201\n",
      "train loss:0.004189647517029477\n",
      "train loss:0.0016925263383182393\n",
      "train loss:0.0006451038920636787\n",
      "train loss:0.03277054158390948\n",
      "train loss:0.027273543924453504\n",
      "train loss:0.0054119385201424775\n",
      "train loss:0.0007512130087726014\n",
      "train loss:0.0007788662526230373\n",
      "train loss:0.04181406542781773\n",
      "train loss:0.002608124123714911\n",
      "train loss:0.0034611981283133625\n",
      "train loss:0.002836912047574053\n",
      "train loss:0.0033460597297038756\n",
      "train loss:0.002672041414977887\n",
      "train loss:0.0017321426974713826\n",
      "train loss:0.006840031404317029\n",
      "train loss:0.015096091937493679\n",
      "train loss:0.007378847702583062\n",
      "train loss:0.0031505397032491824\n",
      "train loss:0.009972522146671223\n",
      "train loss:0.00040375416066145927\n",
      "train loss:0.001792283958446007\n",
      "train loss:0.0024631246976134476\n",
      "train loss:0.0008334906348618616\n",
      "train loss:0.0010985886400729085\n",
      "train loss:0.00024109313837238173\n",
      "train loss:0.0034266495720822803\n",
      "train loss:0.002016959223176639\n",
      "train loss:0.005145254646470052\n",
      "train loss:0.008808318651448788\n",
      "train loss:0.002624821032293685\n",
      "train loss:0.006884598615911896\n",
      "train loss:0.009538373333104418\n",
      "train loss:0.0008825353753407281\n",
      "train loss:0.0006309565383241482\n",
      "train loss:0.0010734302924996226\n",
      "train loss:0.0041542907545618814\n",
      "train loss:0.008165620608710044\n",
      "train loss:0.0006967985827081248\n",
      "train loss:0.0003786200697213835\n",
      "train loss:0.002936524869497528\n",
      "train loss:0.002066391724146851\n",
      "train loss:0.00022944875763968617\n",
      "train loss:0.0015125106705025744\n",
      "train loss:0.0009592227949966228\n",
      "train loss:0.0033169940896947926\n",
      "train loss:0.0033084719888255604\n",
      "train loss:0.0027404291129880676\n",
      "train loss:0.002562323671751894\n",
      "train loss:0.0002056611235424911\n",
      "train loss:0.009237199828053166\n",
      "train loss:0.001765217322056167\n",
      "train loss:0.0009346913527195093\n",
      "train loss:0.00582538785439129\n",
      "train loss:0.00022862558870302308\n",
      "train loss:0.0027074650287239417\n",
      "train loss:0.0002435130782568083\n",
      "train loss:0.0007619118228375275\n",
      "train loss:0.0034344039673622293\n",
      "train loss:0.003084196376214353\n",
      "train loss:0.0009976147250733674\n",
      "train loss:0.0004913796207089001\n",
      "train loss:0.000765264431479539\n",
      "train loss:0.005575375751494221\n",
      "train loss:0.000547654494192207\n",
      "train loss:0.0011286192467409137\n",
      "train loss:2.3353051151687078e-05\n",
      "train loss:0.000271061638528336\n",
      "train loss:0.0005301203977591485\n",
      "train loss:0.0016029859294596164\n",
      "train loss:0.0038033553557282104\n",
      "train loss:0.00036568827896166787\n",
      "train loss:0.0014050770722459224\n",
      "train loss:0.001154767679573686\n",
      "train loss:0.0002195857595382718\n",
      "train loss:0.0016731298200487335\n",
      "train loss:0.0003915569159978112\n",
      "train loss:0.0014604422593545224\n",
      "train loss:0.0005838466536004981\n",
      "train loss:0.001202473519318725\n",
      "train loss:0.004592887716068973\n",
      "train loss:0.0013622142356717601\n",
      "train loss:0.0005434311638295344\n",
      "train loss:0.0007208614779399804\n",
      "train loss:0.0005543523455918905\n",
      "train loss:0.00938513806240894\n",
      "train loss:0.001373891538826513\n",
      "train loss:0.006332789410651563\n",
      "train loss:0.0019273364524972816\n",
      "train loss:0.0012508538650245502\n",
      "train loss:0.0008971533293182672\n",
      "train loss:0.0018230632883493548\n",
      "train loss:0.0007423558566579003\n",
      "train loss:0.0017408351808389825\n",
      "train loss:0.0010494832475177207\n",
      "train loss:0.0013420144106835188\n",
      "train loss:0.0006023047564433686\n",
      "train loss:0.0013898787714670712\n",
      "train loss:0.0007586947071713556\n",
      "train loss:0.0055888977908233614\n",
      "train loss:0.006415976937538794\n",
      "train loss:0.005025948259020085\n",
      "train loss:0.004292569943766862\n",
      "train loss:0.0035647926416974866\n",
      "train loss:0.006394882506406356\n",
      "train loss:0.001030826996581677\n",
      "train loss:0.001162398989259033\n",
      "train loss:0.004377994451902394\n",
      "train loss:0.00045226658271716\n",
      "train loss:0.04606266818970564\n",
      "train loss:0.003291605295556987\n",
      "train loss:0.004195010591313397\n",
      "train loss:0.00013678611685818403\n",
      "train loss:0.0004544255143067452\n",
      "train loss:0.002938739211089046\n",
      "train loss:0.0008326834637922123\n",
      "train loss:0.0005218604990404628\n",
      "train loss:0.0005834952011795068\n",
      "train loss:0.008170586936091316\n",
      "train loss:0.009563359004777021\n",
      "train loss:0.0018318644750997942\n",
      "train loss:0.002437384973369606\n",
      "train loss:0.0004196511471542795\n",
      "train loss:0.001109561766411159\n",
      "train loss:0.0021017728223819004\n",
      "train loss:0.0005229329096422773\n",
      "train loss:0.003899832144574779\n",
      "train loss:0.0015100893665437908\n",
      "train loss:0.00040880609352019886\n",
      "train loss:0.02781329470140352\n",
      "train loss:0.0011563948080892952\n",
      "train loss:0.001500293996975572\n",
      "train loss:9.391791195184919e-05\n",
      "train loss:0.0005650571552804724\n",
      "train loss:0.000531193205457677\n",
      "train loss:0.0009235844030250739\n",
      "train loss:0.0001716150712730741\n",
      "train loss:0.0037592470016087408\n",
      "train loss:0.0010702213238067099\n",
      "train loss:0.00012251830645547141\n",
      "train loss:0.003538750410843945\n",
      "train loss:0.0006766577223437273\n",
      "train loss:0.004833079438434045\n",
      "train loss:0.0034983873022179433\n",
      "train loss:0.000541981467356278\n",
      "train loss:0.0006476001968455673\n",
      "train loss:0.006807939495129657\n",
      "train loss:0.005699233039466265\n",
      "train loss:0.0016866490961896664\n",
      "train loss:0.0005746176773036049\n",
      "train loss:0.0002464846015333934\n",
      "train loss:0.000684327732549079\n",
      "train loss:0.0001166386794814434\n",
      "train loss:0.0021947493601244443\n",
      "train loss:0.001079372506650783\n",
      "train loss:0.0043830845653349305\n",
      "train loss:0.007186770394833508\n",
      "train loss:0.00134858217562755\n",
      "train loss:0.03826025517839489\n",
      "train loss:0.02198015792548405\n",
      "train loss:0.0003754060058928212\n",
      "train loss:0.0014334977925236755\n",
      "train loss:0.0016838104166808652\n",
      "train loss:0.006131061007002087\n",
      "train loss:0.0047597671766992896\n",
      "train loss:0.0015926911217726018\n",
      "train loss:0.0003980572131944059\n",
      "train loss:0.011644654687292873\n",
      "train loss:0.0005388867645963103\n",
      "train loss:0.002695061564898422\n",
      "train loss:0.0033444933315651608\n",
      "train loss:0.0015023980325161433\n",
      "train loss:0.027333992118798386\n",
      "train loss:0.004660494682103083\n",
      "train loss:0.00034857505310054854\n",
      "train loss:0.17059817985444298\n",
      "train loss:0.005369775462027675\n",
      "train loss:0.0025956743880882678\n",
      "train loss:0.0002600562073440553\n",
      "train loss:0.0005791676366821207\n",
      "train loss:0.004333437995022628\n",
      "train loss:0.0007981468333009991\n",
      "train loss:0.0010508890384467334\n",
      "train loss:0.005469655560578458\n",
      "train loss:0.019594952841096806\n",
      "train loss:0.00569832468025654\n",
      "train loss:0.007443939037280586\n",
      "train loss:0.0023665716344179093\n",
      "train loss:0.009225692501829643\n",
      "train loss:0.00043698803612674\n",
      "train loss:0.001709366634865407\n",
      "train loss:0.00043967923630614886\n",
      "train loss:0.006988985762008658\n",
      "train loss:0.028944095749214273\n",
      "train loss:0.0026924857469375623\n",
      "train loss:0.0006600706034606022\n",
      "train loss:0.004786918674557214\n",
      "train loss:0.004620878991033619\n",
      "train loss:0.0006597219623069312\n",
      "train loss:0.0007950216512077409\n",
      "train loss:0.01541107346458201\n",
      "train loss:0.003503753466737637\n",
      "train loss:0.002470731171715126\n",
      "train loss:0.008926228340215015\n",
      "train loss:0.00012132574460473064\n",
      "train loss:0.000626673147058779\n",
      "train loss:0.0012415547628910845\n",
      "train loss:0.0006073365699791855\n",
      "train loss:0.002940711248939528\n",
      "train loss:0.0013213807055013703\n",
      "train loss:0.0030670336949007258\n",
      "train loss:0.012779832082627778\n",
      "train loss:0.00013445864895922973\n",
      "train loss:0.007446032945659214\n",
      "train loss:0.015074786517580128\n",
      "train loss:0.0009156089279878603\n",
      "train loss:0.0205060757498701\n",
      "train loss:0.006191125419554858\n",
      "train loss:0.00018944928546602252\n",
      "train loss:0.006678827114012616\n",
      "train loss:0.0013319594536095939\n",
      "train loss:0.0027354121329911133\n",
      "train loss:0.006225748529790787\n",
      "train loss:0.0017733772757817473\n",
      "train loss:0.0012464383158964272\n",
      "train loss:0.0014947480779305784\n",
      "train loss:0.006121259188869443\n",
      "train loss:0.0008932545702196479\n",
      "train loss:0.003613688724488761\n",
      "train loss:0.026083606139762697\n",
      "train loss:0.0032576797805433997\n",
      "train loss:0.015214634853789065\n",
      "train loss:0.006190861944506192\n",
      "train loss:0.00230494276994904\n",
      "train loss:0.005656565948988573\n",
      "train loss:0.0014320375811362584\n",
      "train loss:0.007329585144640112\n",
      "train loss:0.0014469867113674334\n",
      "train loss:0.0014831707162092625\n",
      "train loss:0.0033806452222473944\n",
      "train loss:0.02699053270699291\n",
      "train loss:0.037054513234271155\n",
      "train loss:0.0004896675830852213\n",
      "train loss:0.004558180792811631\n",
      "train loss:0.04688349371545237\n",
      "train loss:0.005604631663438014\n",
      "train loss:0.004615406433498556\n",
      "train loss:0.0024862062557449035\n",
      "train loss:0.00025874526022350627\n",
      "train loss:0.029763839920095025\n",
      "train loss:0.006015987832388223\n",
      "train loss:0.007886346753744401\n",
      "train loss:0.0010243918063276725\n",
      "train loss:0.0001650988648919153\n",
      "train loss:0.005537228258195941\n",
      "train loss:0.010703636060429152\n",
      "train loss:0.0048812793910142874\n",
      "train loss:0.0017694283715422783\n",
      "train loss:0.00015885965198352993\n",
      "train loss:0.0021009424100016843\n",
      "train loss:0.012328518204040234\n",
      "train loss:0.0029659128674432884\n",
      "train loss:0.0010497650203938177\n",
      "train loss:0.000403970025445961\n",
      "train loss:0.0013279823370022413\n",
      "train loss:0.0015820946005053226\n",
      "train loss:0.01005198918470648\n",
      "train loss:0.0003652767338013182\n",
      "train loss:0.001835857550908864\n",
      "train loss:0.008083820799657556\n",
      "train loss:0.002965143588935904\n",
      "train loss:0.0005003114626086487\n",
      "train loss:0.0013202093507725286\n",
      "train loss:0.0014199242937295495\n",
      "train loss:0.0024118451641022866\n",
      "train loss:0.00029987645749257006\n",
      "train loss:0.005788655746688038\n",
      "train loss:0.0022866287891763763\n",
      "train loss:0.0008774138940620777\n",
      "train loss:0.004360222465512323\n",
      "train loss:0.00023296486553811308\n",
      "train loss:0.002464926152197474\n",
      "train loss:0.0024008416226162957\n",
      "train loss:0.004132573540052121\n",
      "train loss:0.0018947029390499034\n",
      "train loss:0.0037300398644719516\n",
      "train loss:0.00041620026391052384\n",
      "train loss:0.003131834768658446\n",
      "train loss:0.0008157036661996494\n",
      "train loss:0.03265260062698914\n",
      "train loss:0.002236099587278566\n",
      "train loss:0.009161285433084462\n",
      "train loss:0.0013233793946097075\n",
      "train loss:0.0030103571049368426\n",
      "train loss:0.007951816884521165\n",
      "train loss:0.0009543035570256707\n",
      "train loss:0.0014226580149316762\n",
      "train loss:0.001107818505108643\n",
      "train loss:0.0011048585674735107\n",
      "train loss:0.0006571032015208697\n",
      "train loss:0.004032251932036881\n",
      "train loss:0.032084928288724716\n",
      "train loss:0.0007380425716726287\n",
      "train loss:0.0026267527773860917\n",
      "train loss:0.0009692905493874262\n",
      "train loss:0.00036116926439051393\n",
      "train loss:0.00387799934627943\n",
      "train loss:0.001410594863384387\n",
      "train loss:0.004560565131254457\n",
      "train loss:0.0007265541459797767\n",
      "train loss:0.001771403735977687\n",
      "train loss:0.0019396970484168807\n",
      "train loss:0.0006258603757430933\n",
      "train loss:0.0041313742219569825\n",
      "train loss:0.00027035508367638755\n",
      "train loss:0.0038206734323822465\n",
      "train loss:0.00045652999619046335\n",
      "train loss:0.0009702823080410587\n",
      "train loss:0.004587926371324508\n",
      "train loss:0.0003043947387039442\n",
      "train loss:0.0016840781673223932\n",
      "train loss:0.004523138330079728\n",
      "train loss:0.0002902869019124708\n",
      "train loss:0.00045227240508377846\n",
      "train loss:0.0032235823482586463\n",
      "train loss:0.0008494418313857537\n",
      "train loss:0.022761924238350963\n",
      "train loss:0.004060958437985894\n",
      "train loss:0.0006520187991546608\n",
      "train loss:0.0025259539609829925\n",
      "train loss:0.00740870137978285\n",
      "train loss:0.0011108253318978922\n",
      "train loss:0.002824403176958063\n",
      "train loss:0.0010460421744234605\n",
      "train loss:0.0015144440994590991\n",
      "train loss:0.006083548515541871\n",
      "train loss:0.00042813468963167354\n",
      "train loss:0.0032891718827289364\n",
      "train loss:0.0038406576426957863\n",
      "train loss:0.001723240580745601\n",
      "train loss:8.505553107547329e-05\n",
      "train loss:0.0015180893707522816\n",
      "train loss:0.0030366762305559197\n",
      "train loss:0.00832950513654471\n",
      "train loss:0.0039376659471986085\n",
      "train loss:6.091007439506107e-05\n",
      "train loss:0.0013342198635032515\n",
      "train loss:0.035381525896580744\n",
      "train loss:0.0034736582664121923\n",
      "train loss:0.0019783119987388984\n",
      "train loss:0.000943105693798827\n",
      "train loss:0.0033424043930109647\n",
      "train loss:0.0026070191207384036\n",
      "train loss:0.00409757910104508\n",
      "train loss:0.0010398680565810445\n",
      "train loss:0.010718698904573134\n",
      "train loss:0.003963187532294867\n",
      "train loss:0.0010186460834633738\n",
      "train loss:0.004439820988363033\n",
      "train loss:0.0008033095342021316\n",
      "train loss:0.003739926447247611\n",
      "train loss:0.0010394578387498763\n",
      "train loss:0.0007008894086011556\n",
      "train loss:0.0011066672351336664\n",
      "train loss:0.007539286323490234\n",
      "train loss:0.0029223603968277904\n",
      "train loss:0.0004910247998622793\n",
      "train loss:0.000455808860045773\n",
      "train loss:0.0008320195587169804\n",
      "train loss:0.0010391376840704705\n",
      "train loss:0.015342155370145166\n",
      "train loss:0.0007879879522769506\n",
      "train loss:0.00274775411481881\n",
      "train loss:0.0026000344553518905\n",
      "train loss:0.002502335275904432\n",
      "train loss:0.0007555636619875214\n",
      "train loss:0.0011999811103518927\n",
      "train loss:0.004273972537222715\n",
      "train loss:0.0010165327905066778\n",
      "train loss:0.003668914452290767\n",
      "train loss:0.000251956585118974\n",
      "train loss:0.001232528002968702\n",
      "train loss:0.0012830688057025698\n",
      "train loss:0.00483989770451967\n",
      "train loss:0.0010133189461371927\n",
      "train loss:0.0015658901265003793\n",
      "train loss:0.002759116176173922\n",
      "train loss:0.004944142875858425\n",
      "train loss:0.0010356828683098101\n",
      "train loss:0.00016828675091991476\n",
      "train loss:0.005996146146440871\n",
      "train loss:0.0006770856269163773\n",
      "train loss:0.0005105011430650528\n",
      "train loss:0.0005597474134773647\n",
      "train loss:0.00034544916021298216\n",
      "train loss:0.0014631502779325148\n",
      "train loss:0.0021092094229572802\n",
      "train loss:4.7547991947054184e-05\n",
      "train loss:0.001017924880438533\n",
      "train loss:0.0009168740690555693\n",
      "train loss:0.0024906219293548315\n",
      "train loss:0.0012152731069759565\n",
      "train loss:0.032763507160788234\n",
      "train loss:0.001033818105670751\n",
      "train loss:0.002517884869077511\n",
      "train loss:0.0004571464967890874\n",
      "train loss:0.00020051910504218708\n",
      "train loss:0.016391306364398457\n",
      "train loss:0.0008507841589404256\n",
      "train loss:0.006401912494915575\n",
      "train loss:7.879585347032347e-05\n",
      "train loss:0.005346577449544802\n",
      "train loss:0.009251910804177166\n",
      "train loss:0.004341176639998935\n",
      "train loss:0.002969605304394518\n",
      "train loss:0.0013633068775168295\n",
      "train loss:0.0013366002604282563\n",
      "train loss:0.000775191205454842\n",
      "train loss:0.0005352976397217271\n",
      "train loss:0.0023251863179409153\n",
      "train loss:0.020961711858755075\n",
      "train loss:0.04766210263736963\n",
      "train loss:0.013715289975194033\n",
      "train loss:0.003915933869632943\n",
      "train loss:0.0005112414491715399\n",
      "train loss:0.015324784562328157\n",
      "train loss:0.004275133112712311\n",
      "train loss:0.0009416153225094808\n",
      "train loss:0.00018559588119826498\n",
      "train loss:0.0003908197245484329\n",
      "train loss:0.00021583336672325215\n",
      "train loss:0.0006572847660693434\n",
      "train loss:0.00142408660358081\n",
      "train loss:0.002390832084991062\n",
      "train loss:0.0012944314707691864\n",
      "train loss:0.0018567093201175017\n",
      "train loss:0.0004987836171927705\n",
      "train loss:0.0020742850169082464\n",
      "train loss:0.0006731426804513015\n",
      "train loss:0.004241196858292501\n",
      "train loss:0.014380258790514848\n",
      "train loss:0.001924081680297881\n",
      "train loss:0.0035852433288817514\n",
      "train loss:0.00047780382073565024\n",
      "train loss:0.004745919126944759\n",
      "train loss:0.01365959075816402\n",
      "train loss:0.006646661970459557\n",
      "train loss:0.00592172854687161\n",
      "train loss:0.000665029768384236\n",
      "train loss:0.0023736717139229663\n",
      "train loss:0.0029427324958750008\n",
      "train loss:0.0014037544603218322\n",
      "train loss:0.004820141576952119\n",
      "train loss:0.0030325942641743374\n",
      "train loss:0.0015403490018657167\n",
      "train loss:0.003975545480307761\n",
      "train loss:0.0014902771197752174\n",
      "train loss:0.000161180222663441\n",
      "train loss:0.0020732242686433834\n",
      "train loss:0.008720186598060606\n",
      "train loss:0.0020160984897883145\n",
      "train loss:0.006585920687811944\n",
      "train loss:0.0009657679641530594\n",
      "train loss:0.004676209309259007\n",
      "train loss:0.00011530336087966825\n",
      "train loss:0.0014678712052803198\n",
      "train loss:0.002084435502137526\n",
      "train loss:0.000563064247557441\n",
      "train loss:0.0002081610689194045\n",
      "train loss:0.0031180279744868673\n",
      "train loss:0.002617165834946495\n",
      "train loss:0.00218134377893625\n",
      "train loss:0.0013146899789135578\n",
      "train loss:0.0028281635994069827\n",
      "train loss:0.00021009582363518118\n",
      "train loss:0.000271857331114606\n",
      "train loss:0.002722161873956487\n",
      "train loss:0.0004984489053293732\n",
      "train loss:0.005725730707882067\n",
      "train loss:0.00026817057333778656\n",
      "train loss:0.0022220774770490303\n",
      "train loss:0.0029349148742643457\n",
      "train loss:0.003819663935251334\n",
      "train loss:0.00026121121503256566\n",
      "train loss:0.0003661265786307137\n",
      "train loss:0.0018615013226333996\n",
      "train loss:0.0027204508957885828\n",
      "train loss:0.0004804508748631232\n",
      "train loss:0.01108567354386391\n",
      "train loss:0.004099149712133047\n",
      "train loss:0.007369122257243856\n",
      "train loss:0.0009865304065342696\n",
      "train loss:0.0023979534158511955\n",
      "train loss:0.004117730697384987\n",
      "train loss:0.004568922815058411\n",
      "train loss:0.0005643209652921815\n",
      "train loss:0.0004722799744170603\n",
      "train loss:0.038249184407057754\n",
      "train loss:0.0005635334151071496\n",
      "train loss:0.0007795417660872028\n",
      "train loss:0.001378086803652289\n",
      "train loss:0.006096114783058214\n",
      "train loss:0.0005866272845694538\n",
      "train loss:0.001936963825584945\n",
      "train loss:0.0022624711079724863\n",
      "train loss:0.0009786715684677843\n",
      "train loss:0.004088094078655739\n",
      "train loss:0.0006198951974075446\n",
      "train loss:0.0019740410608522383\n",
      "train loss:0.0021920519982102735\n",
      "train loss:0.002903697861701687\n",
      "train loss:0.006122221157949841\n",
      "train loss:0.009223695143441644\n",
      "train loss:0.0008007339025768732\n",
      "train loss:0.0006349902975445584\n",
      "train loss:0.010858608761126131\n",
      "train loss:0.00465776352014126\n",
      "train loss:0.0031906278265316683\n",
      "train loss:0.00620996278602504\n",
      "train loss:0.00017313912399625475\n",
      "train loss:0.002252224400707442\n",
      "train loss:0.0026279119701835595\n",
      "train loss:0.0012238024098992868\n",
      "train loss:0.00539208612082913\n",
      "train loss:0.0008186065376198481\n",
      "train loss:0.004841285246109549\n",
      "train loss:0.0022116237677762703\n",
      "train loss:0.003522588621810253\n",
      "train loss:0.0024822379053051342\n",
      "train loss:0.0024030248372130915\n",
      "train loss:0.00035943442261022427\n",
      "train loss:6.395204340830858e-05\n",
      "train loss:0.008339498097942655\n",
      "train loss:0.00039143228629279236\n",
      "train loss:0.00018229297670154687\n",
      "train loss:0.0002090645127189892\n",
      "train loss:0.0007691684860193297\n",
      "train loss:0.0021158521164038866\n",
      "train loss:0.001457159275665346\n",
      "train loss:0.0011699236588698762\n",
      "train loss:0.0007654369225433773\n",
      "train loss:0.0011684405765685344\n",
      "train loss:0.0010053211271170085\n",
      "train loss:0.0034073433237621475\n",
      "train loss:7.387887404383415e-05\n",
      "train loss:0.0013019002596085113\n",
      "train loss:0.00318596476755673\n",
      "train loss:0.0021488267882233385\n",
      "train loss:0.001390754360709282\n",
      "train loss:0.0001628773583526469\n",
      "train loss:0.007678221875617043\n",
      "train loss:0.0015747052768907272\n",
      "train loss:0.0002820139976929247\n",
      "train loss:0.0014446452677266753\n",
      "train loss:0.0075717329504183094\n",
      "train loss:0.0032362955278410345\n",
      "train loss:0.002579581432441441\n",
      "train loss:0.0034850507001867063\n",
      "train loss:0.000825911948235802\n",
      "train loss:0.007639271722050929\n",
      "train loss:0.004044195159366179\n",
      "train loss:0.005887679686730145\n",
      "train loss:0.013488099633157067\n",
      "train loss:0.0021542508249984757\n",
      "train loss:0.004594307209227267\n",
      "train loss:0.0012185791827859387\n",
      "train loss:0.001901732136821903\n",
      "train loss:0.00732000466105383\n",
      "train loss:0.007634198116803035\n",
      "train loss:0.003877344829752215\n",
      "train loss:0.0027399516912084737\n",
      "train loss:0.0031489345678443834\n",
      "train loss:0.006502784538046402\n",
      "train loss:0.002276169023611532\n",
      "train loss:0.0004114842019967345\n",
      "train loss:0.0009035322939249934\n",
      "train loss:0.017529339777945588\n",
      "train loss:0.0016466078187838294\n",
      "train loss:0.0004487137770326958\n",
      "train loss:0.0011638446569434994\n",
      "train loss:0.0018019705885098946\n",
      "train loss:0.02847872513464206\n",
      "train loss:0.0007598750384719467\n",
      "train loss:0.0012461785121432487\n",
      "train loss:0.0007143348230961511\n",
      "train loss:0.001658446078644257\n",
      "train loss:0.001510028237002991\n",
      "train loss:0.0009934873419442125\n",
      "train loss:0.002246841104058374\n",
      "train loss:0.0012221482951196112\n",
      "train loss:0.0007158884568026197\n",
      "train loss:0.007163840337721795\n",
      "train loss:0.0029494702112916314\n",
      "train loss:0.0002536406920221036\n",
      "train loss:0.0011275729091216264\n",
      "=== epoch:16, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.01237370169292577\n",
      "train loss:0.00013614050796211986\n",
      "train loss:0.023977757434031032\n",
      "train loss:0.0009694139260068703\n",
      "train loss:0.000802862115431911\n",
      "train loss:0.0004304070785320838\n",
      "train loss:0.0008439439426939171\n",
      "train loss:0.0005805440970112467\n",
      "train loss:0.0035878125568705992\n",
      "train loss:0.0008652737085085174\n",
      "train loss:0.007762452264836303\n",
      "train loss:0.0018155928061607469\n",
      "train loss:0.0026307502873095323\n",
      "train loss:0.0009377103769834046\n",
      "train loss:0.0006655051955250617\n",
      "train loss:0.00038661040952653433\n",
      "train loss:0.005071441599003895\n",
      "train loss:0.004169676612841866\n",
      "train loss:0.003279730880884112\n",
      "train loss:0.00020199477051971768\n",
      "train loss:0.00016959757616142132\n",
      "train loss:0.0061906535341886846\n",
      "train loss:0.0017856208693610588\n",
      "train loss:0.0003681362151107427\n",
      "train loss:9.691778784386071e-05\n",
      "train loss:0.0024694049453384483\n",
      "train loss:0.0005375773007861309\n",
      "train loss:0.004267647482750317\n",
      "train loss:0.0023543208896285735\n",
      "train loss:0.0004571220673803244\n",
      "train loss:0.0009184172801682464\n",
      "train loss:0.002303908718701619\n",
      "train loss:0.0005350475995044617\n",
      "train loss:0.0016999763587857665\n",
      "train loss:0.0011153721335913547\n",
      "train loss:0.0002760608015559381\n",
      "train loss:0.0002790246201715857\n",
      "train loss:0.004944993500709184\n",
      "train loss:0.0006276460027434688\n",
      "train loss:0.00145511014066618\n",
      "train loss:0.0013590832129114078\n",
      "train loss:0.0004446898470092084\n",
      "train loss:0.01011330683252954\n",
      "train loss:0.0005797762866146864\n",
      "train loss:0.0029120055942555016\n",
      "train loss:0.0005948320431873847\n",
      "train loss:0.0006127748429513529\n",
      "train loss:0.00014424231729061521\n",
      "train loss:0.002184354067979781\n",
      "train loss:0.0038442736925346967\n",
      "train loss:0.004216177232691079\n",
      "train loss:0.00012103388323449279\n",
      "train loss:0.0007566407554958677\n",
      "train loss:0.0032908871984880152\n",
      "train loss:0.001989732325806412\n",
      "train loss:0.0014093866135721335\n",
      "train loss:0.0008797821903881873\n",
      "train loss:0.001178223455762292\n",
      "train loss:7.914599938804841e-05\n",
      "train loss:5.50123945053887e-05\n",
      "train loss:0.0033004299618787964\n",
      "train loss:0.0008700650504084099\n",
      "train loss:0.00019109957611078174\n",
      "train loss:0.0003297123734883961\n",
      "train loss:0.005542630177924299\n",
      "train loss:0.002863479376009742\n",
      "train loss:0.0020015055560616423\n",
      "train loss:3.677796872723101e-05\n",
      "train loss:0.00029451805373357067\n",
      "train loss:0.00019760605841640373\n",
      "train loss:0.0018674180519636264\n",
      "train loss:0.0005254364102670133\n",
      "train loss:0.0003167944476612577\n",
      "train loss:0.001117403202371968\n",
      "train loss:0.0004188108017266416\n",
      "train loss:0.0012553413367992925\n",
      "train loss:0.001171356737739141\n",
      "train loss:0.0020098380832223235\n",
      "train loss:0.007380626570628206\n",
      "train loss:0.0011641097271739489\n",
      "train loss:0.0004007192684850212\n",
      "train loss:0.008201901731595733\n",
      "train loss:0.004257435841710154\n",
      "train loss:0.0002429682071278781\n",
      "train loss:0.00017347155525524323\n",
      "train loss:0.00044288857504495036\n",
      "train loss:0.0002168781336260753\n",
      "train loss:0.004190516377120008\n",
      "train loss:0.0003941982784367451\n",
      "train loss:0.0025175007874773357\n",
      "train loss:0.0003880043593969772\n",
      "train loss:0.00017001467033029346\n",
      "train loss:0.0010252401009164353\n",
      "train loss:0.007272727515273925\n",
      "train loss:0.00748628895096646\n",
      "train loss:0.0008860115211881041\n",
      "train loss:0.0003975112418291532\n",
      "train loss:0.0029575339967130537\n",
      "train loss:0.00040986521727085423\n",
      "train loss:0.00021470368201641658\n",
      "train loss:0.0032122903700383125\n",
      "train loss:0.001640083270480347\n",
      "train loss:0.0010630606252078221\n",
      "train loss:0.000336589888357064\n",
      "train loss:0.0031983314999591084\n",
      "train loss:0.0015314424003739758\n",
      "train loss:0.0008608008126629923\n",
      "train loss:0.01071282956565413\n",
      "train loss:0.0010778191606841691\n",
      "train loss:0.004696428343795845\n",
      "train loss:0.005069643776989768\n",
      "train loss:0.0055143429868896796\n",
      "train loss:0.0002401880626442569\n",
      "train loss:0.0004992407268745788\n",
      "train loss:0.000327219111006247\n",
      "train loss:0.0020327559889158748\n",
      "train loss:0.00357694101559556\n",
      "train loss:0.002518759063994494\n",
      "train loss:0.00039000448097456584\n",
      "train loss:0.027228991452007193\n",
      "train loss:0.0009494869081318495\n",
      "train loss:0.0013504031472032906\n",
      "train loss:0.007392003149303983\n",
      "train loss:0.002906563006534567\n",
      "train loss:0.000228658266857058\n",
      "train loss:0.00039253345418021994\n",
      "train loss:9.477374986156837e-05\n",
      "train loss:0.003311746145227188\n",
      "train loss:0.0015008734497521533\n",
      "train loss:0.000302466525849708\n",
      "train loss:0.000983147206569905\n",
      "train loss:0.0005242195314199521\n",
      "train loss:0.00046577093990257597\n",
      "train loss:0.003380699135467918\n",
      "train loss:0.005468677833222449\n",
      "train loss:0.002464078696555047\n",
      "train loss:0.0013516794128047107\n",
      "train loss:0.006927584193428068\n",
      "train loss:0.0037010756932206877\n",
      "train loss:0.0018204878076094738\n",
      "train loss:0.006067541769088492\n",
      "train loss:0.00040793920716012793\n",
      "train loss:0.001594461579329369\n",
      "train loss:0.0012424577816037203\n",
      "train loss:0.003788338591751894\n",
      "train loss:0.0001882780657648315\n",
      "train loss:0.005002988419148407\n",
      "train loss:0.002339092163969561\n",
      "train loss:0.002408161857649696\n",
      "train loss:0.004318535339021049\n",
      "train loss:0.0004321439298457896\n",
      "train loss:0.0029241345530792544\n",
      "train loss:8.457830764707408e-05\n",
      "train loss:0.0007874278582206068\n",
      "train loss:0.010762113751508182\n",
      "train loss:0.0008873458755460723\n",
      "train loss:0.0015902946276724827\n",
      "train loss:0.004085479323539912\n",
      "train loss:0.0013655379169278798\n",
      "train loss:0.00021749015565855279\n",
      "train loss:0.0015283215371900939\n",
      "train loss:0.07150886478255244\n",
      "train loss:0.001358279178753814\n",
      "train loss:0.001476866755345377\n",
      "train loss:0.002980572227475476\n",
      "train loss:0.0010412375554716493\n",
      "train loss:0.00040728056981156625\n",
      "train loss:0.0027932091861828223\n",
      "train loss:0.0015001567069872726\n",
      "train loss:0.018416791832889794\n",
      "train loss:0.004330382321921684\n",
      "train loss:0.0022151680553228518\n",
      "train loss:0.0010487116097723072\n",
      "train loss:0.0022195995418300813\n",
      "train loss:0.008177844398947937\n",
      "train loss:0.0031766945103756535\n",
      "train loss:0.0020725438838670213\n",
      "train loss:0.008043328301816383\n",
      "train loss:0.00117806624103376\n",
      "train loss:0.0006521590666604711\n",
      "train loss:0.0035610896749265473\n",
      "train loss:0.0015251655452541465\n",
      "train loss:0.0005733710873122422\n",
      "train loss:0.0018754621914994281\n",
      "train loss:0.0014958682088004167\n",
      "train loss:0.004813438683223963\n",
      "train loss:0.011241864814767884\n",
      "train loss:0.005626896687320001\n",
      "train loss:0.00021364934129705472\n",
      "train loss:0.0008808101665188956\n",
      "train loss:0.0018059230925065383\n",
      "train loss:0.005742318525671698\n",
      "train loss:0.013539472844925356\n",
      "train loss:0.005087300508810587\n",
      "train loss:0.006926747305096872\n",
      "train loss:0.011533021999198412\n",
      "train loss:0.004690544525259334\n",
      "train loss:0.0030472621556967344\n",
      "train loss:0.012690735185347041\n",
      "train loss:0.0006483218483523797\n",
      "train loss:0.0013695531177079757\n",
      "train loss:0.0009823155922932744\n",
      "train loss:0.011674468440935363\n",
      "train loss:0.004940441543402405\n",
      "train loss:0.0016146172582948656\n",
      "train loss:0.0011131076593626946\n",
      "train loss:0.0009075261182557081\n",
      "train loss:0.003374287937142518\n",
      "train loss:0.00030958708160824745\n",
      "train loss:0.00037631256144239134\n",
      "train loss:0.0028811319735138675\n",
      "train loss:0.0011749203834706613\n",
      "train loss:0.0006990043508760114\n",
      "train loss:0.0013862190495363873\n",
      "train loss:0.0012383082451348016\n",
      "train loss:0.0058734029291533495\n",
      "train loss:0.0010901347828221773\n",
      "train loss:0.00764359173089952\n",
      "train loss:0.0009080134607012849\n",
      "train loss:0.0005849776161293423\n",
      "train loss:0.03134627606735754\n",
      "train loss:0.00023976484442967595\n",
      "train loss:0.0006947792681348937\n",
      "train loss:0.004538857899636103\n",
      "train loss:0.0005995262309627151\n",
      "train loss:0.0013777633736506915\n",
      "train loss:0.00029072409762996034\n",
      "train loss:0.007069492679651961\n",
      "train loss:0.0008864369453765719\n",
      "train loss:0.007877415735313956\n",
      "train loss:0.0012893351658458893\n",
      "train loss:0.000239760966640013\n",
      "train loss:0.002400452150879225\n",
      "train loss:0.0011937925869424809\n",
      "train loss:0.004170244184735595\n",
      "train loss:0.00034350068675594936\n",
      "train loss:0.0023232444229527712\n",
      "train loss:0.0039863115689979306\n",
      "train loss:0.001983987250168113\n",
      "train loss:0.0004544095863634529\n",
      "train loss:0.00020611692273582314\n",
      "train loss:0.000590752978501111\n",
      "train loss:0.0026043696984166666\n",
      "train loss:0.001011591000407945\n",
      "train loss:0.0003119384037002971\n",
      "train loss:0.0012921393722383006\n",
      "train loss:9.438128037323504e-05\n",
      "train loss:0.0008264085256913412\n",
      "train loss:0.001556040074481807\n",
      "train loss:0.0010169110563602092\n",
      "train loss:0.0027618059115097167\n",
      "train loss:0.002001679796327916\n",
      "train loss:0.0019162587169405912\n",
      "train loss:0.00021595169308579075\n",
      "train loss:0.0007415145525961842\n",
      "train loss:0.010475623077847756\n",
      "train loss:0.001299330833420599\n",
      "train loss:0.0003472402745392369\n",
      "train loss:0.002615562797940852\n",
      "train loss:0.00035917139778324404\n",
      "train loss:0.0010233218351674205\n",
      "train loss:0.0026890777311354332\n",
      "train loss:0.002886530608060674\n",
      "train loss:0.00024883278720843043\n",
      "train loss:0.0008424005289271374\n",
      "train loss:0.00023233979634662875\n",
      "train loss:0.002020542230256841\n",
      "train loss:0.002377559225321518\n",
      "train loss:0.0004081615706213207\n",
      "train loss:0.0041519099903270604\n",
      "train loss:0.00018227071148039058\n",
      "train loss:0.0023524133689510323\n",
      "train loss:0.004230273928402643\n",
      "train loss:0.009862042022124536\n",
      "train loss:0.000430942787849397\n",
      "train loss:0.0017655719397305664\n",
      "train loss:0.0014036730525526467\n",
      "train loss:0.0019057346058409517\n",
      "train loss:0.001523312784968355\n",
      "train loss:0.0029536129550295047\n",
      "train loss:0.0026224970768954537\n",
      "train loss:0.002100585809931891\n",
      "train loss:0.0010514685237682673\n",
      "train loss:0.0006681875586582791\n",
      "train loss:0.0017959903508944378\n",
      "train loss:0.002891178657704123\n",
      "train loss:0.0008838859380729708\n",
      "train loss:0.00010018809731536932\n",
      "train loss:0.0002744314110544375\n",
      "train loss:0.005350253614888802\n",
      "train loss:0.0015488942281615483\n",
      "train loss:0.004298955735030356\n",
      "train loss:0.0004081860687230624\n",
      "train loss:0.0017001046197886109\n",
      "train loss:0.0030182452962488854\n",
      "train loss:0.001039202418943473\n",
      "train loss:0.00037531963495231386\n",
      "train loss:0.007906480415548754\n",
      "train loss:0.003063188750309917\n",
      "train loss:0.00032451652749483276\n",
      "train loss:0.0006468870357672985\n",
      "train loss:0.0027687805918186524\n",
      "train loss:0.0007905071539162367\n",
      "train loss:0.001679714804283135\n",
      "train loss:0.0002274874145805621\n",
      "train loss:0.004356842010943299\n",
      "train loss:0.0004024771461967346\n",
      "train loss:0.00234267398880103\n",
      "train loss:0.0012819844628980395\n",
      "train loss:0.000555253931014418\n",
      "train loss:0.00037237875263781034\n",
      "train loss:0.0019144171982769622\n",
      "train loss:0.0008113473822012222\n",
      "train loss:0.02923796734543928\n",
      "train loss:0.0001165210919218076\n",
      "train loss:0.008139877295130861\n",
      "train loss:0.00021958697990594078\n",
      "train loss:0.002406446069309371\n",
      "train loss:0.0033932129622135996\n",
      "train loss:0.005426617735758921\n",
      "train loss:0.001912450046646324\n",
      "train loss:0.0010852677441226396\n",
      "train loss:0.0018517741790896572\n",
      "train loss:0.002017236830472007\n",
      "train loss:0.0008148192529031756\n",
      "train loss:0.0007618359993649438\n",
      "train loss:0.0005681619383766249\n",
      "train loss:0.0035280528975842195\n",
      "train loss:0.007513957916768691\n",
      "train loss:0.0001715160875819183\n",
      "train loss:0.004173925073234263\n",
      "train loss:0.0020284275675178666\n",
      "train loss:0.0011007112986998315\n",
      "train loss:0.0026260963008256704\n",
      "train loss:0.0007013375217119815\n",
      "train loss:0.007908615156899211\n",
      "train loss:0.0005740520211717521\n",
      "train loss:0.0004218859098348569\n",
      "train loss:0.0007008023307606745\n",
      "train loss:0.00014223104714377962\n",
      "train loss:0.0004580690997471955\n",
      "train loss:0.004193031979173639\n",
      "train loss:0.0011471868400493759\n",
      "train loss:0.004877035870189435\n",
      "train loss:0.0030371676919269727\n",
      "train loss:0.0002686142353674514\n",
      "train loss:0.004107481839077213\n",
      "train loss:0.0013960136419833833\n",
      "train loss:0.0018838649855561552\n",
      "train loss:0.0007959994606677582\n",
      "train loss:0.0022616546460522678\n",
      "train loss:0.00035134944355569124\n",
      "train loss:0.0002593572331354735\n",
      "train loss:0.003539465953799101\n",
      "train loss:0.0006150918922308325\n",
      "train loss:0.013785976296196923\n",
      "train loss:0.0041001035112459535\n",
      "train loss:0.0004703080745286896\n",
      "train loss:0.0009640212829948774\n",
      "train loss:0.00033183347078492013\n",
      "train loss:0.0015408754079162565\n",
      "train loss:0.00010189539797874672\n",
      "train loss:0.0032591629487826847\n",
      "train loss:0.01670968726573031\n",
      "train loss:0.0018091857858174782\n",
      "train loss:0.0029335461427268845\n",
      "train loss:0.0049562659327884425\n",
      "train loss:0.0009143257479095558\n",
      "train loss:0.0011200155895634935\n",
      "train loss:0.0011042400292328733\n",
      "train loss:0.002257476261716989\n",
      "train loss:0.004076591232536416\n",
      "train loss:0.0009273111516763084\n",
      "train loss:0.00048763792590508055\n",
      "train loss:0.00018975808222123283\n",
      "train loss:0.0031225383829703484\n",
      "train loss:0.0007652389442404823\n",
      "train loss:0.0005047596086751452\n",
      "train loss:0.004792077523360957\n",
      "train loss:0.001531798503575952\n",
      "train loss:0.0002152631055924409\n",
      "train loss:0.0037403896180413176\n",
      "train loss:0.0006379090002797023\n",
      "train loss:0.002069788471701224\n",
      "train loss:0.0017542028679309982\n",
      "train loss:0.0009299816129201142\n",
      "train loss:0.0016708836192730677\n",
      "train loss:0.001955986879049707\n",
      "train loss:0.0014317450892950556\n",
      "train loss:4.803582110484589e-05\n",
      "train loss:0.0004457988461713737\n",
      "train loss:0.0017949608455569686\n",
      "train loss:0.00010888650186119838\n",
      "train loss:0.00032669562339916253\n",
      "train loss:0.0017256349798116424\n",
      "train loss:0.0003688361044579893\n",
      "train loss:0.0061371575234821715\n",
      "train loss:0.0026032872561540126\n",
      "train loss:0.0018496832128855687\n",
      "train loss:0.0023223359965832352\n",
      "train loss:0.0006458542335395255\n",
      "train loss:0.0012328064059554597\n",
      "train loss:0.0004374728545846\n",
      "train loss:0.0014480783556261236\n",
      "train loss:0.0016511255510139383\n",
      "train loss:7.839376255728754e-05\n",
      "train loss:0.0005417317944084533\n",
      "train loss:0.0018539772869063454\n",
      "train loss:0.00019892899948351035\n",
      "train loss:0.0005128662263368872\n",
      "train loss:0.0005496545691148341\n",
      "train loss:0.0014365141590945458\n",
      "train loss:0.0005778121132677532\n",
      "train loss:0.0003850657439652691\n",
      "train loss:0.001251019022651106\n",
      "train loss:0.0013094788900854682\n",
      "train loss:0.0008925936334201625\n",
      "train loss:0.0044584703631345745\n",
      "train loss:0.0008261288441719132\n",
      "train loss:0.0011111825606888175\n",
      "train loss:0.0006123273271193911\n",
      "train loss:0.0036243027245476496\n",
      "train loss:0.00012867447607069833\n",
      "train loss:0.02181424880738503\n",
      "train loss:0.006380295027798903\n",
      "train loss:0.0004033403694160048\n",
      "train loss:0.0005255054144904065\n",
      "train loss:0.0018873538405785823\n",
      "train loss:0.0025959061004703333\n",
      "train loss:0.0004254063933464975\n",
      "train loss:0.0017096620134795307\n",
      "train loss:0.0088988908563722\n",
      "train loss:0.0001488626356298311\n",
      "train loss:0.0021826069200548874\n",
      "train loss:0.0005928893789940862\n",
      "train loss:0.00015246764860850115\n",
      "train loss:0.00018214715994509465\n",
      "train loss:0.00018737893503587808\n",
      "train loss:0.0037454232517827968\n",
      "train loss:0.0003283732769388893\n",
      "train loss:0.0004845442140214258\n",
      "train loss:0.0026489067425093955\n",
      "train loss:0.003095480811570226\n",
      "train loss:0.002702575775058804\n",
      "train loss:0.0005917450173191184\n",
      "train loss:0.00013114456066257854\n",
      "train loss:0.0007811186678456443\n",
      "train loss:0.0026203328520164665\n",
      "train loss:0.0005575445391472044\n",
      "train loss:3.979692162801564e-05\n",
      "train loss:0.0036094753600431073\n",
      "train loss:0.0007100107420828534\n",
      "train loss:0.0004660764340451949\n",
      "train loss:0.0014158553787872643\n",
      "train loss:0.0027508084743087784\n",
      "train loss:0.0006670423511810047\n",
      "train loss:0.004996991070630823\n",
      "train loss:0.006118727840829954\n",
      "train loss:0.00015219334102495162\n",
      "train loss:0.00019026305679780523\n",
      "train loss:0.001428041589271423\n",
      "train loss:0.0006213815645673776\n",
      "train loss:7.897737866698225e-05\n",
      "train loss:0.001623288899866682\n",
      "train loss:0.0029785064556720592\n",
      "train loss:0.00010487672768479148\n",
      "train loss:0.0002660220240990661\n",
      "train loss:0.000926271124233079\n",
      "train loss:0.0006598265646359193\n",
      "train loss:8.516057122828805e-05\n",
      "train loss:0.003228796339157598\n",
      "train loss:0.002045780870757055\n",
      "train loss:0.0001255454678790003\n",
      "train loss:0.0025776123307418423\n",
      "train loss:0.003948769997406259\n",
      "train loss:0.0006491991178818753\n",
      "train loss:0.001744711971312265\n",
      "train loss:0.0005791345335292883\n",
      "train loss:0.00413088982275909\n",
      "train loss:0.0015817513746166864\n",
      "train loss:0.001307202804661315\n",
      "train loss:0.009970813285837616\n",
      "train loss:0.0009132636071653052\n",
      "train loss:0.00026354852057346883\n",
      "train loss:0.0009631388354049474\n",
      "train loss:0.0012193712856519998\n",
      "train loss:0.0001300956002488521\n",
      "train loss:0.0015149738878441957\n",
      "train loss:0.00023717291046192424\n",
      "train loss:0.002868223203669423\n",
      "train loss:0.006208604930869175\n",
      "train loss:8.202301165638737e-05\n",
      "train loss:0.0016716526264054965\n",
      "train loss:0.0017658982856755224\n",
      "train loss:0.003564331316715416\n",
      "train loss:0.0006990478524143017\n",
      "train loss:0.0005723013144204632\n",
      "train loss:0.002360096038006976\n",
      "train loss:0.0010279411716148192\n",
      "train loss:0.00523068954170312\n",
      "train loss:0.0004900134376042379\n",
      "train loss:0.0006688662369787294\n",
      "train loss:0.001388806332267767\n",
      "train loss:0.00697596677725556\n",
      "train loss:0.0005827446104722075\n",
      "train loss:0.0013304724258717954\n",
      "train loss:0.001321912386952728\n",
      "train loss:0.0022940182004766536\n",
      "train loss:0.0003507672603603582\n",
      "train loss:0.0010457627858731081\n",
      "train loss:0.0031487382462501534\n",
      "train loss:0.0001777962170071711\n",
      "train loss:0.0007561719947253913\n",
      "train loss:0.0007027135158374894\n",
      "train loss:0.0022551847356785935\n",
      "train loss:0.0025169739247778615\n",
      "train loss:0.0006289516416170027\n",
      "train loss:0.003181551493792401\n",
      "train loss:0.00019907096960442288\n",
      "train loss:0.006870489176492458\n",
      "train loss:0.00010371947939635161\n",
      "train loss:0.0001311633460269276\n",
      "train loss:3.428688974700114e-05\n",
      "train loss:0.00022110298825033629\n",
      "train loss:0.002165995752814776\n",
      "train loss:0.00022709180375337095\n",
      "train loss:0.0005006214244240229\n",
      "train loss:0.002806558579757865\n",
      "train loss:9.40425159139321e-05\n",
      "train loss:0.0034145759207348265\n",
      "train loss:0.0011142715779113759\n",
      "train loss:7.873683963196018e-05\n",
      "train loss:0.0008674620169984413\n",
      "train loss:0.00027975794763343954\n",
      "train loss:0.0007366878919010423\n",
      "train loss:0.003489791016980608\n",
      "train loss:0.0012891395616738304\n",
      "train loss:0.019857399501919035\n",
      "train loss:0.0007638221751797208\n",
      "train loss:0.0013632919391781914\n",
      "train loss:0.0007104087575432201\n",
      "train loss:0.0031306512799007253\n",
      "train loss:0.0009503631300808248\n",
      "train loss:0.002365288976405221\n",
      "train loss:0.0031711842080506137\n",
      "train loss:0.0020669652064330395\n",
      "train loss:0.0022147008257397396\n",
      "train loss:9.377063062278218e-05\n",
      "train loss:0.0017382176704357375\n",
      "train loss:0.00017781605506215717\n",
      "train loss:0.0056764359321031\n",
      "train loss:0.00262761567217338\n",
      "train loss:0.0038220077981985586\n",
      "train loss:0.003200436519847075\n",
      "train loss:0.0027458470214362807\n",
      "train loss:5.82533696869762e-05\n",
      "train loss:0.004822446471701003\n",
      "train loss:0.0006185094183328728\n",
      "train loss:0.0013593992166432852\n",
      "train loss:0.011432171567672336\n",
      "train loss:0.002417829504605355\n",
      "train loss:0.00019215153082733033\n",
      "train loss:0.00303980882720211\n",
      "train loss:0.010061994547692887\n",
      "train loss:0.0013134627200277035\n",
      "train loss:0.0011485032215342987\n",
      "train loss:0.0015204835867582618\n",
      "train loss:0.0030118470914016694\n",
      "train loss:0.0023685216114188875\n",
      "train loss:0.0001391536551371352\n",
      "train loss:0.00024184400504698216\n",
      "train loss:0.0005134391641214132\n",
      "train loss:0.001074404821139623\n",
      "train loss:0.0010250966864572058\n",
      "train loss:0.0002058999908169731\n",
      "train loss:0.004648365232005519\n",
      "train loss:0.00021602268638192752\n",
      "train loss:0.0009629797152695734\n",
      "train loss:0.004493386723529183\n",
      "train loss:0.0007274784270510815\n",
      "train loss:0.0004531042531969075\n",
      "train loss:0.000658532364627348\n",
      "train loss:0.00016838855367865048\n",
      "train loss:0.0007340174863941928\n",
      "train loss:0.0002921825228721884\n",
      "train loss:0.001159185752604646\n",
      "train loss:0.00019950257938053682\n",
      "train loss:0.0012922041432912785\n",
      "train loss:0.00014945287144915115\n",
      "train loss:0.0003782374841225424\n",
      "train loss:0.000863921133512257\n",
      "train loss:2.105955089067622e-05\n",
      "train loss:0.002715930623300986\n",
      "train loss:0.002585194785136375\n",
      "train loss:0.000201886638095505\n",
      "train loss:7.918871509119495e-05\n",
      "train loss:8.400332379270504e-05\n",
      "train loss:0.0007617532956319807\n",
      "train loss:0.001616806419756704\n",
      "train loss:0.0003548830129662492\n",
      "=== epoch:17, train acc:0.999, test acc:0.994 ===\n",
      "train loss:0.001656526778673149\n",
      "train loss:3.515708191183684e-05\n",
      "train loss:0.021903240120032016\n",
      "train loss:0.0003681027995888109\n",
      "train loss:0.0005600445710406106\n",
      "train loss:0.002794133084376535\n",
      "train loss:0.00020153883922736923\n",
      "train loss:0.0010837743209709853\n",
      "train loss:0.0023579187538023878\n",
      "train loss:0.00010539731585120747\n",
      "train loss:0.00013651880760367913\n",
      "train loss:0.0036962280006130055\n",
      "train loss:0.0002933211438602465\n",
      "train loss:0.0035947520965275825\n",
      "train loss:0.0004333100666312996\n",
      "train loss:0.00019751824475710376\n",
      "train loss:0.0007306382876642432\n",
      "train loss:0.0004401833432391038\n",
      "train loss:0.002121268568111547\n",
      "train loss:0.00460771038930488\n",
      "train loss:0.0018954420815184916\n",
      "train loss:0.0025861411407377324\n",
      "train loss:0.0008128396991064549\n",
      "train loss:0.0027341721577560686\n",
      "train loss:0.006355659406057579\n",
      "train loss:0.0023044106441792362\n",
      "train loss:0.00404877395235264\n",
      "train loss:0.00857842296214856\n",
      "train loss:0.00047335371196880485\n",
      "train loss:0.002849641870676547\n",
      "train loss:0.007326409287050151\n",
      "train loss:0.0015916808073484854\n",
      "train loss:0.0007233669277090692\n",
      "train loss:0.0014709313196733132\n",
      "train loss:0.00013074770312162176\n",
      "train loss:0.0001315878701065851\n",
      "train loss:8.172622914563604e-05\n",
      "train loss:0.0026303619930568086\n",
      "train loss:0.0004954274335220726\n",
      "train loss:0.006468738151658819\n",
      "train loss:0.00047891675948877875\n",
      "train loss:0.0020845310442033508\n",
      "train loss:0.00017605730031100347\n",
      "train loss:0.004902115374828999\n",
      "train loss:0.02033597680206107\n",
      "train loss:0.0011869879569111385\n",
      "train loss:0.0032504261362708213\n",
      "train loss:0.0017837872039726207\n",
      "train loss:0.0010508566380706106\n",
      "train loss:0.00010991739373853463\n",
      "train loss:0.0030613052050675643\n",
      "train loss:0.001113551252498692\n",
      "train loss:0.007549620581572741\n",
      "train loss:0.0022410387448169337\n",
      "train loss:0.0010942291674338805\n",
      "train loss:0.001767129490408087\n",
      "train loss:0.005247935992176049\n",
      "train loss:0.0014148250023383777\n",
      "train loss:0.0023792633589899705\n",
      "train loss:0.0018474488000027973\n",
      "train loss:0.00455717047517069\n",
      "train loss:0.000592934153208918\n",
      "train loss:0.00040708676048517106\n",
      "train loss:0.00011297357636449726\n",
      "train loss:0.0015231183357024619\n",
      "train loss:0.0010812663990437288\n",
      "train loss:0.0003950807296240809\n",
      "train loss:0.0013213974318172347\n",
      "train loss:0.002570318723982641\n",
      "train loss:0.0023773742041519855\n",
      "train loss:0.0014496424176159428\n",
      "train loss:0.01167934580163808\n",
      "train loss:0.0014086162240483896\n",
      "train loss:0.02282336413902579\n",
      "train loss:0.0004813379156558587\n",
      "train loss:0.002386613343593211\n",
      "train loss:0.004956298769107491\n",
      "train loss:0.002833514026430908\n",
      "train loss:0.007824862979995925\n",
      "train loss:0.0005621324557971753\n",
      "train loss:0.0018627916147028903\n",
      "train loss:7.387637794990951e-05\n",
      "train loss:0.0034255493324607477\n",
      "train loss:0.0038837045978604057\n",
      "train loss:0.0028130311336309628\n",
      "train loss:0.0009864535626306825\n",
      "train loss:0.0054491904604438025\n",
      "train loss:0.002016878872969923\n",
      "train loss:0.0010846326568849922\n",
      "train loss:0.0032975959496708836\n",
      "train loss:0.0007978544704166989\n",
      "train loss:0.004660624682329399\n",
      "train loss:0.006294271500846328\n",
      "train loss:0.00024021656882001222\n",
      "train loss:0.00018705620526603342\n",
      "train loss:0.010883388249805346\n",
      "train loss:0.0025999224880291273\n",
      "train loss:0.005795841433896875\n",
      "train loss:0.008633789848837758\n",
      "train loss:0.006045988053014238\n",
      "train loss:0.003222697248041076\n",
      "train loss:0.0018511139043667485\n",
      "train loss:0.0027151590246428416\n",
      "train loss:0.0003252656488799189\n",
      "train loss:0.006701867491183741\n",
      "train loss:0.0011375807273979576\n",
      "train loss:0.0007613420362571115\n",
      "train loss:0.004214178276902421\n",
      "train loss:0.0004499003039613888\n",
      "train loss:0.00024414797265908327\n",
      "train loss:0.001771221138220678\n",
      "train loss:0.016951169147995774\n",
      "train loss:0.0006339674865851875\n",
      "train loss:0.013967114849294868\n",
      "train loss:0.0017670833446173867\n",
      "train loss:0.0004908014920478505\n",
      "train loss:0.0005121885012028954\n",
      "train loss:0.0026308948857377223\n",
      "train loss:0.0007575522662458355\n",
      "train loss:0.002992032629959269\n",
      "train loss:0.002782211534076341\n",
      "train loss:0.0019438152835668696\n",
      "train loss:0.004179517003068693\n",
      "train loss:0.02048801769008414\n",
      "train loss:0.1096976733474228\n",
      "train loss:0.0027908360250563868\n",
      "train loss:0.02132009869259735\n",
      "train loss:0.0010363541810571785\n",
      "train loss:0.004092955364778276\n",
      "train loss:0.005319171144565281\n",
      "train loss:0.0018251664710832317\n",
      "train loss:0.027011412169568042\n",
      "train loss:0.0059456392059203615\n",
      "train loss:0.004240621691645064\n",
      "train loss:0.0005936116249547868\n",
      "train loss:0.004658726750152743\n",
      "train loss:0.0023997951139549108\n",
      "train loss:0.0035583123020849943\n",
      "train loss:0.002296203867883549\n",
      "train loss:0.016143555245759042\n",
      "train loss:8.45386609442741e-05\n",
      "train loss:0.0033128373171467055\n",
      "train loss:0.0013867587739450481\n",
      "train loss:0.0015516151048409108\n",
      "train loss:0.003419493086305886\n",
      "train loss:0.0011529331691366557\n",
      "train loss:0.0023125719626396093\n",
      "train loss:0.0007723494007611964\n",
      "train loss:0.0030701169918064815\n",
      "train loss:0.0009829699749706212\n",
      "train loss:0.0022545020801423114\n",
      "train loss:8.014731250565841e-05\n",
      "train loss:0.0009511908342967404\n",
      "train loss:0.003529312366584748\n",
      "train loss:0.05580544080827062\n",
      "train loss:0.004780340681766051\n",
      "train loss:0.015108614385061179\n",
      "train loss:0.001603381760958933\n",
      "train loss:0.00014172043331736497\n",
      "train loss:0.0011576950244703529\n",
      "train loss:0.00024475241553678916\n",
      "train loss:0.005716149639366191\n",
      "train loss:0.0030050443770981094\n",
      "train loss:0.003322868221528768\n",
      "train loss:0.007308508417470106\n",
      "train loss:0.001269295207815254\n",
      "train loss:0.003164907551738094\n",
      "train loss:0.001071647813210406\n",
      "train loss:0.00022662140797193535\n",
      "train loss:0.0022770497927031372\n",
      "train loss:0.000331568655891234\n",
      "train loss:0.0005815663996328564\n",
      "train loss:0.001763538328871464\n",
      "train loss:0.0005077837859481447\n",
      "train loss:0.0015405668263907806\n",
      "train loss:0.0012743392502138804\n",
      "train loss:0.005119695971313529\n",
      "train loss:0.0028480662327084855\n",
      "train loss:0.0008955096462092361\n",
      "train loss:0.00219754384263423\n",
      "train loss:0.0011636880214691684\n",
      "train loss:0.00013368694339837962\n",
      "train loss:0.0011768694485518147\n",
      "train loss:0.00045375935638437387\n",
      "train loss:0.0021978535691183883\n",
      "train loss:0.0018247605135886275\n",
      "train loss:0.000210369786859303\n",
      "train loss:0.0019428978623925936\n",
      "train loss:0.012645056678613193\n",
      "train loss:0.0008401135286322445\n",
      "train loss:0.0006966183873675514\n",
      "train loss:0.0005690428762238604\n",
      "train loss:0.0051075257872037535\n",
      "train loss:0.0007458156362122919\n",
      "train loss:0.0006288756867662404\n",
      "train loss:0.00048610899700549\n",
      "train loss:0.0003585050763031421\n",
      "train loss:0.0006730710613391457\n",
      "train loss:0.0011748035851687534\n",
      "train loss:0.0006174571513487554\n",
      "train loss:0.0005809234448235522\n",
      "train loss:0.002684039813199\n",
      "train loss:0.0035737476074055884\n",
      "train loss:0.0002828471811659598\n",
      "train loss:0.004721160099247752\n",
      "train loss:0.0013653888107886592\n",
      "train loss:0.003702832045905791\n",
      "train loss:0.0006170864667961579\n",
      "train loss:0.0020849432365402953\n",
      "train loss:0.00036710441027471463\n",
      "train loss:0.0004370392918175192\n",
      "train loss:0.0029117565110196196\n",
      "train loss:0.001063158304715707\n",
      "train loss:0.0010374588333640455\n",
      "train loss:0.0005804471732645842\n",
      "train loss:0.0027132338673942834\n",
      "train loss:0.0036187116411485728\n",
      "train loss:0.005533333795445184\n",
      "train loss:0.029149982195830287\n",
      "train loss:0.0008840440774665159\n",
      "train loss:0.0009705512989863317\n",
      "train loss:0.0003643627612317706\n",
      "train loss:0.002027724098407348\n",
      "train loss:0.0007653710962880005\n",
      "train loss:0.0014936316006301349\n",
      "train loss:0.00011242769862825982\n",
      "train loss:0.00047162930990149264\n",
      "train loss:0.000969142966651922\n",
      "train loss:0.0008061387952265977\n",
      "train loss:0.0030130143271925717\n",
      "train loss:0.00034521465697241515\n",
      "train loss:0.001613085084406967\n",
      "train loss:0.0005088582546834017\n",
      "train loss:0.0007097435536926861\n",
      "train loss:0.0006304338887120418\n",
      "train loss:0.0020279649295370868\n",
      "train loss:0.0007543849749321466\n",
      "train loss:0.0008355333730251431\n",
      "train loss:0.01528745469652147\n",
      "train loss:0.0002756287643686715\n",
      "train loss:0.00539436609795479\n",
      "train loss:0.0003673739634673144\n",
      "train loss:0.0010729896808105385\n",
      "train loss:0.001027709275671667\n",
      "train loss:0.0024856358391348986\n",
      "train loss:0.00044335424118406526\n",
      "train loss:0.0009110662750783197\n",
      "train loss:0.008723513287276417\n",
      "train loss:0.0038608414864962155\n",
      "train loss:0.0032383659536174454\n",
      "train loss:0.00670164724576987\n",
      "train loss:0.0004636690699817577\n",
      "train loss:0.0013019672217738087\n",
      "train loss:0.00039560525235120774\n",
      "train loss:0.030894407300259316\n",
      "train loss:0.0028988951275098905\n",
      "train loss:0.0032045267191524113\n",
      "train loss:0.003843975107257438\n",
      "train loss:0.0004094266587324012\n",
      "train loss:0.0009030534093305396\n",
      "train loss:0.0006421508188600965\n",
      "train loss:0.0001480611777507534\n",
      "train loss:0.00012285960526586614\n",
      "train loss:0.0008945221286547152\n",
      "train loss:0.00011656910460234861\n",
      "train loss:0.0015910533887320783\n",
      "train loss:0.0027748409438689654\n",
      "train loss:0.0002225794052206189\n",
      "train loss:0.0006369050565808629\n",
      "train loss:0.001401132204607486\n",
      "train loss:0.0005312798181781479\n",
      "train loss:0.000939883264747814\n",
      "train loss:0.001741224287727425\n",
      "train loss:0.0024884235430292735\n",
      "train loss:0.001643110208673327\n",
      "train loss:0.0013733656998802593\n",
      "train loss:0.004995570084205777\n",
      "train loss:0.0006391494691506811\n",
      "train loss:0.0026675370751086396\n",
      "train loss:0.000218909825866513\n",
      "train loss:0.0026318497943204106\n",
      "train loss:0.0026028353783590385\n",
      "train loss:0.00021956450024305884\n",
      "train loss:0.0009833276470721621\n",
      "train loss:0.0006647434715761781\n",
      "train loss:0.00027131688756743574\n",
      "train loss:0.0013583705069250464\n",
      "train loss:0.0009373318023561024\n",
      "train loss:0.0004752909340272182\n",
      "train loss:0.0015192228431447751\n",
      "train loss:0.0009857852305902672\n",
      "train loss:0.004724140242706679\n",
      "train loss:0.0019874127482438857\n",
      "train loss:0.0007618841618176553\n",
      "train loss:0.0008655754259149768\n",
      "train loss:0.0003290816768206923\n",
      "train loss:0.0008574852473120543\n",
      "train loss:0.002822881754390462\n",
      "train loss:0.0009331083337120473\n",
      "train loss:0.0004914210146975815\n",
      "train loss:0.001375078007977104\n",
      "train loss:0.0020286711542672965\n",
      "train loss:0.0034889106889306482\n",
      "train loss:0.0007106482509302995\n",
      "train loss:0.0014583164923544214\n",
      "train loss:0.00018124798423987555\n",
      "train loss:0.0006175325527091269\n",
      "train loss:0.003676589495723856\n",
      "train loss:0.0013825279487383907\n",
      "train loss:0.0008128562745971568\n",
      "train loss:0.00017929724528130636\n",
      "train loss:0.0027777575005262295\n",
      "train loss:0.0029858288814878413\n",
      "train loss:0.0011653874072140174\n",
      "train loss:0.0013533486683794762\n",
      "train loss:0.003253496179977294\n",
      "train loss:0.005304216087017945\n",
      "train loss:0.002049248341700365\n",
      "train loss:0.0007176026374664578\n",
      "train loss:0.00036882531784872464\n",
      "train loss:0.0009360971339577199\n",
      "train loss:0.0012001541660430564\n",
      "train loss:0.0003488934640665096\n",
      "train loss:0.001236867769743155\n",
      "train loss:0.0014225243967255275\n",
      "train loss:0.0062873731245206965\n",
      "train loss:0.00034953462982702374\n",
      "train loss:0.00013659735278127264\n",
      "train loss:0.00038499853532412786\n",
      "train loss:0.001874769402632414\n",
      "train loss:0.000458848397560717\n",
      "train loss:0.0004745580620571483\n",
      "train loss:0.0014594307596730405\n",
      "train loss:0.0004257121116191422\n",
      "train loss:0.010404243096686494\n",
      "train loss:0.0007696686149675863\n",
      "train loss:0.000237008602410701\n",
      "train loss:0.0004838273224756106\n",
      "train loss:9.092698999358165e-05\n",
      "train loss:0.0007123794396697983\n",
      "train loss:0.0011322875539340684\n",
      "train loss:0.0003148220947604605\n",
      "train loss:0.0002884269924930551\n",
      "train loss:0.0022982661742500144\n",
      "train loss:0.003355282027047043\n",
      "train loss:0.0010090082577999264\n",
      "train loss:0.00022492665068752878\n",
      "train loss:0.0002435345200442438\n",
      "train loss:0.0017187471889226736\n",
      "train loss:2.005287472294573e-05\n",
      "train loss:0.0006974110534578835\n",
      "train loss:0.0012592357082025537\n",
      "train loss:0.0032572752465641675\n",
      "train loss:0.0002666888686948283\n",
      "train loss:0.0006457269848005932\n",
      "train loss:0.003996366060012041\n",
      "train loss:3.44839969535542e-05\n",
      "train loss:0.004338986035021486\n",
      "train loss:0.00023491600066916844\n",
      "train loss:0.0014355518872505107\n",
      "train loss:0.00265044022650402\n",
      "train loss:0.0001566681551180612\n",
      "train loss:0.0004292145881326998\n",
      "train loss:0.0006372928495777014\n",
      "train loss:0.00036541500345753744\n",
      "train loss:0.0007739827555789372\n",
      "train loss:0.0001738888549675917\n",
      "train loss:0.00036534767429032006\n",
      "train loss:0.0015044965050153324\n",
      "train loss:0.0034203173972365765\n",
      "train loss:0.0009278762681015241\n",
      "train loss:0.0006653433442851424\n",
      "train loss:0.0006720302716007801\n",
      "train loss:0.0003290305942960635\n",
      "train loss:0.001655037993948266\n",
      "train loss:0.00265888319669798\n",
      "train loss:0.0026357355165002668\n",
      "train loss:0.000980295796872267\n",
      "train loss:0.0019080874811919569\n",
      "train loss:0.004199495429582871\n",
      "train loss:0.0013592837701991306\n",
      "train loss:0.001716959671091163\n",
      "train loss:0.000881471426609498\n",
      "train loss:6.259434180336148e-06\n",
      "train loss:0.00014446630535745183\n",
      "train loss:0.00045869143434071243\n",
      "train loss:0.0006402551902005673\n",
      "train loss:0.0007806545175875156\n",
      "train loss:0.0020223021913752443\n",
      "train loss:0.0003419264270301639\n",
      "train loss:0.00015887575224685403\n",
      "train loss:0.000357105076506522\n",
      "train loss:0.0009520526540533926\n",
      "train loss:0.0006146995900685564\n",
      "train loss:0.004387269075420059\n",
      "train loss:0.0008856457556371229\n",
      "train loss:0.0004976145158971001\n",
      "train loss:0.011979259968858196\n",
      "train loss:0.00020252335365324186\n",
      "train loss:0.00018619691864082405\n",
      "train loss:0.0013603597736036757\n",
      "train loss:0.0011608756528954283\n",
      "train loss:4.0227700542198035e-05\n",
      "train loss:0.003293308661760064\n",
      "train loss:0.0006014422433262788\n",
      "train loss:0.0024762504894781934\n",
      "train loss:0.002480111698344892\n",
      "train loss:0.002331026946570291\n",
      "train loss:0.000507615018202926\n",
      "train loss:0.0008145297253567275\n",
      "train loss:0.0009399426160043092\n",
      "train loss:0.00021958645621314739\n",
      "train loss:0.00197681425701147\n",
      "train loss:0.0005820225205193486\n",
      "train loss:0.00022371680915349217\n",
      "train loss:4.823487969099601e-05\n",
      "train loss:0.009072666250279495\n",
      "train loss:0.059473706627496466\n",
      "train loss:0.004056937373903029\n",
      "train loss:0.002372526350703747\n",
      "train loss:0.0028449256124514783\n",
      "train loss:0.0034583670519132965\n",
      "train loss:0.00013159987088041567\n",
      "train loss:0.00045312418168545055\n",
      "train loss:0.000961849993156018\n",
      "train loss:0.00017542508283931635\n",
      "train loss:0.0026280663689594486\n",
      "train loss:0.0012966110048387037\n",
      "train loss:0.0006973525542700458\n",
      "train loss:0.0028093631969430288\n",
      "train loss:0.00026467601554608936\n",
      "train loss:0.008117045764239685\n",
      "train loss:0.0006861903296318791\n",
      "train loss:0.008369827611626756\n",
      "train loss:0.001510154002394296\n",
      "train loss:0.0019435106997691227\n",
      "train loss:0.0034032088749446267\n",
      "train loss:0.00014229206395250513\n",
      "train loss:0.0007149869665274079\n",
      "train loss:0.000221062948609446\n",
      "train loss:0.0009160693123977494\n",
      "train loss:0.0008966782651198749\n",
      "train loss:0.004067671462698899\n",
      "train loss:0.0005700230643092628\n",
      "train loss:0.00038820996571102285\n",
      "train loss:0.005705355221377056\n",
      "train loss:0.0030286470227287436\n",
      "train loss:0.000890516715128917\n",
      "train loss:7.212048413033564e-05\n",
      "train loss:0.005230054652300725\n",
      "train loss:0.0005593986163693021\n",
      "train loss:0.0022950226302753335\n",
      "train loss:0.00199795433218202\n",
      "train loss:0.00033268308210444066\n",
      "train loss:5.827606247265874e-05\n",
      "train loss:0.001189719453852295\n",
      "train loss:0.005975596902346583\n",
      "train loss:0.0005790664845202434\n",
      "train loss:0.0013073690262284505\n",
      "train loss:0.000496988767405872\n",
      "train loss:0.007233060158561657\n",
      "train loss:0.0009526132219659202\n",
      "train loss:0.0026045828074677587\n",
      "train loss:0.0076245368377812275\n",
      "train loss:0.0015841742678888257\n",
      "train loss:0.00027785830680955836\n",
      "train loss:0.0021350374506135944\n",
      "train loss:0.0023559681752010732\n",
      "train loss:0.0001672323304673387\n",
      "train loss:0.003867210878000623\n",
      "train loss:0.0006975659440749988\n",
      "train loss:0.0010428585677929997\n",
      "train loss:0.0015281269053572504\n",
      "train loss:0.002484481226903729\n",
      "train loss:0.0018246485532956366\n",
      "train loss:0.0009740794397714492\n",
      "train loss:0.0009427857818252251\n",
      "train loss:0.0003718872638777645\n",
      "train loss:0.00011216043461857858\n",
      "train loss:0.001134049936476437\n",
      "train loss:0.0002800048109262559\n",
      "train loss:0.00028113122571708885\n",
      "train loss:0.001411022841025557\n",
      "train loss:3.66408719494286e-05\n",
      "train loss:0.0024122869463239246\n",
      "train loss:0.0022942451208220094\n",
      "train loss:0.00034018748009095027\n",
      "train loss:0.0011506554816182097\n",
      "train loss:0.000392418391867051\n",
      "train loss:0.0021398718391887886\n",
      "train loss:0.00014148598754245914\n",
      "train loss:0.0028646873471211646\n",
      "train loss:0.00027960212247977355\n",
      "train loss:0.00048821775862954345\n",
      "train loss:0.001073084296848376\n",
      "train loss:0.00100617208484651\n",
      "train loss:0.005184069474271711\n",
      "train loss:0.0002154711531850632\n",
      "train loss:0.0008047219212999313\n",
      "train loss:0.00048736482813679845\n",
      "train loss:0.0021538018438565583\n",
      "train loss:6.957172699437892e-05\n",
      "train loss:0.0010747724554956526\n",
      "train loss:0.0011143449204405634\n",
      "train loss:0.0006803394769529148\n",
      "train loss:0.0013098853786160632\n",
      "train loss:0.0006378861712146204\n",
      "train loss:0.0006961372033323292\n",
      "train loss:6.581975790950344e-05\n",
      "train loss:0.00042964790756589084\n",
      "train loss:0.03067320880386013\n",
      "train loss:0.00031729884023071143\n",
      "train loss:0.004888520146429229\n",
      "train loss:0.0007302650551937815\n",
      "train loss:0.0013016574420348528\n",
      "train loss:0.00026640329647751313\n",
      "train loss:0.0009710920665002004\n",
      "train loss:0.0011926801639876507\n",
      "train loss:0.0055930092490008645\n",
      "train loss:0.022246771907082193\n",
      "train loss:0.001589222389572313\n",
      "train loss:0.0005643712829765299\n",
      "train loss:0.0029820998813910042\n",
      "train loss:0.0031035108282176246\n",
      "train loss:0.0013268271906199667\n",
      "train loss:0.0019137938716080537\n",
      "train loss:0.00013796495025337845\n",
      "train loss:0.0012261397341716863\n",
      "train loss:0.006525565706918454\n",
      "train loss:0.0016941750108864409\n",
      "train loss:7.607785571763114e-05\n",
      "train loss:0.0006752391043309629\n",
      "train loss:0.00376139432173402\n",
      "train loss:0.02627078890499961\n",
      "train loss:1.687102040892392e-05\n",
      "train loss:0.0020113808644681708\n",
      "train loss:0.000919807829031409\n",
      "train loss:0.006529668226768368\n",
      "train loss:0.0012323962551654105\n",
      "train loss:0.0007402418797797497\n",
      "train loss:0.0004795194626173501\n",
      "train loss:0.002558776589790991\n",
      "train loss:0.0007332076451127832\n",
      "train loss:0.0003001515182327953\n",
      "train loss:9.107367474608676e-05\n",
      "train loss:0.0012817419292086695\n",
      "train loss:0.005867031324396855\n",
      "train loss:0.00013013496323946682\n",
      "train loss:8.404720524972331e-05\n",
      "train loss:0.0010745380000566583\n",
      "train loss:9.253633184370911e-05\n",
      "train loss:0.0023178106017709282\n",
      "train loss:0.00047754754409643207\n",
      "train loss:0.001984259484233651\n",
      "train loss:0.004316854773274399\n",
      "train loss:0.0015342783460015439\n",
      "train loss:0.0003148906518515347\n",
      "train loss:0.0020003237062777225\n",
      "train loss:0.0013545411898879427\n",
      "train loss:0.0006160659518194784\n",
      "train loss:0.0003056752084249931\n",
      "train loss:0.00016578282941084318\n",
      "train loss:0.0007559040647160657\n",
      "train loss:0.007979433709377665\n",
      "train loss:0.002188641048387144\n",
      "train loss:0.0003866182866577311\n",
      "train loss:0.0011442052614276325\n",
      "train loss:0.0005125913317844024\n",
      "train loss:0.003474483405106735\n",
      "train loss:0.0015283098067275544\n",
      "train loss:0.00025725417556897635\n",
      "train loss:0.004773312207847371\n",
      "train loss:6.78382663266959e-05\n",
      "train loss:0.0009438472370666729\n",
      "train loss:0.0012172398153704504\n",
      "train loss:0.004227861646208971\n",
      "train loss:0.0011627830844375242\n",
      "train loss:2.0632720791903474e-05\n",
      "train loss:2.758085679513239e-05\n",
      "train loss:0.0002942412080732227\n",
      "train loss:0.015647781711977803\n",
      "train loss:0.0003373018938240782\n",
      "train loss:6.432439402243434e-05\n",
      "train loss:0.0008884891937050257\n",
      "train loss:0.0013635546896215267\n",
      "train loss:0.003042293718109605\n",
      "train loss:7.685628077876176e-05\n",
      "train loss:0.00019208728303255499\n",
      "train loss:0.0004932539377061336\n",
      "train loss:0.00013323672740277276\n",
      "train loss:0.0007552641598939919\n",
      "train loss:0.0005750276276388958\n",
      "train loss:0.00034242406748971816\n",
      "train loss:0.0005613393913533528\n",
      "train loss:0.00042765284011575137\n",
      "train loss:0.0005627712997142828\n",
      "train loss:0.00025684309302426937\n",
      "train loss:0.000877128592011684\n",
      "train loss:0.0003558612990596295\n",
      "train loss:0.0007261306800976557\n",
      "=== epoch:18, train acc:1.0, test acc:0.989 ===\n",
      "train loss:0.00040811091705294546\n",
      "train loss:0.0012940390974497274\n",
      "train loss:0.001814686386168045\n",
      "train loss:0.00135906030370343\n",
      "train loss:0.0001690657723417612\n",
      "train loss:0.0004894969166376468\n",
      "train loss:0.0008738070105189778\n",
      "train loss:0.0008394945800653664\n",
      "train loss:0.00019333438164126013\n",
      "train loss:0.0022970684271655835\n",
      "train loss:4.410256600745935e-05\n",
      "train loss:0.002544767969974792\n",
      "train loss:0.001612756746122746\n",
      "train loss:7.404595810852657e-05\n",
      "train loss:0.0016794353908158983\n",
      "train loss:0.00018380488297628606\n",
      "train loss:0.0031230555309595615\n",
      "train loss:0.00038896597822674273\n",
      "train loss:0.0006623635472736675\n",
      "train loss:0.0002168703905380768\n",
      "train loss:0.002735606428478929\n",
      "train loss:0.0008818532553495176\n",
      "train loss:0.00045208736461764445\n",
      "train loss:0.00027431492223329966\n",
      "train loss:0.0016446759102939502\n",
      "train loss:0.0002015910248908034\n",
      "train loss:0.0002958690942108025\n",
      "train loss:4.5145591876003926e-05\n",
      "train loss:0.0006707222957373132\n",
      "train loss:9.003706041130609e-05\n",
      "train loss:0.0015098537664517244\n",
      "train loss:0.0017892999719201217\n",
      "train loss:3.4633177229232184e-05\n",
      "train loss:8.86533288594684e-05\n",
      "train loss:0.001538939532239466\n",
      "train loss:0.0001645426029855841\n",
      "train loss:0.0008476130826234386\n",
      "train loss:0.002484701254007862\n",
      "train loss:0.00029023201306301033\n",
      "train loss:0.0005245995918495873\n",
      "train loss:0.001639825308747451\n",
      "train loss:0.001756150092671877\n",
      "train loss:0.00041606353198960736\n",
      "train loss:0.0009910412464706564\n",
      "train loss:0.002428001700603982\n",
      "train loss:0.0007645042867148855\n",
      "train loss:7.845519853437764e-05\n",
      "train loss:0.0007952342941991619\n",
      "train loss:0.0012382964403970893\n",
      "train loss:0.0004234126479550215\n",
      "train loss:0.00046663925326524463\n",
      "train loss:0.0002968146480101102\n",
      "train loss:0.003170058896489303\n",
      "train loss:5.014641421403022e-05\n",
      "train loss:0.0004361930127739252\n",
      "train loss:0.0002684491083495252\n",
      "train loss:0.0015228406576809918\n",
      "train loss:0.00011330559241354239\n",
      "train loss:0.0018818270448278927\n",
      "train loss:0.0005182838552392786\n",
      "train loss:0.0001574583645409781\n",
      "train loss:0.00021554396371489262\n",
      "train loss:0.00038689924125994633\n",
      "train loss:0.0007189017469083823\n",
      "train loss:0.00031438592074936573\n",
      "train loss:0.0019188457269674708\n",
      "train loss:0.00016944955668819027\n",
      "train loss:0.0014272308409978556\n",
      "train loss:0.006368718863744348\n",
      "train loss:0.0008830196744423484\n",
      "train loss:0.00017054778237481107\n",
      "train loss:0.0013365587965437275\n",
      "train loss:0.0015434807524071542\n",
      "train loss:0.003480138459459815\n",
      "train loss:0.00028449668727376093\n",
      "train loss:0.000562510849291153\n",
      "train loss:1.717662818699049e-05\n",
      "train loss:0.00014223487942683675\n",
      "train loss:8.639009407337899e-05\n",
      "train loss:0.004342567174892195\n",
      "train loss:0.0015437542903530546\n",
      "train loss:0.0005466961378378108\n",
      "train loss:0.0007326751229484576\n",
      "train loss:0.0012382441980199532\n",
      "train loss:0.0007916686319883258\n",
      "train loss:0.018606229177771463\n",
      "train loss:0.0017710022181157076\n",
      "train loss:0.0038102749342184645\n",
      "train loss:0.00012854068191334484\n",
      "train loss:0.0010728067769192652\n",
      "train loss:0.05655757382132453\n",
      "train loss:0.00010999654951842239\n",
      "train loss:0.0012209503171947058\n",
      "train loss:0.00019726106037163882\n",
      "train loss:0.0017256165275267108\n",
      "train loss:7.805099713605808e-05\n",
      "train loss:0.0001644702081962597\n",
      "train loss:0.0010157122108796208\n",
      "train loss:0.0002623119872926602\n",
      "train loss:0.008023351218548278\n",
      "train loss:0.0001900652062123575\n",
      "train loss:0.00018311775224067093\n",
      "train loss:0.002133047351050573\n",
      "train loss:0.003941964157464492\n",
      "train loss:0.0018590425016743086\n",
      "train loss:0.0025724710789728866\n",
      "train loss:0.0067421885224579915\n",
      "train loss:0.0018732061270456742\n",
      "train loss:0.001066031679005005\n",
      "train loss:0.00018040495351359244\n",
      "train loss:0.007582667120153522\n",
      "train loss:0.0023691045956508857\n",
      "train loss:0.0002217706820704036\n",
      "train loss:0.0014405369107654395\n",
      "train loss:0.0014159460382300163\n",
      "train loss:0.0050572657807927916\n",
      "train loss:0.0029046822508820673\n",
      "train loss:8.342899641576357e-05\n",
      "train loss:0.0020957531536606572\n",
      "train loss:0.0006813731256013091\n",
      "train loss:0.0007519744564806707\n",
      "train loss:0.0016696956091372345\n",
      "train loss:0.0024637232776337377\n",
      "train loss:0.0011153428425557585\n",
      "train loss:1.2384231484113303e-05\n",
      "train loss:0.0006944660857814679\n",
      "train loss:0.0015791169329205752\n",
      "train loss:0.0027868755848702562\n",
      "train loss:0.0032224663103739433\n",
      "train loss:0.0005026288736265274\n",
      "train loss:0.0007699021284364492\n",
      "train loss:0.0017500954517435058\n",
      "train loss:0.0005533896494796654\n",
      "train loss:0.0019800289655087437\n",
      "train loss:0.0002640760301563027\n",
      "train loss:0.001358886997553148\n",
      "train loss:0.0010435348438919767\n",
      "train loss:0.0006103902293452361\n",
      "train loss:0.0002566684051235472\n",
      "train loss:0.0006495819143794405\n",
      "train loss:0.0015103579884599549\n",
      "train loss:0.0014340450128745201\n",
      "train loss:0.010155716310437239\n",
      "train loss:0.0018047958727288765\n",
      "train loss:0.0019444119535958345\n",
      "train loss:0.0018199443143287178\n",
      "train loss:0.0014645543089842922\n",
      "train loss:0.0005661195106028021\n",
      "train loss:0.003148215369127334\n",
      "train loss:0.0003490799988614513\n",
      "train loss:0.00016467614228827407\n",
      "train loss:0.0014900110275097406\n",
      "train loss:0.00013363878974895546\n",
      "train loss:0.010039855770780877\n",
      "train loss:0.0019599066723602686\n",
      "train loss:0.0027068378380948666\n",
      "train loss:0.002490657110821304\n",
      "train loss:0.0005625065100278044\n",
      "train loss:0.001595725886523097\n",
      "train loss:0.0019666289399327915\n",
      "train loss:0.0024070699790362466\n",
      "train loss:0.00010022073746358972\n",
      "train loss:0.007058954476377726\n",
      "train loss:0.0004261772252963759\n",
      "train loss:0.0002744447633225121\n",
      "train loss:0.0056437900342374316\n",
      "train loss:0.00973033201399897\n",
      "train loss:0.0010847291401756313\n",
      "train loss:0.008339088560311925\n",
      "train loss:0.0001984104602688014\n",
      "train loss:0.0005631296096792306\n",
      "train loss:0.0010182315857240525\n",
      "train loss:0.029395195478258213\n",
      "train loss:0.0007484224329937998\n",
      "train loss:0.0011452428385231074\n",
      "train loss:0.005565104055120301\n",
      "train loss:0.0002478038681381907\n",
      "train loss:0.0011531973637389193\n",
      "train loss:0.00025579138571701703\n",
      "train loss:0.0022774840654490413\n",
      "train loss:0.0001799313163617081\n",
      "train loss:0.0018127486835678311\n",
      "train loss:0.001118222553333543\n",
      "train loss:0.00031045052892376035\n",
      "train loss:0.01859661570915184\n",
      "train loss:0.002320999960691619\n",
      "train loss:0.008515274796932896\n",
      "train loss:0.00149140234814204\n",
      "train loss:0.0033155282225513067\n",
      "train loss:0.0002007372963384566\n",
      "train loss:0.0003034920801616637\n",
      "train loss:0.002503926771502152\n",
      "train loss:0.0454666576151612\n",
      "train loss:0.000410967871256576\n",
      "train loss:0.0054510316054741\n",
      "train loss:0.000649568064073055\n",
      "train loss:0.00015092199543786453\n",
      "train loss:0.0010823974855772456\n",
      "train loss:0.0019386035267162905\n",
      "train loss:0.000785418045399586\n",
      "train loss:0.0015402802183681875\n",
      "train loss:0.0001356642445617566\n",
      "train loss:0.0008076706195344377\n",
      "train loss:0.001102159710835388\n",
      "train loss:0.00028798916579738444\n",
      "train loss:0.0023275557719463\n",
      "train loss:0.006494610240714791\n",
      "train loss:0.0036510471378061733\n",
      "train loss:0.0002290374123956459\n",
      "train loss:0.0008663212716246289\n",
      "train loss:0.00046433398622333324\n",
      "train loss:0.0007937577500199207\n",
      "train loss:7.652980384367894e-05\n",
      "train loss:0.0006511561077044794\n",
      "train loss:0.0002558661828166985\n",
      "train loss:0.0003379357337081904\n",
      "train loss:0.0012184150477284946\n",
      "train loss:4.467950823325812e-05\n",
      "train loss:0.00014344121444622227\n",
      "train loss:0.0006566484989475657\n",
      "train loss:0.00040478319294379243\n",
      "train loss:0.002863028289510492\n",
      "train loss:0.007936663381651781\n",
      "train loss:0.003887398701003615\n",
      "train loss:0.0008336423874771859\n",
      "train loss:0.0004163901339285806\n",
      "train loss:0.0018343319781813725\n",
      "train loss:0.0003319002586516165\n",
      "train loss:7.606233777767969e-05\n",
      "train loss:0.00013415576881431267\n",
      "train loss:0.0028887909745437474\n",
      "train loss:0.0007687118720131154\n",
      "train loss:0.0009647591763326089\n",
      "train loss:0.003292575828215579\n",
      "train loss:0.005450433380212315\n",
      "train loss:0.0014447510284224141\n",
      "train loss:4.413827144790898e-05\n",
      "train loss:0.0002428290501150174\n",
      "train loss:0.0026097180144495796\n",
      "train loss:0.035201877986435454\n",
      "train loss:0.0002045996280018874\n",
      "train loss:0.0012420108946067819\n",
      "train loss:0.0009062801257376556\n",
      "train loss:0.007179076761706396\n",
      "train loss:0.0029260081491234817\n",
      "train loss:0.0015603749865902995\n",
      "train loss:0.0009557553553454621\n",
      "train loss:0.0010049274335811598\n",
      "train loss:0.00011598723751955438\n",
      "train loss:0.0010672725396976442\n",
      "train loss:0.010820099225946038\n",
      "train loss:0.0044622048538202\n",
      "train loss:0.0012785332709480532\n",
      "train loss:0.003615057098081491\n",
      "train loss:0.002578870402481969\n",
      "train loss:0.0008007744918082421\n",
      "train loss:0.009982783517960675\n",
      "train loss:0.0007380717617188956\n",
      "train loss:0.0007709295910011941\n",
      "train loss:0.0038736793464710247\n",
      "train loss:0.000508332838597777\n",
      "train loss:0.0028645579907455943\n",
      "train loss:0.0012171258546809418\n",
      "train loss:0.004011107081169448\n",
      "train loss:0.0023892645266439328\n",
      "train loss:0.010176505592312668\n",
      "train loss:0.004511881558462273\n",
      "train loss:0.002476486727186884\n",
      "train loss:0.00024706542816093236\n",
      "train loss:0.0029781718987374984\n",
      "train loss:0.0010460310880142964\n",
      "train loss:0.0009502481811183011\n",
      "train loss:0.0003364602374374968\n",
      "train loss:0.002164011539867385\n",
      "train loss:0.0016876673274771503\n",
      "train loss:0.005354360297278466\n",
      "train loss:0.005807682652108063\n",
      "train loss:0.003674363813377195\n",
      "train loss:0.00042172978250103443\n",
      "train loss:0.001529540708347634\n",
      "train loss:0.006304747338833397\n",
      "train loss:0.00011632768610409572\n",
      "train loss:0.0002312039863133834\n",
      "train loss:0.0011201707653332375\n",
      "train loss:0.0010528606981343282\n",
      "train loss:0.006171467330472886\n",
      "train loss:0.0005352036302906611\n",
      "train loss:0.004542266114361298\n",
      "train loss:0.0008006900945780938\n",
      "train loss:0.005566318233415985\n",
      "train loss:0.0007319946256668647\n",
      "train loss:0.0002456887584592483\n",
      "train loss:0.00250647023332872\n",
      "train loss:0.0014582056907336985\n",
      "train loss:0.0015734324526122054\n",
      "train loss:0.0028919618551842717\n",
      "train loss:0.0030070546258986696\n",
      "train loss:0.003964969480467729\n",
      "train loss:0.004129313486014346\n",
      "train loss:0.00021712956631880724\n",
      "train loss:0.0018566245354312064\n",
      "train loss:0.0021560836923496538\n",
      "train loss:0.004240179924124793\n",
      "train loss:0.0006987654647746929\n",
      "train loss:6.0325363514367136e-05\n",
      "train loss:0.00014650988664996573\n",
      "train loss:0.001029662876167087\n",
      "train loss:0.002210002756700628\n",
      "train loss:0.005420807946212394\n",
      "train loss:1.9093793366199585e-05\n",
      "train loss:0.0040915828912836075\n",
      "train loss:0.0028544685399348115\n",
      "train loss:0.002511035364818385\n",
      "train loss:0.017744089313165137\n",
      "train loss:0.004040521390036754\n",
      "train loss:0.001509364776539889\n",
      "train loss:0.0016307333018592482\n",
      "train loss:0.00032675038932439824\n",
      "train loss:0.0015062702175732221\n",
      "train loss:0.004488620796012099\n",
      "train loss:0.0008019652888913491\n",
      "train loss:0.00026460901933771563\n",
      "train loss:0.0018039548588247981\n",
      "train loss:0.0005622306465756916\n",
      "train loss:0.0005434956520512367\n",
      "train loss:0.0022495866766778587\n",
      "train loss:0.002584324974498043\n",
      "train loss:0.004313661983852832\n",
      "train loss:0.0007878210782346782\n",
      "train loss:0.0022422167239006447\n",
      "train loss:0.003076011993950297\n",
      "train loss:0.0013057167151078292\n",
      "train loss:0.0005785039399541452\n",
      "train loss:2.5243719842215395e-05\n",
      "train loss:0.0014296133404728096\n",
      "train loss:0.0003865366275999622\n",
      "train loss:0.0009285570238886778\n",
      "train loss:0.005851479998389086\n",
      "train loss:0.024590172204552202\n",
      "train loss:0.0015488655405526696\n",
      "train loss:0.00390277243350938\n",
      "train loss:0.002596146158348077\n",
      "train loss:0.001482549189114856\n",
      "train loss:0.0015555704773095543\n",
      "train loss:0.00288050643346125\n",
      "train loss:0.005265618768410973\n",
      "train loss:0.003933520242170632\n",
      "train loss:0.0004334599772350055\n",
      "train loss:0.001772424214589073\n",
      "train loss:0.0028455840539179846\n",
      "train loss:0.001497407077099775\n",
      "train loss:0.0005516137118703457\n",
      "train loss:0.011986087844207216\n",
      "train loss:0.006694848123485244\n",
      "train loss:0.0009876502237344336\n",
      "train loss:0.003181768164456583\n",
      "train loss:0.0007445862978868299\n",
      "train loss:0.005033142353271558\n",
      "train loss:0.004885157203303262\n",
      "train loss:0.00024205061023807627\n",
      "train loss:0.00018746676678133326\n",
      "train loss:0.0015676298481504007\n",
      "train loss:0.004421684866275732\n",
      "train loss:0.0003974462071433981\n",
      "train loss:0.001483592615549094\n",
      "train loss:0.010970291786218181\n",
      "train loss:0.0010687074559200226\n",
      "train loss:0.003794939549627592\n",
      "train loss:0.00033747390678862745\n",
      "train loss:0.0006750951183979657\n",
      "train loss:0.0013713547204699406\n",
      "train loss:0.002294014268651835\n",
      "train loss:0.0025603641084365443\n",
      "train loss:0.004481835579245347\n",
      "train loss:0.006816949564648133\n",
      "train loss:0.002842139944034152\n",
      "train loss:0.0005774990118786984\n",
      "train loss:0.0021577932303653608\n",
      "train loss:0.003920096002140552\n",
      "train loss:0.014948733979116155\n",
      "train loss:0.0007085114159010466\n",
      "train loss:0.0012603719600331332\n",
      "train loss:0.0009071033865921065\n",
      "train loss:0.0001479288466215078\n",
      "train loss:0.0019196120291843346\n",
      "train loss:0.00011470435734452314\n",
      "train loss:0.013841010030299285\n",
      "train loss:0.00015974681110748654\n",
      "train loss:0.008241594758321924\n",
      "train loss:0.004387543096655942\n",
      "train loss:0.0009478859494454092\n",
      "train loss:0.0018632818893934663\n",
      "train loss:0.0012585081426966275\n",
      "train loss:0.0022320731529319863\n",
      "train loss:0.0005963835388440628\n",
      "train loss:9.820874758523985e-05\n",
      "train loss:0.023957239859364595\n",
      "train loss:0.0011039541812011796\n",
      "train loss:0.003347477945651289\n",
      "train loss:0.005681009016517943\n",
      "train loss:0.0019020878717254904\n",
      "train loss:0.00011310717864894783\n",
      "train loss:0.0026465184176337323\n",
      "train loss:0.0019259653733174687\n",
      "train loss:0.0028795819133435397\n",
      "train loss:0.0029053306747358356\n",
      "train loss:0.001553297215419791\n",
      "train loss:0.005747117419661041\n",
      "train loss:0.0008174046460908131\n",
      "train loss:0.001200398675285798\n",
      "train loss:0.000634361325012702\n",
      "train loss:0.0002984688144517884\n",
      "train loss:0.0016226307876566985\n",
      "train loss:0.039642764269803295\n",
      "train loss:0.0008984726567363016\n",
      "train loss:0.0071326444289750235\n",
      "train loss:0.0006439519828538416\n",
      "train loss:0.0064318296791510444\n",
      "train loss:0.008713659516590574\n",
      "train loss:0.001557474835492223\n",
      "train loss:0.0027001769146805937\n",
      "train loss:0.002419890910531064\n",
      "train loss:0.0030336718147854886\n",
      "train loss:0.01254390661552582\n",
      "train loss:0.004341973540057966\n",
      "train loss:0.00045773575639042693\n",
      "train loss:0.00021653101310877075\n",
      "train loss:0.0006109210932772114\n",
      "train loss:0.0011318687495146759\n",
      "train loss:0.0008017011752552466\n",
      "train loss:0.0005931894591764828\n",
      "train loss:0.001053840040837284\n",
      "train loss:0.00047791285188211735\n",
      "train loss:8.328095660129625e-05\n",
      "train loss:0.0008454562508180695\n",
      "train loss:0.004565414689361701\n",
      "train loss:0.0028890692898557294\n",
      "train loss:0.001998244156540753\n",
      "train loss:0.00020751542007009283\n",
      "train loss:0.0006519759828087615\n",
      "train loss:0.0003161589119793375\n",
      "train loss:0.0005154373416770722\n",
      "train loss:0.0004895041779301957\n",
      "train loss:0.0006478460186988674\n",
      "train loss:0.0020778463738327247\n",
      "train loss:0.0007185511863020475\n",
      "train loss:0.000503794204896485\n",
      "train loss:0.0004943738659464544\n",
      "train loss:0.03563462383859139\n",
      "train loss:0.00014405517422703154\n",
      "train loss:0.0017127513831302424\n",
      "train loss:0.0022635847430444076\n",
      "train loss:0.004481547933134684\n",
      "train loss:0.00022682883874833683\n",
      "train loss:0.011318421310249606\n",
      "train loss:0.0015099211543889487\n",
      "train loss:0.0005828323312087724\n",
      "train loss:0.0009543143080853506\n",
      "train loss:0.004412837011566603\n",
      "train loss:0.0002874679476976889\n",
      "train loss:0.004559111331669971\n",
      "train loss:0.00391793655207742\n",
      "train loss:0.0015704342631129554\n",
      "train loss:0.0028736809701704145\n",
      "train loss:0.003862281876097792\n",
      "train loss:0.00012750595854448153\n",
      "train loss:0.0003048522394756543\n",
      "train loss:0.001616827174424488\n",
      "train loss:0.00031500461829198\n",
      "train loss:0.0020234191025008848\n",
      "train loss:0.004078971037004362\n",
      "train loss:0.0026323652130793144\n",
      "train loss:0.002897793556465227\n",
      "train loss:0.0010101158079083223\n",
      "train loss:0.004802540170888611\n",
      "train loss:0.0005444929631800705\n",
      "train loss:0.006833069230604823\n",
      "train loss:0.007189824163196098\n",
      "train loss:0.00024628891079583166\n",
      "train loss:0.004689720081242514\n",
      "train loss:0.0008743586578133225\n",
      "train loss:9.861588579034638e-05\n",
      "train loss:0.011567737743118495\n",
      "train loss:0.004505541033431174\n",
      "train loss:0.0017928995900663902\n",
      "train loss:0.0008741088917486967\n",
      "train loss:0.0020389225698257325\n",
      "train loss:0.00011597417718901499\n",
      "train loss:0.0003038618632972017\n",
      "train loss:0.0018637874293681589\n",
      "train loss:0.0007073769951029828\n",
      "train loss:0.00019142710336965738\n",
      "train loss:0.0006494489823357205\n",
      "train loss:0.0022738928163362065\n",
      "train loss:0.004300899966706692\n",
      "train loss:0.0003146812381056835\n",
      "train loss:0.0032618969508409605\n",
      "train loss:0.0008270282180274607\n",
      "train loss:0.0024280290421359106\n",
      "train loss:0.0004291500941016829\n",
      "train loss:0.0015633595062784676\n",
      "train loss:0.0016811631755926529\n",
      "train loss:0.0010284714318908176\n",
      "train loss:0.004746626107497163\n",
      "train loss:0.005515394354633202\n",
      "train loss:0.0012809561732359945\n",
      "train loss:0.01239393180206835\n",
      "train loss:0.0016330113863619747\n",
      "train loss:0.00023248511134779028\n",
      "train loss:0.00716857511551565\n",
      "train loss:0.0010697063989814288\n",
      "train loss:0.0016310647600117924\n",
      "train loss:8.67923503523378e-05\n",
      "train loss:0.0009012658552423172\n",
      "train loss:9.219796609604265e-05\n",
      "train loss:0.0018299824261051368\n",
      "train loss:0.000574121916587331\n",
      "train loss:0.0002847254444892198\n",
      "train loss:0.00034443398585533026\n",
      "train loss:0.0002270302761180432\n",
      "train loss:0.0023243483592494266\n",
      "train loss:5.153537008374117e-05\n",
      "train loss:0.0011058207677442573\n",
      "train loss:0.0005934491494585885\n",
      "train loss:0.0005065181133225552\n",
      "train loss:0.007387527278464134\n",
      "train loss:0.001747381962413969\n",
      "train loss:0.0009389538374291759\n",
      "train loss:0.0008575234981887906\n",
      "train loss:6.981837430727478e-05\n",
      "train loss:0.007217945346249393\n",
      "train loss:0.0029130799918620043\n",
      "train loss:0.0002307120360543398\n",
      "train loss:0.0025229714812080224\n",
      "train loss:0.0034980963964669474\n",
      "train loss:0.003743881362415125\n",
      "train loss:0.008918529623397509\n",
      "train loss:0.0025639202764670523\n",
      "train loss:0.00339192174898301\n",
      "train loss:0.0010952415681357009\n",
      "train loss:0.00034486516438990823\n",
      "train loss:0.0008897946940461164\n",
      "train loss:0.0004015314532958712\n",
      "train loss:0.0017043025859554688\n",
      "train loss:0.004196395972303295\n",
      "train loss:0.007265967844104224\n",
      "train loss:0.0032166158552540637\n",
      "train loss:0.002899100274249654\n",
      "train loss:0.0009712373647113054\n",
      "train loss:0.000876930688496719\n",
      "train loss:0.002225744740226549\n",
      "train loss:0.0009573109038856641\n",
      "train loss:0.00681343986620742\n",
      "train loss:0.0024886101476248243\n",
      "train loss:0.002169551325092496\n",
      "train loss:0.00027882704100437176\n",
      "train loss:0.002944551998464656\n",
      "train loss:0.0003610667710042083\n",
      "train loss:0.0013181266911657188\n",
      "train loss:0.0006207563605728872\n",
      "train loss:0.003095659762942067\n",
      "train loss:0.0003918542334899075\n",
      "train loss:0.0006799027268507469\n",
      "train loss:0.005655290839150476\n",
      "train loss:0.004429759553248636\n",
      "train loss:0.012483878405088918\n",
      "train loss:0.0011343740671508097\n",
      "train loss:0.0027896452412396683\n",
      "train loss:0.0012856809647021873\n",
      "train loss:0.0004777605161207696\n",
      "train loss:0.00060089283810539\n",
      "train loss:0.0016425049060628514\n",
      "train loss:0.005328245225018323\n",
      "train loss:0.0002501173062769283\n",
      "train loss:0.00919161378097601\n",
      "train loss:0.002090152316856238\n",
      "train loss:0.0005288774704680838\n",
      "train loss:0.0019376663514292277\n",
      "train loss:0.0009861551859720197\n",
      "train loss:0.002333003989963383\n",
      "train loss:0.002081905395414306\n",
      "train loss:0.002996373644810231\n",
      "train loss:0.0018923077853990522\n",
      "train loss:0.0001602870090352947\n",
      "train loss:0.00030513493748758727\n",
      "train loss:0.0022578853508193253\n",
      "train loss:0.0016241264302785416\n",
      "train loss:0.0017996747501376601\n",
      "train loss:0.0007065523294632159\n",
      "train loss:0.00040292342037356985\n",
      "train loss:0.00288459219357097\n",
      "train loss:0.0011319537860857575\n",
      "train loss:0.0006654930701980948\n",
      "train loss:0.00010633052613120072\n",
      "train loss:0.0033467055033381127\n",
      "train loss:0.0025557802173166518\n",
      "train loss:7.65748657968266e-05\n",
      "train loss:9.974791706929139e-05\n",
      "train loss:0.0053046867410928\n",
      "train loss:0.004345498133257999\n",
      "=== epoch:19, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.0014968677005813224\n",
      "train loss:0.001060824233449591\n",
      "train loss:0.0031349916390065926\n",
      "train loss:0.0008730524918637496\n",
      "train loss:0.0041158877541058085\n",
      "train loss:0.000409349434092363\n",
      "train loss:0.0037983799080824414\n",
      "train loss:4.168310348611525e-05\n",
      "train loss:0.0016487308652967491\n",
      "train loss:0.00033087897634132143\n",
      "train loss:6.981085116666623e-05\n",
      "train loss:0.002237278230243242\n",
      "train loss:0.0005056606224891967\n",
      "train loss:0.001191999297099213\n",
      "train loss:0.003059314396615976\n",
      "train loss:0.0002732752153413951\n",
      "train loss:0.00017764075526315853\n",
      "train loss:0.002532888602236026\n",
      "train loss:0.00041847462197978544\n",
      "train loss:0.011326849272869498\n",
      "train loss:0.0010142399697067083\n",
      "train loss:0.007540483302423077\n",
      "train loss:0.0017638988668248338\n",
      "train loss:0.00042072273598514083\n",
      "train loss:8.410374297376925e-05\n",
      "train loss:0.0012088861459569366\n",
      "train loss:0.004164457727160374\n",
      "train loss:0.00029707529676383025\n",
      "train loss:0.00029513951632975617\n",
      "train loss:0.000309368129495364\n",
      "train loss:0.0003782752924593659\n",
      "train loss:0.0007648918134270664\n",
      "train loss:0.0011509572361658791\n",
      "train loss:0.0018387517066578518\n",
      "train loss:0.0001845194160162448\n",
      "train loss:0.0028401979567348684\n",
      "train loss:0.0015387571676680834\n",
      "train loss:0.0018698008986540212\n",
      "train loss:0.0009925475350681442\n",
      "train loss:0.00023809250997274388\n",
      "train loss:0.014234518546361163\n",
      "train loss:0.0007279662688501198\n",
      "train loss:0.0006164766883779405\n",
      "train loss:0.0011105794118207001\n",
      "train loss:0.0005323927339356342\n",
      "train loss:0.001292231898070447\n",
      "train loss:0.0006293598523212885\n",
      "train loss:0.0001757633922087726\n",
      "train loss:0.011552340466039228\n",
      "train loss:0.0013058493124640115\n",
      "train loss:0.00045701215744021773\n",
      "train loss:0.0018618959289054856\n",
      "train loss:0.0019095988433826896\n",
      "train loss:0.002982709012400404\n",
      "train loss:0.0002423612162791794\n",
      "train loss:0.00018595483180889108\n",
      "train loss:0.005222533248803365\n",
      "train loss:0.0021319442149345235\n",
      "train loss:0.0012721274616920377\n",
      "train loss:0.008473064237846252\n",
      "train loss:0.00035051377402023023\n",
      "train loss:0.0013492720637087174\n",
      "train loss:0.011815735180189961\n",
      "train loss:0.0013337703545502956\n",
      "train loss:0.0003406460105081398\n",
      "train loss:0.0012724172376371154\n",
      "train loss:0.002145711704634835\n",
      "train loss:0.00018923411967815894\n",
      "train loss:0.0006064776300874372\n",
      "train loss:0.000776353557377676\n",
      "train loss:0.0002352455905691142\n",
      "train loss:5.571013630522739e-05\n",
      "train loss:0.0001845010918138805\n",
      "train loss:8.95457705854376e-05\n",
      "train loss:0.0010142559804201012\n",
      "train loss:0.0010866407844730124\n",
      "train loss:0.001521895565147797\n",
      "train loss:0.00015083004464911347\n",
      "train loss:0.0003827131195190954\n",
      "train loss:0.0007970880926045707\n",
      "train loss:0.0016726236192609676\n",
      "train loss:0.001138429360105171\n",
      "train loss:0.00034805205916071843\n",
      "train loss:0.0025139464975288944\n",
      "train loss:0.005548796254593218\n",
      "train loss:0.0001603493886358804\n",
      "train loss:0.0020452986146342\n",
      "train loss:0.0005913852039523639\n",
      "train loss:0.0035230322041662947\n",
      "train loss:0.0013699842265137894\n",
      "train loss:0.00028861219924222997\n",
      "train loss:0.0008940304922940721\n",
      "train loss:0.003680667935799389\n",
      "train loss:0.00030087091803937993\n",
      "train loss:6.136967118603836e-05\n",
      "train loss:0.0029502518839950296\n",
      "train loss:0.0004955543250154308\n",
      "train loss:0.00015213728326426686\n",
      "train loss:0.0007793539104130753\n",
      "train loss:0.001551836657493652\n",
      "train loss:2.2419664123084136e-05\n",
      "train loss:0.0020627906320586555\n",
      "train loss:0.00857535882897849\n",
      "train loss:0.00015308565771992403\n",
      "train loss:0.000381698611300317\n",
      "train loss:0.0022815768447603845\n",
      "train loss:0.0023327790013814172\n",
      "train loss:0.0018861509425507983\n",
      "train loss:4.0446644453781734e-05\n",
      "train loss:0.0023228975645165914\n",
      "train loss:0.03089735654214289\n",
      "train loss:0.00039436561604473783\n",
      "train loss:0.017821310765570815\n",
      "train loss:0.0014670427621470688\n",
      "train loss:0.001187005069926261\n",
      "train loss:0.0015861442796275757\n",
      "train loss:0.001642225815697288\n",
      "train loss:0.00022163900434820058\n",
      "train loss:0.0001524751576156207\n",
      "train loss:0.004260043765925577\n",
      "train loss:0.0019979786873656593\n",
      "train loss:0.00046282506819170086\n",
      "train loss:0.00040774035207640375\n",
      "train loss:0.0009089150016050205\n",
      "train loss:0.0018160800610992059\n",
      "train loss:0.0029213683864540096\n",
      "train loss:0.001691235294314264\n",
      "train loss:0.0013715952869303135\n",
      "train loss:0.009909209018779017\n",
      "train loss:0.002636482792010256\n",
      "train loss:0.0007305891254431864\n",
      "train loss:0.0004244399803529974\n",
      "train loss:0.001910725008427823\n",
      "train loss:0.002953955032796994\n",
      "train loss:0.0013926154935966879\n",
      "train loss:0.0030667155119200617\n",
      "train loss:0.0011137455311729235\n",
      "train loss:0.004828562826967403\n",
      "train loss:0.0006015287896002613\n",
      "train loss:0.0008180396554609336\n",
      "train loss:8.845991605912585e-05\n",
      "train loss:0.0007524136336572183\n",
      "train loss:0.0013397109351258466\n",
      "train loss:0.011288034376586977\n",
      "train loss:0.001186940713182943\n",
      "train loss:0.007980057396250573\n",
      "train loss:0.0009643991909755823\n",
      "train loss:0.0011300756931633769\n",
      "train loss:0.0001996882207647423\n",
      "train loss:0.00028785786913688045\n",
      "train loss:0.0005419621853032892\n",
      "train loss:6.430674014967448e-05\n",
      "train loss:0.01139339947794306\n",
      "train loss:0.004870230199253487\n",
      "train loss:0.002536312632803127\n",
      "train loss:0.00025890765769540276\n",
      "train loss:0.004334109178138839\n",
      "train loss:4.2744362870247e-05\n",
      "train loss:3.859185633273445e-05\n",
      "train loss:0.0002547580926785556\n",
      "train loss:0.0015241126110954026\n",
      "train loss:0.0018759967225744488\n",
      "train loss:0.001406304803854663\n",
      "train loss:0.003199445744172745\n",
      "train loss:0.004471327767302117\n",
      "train loss:0.00029163841181712705\n",
      "train loss:0.0003762191494738234\n",
      "train loss:6.57323584157608e-05\n",
      "train loss:0.003970671827480312\n",
      "train loss:0.00166196613478165\n",
      "train loss:0.0002392443827640234\n",
      "train loss:0.00022881290986037425\n",
      "train loss:0.00031670592584846514\n",
      "train loss:4.674676430396499e-05\n",
      "train loss:0.0004955170541191558\n",
      "train loss:0.0019910527794198625\n",
      "train loss:0.003654513415588895\n",
      "train loss:0.0015335651699521142\n",
      "train loss:0.0026448475073937512\n",
      "train loss:0.0009313488340686932\n",
      "train loss:0.002168879737075613\n",
      "train loss:0.0006860546858361981\n",
      "train loss:0.0006110769099736413\n",
      "train loss:2.0012984109080014e-05\n",
      "train loss:0.00019168462279206826\n",
      "train loss:0.0036353474258968665\n",
      "train loss:0.00038914407385622725\n",
      "train loss:0.004340985916862956\n",
      "train loss:0.00046661155994786604\n",
      "train loss:0.00099316937581164\n",
      "train loss:2.1894043421124736e-05\n",
      "train loss:0.0003613591627514422\n",
      "train loss:0.0008437859321834734\n",
      "train loss:0.004626974561337559\n",
      "train loss:6.77623058152533e-05\n",
      "train loss:0.00036551126315497134\n",
      "train loss:0.0005972399382208521\n",
      "train loss:0.0003653797385950085\n",
      "train loss:0.001697709889246462\n",
      "train loss:0.0020981811041335717\n",
      "train loss:0.0037840437774648143\n",
      "train loss:0.0013228865870977388\n",
      "train loss:0.000806973650748647\n",
      "train loss:0.007164366576493806\n",
      "train loss:0.0006253520122216061\n",
      "train loss:0.000693007530709003\n",
      "train loss:0.0008242500588012689\n",
      "train loss:0.00015559249935239038\n",
      "train loss:0.00015090955905440811\n",
      "train loss:0.0016214634218016776\n",
      "train loss:0.0029140242697736685\n",
      "train loss:0.0017937812478820347\n",
      "train loss:0.0009438580623577484\n",
      "train loss:0.0003110105037057064\n",
      "train loss:0.00029289418808180087\n",
      "train loss:0.0007119774320143823\n",
      "train loss:4.6087147887847585e-05\n",
      "train loss:0.0017686188303290037\n",
      "train loss:0.00033940227005839783\n",
      "train loss:0.0011441987247484517\n",
      "train loss:0.0010730914222795975\n",
      "train loss:0.0016057036734247862\n",
      "train loss:0.0009972276583131996\n",
      "train loss:7.888481819430507e-05\n",
      "train loss:0.0005621145668155625\n",
      "train loss:0.0002600045538678954\n",
      "train loss:2.593010289031954e-05\n",
      "train loss:0.0007551685726284174\n",
      "train loss:0.0010457237261979671\n",
      "train loss:0.0001300769545916523\n",
      "train loss:0.00020530717143596422\n",
      "train loss:0.005342193993616053\n",
      "train loss:0.0030289768693418056\n",
      "train loss:0.0004725352029528073\n",
      "train loss:0.0006608002170611518\n",
      "train loss:8.117845835654193e-05\n",
      "train loss:0.003034587312019393\n",
      "train loss:9.643149643686899e-05\n",
      "train loss:0.0007297254401390315\n",
      "train loss:0.0007104682949889205\n",
      "train loss:0.0013008996435139367\n",
      "train loss:0.0009503403363539155\n",
      "train loss:0.002731665088869947\n",
      "train loss:0.0008018690788727577\n",
      "train loss:0.0004079366445402061\n",
      "train loss:0.0007698310669584692\n",
      "train loss:0.0012268855851979594\n",
      "train loss:0.0020473812247250515\n",
      "train loss:0.0022303123050981546\n",
      "train loss:0.0015386059568537392\n",
      "train loss:0.00016341695508988483\n",
      "train loss:0.005028254221732501\n",
      "train loss:0.004496353135302022\n",
      "train loss:0.0004106887657848827\n",
      "train loss:0.0009538506664097629\n",
      "train loss:0.0009227672721611984\n",
      "train loss:0.0006540389957738778\n",
      "train loss:4.7233522689553254e-05\n",
      "train loss:0.003110972988412532\n",
      "train loss:0.00010834741300767221\n",
      "train loss:6.542965207584688e-05\n",
      "train loss:9.014906458965709e-05\n",
      "train loss:0.00035508144920484567\n",
      "train loss:0.0023406273375280117\n",
      "train loss:0.0005597616683549027\n",
      "train loss:0.0015668705062128253\n",
      "train loss:0.0011059732058302178\n",
      "train loss:8.594614617471543e-05\n",
      "train loss:0.0007285332123956448\n",
      "train loss:0.003689305446982595\n",
      "train loss:0.00045883830636954474\n",
      "train loss:0.00020843770169571353\n",
      "train loss:0.0002445363132011518\n",
      "train loss:0.0005127469657501402\n",
      "train loss:0.0008787656394607632\n",
      "train loss:8.753553765966529e-05\n",
      "train loss:0.0008884321113388172\n",
      "train loss:0.0038311876836720294\n",
      "train loss:0.0008261255750117534\n",
      "train loss:0.0006772445511061499\n",
      "train loss:0.0033845618703168224\n",
      "train loss:0.00047539669980168475\n",
      "train loss:0.00020073367262265688\n",
      "train loss:0.00024186569012002045\n",
      "train loss:0.0017573551378840607\n",
      "train loss:0.0006792593935296042\n",
      "train loss:0.040010002821787835\n",
      "train loss:0.0011425643773323004\n",
      "train loss:0.0006891650228656286\n",
      "train loss:0.00011250651609076237\n",
      "train loss:0.0004036739777634376\n",
      "train loss:0.00420587313826379\n",
      "train loss:0.003701774360099604\n",
      "train loss:0.0015891325475907534\n",
      "train loss:0.0003506271673306947\n",
      "train loss:0.0001263905221039135\n",
      "train loss:0.0008384821695277509\n",
      "train loss:4.4259958505616814e-05\n",
      "train loss:0.0010821210481370591\n",
      "train loss:0.0005137735254887398\n",
      "train loss:0.00016459771216314627\n",
      "train loss:0.0001359480076485066\n",
      "train loss:0.0039596401322307805\n",
      "train loss:0.005581156899151679\n",
      "train loss:0.0008680944594331272\n",
      "train loss:0.005028578745676819\n",
      "train loss:0.0005464104004615996\n",
      "train loss:0.0006448809126796956\n",
      "train loss:0.00019686045399191587\n",
      "train loss:0.00229115989924436\n",
      "train loss:0.0006079651666235282\n",
      "train loss:0.0002083068973163878\n",
      "train loss:0.0022487002105913757\n",
      "train loss:0.002395003291639074\n",
      "train loss:0.00043648848471479083\n",
      "train loss:0.00029053245559172426\n",
      "train loss:0.0007843729154425174\n",
      "train loss:0.0001289896669130967\n",
      "train loss:0.0019806663354814268\n",
      "train loss:0.000623187084947924\n",
      "train loss:0.007375317729940434\n",
      "train loss:0.001546420128639989\n",
      "train loss:0.0009470884110616899\n",
      "train loss:0.0005057739256981995\n",
      "train loss:0.0006782789385238254\n",
      "train loss:0.001195042323247525\n",
      "train loss:0.0005684442296021479\n",
      "train loss:0.0003042240748367119\n",
      "train loss:8.106922704586321e-06\n",
      "train loss:2.225880119798142e-05\n",
      "train loss:0.0011280246258381231\n",
      "train loss:0.0023238416355859694\n",
      "train loss:0.00012955104662702602\n",
      "train loss:0.0001785036522017051\n",
      "train loss:0.0011241448342749016\n",
      "train loss:0.00014744232899979983\n",
      "train loss:0.0015532444611020236\n",
      "train loss:0.0006389174421282807\n",
      "train loss:2.5452526532446044e-05\n",
      "train loss:0.0028389941251051732\n",
      "train loss:0.0004610760953499509\n",
      "train loss:0.00016430824606047996\n",
      "train loss:0.000530744198622858\n",
      "train loss:0.00021866127460473323\n",
      "train loss:0.0012401082639116876\n",
      "train loss:0.0044636832816342285\n",
      "train loss:0.0025381039430230432\n",
      "train loss:0.0005657320362960817\n",
      "train loss:0.00014950017276008418\n",
      "train loss:0.0018668788378531276\n",
      "train loss:0.00021112136731145717\n",
      "train loss:0.0008842267981708847\n",
      "train loss:0.014118268794150688\n",
      "train loss:0.000435477369333286\n",
      "train loss:8.591066755983553e-05\n",
      "train loss:0.0021715142250098123\n",
      "train loss:0.0006489226764261826\n",
      "train loss:0.022912818734743573\n",
      "train loss:0.0015260700664828596\n",
      "train loss:0.0011396243800331264\n",
      "train loss:0.00033257052823437017\n",
      "train loss:0.0012098006147573121\n",
      "train loss:0.0017111428806159375\n",
      "train loss:0.0017078590897187888\n",
      "train loss:0.0006366349922829331\n",
      "train loss:0.0021634978449566146\n",
      "train loss:0.0009553503474786905\n",
      "train loss:0.001396451697927937\n",
      "train loss:0.0008448776865526657\n",
      "train loss:0.00016520727257862306\n",
      "train loss:0.00028914856229810367\n",
      "train loss:0.0019946066741447924\n",
      "train loss:0.0002768143513746124\n",
      "train loss:0.0035449732034375124\n",
      "train loss:8.098215164464293e-05\n",
      "train loss:0.0025831562327249635\n",
      "train loss:0.001646090625243595\n",
      "train loss:0.00011757529113993808\n",
      "train loss:0.0010161128388711269\n",
      "train loss:0.0009084789402805699\n",
      "train loss:1.573297364281569e-05\n",
      "train loss:0.00010687709847445399\n",
      "train loss:2.8235009914035382e-05\n",
      "train loss:0.00012566427133694697\n",
      "train loss:0.009534468220618358\n",
      "train loss:0.0005331399743242911\n",
      "train loss:0.000675404598118421\n",
      "train loss:4.894491751050703e-05\n",
      "train loss:0.0003052250265936372\n",
      "train loss:0.0010520088231027605\n",
      "train loss:0.0011349329357405941\n",
      "train loss:0.0014330952521147261\n",
      "train loss:0.001623335961823685\n",
      "train loss:0.00014842503579681307\n",
      "train loss:0.000129279831427056\n",
      "train loss:0.0005154448051468745\n",
      "train loss:7.652855045987614e-05\n",
      "train loss:7.46557814854796e-05\n",
      "train loss:0.0008735269895065883\n",
      "train loss:0.00037603533107982554\n",
      "train loss:0.00026943996162148834\n",
      "train loss:0.0003780635178331807\n",
      "train loss:0.0006371650567211511\n",
      "train loss:0.00044366471032882123\n",
      "train loss:0.0025025163186172573\n",
      "train loss:0.007543169345050408\n",
      "train loss:0.00037178237466491994\n",
      "train loss:5.656996299459351e-05\n",
      "train loss:0.0008611780127942051\n",
      "train loss:0.0004540787478815498\n",
      "train loss:0.002232039792588985\n",
      "train loss:0.0007176175751504593\n",
      "train loss:0.0008516160714491681\n",
      "train loss:0.0003965852497842406\n",
      "train loss:0.0185892685819475\n",
      "train loss:0.003610177278990519\n",
      "train loss:1.2287038961663126e-05\n",
      "train loss:0.0005643557554518329\n",
      "train loss:0.0009725586060326888\n",
      "train loss:0.00188232382428448\n",
      "train loss:0.00022982617497769426\n",
      "train loss:0.0011285460057178915\n",
      "train loss:0.0005613864426216299\n",
      "train loss:0.0026754580837621516\n",
      "train loss:0.0003620266999023525\n",
      "train loss:0.00039968712857127025\n",
      "train loss:5.356190780597421e-05\n",
      "train loss:0.000472264645193763\n",
      "train loss:6.232770803446427e-05\n",
      "train loss:0.00016608006301617326\n",
      "train loss:0.0028135837123082898\n",
      "train loss:0.0013980446159874251\n",
      "train loss:0.0003128752597606993\n",
      "train loss:3.064050941365602e-05\n",
      "train loss:0.0004360859810474769\n",
      "train loss:0.0005424909449937646\n",
      "train loss:0.00018058219371133832\n",
      "train loss:0.0027237067114602963\n",
      "train loss:0.0001304904159037558\n",
      "train loss:8.782905774610174e-05\n",
      "train loss:0.00021293924620595806\n",
      "train loss:0.0017247303900437443\n",
      "train loss:0.00012897221997747746\n",
      "train loss:7.176732252152947e-05\n",
      "train loss:0.0005793759601581381\n",
      "train loss:1.6900827075292565e-05\n",
      "train loss:0.00046382470773222737\n",
      "train loss:0.0017818021565918513\n",
      "train loss:0.00042351370900457004\n",
      "train loss:0.0011597590288164362\n",
      "train loss:0.00147055092794931\n",
      "train loss:0.00019935940135668348\n",
      "train loss:5.7427385347991056e-05\n",
      "train loss:0.00028662224955388374\n",
      "train loss:0.0010401409481182154\n",
      "train loss:0.0001695440438967122\n",
      "train loss:0.0008179376362115409\n",
      "train loss:4.915108833218136e-05\n",
      "train loss:0.0009544616289340899\n",
      "train loss:0.00045772717939954335\n",
      "train loss:0.0012837138167982988\n",
      "train loss:3.0152045943939353e-05\n",
      "train loss:0.000901658769656986\n",
      "train loss:0.002404326413468208\n",
      "train loss:0.0004134620627861806\n",
      "train loss:0.0006403920813335006\n",
      "train loss:0.0006543500201295246\n",
      "train loss:7.258931223822904e-05\n",
      "train loss:0.00010080706855246407\n",
      "train loss:0.0005476878233279018\n",
      "train loss:0.0003166870482089832\n",
      "train loss:0.00010553648352155395\n",
      "train loss:7.401757971576426e-05\n",
      "train loss:0.0036232801475264416\n",
      "train loss:0.0013144264417802233\n",
      "train loss:0.0005893427623491425\n",
      "train loss:3.8762081325392295e-05\n",
      "train loss:3.833342338645189e-05\n",
      "train loss:8.232852748804835e-05\n",
      "train loss:0.00011061205470720417\n",
      "train loss:0.001787241957525193\n",
      "train loss:0.0010797704506377184\n",
      "train loss:0.0005005526338282444\n",
      "train loss:0.00024532630516953664\n",
      "train loss:0.002254446815842882\n",
      "train loss:0.0010568021618981242\n",
      "train loss:0.001134071823637949\n",
      "train loss:0.002311570689330729\n",
      "train loss:0.0008767498131473728\n",
      "train loss:5.907115647450234e-05\n",
      "train loss:0.00027550823902046514\n",
      "train loss:0.0010830014163305964\n",
      "train loss:0.000542817423309783\n",
      "train loss:0.0016488830858430907\n",
      "train loss:0.0016512688782637321\n",
      "train loss:0.0022387782402838816\n",
      "train loss:3.1135780654077595e-05\n",
      "train loss:0.0009358503091468372\n",
      "train loss:0.0024559325963278266\n",
      "train loss:0.00022219695779330032\n",
      "train loss:0.0004245120724166853\n",
      "train loss:0.0004921094668777563\n",
      "train loss:0.00014530680136205315\n",
      "train loss:0.00038356226637760774\n",
      "train loss:0.001178379532156072\n",
      "train loss:0.0005315366826266924\n",
      "train loss:2.5147804156023927e-05\n",
      "train loss:0.0003860407717807481\n",
      "train loss:0.0005433841778557896\n",
      "train loss:0.00045200093674151843\n",
      "train loss:2.0158449506200287e-05\n",
      "train loss:0.0008518219112916668\n",
      "train loss:0.0015445188026691214\n",
      "train loss:0.001356659371389165\n",
      "train loss:0.00041579918079125036\n",
      "train loss:0.0008334217899245666\n",
      "train loss:0.0022549951515175954\n",
      "train loss:0.0009435317013542241\n",
      "train loss:0.001504393513378435\n",
      "train loss:0.0022789614429291516\n",
      "train loss:0.00015440993420395084\n",
      "train loss:8.989817233201162e-05\n",
      "train loss:0.002974772629601746\n",
      "train loss:0.0005829775975022249\n",
      "train loss:7.58762193084759e-05\n",
      "train loss:0.000375543503972337\n",
      "train loss:0.00013854468362173712\n",
      "train loss:0.0002022638090409574\n",
      "train loss:0.0017199885957777119\n",
      "train loss:0.0032523875097171377\n",
      "train loss:0.00010803895204847922\n",
      "train loss:0.00015676089472973137\n",
      "train loss:0.00046733729898480384\n",
      "train loss:0.00033327458485746535\n",
      "train loss:4.9757707801416204e-05\n",
      "train loss:0.0003195722998530544\n",
      "train loss:0.00022768861305177407\n",
      "train loss:0.0009948050611872832\n",
      "train loss:0.00015115375627527562\n",
      "train loss:0.00801285655307734\n",
      "train loss:0.00020337366065293751\n",
      "train loss:0.002482722061203468\n",
      "train loss:3.604491032480467e-05\n",
      "train loss:0.0008752135169094645\n",
      "train loss:9.432432872745281e-05\n",
      "train loss:0.00010150987735460862\n",
      "train loss:2.4331678741786748e-05\n",
      "train loss:5.658645390525486e-05\n",
      "train loss:0.00010709711085050433\n",
      "train loss:0.0010530960612538446\n",
      "train loss:9.981124663408135e-06\n",
      "train loss:0.0008385712220177206\n",
      "train loss:2.1571336305469662e-05\n",
      "train loss:0.0014122982280363656\n",
      "train loss:0.004295309412830298\n",
      "train loss:9.926645122848308e-05\n",
      "train loss:0.00010226259342421549\n",
      "train loss:0.0008814736623997398\n",
      "train loss:0.0006259174025961733\n",
      "train loss:0.0009629841018093318\n",
      "train loss:0.00011064566062626988\n",
      "train loss:0.0016267324305801944\n",
      "train loss:0.001471417812871155\n",
      "train loss:1.3904091698762276e-05\n",
      "train loss:0.00014946259556578777\n",
      "train loss:0.0001374981529442979\n",
      "train loss:0.0007717610966483478\n",
      "train loss:0.0014301200505542095\n",
      "train loss:0.0012786230566367604\n",
      "train loss:0.0009587862973332925\n",
      "train loss:0.027225289884414246\n",
      "train loss:0.0007359874952108519\n",
      "train loss:0.0028737306847109313\n",
      "train loss:0.0003531603556142305\n",
      "train loss:0.00029658012357173196\n",
      "train loss:0.0036671525683395355\n",
      "train loss:0.0009612378872451021\n",
      "train loss:0.008281590198656971\n",
      "train loss:0.0016045797147963888\n",
      "train loss:0.001860137142999071\n",
      "train loss:0.00017990582817192552\n",
      "train loss:0.0007708732051588841\n",
      "train loss:0.0030743064234280953\n",
      "train loss:0.009152953841479412\n",
      "train loss:0.00010756964954159687\n",
      "train loss:0.001161378775302754\n",
      "train loss:0.00023875804500234099\n",
      "train loss:0.00017015933154530173\n",
      "train loss:8.987014316184221e-05\n",
      "train loss:0.013812258357609672\n",
      "train loss:0.00033111428918994676\n",
      "train loss:0.0006969255177786419\n",
      "train loss:0.0004182129862593751\n",
      "train loss:0.0004569479410179323\n",
      "train loss:0.0007139213472627705\n",
      "train loss:0.0003803118876648582\n",
      "train loss:0.0002639494820591554\n",
      "train loss:0.002635181946251359\n",
      "train loss:0.003326787882224494\n",
      "train loss:0.00014033897965789945\n",
      "=== epoch:20, train acc:0.999, test acc:0.988 ===\n",
      "train loss:0.00023773209722268026\n",
      "train loss:0.001338898744625614\n",
      "train loss:0.0001006159362475538\n",
      "train loss:0.0007808758334010706\n",
      "train loss:0.0006040782462865134\n",
      "train loss:0.0003367211866974691\n",
      "train loss:0.0006408534309802394\n",
      "train loss:0.000812365793473473\n",
      "train loss:7.395639233666294e-05\n",
      "train loss:0.0001557144162212638\n",
      "train loss:0.0005564466413454895\n",
      "train loss:0.001038331986098532\n",
      "train loss:0.0003644870880287367\n",
      "train loss:0.0006670252515487992\n",
      "train loss:0.00020286378784273692\n",
      "train loss:0.002845768144092933\n",
      "train loss:9.57252329166157e-05\n",
      "train loss:0.0005998901083753884\n",
      "train loss:0.0008370277744898707\n",
      "train loss:0.0004999563489684711\n",
      "train loss:0.001066610566148916\n",
      "train loss:0.0006904548525074809\n",
      "train loss:0.00034887994341775447\n",
      "train loss:0.0015771635140742453\n",
      "train loss:0.002656927383002752\n",
      "train loss:0.00011499442872608721\n",
      "train loss:0.00017171642867130216\n",
      "train loss:0.0016305978475717525\n",
      "train loss:0.0005509415615636261\n",
      "train loss:5.4949545064735756e-05\n",
      "train loss:0.0009671708846078074\n",
      "train loss:0.0025412718945210704\n",
      "train loss:0.001614122926282885\n",
      "train loss:0.001374828661546442\n",
      "train loss:0.00025719187577933884\n",
      "train loss:0.00031274041562279783\n",
      "train loss:0.0016424632930707645\n",
      "train loss:0.00483942910113486\n",
      "train loss:0.003497781011607427\n",
      "train loss:0.00026098400953243785\n",
      "train loss:9.08968101081228e-05\n",
      "train loss:0.0008652342879169864\n",
      "train loss:0.0004881577280710756\n",
      "train loss:0.009266056258421392\n",
      "train loss:0.002425690386622521\n",
      "train loss:0.0004358639078141697\n",
      "train loss:0.00014085170619732178\n",
      "train loss:0.0015442234433436042\n",
      "train loss:0.001486821495443008\n",
      "train loss:0.0016773906585312276\n",
      "train loss:0.001991461176856929\n",
      "train loss:2.4592021903669194e-05\n",
      "train loss:0.00016980781696123635\n",
      "train loss:4.293030651411632e-05\n",
      "train loss:0.00017931714036110595\n",
      "train loss:0.0016626208365845213\n",
      "train loss:0.0007369506490832982\n",
      "train loss:0.0007804032578957257\n",
      "train loss:5.991259652608884e-05\n",
      "train loss:3.4285016491288594e-05\n",
      "train loss:0.0007496526869263438\n",
      "train loss:0.000886349922056811\n",
      "train loss:0.0006232861242939955\n",
      "train loss:0.0027149403996136103\n",
      "train loss:0.00014636676469091973\n",
      "train loss:0.0024655869713504936\n",
      "train loss:0.0020481001552087614\n",
      "train loss:0.0008235301204106452\n",
      "train loss:0.00029565328214840257\n",
      "train loss:9.311537470329434e-05\n",
      "train loss:0.0016576847825810683\n",
      "train loss:0.00021234921840141706\n",
      "train loss:0.0006133321334755516\n",
      "train loss:0.001457014009886157\n",
      "train loss:0.0005472589880563141\n",
      "train loss:0.0019534615175466567\n",
      "train loss:9.451955319359391e-05\n",
      "train loss:0.00038339270821062234\n",
      "train loss:0.00031147386950302627\n",
      "train loss:0.0002153592542929927\n",
      "train loss:0.00046759005004438177\n",
      "train loss:0.0002243657693370808\n",
      "train loss:0.0023552359993884732\n",
      "train loss:0.018366980992110545\n",
      "train loss:0.00031520916153643364\n",
      "train loss:0.0024658704272184583\n",
      "train loss:0.0007801317355470344\n",
      "train loss:0.00020617800288123917\n",
      "train loss:0.021238168269582997\n",
      "train loss:0.000246174869818\n",
      "train loss:0.0012415449794096626\n",
      "train loss:0.0003376698764681635\n",
      "train loss:0.00037975484570611706\n",
      "train loss:0.00031970436851869557\n",
      "train loss:0.03602656931864176\n",
      "train loss:0.0022538572923518686\n",
      "train loss:0.0009570129410092106\n",
      "train loss:0.00013020074055317642\n",
      "train loss:0.0016563269170862239\n",
      "train loss:0.0007975314168104094\n",
      "train loss:0.0008751388377019833\n",
      "train loss:0.000244530711554065\n",
      "train loss:0.0019897354639313333\n",
      "train loss:0.0006730850874621276\n",
      "train loss:0.0007612694911536598\n",
      "train loss:0.0009523042607926426\n",
      "train loss:0.002737908613816715\n",
      "train loss:0.0011631613748511324\n",
      "train loss:0.0006433816900543459\n",
      "train loss:0.000505134143528855\n",
      "train loss:6.56301218995567e-05\n",
      "train loss:0.0014399351798391074\n",
      "train loss:0.0007245968372343794\n",
      "train loss:0.007243413379010963\n",
      "train loss:0.00019323440996901406\n",
      "train loss:0.0005423108800784091\n",
      "train loss:0.0005299983148940751\n",
      "train loss:0.0002993728131947353\n",
      "train loss:0.0020508631078137197\n",
      "train loss:0.0007570309638621171\n",
      "train loss:0.002202538774927574\n",
      "train loss:8.129594453826179e-05\n",
      "train loss:4.4169977560518465e-05\n",
      "train loss:0.0023315068822705796\n",
      "train loss:3.949791906065056e-05\n",
      "train loss:0.0010564109698510224\n",
      "train loss:0.002960785536394026\n",
      "train loss:0.0004676415000029684\n",
      "train loss:0.00048512879432622874\n",
      "train loss:0.0005838609522402272\n",
      "train loss:0.0009610503420677544\n",
      "train loss:0.0004493354014815016\n",
      "train loss:0.0008684816537555573\n",
      "train loss:0.007208465561099376\n",
      "train loss:0.0005014824883752582\n",
      "train loss:0.0002592066766469866\n",
      "train loss:0.00020283794965176492\n",
      "train loss:0.002375741928025343\n",
      "train loss:0.0007515716540720283\n",
      "train loss:0.0005811623103110818\n",
      "train loss:0.0007952580873628775\n",
      "train loss:0.0011975497012681653\n",
      "train loss:6.93753361110338e-05\n",
      "train loss:0.0014093673456686412\n",
      "train loss:0.002539175957124492\n",
      "train loss:0.0009961670326684908\n",
      "train loss:0.014911483522108571\n",
      "train loss:0.0002828903292671441\n",
      "train loss:1.588994022735646e-05\n",
      "train loss:3.2653624754856444e-05\n",
      "train loss:0.001845666872221517\n",
      "train loss:5.058002251846929e-05\n",
      "train loss:0.0003414213290523734\n",
      "train loss:0.002219021562959455\n",
      "train loss:0.002680458253723918\n",
      "train loss:0.000707949087601416\n",
      "train loss:0.00030461574584748197\n",
      "train loss:0.003444700173627603\n",
      "train loss:0.003385953608362151\n",
      "train loss:0.003014636837691465\n",
      "train loss:0.00015033831437348183\n",
      "train loss:0.0017680515779651081\n",
      "train loss:0.004884081911491513\n",
      "train loss:0.0014720764599121586\n",
      "train loss:0.0008139751572022161\n",
      "train loss:0.00017168373143738332\n",
      "train loss:0.00052672873718156\n",
      "train loss:0.0006823646183754812\n",
      "train loss:0.00013015121862246216\n",
      "train loss:4.324128802331551e-05\n",
      "train loss:0.0010727523731528445\n",
      "train loss:0.0005677282539829992\n",
      "train loss:0.002642154893072939\n",
      "train loss:0.0009105569640970524\n",
      "train loss:0.010828206050224077\n",
      "train loss:0.0008018238099070959\n",
      "train loss:0.00013221590362714165\n",
      "train loss:0.00012161021137462158\n",
      "train loss:0.00043375619715821747\n",
      "train loss:4.9326253059569605e-05\n",
      "train loss:0.0023059714787530207\n",
      "train loss:0.0005826859405010288\n",
      "train loss:0.002905063772882851\n",
      "train loss:0.002842827550803697\n",
      "train loss:0.0002241710037121684\n",
      "train loss:0.0017839103966163965\n",
      "train loss:0.0029690359775045366\n",
      "train loss:0.0004917409027246411\n",
      "train loss:0.007862288012706147\n",
      "train loss:0.0005639702831662244\n",
      "train loss:0.0004872963363543772\n",
      "train loss:0.00039589926295712256\n",
      "train loss:0.0008338039345094485\n",
      "train loss:0.0002681104662251856\n",
      "train loss:0.00017524194505496736\n",
      "train loss:0.003206835271287414\n",
      "train loss:0.0017917972913235045\n",
      "train loss:9.657763464758416e-06\n",
      "train loss:0.0012723255791411276\n",
      "train loss:0.0012288821717861165\n",
      "train loss:0.0008002890698236852\n",
      "train loss:0.0006137968892080668\n",
      "train loss:0.003387391947756541\n",
      "train loss:0.00026230387767414037\n",
      "train loss:0.0012024908092454591\n",
      "train loss:0.0004721233528631892\n",
      "train loss:0.0027751953777958973\n",
      "train loss:0.0023842186806969103\n",
      "train loss:0.00023312754384321324\n",
      "train loss:0.0021552500333181014\n",
      "train loss:0.00023245773144116858\n",
      "train loss:0.0019594622911098584\n",
      "train loss:0.003251263767835981\n",
      "train loss:0.0014851723318780438\n",
      "train loss:0.000779725958065269\n",
      "train loss:0.0008048102782552225\n",
      "train loss:8.765338120863555e-05\n",
      "train loss:0.00031206975009808575\n",
      "train loss:0.00015811997725239237\n",
      "train loss:0.0006606852341012305\n",
      "train loss:0.0005616096788057806\n",
      "train loss:0.002471554596707056\n",
      "train loss:0.001837839963011111\n",
      "train loss:0.000181020100719257\n",
      "train loss:0.0007969147528881083\n",
      "train loss:0.0014429011773236917\n",
      "train loss:0.0022516335724446068\n",
      "train loss:5.898510644176159e-05\n",
      "train loss:0.002596465035430961\n",
      "train loss:0.0010031988634335697\n",
      "train loss:0.00197769374103533\n",
      "train loss:0.0020060693147277526\n",
      "train loss:6.180110499586136e-05\n",
      "train loss:6.633705844753617e-05\n",
      "train loss:0.0003704700564291346\n",
      "train loss:0.00020063715604113106\n",
      "train loss:0.003636696108406511\n",
      "train loss:0.0019203914487582107\n",
      "train loss:0.003480278400849636\n",
      "train loss:0.00011335887520484377\n",
      "train loss:0.0011835932976923661\n",
      "train loss:0.00011966507058776991\n",
      "train loss:0.0010271263701056074\n",
      "train loss:2.022352122842308e-05\n",
      "train loss:0.0008223143435436657\n",
      "train loss:0.0001592075431309669\n",
      "train loss:0.00028610736751811123\n",
      "train loss:0.004586997180097358\n",
      "train loss:0.0003598732486538337\n",
      "train loss:0.0016704328678408703\n",
      "train loss:0.0007330256486581685\n",
      "train loss:0.0005388315349538275\n",
      "train loss:0.003113607591944957\n",
      "train loss:0.0006959725388616326\n",
      "train loss:0.0001248887202862598\n",
      "train loss:0.002422923668220443\n",
      "train loss:0.0006014764955346309\n",
      "train loss:0.003112820439311144\n",
      "train loss:0.0006066908186751952\n",
      "train loss:0.002333301998455975\n",
      "train loss:0.004958217918009968\n",
      "train loss:0.00010257023378243901\n",
      "train loss:0.0008667984688888985\n",
      "train loss:0.0010751688130758409\n",
      "train loss:8.177173200524922e-05\n",
      "train loss:0.004862859329027329\n",
      "train loss:0.0010576433819734314\n",
      "train loss:0.0007188559881054216\n",
      "train loss:0.00011327006893105942\n",
      "train loss:0.0028142624930563532\n",
      "train loss:0.0017744781097016188\n",
      "train loss:0.00045557226147376376\n",
      "train loss:0.0008916093813937587\n",
      "train loss:0.0004659043759122998\n",
      "train loss:0.0005129183383639918\n",
      "train loss:0.002687067776729046\n",
      "train loss:0.0004653313490912449\n",
      "train loss:0.000423396778222987\n",
      "train loss:0.0018873641351644479\n",
      "train loss:0.0018984497055853815\n",
      "train loss:9.95222741288543e-05\n",
      "train loss:0.001959921782371071\n",
      "train loss:0.0017871534312975826\n",
      "train loss:8.96160440347995e-05\n",
      "train loss:0.0008156880239604654\n",
      "train loss:0.0005306650432000588\n",
      "train loss:0.0009307948200182768\n",
      "train loss:0.0017135302289386638\n",
      "train loss:6.749774962957152e-05\n",
      "train loss:0.00012015419005530049\n",
      "train loss:0.000539459471741891\n",
      "train loss:6.237068668191042e-05\n",
      "train loss:0.0018390771965420556\n",
      "train loss:0.000643370651808123\n",
      "train loss:0.0008406895382184912\n",
      "train loss:0.002017341066201235\n",
      "train loss:0.0009914174820188832\n",
      "train loss:0.001146686900402684\n",
      "train loss:0.001638416502101055\n",
      "train loss:0.0006297855384400118\n",
      "train loss:0.0002491439569460008\n",
      "train loss:0.0008722866046105435\n",
      "train loss:0.00012087763233220105\n",
      "train loss:0.0012944297359909333\n",
      "train loss:0.0009957541378227386\n",
      "train loss:0.0002955663723459776\n",
      "train loss:0.0038377260894273844\n",
      "train loss:0.0019695227321312836\n",
      "train loss:0.0028958964234242456\n",
      "train loss:3.026153475276508e-05\n",
      "train loss:0.0001963932631919511\n",
      "train loss:0.0005801717538894184\n",
      "train loss:0.00023917953172571772\n",
      "train loss:2.7018526272027677e-05\n",
      "train loss:0.0012572941743916343\n",
      "train loss:0.0008960161256777176\n",
      "train loss:0.0013927364997687137\n",
      "train loss:0.00029842486587244686\n",
      "train loss:1.5721905570248746e-05\n",
      "train loss:0.0019432125039115138\n",
      "train loss:0.0012113026808994406\n",
      "train loss:0.027637217248907088\n",
      "train loss:0.00016832309636590387\n",
      "train loss:0.0018838390364450503\n",
      "train loss:0.0001377182924653283\n",
      "train loss:3.374160206432952e-05\n",
      "train loss:0.0008897003283975303\n",
      "train loss:0.0002120082481433908\n",
      "train loss:0.00014026246515999415\n",
      "train loss:0.00019852140758204486\n",
      "train loss:0.00438267348777307\n",
      "train loss:0.001062874264184759\n",
      "train loss:0.0019240013531410926\n",
      "train loss:0.0008065687356689406\n",
      "train loss:0.0010785252677305902\n",
      "train loss:0.0008135527099702114\n",
      "train loss:0.0006969602936040422\n",
      "train loss:0.00411139063976262\n",
      "train loss:0.00042024063272355557\n",
      "train loss:0.002493048918953589\n",
      "train loss:0.001041805171730437\n",
      "train loss:0.002352487860131966\n",
      "train loss:9.312208169040609e-05\n",
      "train loss:0.0009939858440577935\n",
      "train loss:0.0008148288618633789\n",
      "train loss:0.0005248682615132433\n",
      "train loss:0.00159508953087247\n",
      "train loss:0.00021829750551104597\n",
      "train loss:0.002198775817589018\n",
      "train loss:0.0001662303719597087\n",
      "train loss:0.0001443465102796814\n",
      "train loss:0.0002991819741889117\n",
      "train loss:0.00013200247367511496\n",
      "train loss:0.0002702869612816192\n",
      "train loss:0.0008227811701110242\n",
      "train loss:0.003069843160768267\n",
      "train loss:0.0002992085289111287\n",
      "train loss:0.0005134512280745069\n",
      "train loss:0.00014965106191386124\n",
      "train loss:0.002496923621983091\n",
      "train loss:4.9344243785639605e-05\n",
      "train loss:0.00027216000144505336\n",
      "train loss:0.00014984237988421674\n",
      "train loss:0.0065305402349042155\n",
      "train loss:0.00016634614487410574\n",
      "train loss:0.00033257832624028326\n",
      "train loss:0.0006675615793162224\n",
      "train loss:0.0030841776299759417\n",
      "train loss:0.0003167610846415199\n",
      "train loss:0.0006944751090245527\n",
      "train loss:0.00041623361835470523\n",
      "train loss:0.0005080037724448538\n",
      "train loss:0.0005452967521470404\n",
      "train loss:0.0023002013336860814\n",
      "train loss:0.0006309236638320641\n",
      "train loss:6.38184856454815e-05\n",
      "train loss:0.00940210796725422\n",
      "train loss:0.0006135298640246316\n",
      "train loss:0.0005206940714258744\n",
      "train loss:1.0675166929548787e-05\n",
      "train loss:0.00015881361912180856\n",
      "train loss:0.002248795036644144\n",
      "train loss:0.001152164389513454\n",
      "train loss:0.0005753408639270015\n",
      "train loss:0.0015657118741452696\n",
      "train loss:0.0008657996624116687\n",
      "train loss:0.00023400637662261535\n",
      "train loss:5.572283928679696e-05\n",
      "train loss:4.731131388833809e-05\n",
      "train loss:0.002884075140002813\n",
      "train loss:0.001154367469714183\n",
      "train loss:0.0014486923312911862\n",
      "train loss:2.2239036536275282e-05\n",
      "train loss:0.00037197927407866627\n",
      "train loss:0.0005807171194790572\n",
      "train loss:0.002029529179953744\n",
      "train loss:0.0001631021294226857\n",
      "train loss:0.00038606458526309134\n",
      "train loss:0.0004917556266027614\n",
      "train loss:0.0002586633399285973\n",
      "train loss:0.007407829539446945\n",
      "train loss:0.0006420466309108852\n",
      "train loss:0.0012191164191172564\n",
      "train loss:0.0011678930309145159\n",
      "train loss:0.0003706506028822679\n",
      "train loss:0.011352629479750069\n",
      "train loss:0.0008670797111743621\n",
      "train loss:0.00031628503472086775\n",
      "train loss:2.2673018979152032e-05\n",
      "train loss:0.002263122948881707\n",
      "train loss:0.00023432718229079156\n",
      "train loss:0.0019258077474891256\n",
      "train loss:0.0009275036439644074\n",
      "train loss:0.00030947930740903804\n",
      "train loss:0.0001365378661363275\n",
      "train loss:0.003048747423280266\n",
      "train loss:0.0032704803743123655\n",
      "train loss:0.00224720650375016\n",
      "train loss:0.0016227312412793037\n",
      "train loss:0.002179124790349607\n",
      "train loss:0.003202178297770988\n",
      "train loss:0.002328504453255987\n",
      "train loss:0.0009108298668359971\n",
      "train loss:9.82822512565729e-05\n",
      "train loss:0.002151217412115892\n",
      "train loss:3.3698681775056544e-05\n",
      "train loss:2.82693033533213e-05\n",
      "train loss:0.0015228387562345029\n",
      "train loss:1.9626731563213475e-05\n",
      "train loss:0.003357723882682978\n",
      "train loss:0.0003752437417786495\n",
      "train loss:0.0013862175471292904\n",
      "train loss:0.0023014042438732943\n",
      "train loss:0.0009242024780728322\n",
      "train loss:0.001567914581586678\n",
      "train loss:7.1013025170294655e-06\n",
      "train loss:0.001463558315577972\n",
      "train loss:0.000163025007380135\n",
      "train loss:0.00048047790009051746\n",
      "train loss:0.0006815648869730773\n",
      "train loss:0.0005086141770022034\n",
      "train loss:0.0005152358547313092\n",
      "train loss:0.00046744817850441635\n",
      "train loss:0.00261760951533559\n",
      "train loss:0.004018735443353965\n",
      "train loss:0.001515215575875349\n",
      "train loss:0.0018656708808441824\n",
      "train loss:0.00037436714168878946\n",
      "train loss:0.00014997047628459385\n",
      "train loss:0.001624576968378317\n",
      "train loss:0.000467099339517236\n",
      "train loss:0.0024087709270366165\n",
      "train loss:0.0014154158067992484\n",
      "train loss:0.011716537419099672\n",
      "train loss:0.0009931665053164896\n",
      "train loss:0.00037327421549266044\n",
      "train loss:0.0018910374547509877\n",
      "train loss:0.0002668153060420835\n",
      "train loss:0.0053110632741833076\n",
      "train loss:0.002221938361839247\n",
      "train loss:0.004198332182399242\n",
      "train loss:0.0038594458720040688\n",
      "train loss:0.0015978983072176042\n",
      "train loss:0.0006333981615851046\n",
      "train loss:0.0012690142431468574\n",
      "train loss:0.003057504221300356\n",
      "train loss:5.86313945766127e-05\n",
      "train loss:0.0004949992817590429\n",
      "train loss:0.0011440956362102307\n",
      "train loss:0.0017699130837872537\n",
      "train loss:0.00034325780925633634\n",
      "train loss:0.0038046190444033924\n",
      "train loss:0.000359552685468527\n",
      "train loss:0.00266560822992846\n",
      "train loss:0.00015824934688710257\n",
      "train loss:0.0005378607668380375\n",
      "train loss:0.0013577563496475365\n",
      "train loss:0.001102380080495362\n",
      "train loss:0.0014454559884441679\n",
      "train loss:0.00014870109999020036\n",
      "train loss:0.00014443225408236482\n",
      "train loss:0.0009615743389899893\n",
      "train loss:0.00029189156392218045\n",
      "train loss:0.07918754999937411\n",
      "train loss:0.0012725502106033279\n",
      "train loss:0.05236392518112616\n",
      "train loss:0.0005494289749124286\n",
      "train loss:0.0006646961660443939\n",
      "train loss:0.0009437117736701917\n",
      "train loss:0.0009661085106625611\n",
      "train loss:0.00024181809500687282\n",
      "train loss:0.0014712035016334693\n",
      "train loss:0.0007907523462782613\n",
      "train loss:0.0016156792259287365\n",
      "train loss:7.345995558774537e-05\n",
      "train loss:0.0017663026151140673\n",
      "train loss:0.0011428665955048707\n",
      "train loss:0.0015571216677195269\n",
      "train loss:0.002790817334580365\n",
      "train loss:0.0001332568862627125\n",
      "train loss:0.00048070858644815674\n",
      "train loss:0.0019955459246022026\n",
      "train loss:0.002317994742773933\n",
      "train loss:0.002825664178756864\n",
      "train loss:0.0006517289940536078\n",
      "train loss:0.0009421144150353213\n",
      "train loss:0.002409899574083771\n",
      "train loss:0.0001755151595566813\n",
      "train loss:0.0006517109262851436\n",
      "train loss:0.0005306981355579086\n",
      "train loss:0.004493767893420928\n",
      "train loss:0.0017755503004975375\n",
      "train loss:0.00016800007538787212\n",
      "train loss:7.313527740647734e-05\n",
      "train loss:2.5424139464030818e-05\n",
      "train loss:0.0013885709332428326\n",
      "train loss:0.0003784852857593736\n",
      "train loss:0.003147234487259351\n",
      "train loss:0.0024623071156279147\n",
      "train loss:0.00027416617114464745\n",
      "train loss:0.0022042693791238005\n",
      "train loss:0.003584793625277418\n",
      "train loss:0.0006859425704580707\n",
      "train loss:1.3990003351244334e-05\n",
      "train loss:0.0027147255530737017\n",
      "train loss:0.0020205279663598856\n",
      "train loss:0.0001912138229205613\n",
      "train loss:7.256984791471978e-05\n",
      "train loss:0.0014094135517277646\n",
      "train loss:0.0019241408036417618\n",
      "train loss:0.0005833382662749164\n",
      "train loss:0.0012096277563023925\n",
      "train loss:0.0003440490506472288\n",
      "train loss:0.0030094313400697483\n",
      "train loss:0.0018720951821578795\n",
      "train loss:0.0008386816328583064\n",
      "train loss:0.0009392852714304392\n",
      "train loss:0.00012166793172368765\n",
      "train loss:4.513047399080511e-05\n",
      "train loss:0.00020806752561478234\n",
      "train loss:0.0012845115539509594\n",
      "train loss:0.0004274774670327797\n",
      "train loss:0.000786512238623584\n",
      "train loss:0.0014589826416576135\n",
      "train loss:0.002642805661860514\n",
      "train loss:0.0002249756841961312\n",
      "train loss:0.0001410843253647102\n",
      "train loss:0.0011444369633461502\n",
      "train loss:0.0035624633328904132\n",
      "train loss:0.0008778163754100459\n",
      "train loss:0.0006208367383228534\n",
      "train loss:9.277264352137993e-05\n",
      "train loss:0.0009000800309662785\n",
      "train loss:4.53916006755253e-05\n",
      "train loss:0.0033955444456541233\n",
      "train loss:0.0016475800578686487\n",
      "train loss:0.000818461684899749\n",
      "train loss:0.0033326138473287275\n",
      "train loss:0.0006523596631215681\n",
      "train loss:0.0012230422008442452\n",
      "train loss:0.000329712672081151\n",
      "train loss:4.0648086986388125e-05\n",
      "train loss:0.0025352982688646745\n",
      "train loss:3.6846581160051e-05\n",
      "train loss:0.00017338135817658674\n",
      "train loss:0.001114550794479614\n",
      "train loss:0.0037855276333839637\n",
      "train loss:6.38364018315658e-05\n",
      "train loss:0.0004119805456037953\n",
      "train loss:0.007327738827075527\n",
      "train loss:0.0011185856104592986\n",
      "train loss:0.0004148745840981832\n",
      "train loss:0.00012187796580142321\n",
      "train loss:8.851016227970616e-05\n",
      "train loss:0.001161412202748636\n",
      "train loss:0.0011163919581353187\n",
      "train loss:0.00022649176461879859\n",
      "train loss:0.001497689130141445\n",
      "train loss:0.0002532437512313305\n",
      "train loss:0.00019322335060126074\n",
      "train loss:0.000634790395772147\n",
      "train loss:0.003937903571273159\n",
      "train loss:0.0025244645547650877\n",
      "train loss:0.0004719275071830061\n",
      "train loss:0.0009597614752766817\n",
      "train loss:0.0005933543207514211\n",
      "train loss:0.0027856663946396352\n",
      "train loss:0.0004654746993332624\n",
      "train loss:0.0008303770629307173\n",
      "train loss:0.0014954606206006662\n",
      "train loss:0.010172401480250535\n",
      "train loss:0.001997507690812232\n",
      "train loss:0.00034224296467241647\n",
      "train loss:0.0009350815439088028\n",
      "train loss:0.0016812837975764593\n",
      "train loss:5.317582797714894e-05\n",
      "train loss:0.0005126771466482489\n",
      "train loss:2.969395176029487e-06\n",
      "train loss:0.005783995251750239\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9886\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ch07/train_convnet.py\n",
    "from src.dataset.mnist import load_mnist\n",
    "from src.common.layers import Relu, Affine, SoftmaxWithLoss\n",
    "from src.common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습에 대략 30분 정도 걸린듯..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 CNN 시각화 하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.1 1번째 층의 가중치 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "무작위(랜덤) 초기화 후의 가중치\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습된 가중치\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ch07/visualize_filter.py\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "print(\"무작위(랜덤) 초기화 후의 가중치\")\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "print(\"학습된 가중치\")\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

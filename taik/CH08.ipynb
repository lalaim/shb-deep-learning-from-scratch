{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| awesome_net.py | 빈 파일입니다. 여기에 여러분만의 멋진 신경망을 구현해보세요! |  |  |\n",
    "| deep_convnet.py | [그림 8-1]의 깊은 신경망을 구현한 소스입니다. | 8.1.1 더 깊은 신경망으로 | 262 |\n",
    "| deep_convnet_params.pkl | deep_convnet.py용 학습된 가중치입니다. |  |  |\n",
    "| half_float_network.py | 수치 정밀도를 반정밀도(16비트)로 낮춰 계산하여 배정밀도(64비트)일 때와 정확도를 비교해본다. | 8.3.4 연산 정밀도와 비트 줄이기 | 278 |\n",
    "| misclassified_mnist.py | 이번 장에서 구현한 신경망이 인식에 실패한 손글씨 이미지들을 화면에 보여줍니다. | 8.1.1 더 깊은 신경망으로 | 263 |\n",
    "| train_deepnet.py | deep_convnet.py의 신경망을 학습시킵니다. 몇 시간은 걸리기 때문에 다른 코드에서는 미리 학습된 가중치인 deep_convnet_params.pkl을 읽어서 사용합니다. | 8.1.1 더 깊은 신경망으로 | 262 |\n",
    "\n",
    "## 8장 딥러닝\n",
    "딥러닝은 층을 깊게 한 심층 신경망입니다. 심층 신경망은 지금까지 설명한 신경망을 바탕으로 뒷단에 층을 추가하기만 하면 만들 수 있지만, 커다란 문제가 몇 개 있습니다. 이번 장에서는 딥러닝의 특징과 과제, 그리고 가능성을 살펴봅니다. 또 오늘날의 첨단 딥러닝에 대한 설명도 준비했습니다.\n",
    "\n",
    "## 목차\n",
    "```\n",
    "8.1 더 깊게 \n",
    "__8.1.1 더 깊은 네트워크로 \n",
    "__8.1.2 정확도를 더 높이려면 \n",
    "__8.1.3 깊게 하는 이유 \n",
    "8.2 딥러닝의 초기 역사 \n",
    "__8.2.1 이미지넷 \n",
    "__8.2.2 VGG \n",
    "__8.2.3 GoogLeNet \n",
    "__8.2.4 ResNet \n",
    "8.3 더 빠르게(딥러닝 고속화) \n",
    "__8.3.1 풀어야 할 숙제 \n",
    "__8.3.2 GPU를 활용한 고속화 \n",
    "__8.3.3 분산 학습 \n",
    "__8.3.4 연산 정밀도와 비트 줄이기 \n",
    "8.4 딥러닝의 활용 \n",
    "__8.4.1 사물 검출 \n",
    "__8.4.2 분할 \n",
    "__8.4.3 사진 캡션 생성 \n",
    "8.5 딥러닝의 미래 \n",
    "__8.5.1 이미지 스타일(화풍) 변환 \n",
    "__8.5.2 이미지 생성 \n",
    "__8.5.3 자율 주행 \n",
    "__8.5.4 Deep Q-Network(강화학습) \n",
    "```\n",
    "\n",
    "## 이번 장에서 배운 내용\n",
    "* 수많은 문제에서 신경망을 더 깊게 하여 성능을 개선할 수 있다.\n",
    "* 이미지 인식 기술 대회인 ILSVRC에서는 최근 딥러닝 기반 기법이 상위권을 독점하고 있으며, 그 깊이도 더 깊어지는 추세다.\n",
    "* 유명한 신경망으로는 VGG, GoogLeNet, ResNet이 있다.\n",
    "* GPU와 분산 학습, 비트 정밀도 감소 등으로 딥러닝을 고속화할 수 있다.\n",
    "* 딥러닝(신경망)은 사물 인식뿐 아니라 사물 검출과 분할에도 이용할 수 있다.\n",
    "* 딥러닝의 응용 분야로는 사진의 캡션 생성, 이미지 생성, 강화학습 등이 있다. 최근에는 자율 주행에도 딥러닝을 접목하고 있어 기대된다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1.1 더 깊은 신경망으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# DeepConvNet 구현 (VGG 참조, ch08/deep_convnet.py)\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from src.common.layers import *\n",
    "\n",
    "\n",
    "class DeepConvNet:\n",
    "    \"\"\"정확도 99% 이상의 고정밀 합성곱 신경망\n",
    "\n",
    "    네트워크 구성은 아래와 같음\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        conv - relu - conv- relu - pool -\n",
    "        affine - relu - dropout - affine - dropout - softmax\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                 conv_param_1 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_2 = {'filter_num':16, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_3 = {'filter_num':32, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_4 = {'filter_num':32, 'filter_size':3, 'pad':2, 'stride':1},\n",
    "                 conv_param_5 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 conv_param_6 = {'filter_num':64, 'filter_size':3, 'pad':1, 'stride':1},\n",
    "                 hidden_size=50, output_size=10):\n",
    "        # 가중치 초기화===========\n",
    "        # 각 층의 뉴런 하나당 앞 층의 몇 개 뉴런과 연결되는가（TODO: 자동 계산되게 바꿀 것）\n",
    "        pre_node_nums = np.array([1*3*3, 16*3*3, 16*3*3, 32*3*3, 32*3*3, 64*3*3, 64*4*4, hidden_size])\n",
    "        wight_init_scales = np.sqrt(2.0 / pre_node_nums)  # ReLU를 사용할 때의 권장 초깃값\n",
    "        \n",
    "        self.params = {}\n",
    "        pre_channel_num = input_dim[0]\n",
    "        for idx, conv_param in enumerate([conv_param_1, conv_param_2, conv_param_3, conv_param_4, conv_param_5, conv_param_6]):\n",
    "            self.params['W' + str(idx+1)] = wight_init_scales[idx] * np.random.randn(conv_param['filter_num'], pre_channel_num, conv_param['filter_size'], conv_param['filter_size'])\n",
    "            self.params['b' + str(idx+1)] = np.zeros(conv_param['filter_num'])\n",
    "            pre_channel_num = conv_param['filter_num']\n",
    "        self.params['W7'] = wight_init_scales[6] * np.random.randn(64*4*4, hidden_size)\n",
    "        self.params['b7'] = np.zeros(hidden_size)\n",
    "        self.params['W8'] = wight_init_scales[7] * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b8'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성===========\n",
    "        self.layers = []\n",
    "        self.layers.append(Convolution(self.params['W1'], self.params['b1'], \n",
    "                           conv_param_1['stride'], conv_param_1['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W2'], self.params['b2'], \n",
    "                           conv_param_2['stride'], conv_param_2['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W3'], self.params['b3'], \n",
    "                           conv_param_3['stride'], conv_param_3['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W4'], self.params['b4'],\n",
    "                           conv_param_4['stride'], conv_param_4['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Convolution(self.params['W5'], self.params['b5'],\n",
    "                           conv_param_5['stride'], conv_param_5['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Convolution(self.params['W6'], self.params['b6'],\n",
    "                           conv_param_6['stride'], conv_param_6['pad']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Pooling(pool_h=2, pool_w=2, stride=2))\n",
    "        self.layers.append(Affine(self.params['W7'], self.params['b7']))\n",
    "        self.layers.append(Relu())\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        self.layers.append(Affine(self.params['W8'], self.params['b8']))\n",
    "        self.layers.append(Dropout(0.5))\n",
    "        \n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x, train_flg=False):\n",
    "        for layer in self.layers:\n",
    "            if isinstance(layer, Dropout):\n",
    "                x = layer.forward(x, train_flg)\n",
    "            else:\n",
    "                x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x, train_flg=True)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "\n",
    "        acc = 0.0\n",
    "\n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx, train_flg=False)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt)\n",
    "\n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        tmp_layers = self.layers.copy()\n",
    "        tmp_layers.reverse()\n",
    "        for layer in tmp_layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            grads['W' + str(i+1)] = self.layers[layer_idx].dW\n",
    "            grads['b' + str(i+1)] = self.layers[layer_idx].db\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, layer_idx in enumerate((0, 2, 5, 7, 10, 12, 15, 18)):\n",
    "            self.layers[layer_idx].W = self.params['W' + str(i+1)]\n",
    "            self.layers[layer_idx].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.3314808707485404\n",
      "=== epoch:1, train acc:0.11, test acc:0.102 ===\n",
      "train loss:2.344521185652562\n",
      "train loss:2.2693627718193254\n",
      "train loss:2.254760306836987\n",
      "train loss:2.2396952116504765\n",
      "train loss:2.245664412084892\n",
      "train loss:2.2227374101189667\n",
      "train loss:2.2092781028383195\n",
      "train loss:2.1998111373256837\n",
      "train loss:2.215444196456859\n",
      "train loss:2.225134399973095\n",
      "train loss:2.171001248811346\n",
      "train loss:2.1977629121081668\n",
      "train loss:2.190490860150535\n",
      "train loss:2.1302219111343565\n",
      "train loss:2.2021260251180217\n",
      "train loss:2.131239688115377\n",
      "train loss:2.1455318970928023\n",
      "train loss:2.1475339621210305\n",
      "train loss:2.0906275281492945\n",
      "train loss:2.0694555569077115\n",
      "train loss:2.0407175323092734\n",
      "train loss:2.0388371551560995\n",
      "train loss:2.0107981209713626\n",
      "train loss:1.9884837110612634\n",
      "train loss:1.951875098777368\n",
      "train loss:1.9529471029233607\n",
      "train loss:1.9555693305417026\n",
      "train loss:1.8413431600463346\n",
      "train loss:1.9597510705691246\n",
      "train loss:1.8087791612396849\n",
      "train loss:1.7995426644847259\n",
      "train loss:1.9636867802000222\n",
      "train loss:1.8344722181030573\n",
      "train loss:1.8848331440453159\n",
      "train loss:1.9110062396279617\n",
      "train loss:1.7290470561483429\n",
      "train loss:1.904863449546126\n",
      "train loss:1.8294133999010596\n",
      "train loss:1.77332876847629\n",
      "train loss:1.8036987548057135\n",
      "train loss:1.7582421260772376\n",
      "train loss:1.8023610604212863\n",
      "train loss:1.7231067932668307\n",
      "train loss:1.9477490662465882\n",
      "train loss:1.5990289463703835\n",
      "train loss:1.917666989050065\n",
      "train loss:1.7999968747934807\n",
      "train loss:1.7613375823471116\n",
      "train loss:1.7056952677446833\n",
      "train loss:1.8111149704149219\n",
      "train loss:1.7710244736194687\n",
      "train loss:1.744074376418157\n",
      "train loss:1.7261710635191887\n",
      "train loss:1.727653398096936\n",
      "train loss:1.7629961128344098\n",
      "train loss:1.786928943453911\n",
      "train loss:1.6479148420880663\n",
      "train loss:1.6485588011127543\n",
      "train loss:1.7666152425926065\n",
      "train loss:1.6522301035731801\n",
      "train loss:1.6948486894489294\n",
      "train loss:1.6119248594583655\n",
      "train loss:1.7003698991375273\n",
      "train loss:1.7716602324586344\n",
      "train loss:1.7120373552478088\n",
      "train loss:1.592236968375328\n",
      "train loss:1.5432590943388158\n",
      "train loss:1.8947463890618061\n",
      "train loss:1.5362667424755134\n",
      "train loss:1.691064520161289\n",
      "train loss:1.6509022612425905\n",
      "train loss:1.502690037472623\n",
      "train loss:1.6050958483177198\n",
      "train loss:1.5020592410368676\n",
      "train loss:1.665766226681106\n",
      "train loss:1.6157848863137858\n",
      "train loss:1.7695995919339436\n",
      "train loss:1.5112839709804298\n",
      "train loss:1.7098644195739852\n",
      "train loss:1.6522702284721078\n",
      "train loss:1.4931947095529736\n",
      "train loss:1.7594463519084107\n",
      "train loss:1.6514557509412489\n",
      "train loss:1.5486010206690253\n",
      "train loss:1.4795194160603635\n",
      "train loss:1.465881327690881\n",
      "train loss:1.6167305491434716\n",
      "train loss:1.5582583220088027\n",
      "train loss:1.4736717501969263\n",
      "train loss:1.3281775095027004\n",
      "train loss:1.4558816070805687\n",
      "train loss:1.5761184710548293\n",
      "train loss:1.4367898451599717\n",
      "train loss:1.3429771634834302\n",
      "train loss:1.4372011110621725\n",
      "train loss:1.6352777776012308\n",
      "train loss:1.4292365051058165\n",
      "train loss:1.5753693664966752\n",
      "train loss:1.4794104137288662\n",
      "train loss:1.5575212566417491\n",
      "train loss:1.3734305578315795\n",
      "train loss:1.2473006428770235\n",
      "train loss:1.5041914716538838\n",
      "train loss:1.3690813349279285\n",
      "train loss:1.4021556144995442\n",
      "train loss:1.3986706207137356\n",
      "train loss:1.3610130678901051\n",
      "train loss:1.3693283316172282\n",
      "train loss:1.5396893697978837\n",
      "train loss:1.4574469081446042\n",
      "train loss:1.4204858815061698\n",
      "train loss:1.4907517261343437\n",
      "train loss:1.5042202465380015\n",
      "train loss:1.4069795437908643\n",
      "train loss:1.475974434569285\n",
      "train loss:1.5073782172077341\n",
      "train loss:1.4879584512219808\n",
      "train loss:1.453531474782402\n",
      "train loss:1.4136240625486685\n",
      "train loss:1.4235410595304345\n",
      "train loss:1.4322660255182333\n",
      "train loss:1.6065291293116875\n",
      "train loss:1.5338160803692973\n",
      "train loss:1.4650885696916738\n",
      "train loss:1.2984277980412104\n",
      "train loss:1.4227961226626769\n",
      "train loss:1.37631763243682\n",
      "train loss:1.3038883921213908\n",
      "train loss:1.4859293573766976\n",
      "train loss:1.5194734859301493\n",
      "train loss:1.3991737214785112\n",
      "train loss:1.3761066047713022\n",
      "train loss:1.122957233342184\n",
      "train loss:1.3348710257517493\n",
      "train loss:1.4175307922324578\n",
      "train loss:1.4538426941659595\n",
      "train loss:1.237192579823342\n",
      "train loss:1.1580610999018672\n",
      "train loss:1.3724567779153387\n",
      "train loss:1.3703317562475041\n",
      "train loss:1.195183171436452\n",
      "train loss:1.3247979311211977\n",
      "train loss:1.3888099627196147\n",
      "train loss:1.3616966731858589\n",
      "train loss:1.2750504845387507\n",
      "train loss:1.645147482370484\n",
      "train loss:1.3440380848477431\n",
      "train loss:1.4076544190524907\n",
      "train loss:1.421413628231125\n",
      "train loss:1.4768338795163236\n",
      "train loss:1.34361203144952\n",
      "train loss:1.3439560490754079\n",
      "train loss:1.2864002295936263\n",
      "train loss:1.288146892254669\n",
      "train loss:1.413355175242463\n",
      "train loss:1.2377317430568744\n",
      "train loss:1.3183697378556989\n",
      "train loss:1.3571274355899843\n",
      "train loss:1.3898342924847318\n",
      "train loss:1.3556788717918937\n",
      "train loss:1.3275337647989094\n",
      "train loss:1.2944034543851166\n",
      "train loss:1.2149154771855626\n",
      "train loss:1.4598774692837322\n",
      "train loss:1.4971079310071949\n",
      "train loss:1.2742998976507556\n",
      "train loss:1.40526715009911\n",
      "train loss:1.3285780623590109\n",
      "train loss:1.3157877547635124\n",
      "train loss:1.2480070316116063\n",
      "train loss:1.4322495649067997\n",
      "train loss:1.1475062773692224\n",
      "train loss:1.4367695633724582\n",
      "train loss:1.2596107935581475\n",
      "train loss:1.3112418846843474\n",
      "train loss:1.3651631334474918\n",
      "train loss:1.177797671966447\n",
      "train loss:1.226959481547289\n",
      "train loss:1.287747919498772\n",
      "train loss:1.3479702832909441\n",
      "train loss:1.1561860308394452\n",
      "train loss:1.0386555144025496\n",
      "train loss:1.2868670103464384\n",
      "train loss:1.5388020921636365\n",
      "train loss:1.2998160483880468\n",
      "train loss:1.276876079218369\n",
      "train loss:1.1716211921129136\n",
      "train loss:1.1747918225712206\n",
      "train loss:1.1368749349857474\n",
      "train loss:1.266099633084922\n",
      "train loss:1.2904304651033842\n",
      "train loss:1.21088107740842\n",
      "train loss:1.1128113751052182\n",
      "train loss:1.1949245864951195\n",
      "train loss:1.3198664491904506\n",
      "train loss:1.5019883686597213\n",
      "train loss:1.3047956366013844\n",
      "train loss:1.1205954462981211\n",
      "train loss:1.368991080030589\n",
      "train loss:1.2237903431707524\n",
      "train loss:1.384796526216477\n",
      "train loss:1.3154580864290057\n",
      "train loss:1.426749616705689\n",
      "train loss:1.434089714814742\n",
      "train loss:1.3802392964972392\n",
      "train loss:1.275570178413996\n",
      "train loss:1.2993161912627513\n",
      "train loss:1.2552562857278193\n",
      "train loss:1.257878744250638\n",
      "train loss:1.167353636228469\n",
      "train loss:1.2520357722530182\n",
      "train loss:1.22196016071972\n",
      "train loss:0.9973112790311538\n",
      "train loss:1.3275897736551596\n",
      "train loss:1.427260709642801\n",
      "train loss:1.3093434745848667\n",
      "train loss:1.413236873571362\n",
      "train loss:1.3740151846954272\n",
      "train loss:1.3380107260838687\n",
      "train loss:1.4187482498884214\n",
      "train loss:1.1664869305842482\n",
      "train loss:1.2377152878915945\n",
      "train loss:1.3917645313501081\n",
      "train loss:1.3570109950121514\n",
      "train loss:1.3777331790262495\n",
      "train loss:1.2705265469253897\n",
      "train loss:1.2021052998928143\n",
      "train loss:1.136347733368753\n",
      "train loss:1.2088907235406336\n",
      "train loss:1.1907481687163526\n",
      "train loss:1.1787400701545054\n",
      "train loss:1.0352691116029873\n",
      "train loss:1.1396168291685782\n",
      "train loss:1.1207813243037095\n",
      "train loss:1.2586332950930303\n",
      "train loss:1.1371527850797483\n",
      "train loss:1.5071398984890256\n",
      "train loss:1.2240168538843053\n",
      "train loss:1.1099373586437888\n",
      "train loss:1.313351673346412\n",
      "train loss:1.3278640961244403\n",
      "train loss:1.241922064031455\n",
      "train loss:1.2745216226325329\n",
      "train loss:1.1991842734969698\n",
      "train loss:1.4564667755544713\n",
      "train loss:1.3829344522267872\n",
      "train loss:1.1838135033933355\n",
      "train loss:1.1308605790014707\n",
      "train loss:1.3536506664198433\n",
      "train loss:1.5055730486558432\n",
      "train loss:1.2669177108974612\n",
      "train loss:1.12686634961009\n",
      "train loss:1.0544772288691306\n",
      "train loss:1.0299762531831285\n",
      "train loss:1.1639706679756796\n",
      "train loss:1.2147835506499856\n",
      "train loss:1.1187563228568433\n",
      "train loss:1.4225038631313254\n",
      "train loss:0.9452677792547852\n",
      "train loss:1.308117671569629\n",
      "train loss:1.1944916235547793\n",
      "train loss:1.0670291285846274\n",
      "train loss:0.9614748515871118\n",
      "train loss:1.1379067888386316\n",
      "train loss:1.1859032086577173\n",
      "train loss:1.3707996397743358\n",
      "train loss:1.1418123751040223\n",
      "train loss:1.2616978969350034\n",
      "train loss:1.2597416750088366\n",
      "train loss:1.172195970492401\n",
      "train loss:1.4251623471724162\n",
      "train loss:1.208649105881805\n",
      "train loss:1.1339324698317896\n",
      "train loss:1.0074350206872138\n",
      "train loss:1.230022830685273\n",
      "train loss:1.3176982909292843\n",
      "train loss:1.1099077022865205\n",
      "train loss:1.188775513277172\n",
      "train loss:1.307748297445\n",
      "train loss:1.2885098739668235\n",
      "train loss:1.0778090882986782\n",
      "train loss:1.2146826899062053\n",
      "train loss:1.2842655543191435\n",
      "train loss:1.309054914721032\n",
      "train loss:1.0219362121716038\n",
      "train loss:1.0760922194190876\n",
      "train loss:1.1305166017023887\n",
      "train loss:1.228047606310747\n",
      "train loss:1.1428124667168225\n",
      "train loss:1.2635124724392512\n",
      "train loss:0.9022600205672721\n",
      "train loss:1.2929781365439057\n",
      "train loss:1.239189483359147\n",
      "train loss:1.1154748733745636\n",
      "train loss:1.1918844521487555\n",
      "train loss:1.0774343388283854\n",
      "train loss:1.2620890136640739\n",
      "train loss:1.0830602879654514\n",
      "train loss:1.198827022720732\n",
      "train loss:1.143102097752196\n",
      "train loss:1.0699026560112062\n",
      "train loss:1.179620983132277\n",
      "train loss:1.1582232216716497\n",
      "train loss:1.0671058372408877\n",
      "train loss:1.21017245488051\n",
      "train loss:1.1287465265477183\n",
      "train loss:1.176731169968379\n",
      "train loss:1.1519270547440836\n",
      "train loss:1.1506338870440664\n",
      "train loss:1.3177846936323596\n",
      "train loss:1.101586921606013\n",
      "train loss:1.1427548244339287\n",
      "train loss:1.0493001645577322\n",
      "train loss:1.1266396231275388\n",
      "train loss:1.0187841379422644\n",
      "train loss:1.182423785875125\n",
      "train loss:1.1324112368513746\n",
      "train loss:1.1569981588911904\n",
      "train loss:1.127500232145289\n",
      "train loss:1.203876569859854\n",
      "train loss:1.2421184091398931\n",
      "train loss:1.001453733621535\n",
      "train loss:1.3744430502554494\n",
      "train loss:1.2915425474932105\n",
      "train loss:1.1920128903701532\n",
      "train loss:1.1669663524965441\n",
      "train loss:0.9995409303882213\n",
      "train loss:1.254585796212954\n",
      "train loss:1.3775368132267973\n",
      "train loss:1.1023594505678322\n",
      "train loss:1.2133886240477219\n",
      "train loss:1.2579079262254276\n",
      "train loss:1.3353883198339234\n",
      "train loss:1.1534287790319808\n",
      "train loss:1.1222709110852391\n",
      "train loss:1.2269553569345826\n",
      "train loss:1.1385828041104944\n",
      "train loss:1.0959579594099162\n",
      "train loss:1.285701667589339\n",
      "train loss:1.0906929331775814\n",
      "train loss:1.2213266248659072\n",
      "train loss:1.0629847820709903\n",
      "train loss:1.185462442038921\n",
      "train loss:1.1212677492955492\n",
      "train loss:1.2657750605917564\n",
      "train loss:1.153513191589642\n",
      "train loss:1.237531417994205\n",
      "train loss:1.0117200806536162\n",
      "train loss:1.114483779392881\n",
      "train loss:1.2121437753426836\n",
      "train loss:1.232811855797259\n",
      "train loss:1.0917064859636578\n",
      "train loss:1.173751063757485\n",
      "train loss:1.1595107586767541\n",
      "train loss:1.0714398030930994\n",
      "train loss:1.1779730690229062\n",
      "train loss:1.1976533236296825\n",
      "train loss:1.2934098830338283\n",
      "train loss:1.0858336061049731\n",
      "train loss:1.1930138704578563\n",
      "train loss:1.0614825117475137\n",
      "train loss:1.2923136184074904\n",
      "train loss:1.2861225648222858\n",
      "train loss:1.2476656463328173\n",
      "train loss:1.2475622078169406\n",
      "train loss:1.2062404081507905\n",
      "train loss:1.043758007506242\n",
      "train loss:1.217171902282786\n",
      "train loss:1.1709985230759539\n",
      "train loss:1.2229909551667142\n",
      "train loss:1.1715644644387075\n",
      "train loss:1.1973608693717486\n",
      "train loss:1.4009678391253637\n",
      "train loss:1.0629108454096325\n",
      "train loss:1.2230417064371388\n",
      "train loss:1.122688191675021\n",
      "train loss:1.0616322725019869\n",
      "train loss:0.9806861859478101\n",
      "train loss:1.0549820573491955\n",
      "train loss:1.1556657764035332\n",
      "train loss:1.025532795035629\n",
      "train loss:1.1316341234971028\n",
      "train loss:1.2408950036096007\n",
      "train loss:1.1384389061697566\n",
      "train loss:1.111972225743348\n",
      "train loss:1.2326906645058489\n",
      "train loss:0.9022701541097358\n",
      "train loss:1.196193298539898\n",
      "train loss:1.0331891510271314\n",
      "train loss:1.2028972210488031\n",
      "train loss:0.9998801396798008\n",
      "train loss:1.1021811662263927\n",
      "train loss:0.9520031742493507\n",
      "train loss:0.9430915831936559\n",
      "train loss:1.0961097630352825\n",
      "train loss:1.2838135050884107\n",
      "train loss:1.0293480217901285\n",
      "train loss:1.190923718928114\n",
      "train loss:1.1134885534055396\n",
      "train loss:1.2122949061960169\n",
      "train loss:1.3989457932894158\n",
      "train loss:1.176339442144394\n",
      "train loss:1.1128639590683467\n",
      "train loss:1.0530488182039344\n",
      "train loss:1.1159686642267468\n",
      "train loss:1.1697624702762446\n",
      "train loss:0.9586020259926152\n",
      "train loss:1.0833992740880214\n",
      "train loss:1.0280213374670284\n",
      "train loss:1.0705437016538377\n",
      "train loss:1.2181069281732926\n",
      "train loss:1.0242259944650969\n",
      "train loss:1.027483473776024\n",
      "train loss:1.1647329360509142\n",
      "train loss:0.979795387821143\n",
      "train loss:1.0700867867220363\n",
      "train loss:1.0388110690062105\n",
      "train loss:1.0803605453841838\n",
      "train loss:1.10313162157166\n",
      "train loss:1.2179126068501753\n",
      "train loss:1.026758603916644\n",
      "train loss:1.0944634083547478\n",
      "train loss:1.0757547827257694\n",
      "train loss:1.1070605255856512\n",
      "train loss:1.2591811804600892\n",
      "train loss:1.1730566536793965\n",
      "train loss:1.1965239266603083\n",
      "train loss:1.205827731175604\n",
      "train loss:1.1344607089946355\n",
      "train loss:1.1910918102424886\n",
      "train loss:1.2192193652327452\n",
      "train loss:1.033478268881195\n",
      "train loss:1.1082144187040757\n",
      "train loss:1.1175016905347386\n",
      "train loss:1.0785295359128364\n",
      "train loss:0.9441002284755353\n",
      "train loss:1.113566642951162\n",
      "train loss:0.9566108596913108\n",
      "train loss:1.1984666765336838\n",
      "train loss:1.136521831268418\n",
      "train loss:1.1373382225916262\n",
      "train loss:1.206998483901536\n",
      "train loss:1.0712579012420311\n",
      "train loss:1.1011171997231266\n",
      "train loss:1.0523082595408557\n",
      "train loss:1.1157232968039077\n",
      "train loss:1.1205957809842095\n",
      "train loss:1.1507982094914595\n",
      "train loss:1.124079488686344\n",
      "train loss:1.1119006503238145\n",
      "train loss:0.93946164691302\n",
      "train loss:1.1331975562779413\n",
      "train loss:1.1077427770247534\n",
      "train loss:1.0491606614505569\n",
      "train loss:1.189369279894239\n",
      "train loss:0.8724030792161855\n",
      "train loss:1.0597333268392548\n",
      "train loss:1.0391077183471051\n",
      "train loss:1.163708692730615\n",
      "train loss:1.100302644633472\n",
      "train loss:1.1462537085973112\n",
      "train loss:1.0450703285431173\n",
      "train loss:1.1863896189482517\n",
      "train loss:1.264879644686156\n",
      "train loss:0.9133710073002057\n",
      "train loss:0.957591799201416\n",
      "train loss:1.2332543602257504\n",
      "train loss:1.2886603512499264\n",
      "train loss:1.1137381656368954\n",
      "train loss:1.1830856802882797\n",
      "train loss:0.9472852734767144\n",
      "train loss:1.355557974565326\n",
      "train loss:1.2879714972635445\n",
      "train loss:0.8594726573766834\n",
      "train loss:1.0736744124557496\n",
      "train loss:0.9362389075305664\n",
      "train loss:1.16934730116336\n",
      "train loss:0.9892508057947722\n",
      "train loss:1.1136999213987044\n",
      "train loss:1.2164574146627238\n",
      "train loss:1.0699174686901998\n",
      "train loss:0.9555351673559557\n",
      "train loss:0.9308152052428418\n",
      "train loss:1.003602661363531\n",
      "train loss:1.195926960511897\n",
      "train loss:1.1026320018772262\n",
      "train loss:1.04320780180303\n",
      "train loss:1.0457919727684315\n",
      "train loss:1.0204868813916073\n",
      "train loss:1.193444244587391\n",
      "train loss:0.9899422258368241\n",
      "train loss:1.1102261076250768\n",
      "train loss:1.0007950846003713\n",
      "train loss:1.2005742092324265\n",
      "train loss:0.9921502456762041\n",
      "train loss:1.323712247330285\n",
      "train loss:1.1846955557935364\n",
      "train loss:0.9651320902515391\n",
      "train loss:1.1065553143910556\n",
      "train loss:1.028370952034651\n",
      "train loss:1.0378754046857106\n",
      "train loss:1.1789428684032244\n",
      "train loss:0.9907669936683586\n",
      "train loss:1.048213911650493\n",
      "train loss:0.9903439275047525\n",
      "train loss:0.9775289120469046\n",
      "train loss:1.1243555711498798\n",
      "train loss:1.025508467622727\n",
      "train loss:0.9798949133941209\n",
      "train loss:1.206057558915895\n",
      "train loss:1.0232481495393255\n",
      "train loss:1.0677918283117405\n",
      "train loss:1.2309814717099374\n",
      "train loss:1.0862024174974734\n",
      "train loss:1.199579796799786\n",
      "train loss:1.2096479120232984\n",
      "train loss:1.1320882575747482\n",
      "train loss:1.2437559346714844\n",
      "train loss:1.1362398104240565\n",
      "train loss:0.9508237099041983\n",
      "train loss:0.9621808047711347\n",
      "train loss:0.9758580001595583\n",
      "train loss:1.2653039893400557\n",
      "train loss:1.152329689801181\n",
      "train loss:1.1000030529476685\n",
      "train loss:1.1477105046646507\n",
      "train loss:1.0021464426438997\n",
      "train loss:0.8988600059911817\n",
      "train loss:1.2072372628478205\n",
      "train loss:1.2385629552216004\n",
      "train loss:1.259326858704965\n",
      "train loss:1.1318012797031083\n",
      "train loss:1.0965726678082404\n",
      "train loss:1.0150369910380639\n",
      "train loss:1.1872666015367688\n",
      "train loss:1.2401216496870169\n",
      "train loss:1.130693080375068\n",
      "train loss:1.0117172093576192\n",
      "train loss:1.2179215985373835\n",
      "train loss:1.0360935389304413\n",
      "train loss:0.9578508747420131\n",
      "train loss:1.0432235814419102\n",
      "train loss:0.949480126903048\n",
      "train loss:1.0554062468390737\n",
      "train loss:1.109742764953266\n",
      "train loss:1.02691618148621\n",
      "train loss:1.2375872138262556\n",
      "train loss:1.0478097054296795\n",
      "train loss:1.0747657419218808\n",
      "train loss:0.9706748977397033\n",
      "train loss:0.9678877093618219\n",
      "train loss:0.977015881738369\n",
      "train loss:1.1608675640921542\n",
      "train loss:1.172154452112853\n",
      "train loss:1.1120087887964443\n",
      "train loss:1.0030645258166646\n",
      "train loss:1.1133768075900834\n",
      "train loss:1.0677201418429\n",
      "train loss:1.0400325006804925\n",
      "train loss:1.026396432494401\n",
      "train loss:1.0057198754554153\n",
      "train loss:1.2301022465965439\n",
      "train loss:1.1157152930666292\n",
      "train loss:1.0307324876212338\n",
      "train loss:0.9393657287768156\n",
      "train loss:1.024970754757359\n",
      "train loss:1.1120815251677174\n",
      "train loss:1.1098925519845266\n",
      "train loss:0.9590102479257431\n",
      "train loss:1.056332460055284\n",
      "train loss:1.0664875177995476\n",
      "train loss:1.1300587919834375\n",
      "train loss:0.9598128112127939\n",
      "train loss:1.102326637030417\n",
      "train loss:1.1839489273559307\n",
      "train loss:0.9974941197655031\n",
      "train loss:1.3503146519270286\n",
      "train loss:1.1541556298726652\n",
      "train loss:1.0366866060078133\n",
      "train loss:0.9899130633212715\n",
      "train loss:1.0374827766426302\n",
      "train loss:1.073771475385192\n",
      "train loss:1.1526670160380508\n",
      "train loss:1.060295304848303\n",
      "train loss:1.080105424005844\n",
      "train loss:0.9901310415794103\n",
      "train loss:0.853021263499829\n",
      "train loss:1.0549340545792616\n",
      "train loss:1.138658654083104\n",
      "train loss:1.174641395992395\n",
      "train loss:1.0891488011580766\n",
      "train loss:1.2425715496900145\n",
      "train loss:1.1511109146084098\n",
      "train loss:0.9855336281744518\n",
      "train loss:0.954522988877201\n",
      "train loss:1.0354106552459825\n",
      "train loss:0.8411450095682942\n",
      "train loss:1.0930118206253858\n",
      "train loss:1.034230777380225\n",
      "train loss:1.1339086455042697\n",
      "=== epoch:2, train acc:0.978, test acc:0.972 ===\n",
      "train loss:1.1046204339714158\n",
      "train loss:0.9442935779165819\n",
      "train loss:1.1422481922014387\n",
      "train loss:1.1014508141277357\n",
      "train loss:1.1309004003715726\n",
      "train loss:1.1116185062002617\n",
      "train loss:1.1305640713836724\n",
      "train loss:0.9883472592571294\n",
      "train loss:0.97041454221072\n",
      "train loss:1.019886230949589\n",
      "train loss:1.083191990418062\n",
      "train loss:0.9963350692451062\n",
      "train loss:1.1760620798692007\n",
      "train loss:0.9351305464714876\n",
      "train loss:1.0411303113692048\n",
      "train loss:0.9834868087855962\n",
      "train loss:1.2172021450174606\n",
      "train loss:1.0255603259106578\n",
      "train loss:0.877099971392629\n",
      "train loss:0.977328168210133\n",
      "train loss:0.843862358161948\n",
      "train loss:0.8565814811068987\n",
      "train loss:0.8473461742376449\n",
      "train loss:1.1995078271528101\n",
      "train loss:1.3719042444217495\n",
      "train loss:1.0041182024250903\n",
      "train loss:1.0018996835831442\n",
      "train loss:0.9299051541601273\n",
      "train loss:1.0700111917021824\n",
      "train loss:0.834586711384596\n",
      "train loss:1.306928057530372\n",
      "train loss:1.0295442294892463\n",
      "train loss:1.2419204269721247\n",
      "train loss:1.0365434389580743\n",
      "train loss:1.0451316549809488\n",
      "train loss:0.9572266446346053\n",
      "train loss:0.9198370352131563\n",
      "train loss:1.1054824438644204\n",
      "train loss:1.178669917616029\n",
      "train loss:0.8938763107733824\n",
      "train loss:1.0061662836947745\n",
      "train loss:1.164130921682575\n",
      "train loss:0.9908600886658594\n",
      "train loss:1.1382143400209759\n",
      "train loss:1.2900105039618432\n",
      "train loss:1.0478698711351138\n",
      "train loss:0.9406446010574671\n",
      "train loss:1.1721062953446586\n",
      "train loss:0.9661493718957079\n",
      "train loss:1.1085396594555563\n",
      "train loss:1.0145326110572663\n",
      "train loss:0.9988037651377495\n",
      "train loss:1.2075518989587517\n",
      "train loss:1.024820155868045\n",
      "train loss:1.0569317349052505\n",
      "train loss:1.063390484364954\n",
      "train loss:1.0669258081811694\n",
      "train loss:1.2289763557434383\n",
      "train loss:1.2461648389999598\n",
      "train loss:1.1121841100569396\n",
      "train loss:1.0800832053666678\n",
      "train loss:1.0568505567494761\n",
      "train loss:0.7935330609175313\n",
      "train loss:1.0262116879367909\n",
      "train loss:0.9549606033839855\n",
      "train loss:1.12951086647997\n",
      "train loss:1.20456005573441\n",
      "train loss:1.1243968047601758\n",
      "train loss:1.03949070015672\n",
      "train loss:1.2755113683489747\n",
      "train loss:1.0005821030779924\n",
      "train loss:1.027116035904165\n",
      "train loss:1.1672290267568244\n",
      "train loss:1.0658838184845905\n",
      "train loss:1.0660318454139914\n",
      "train loss:0.9627508721732793\n",
      "train loss:1.1109046840129928\n",
      "train loss:1.0118621865479285\n",
      "train loss:1.060200506392137\n",
      "train loss:0.9516932337770528\n",
      "train loss:1.0597125322878889\n",
      "train loss:0.9656272302157656\n",
      "train loss:1.0381111705644026\n",
      "train loss:1.0061153215503629\n",
      "train loss:0.9418825085088345\n",
      "train loss:1.1493694230024563\n",
      "train loss:1.0300300985265876\n",
      "train loss:1.0861955707320365\n",
      "train loss:1.0181619504718185\n",
      "train loss:0.9875162599860258\n",
      "train loss:1.0923755541342302\n",
      "train loss:1.1222122509464483\n",
      "train loss:1.1343485478691766\n",
      "train loss:1.2091622244149953\n",
      "train loss:1.0006066823703568\n",
      "train loss:1.0621921190177666\n",
      "train loss:0.9350887829056913\n",
      "train loss:1.1293026789095741\n",
      "train loss:0.9446158199701474\n",
      "train loss:0.9464161466550578\n",
      "train loss:1.0850087487300726\n",
      "train loss:1.0741533657203255\n",
      "train loss:1.2088543134619334\n",
      "train loss:1.0984905696534213\n",
      "train loss:1.106869788990584\n",
      "train loss:0.9840655386659952\n",
      "train loss:1.0916724480040358\n",
      "train loss:0.9564760230521064\n",
      "train loss:0.9049017370232826\n",
      "train loss:1.0574333955274342\n",
      "train loss:1.0120244367455982\n",
      "train loss:1.0906502899857384\n",
      "train loss:1.0991098272097182\n",
      "train loss:1.2665125313731929\n",
      "train loss:0.9911230423114995\n",
      "train loss:1.0336851056089018\n",
      "train loss:0.9182302304251578\n",
      "train loss:0.8472176683277302\n",
      "train loss:1.0098403062494623\n",
      "train loss:1.1829567641172067\n",
      "train loss:0.9621915864754267\n",
      "train loss:1.1243787791205988\n",
      "train loss:1.1356138056705876\n",
      "train loss:0.7972482141594025\n",
      "train loss:1.1672133319766147\n",
      "train loss:0.8173128870170153\n",
      "train loss:0.9889259040572838\n",
      "train loss:1.0625267581260538\n",
      "train loss:1.018136826431968\n",
      "train loss:1.0960161314856876\n",
      "train loss:1.1034523481216665\n",
      "train loss:1.1319088003185223\n",
      "train loss:0.8058110088555834\n",
      "train loss:1.1270684201121208\n",
      "train loss:1.0495338282504296\n",
      "train loss:1.0386036249650017\n",
      "train loss:1.1128733345604258\n",
      "train loss:1.1337903701009393\n",
      "train loss:0.9006527575346724\n",
      "train loss:1.0133732820861987\n",
      "train loss:0.9258670307541342\n",
      "train loss:0.9474618375387662\n",
      "train loss:0.9914654983998408\n",
      "train loss:0.9768690667416904\n",
      "train loss:0.8953954929736204\n",
      "train loss:0.9661842847430847\n",
      "train loss:1.0619843359802814\n",
      "train loss:1.1948819854995347\n",
      "train loss:1.1204119496923604\n",
      "train loss:0.936024941603465\n",
      "train loss:0.8433025808658651\n",
      "train loss:1.1381343283845726\n",
      "train loss:1.0171681561199732\n",
      "train loss:0.9495642857502902\n",
      "train loss:1.0645154500699678\n",
      "train loss:1.0831298685130808\n",
      "train loss:1.0004698979274793\n",
      "train loss:0.9785731583438979\n",
      "train loss:0.8597957549636882\n",
      "train loss:1.055501678003862\n",
      "train loss:1.0143820396815237\n",
      "train loss:0.9796120682842576\n",
      "train loss:0.9578759949133362\n",
      "train loss:1.0915832703582926\n",
      "train loss:0.9736078737394722\n",
      "train loss:0.8676707412927647\n",
      "train loss:0.9405052574777626\n",
      "train loss:0.9238521982195133\n",
      "train loss:0.8528989877374487\n",
      "train loss:0.9147088200881922\n",
      "train loss:0.8445408160798162\n",
      "train loss:0.9318826555558622\n",
      "train loss:1.2508240484540802\n",
      "train loss:1.1400389459710307\n",
      "train loss:1.19669595772938\n",
      "train loss:1.0358443815568292\n",
      "train loss:1.0692421221548514\n",
      "train loss:0.9178354438758847\n",
      "train loss:1.0464727797968858\n",
      "train loss:1.123818293676086\n",
      "train loss:0.7871618356293628\n",
      "train loss:0.9970991937251737\n",
      "train loss:1.0888116740508835\n",
      "train loss:0.9888440936131788\n",
      "train loss:0.9862595026742155\n",
      "train loss:1.141228353205075\n",
      "train loss:1.0848777203205624\n",
      "train loss:1.1350989090513957\n",
      "train loss:1.0003079466020575\n",
      "train loss:1.1047129421218316\n",
      "train loss:0.9337516063019055\n",
      "train loss:0.8323387683726932\n",
      "train loss:1.072098045886545\n",
      "train loss:1.048140769230333\n",
      "train loss:1.075550374092359\n",
      "train loss:1.0453004946342268\n",
      "train loss:1.1103495778187453\n",
      "train loss:1.1496747126938893\n",
      "train loss:0.9551200028596667\n",
      "train loss:1.192800030842732\n",
      "train loss:0.8987771456791522\n",
      "train loss:0.9532562304962579\n",
      "train loss:0.9716370852748019\n",
      "train loss:0.8651324256801657\n",
      "train loss:1.0101817603907965\n",
      "train loss:1.0346759742726201\n",
      "train loss:1.1200914442421808\n",
      "train loss:0.968773181485693\n",
      "train loss:1.0754312359319704\n",
      "train loss:1.073360016670311\n",
      "train loss:0.8148571278685249\n",
      "train loss:0.9448979624155841\n",
      "train loss:1.09389305818525\n",
      "train loss:0.9146038975906557\n",
      "train loss:0.7889142054646485\n",
      "train loss:0.8927375236008821\n",
      "train loss:1.1379113574428252\n",
      "train loss:0.9762253183744959\n",
      "train loss:1.0036040767674053\n",
      "train loss:1.051121056260697\n",
      "train loss:0.9048858033015794\n",
      "train loss:0.9391390665921374\n",
      "train loss:1.0953369716536883\n",
      "train loss:1.024598100866545\n",
      "train loss:0.8008498905970094\n",
      "train loss:1.014568820294718\n",
      "train loss:0.9891651427692076\n",
      "train loss:0.9752498791447178\n",
      "train loss:0.962259288227132\n",
      "train loss:0.8682840977979425\n",
      "train loss:1.0091484545743687\n",
      "train loss:0.8152020019482604\n",
      "train loss:0.8415822123221823\n",
      "train loss:0.9549927204037074\n",
      "train loss:1.0502368580120542\n",
      "train loss:0.7067243068310748\n",
      "train loss:0.9748226992881024\n",
      "train loss:0.8717851446271746\n",
      "train loss:1.1240747332912926\n",
      "train loss:0.9349214598952507\n",
      "train loss:0.9713619838050594\n",
      "train loss:1.0438869109741709\n",
      "train loss:0.934193874447758\n",
      "train loss:0.9514334126038015\n",
      "train loss:0.7512713449056977\n",
      "train loss:0.9271013771137084\n",
      "train loss:1.0165869160860124\n",
      "train loss:1.0612668282409112\n",
      "train loss:0.970945579486289\n",
      "train loss:1.2700461329008896\n",
      "train loss:1.171962629039242\n",
      "train loss:1.0033355957335126\n",
      "train loss:1.0392926352993201\n",
      "train loss:1.0130920679216087\n",
      "train loss:1.2196735265038783\n",
      "train loss:1.0143748483710475\n",
      "train loss:1.1437858491895687\n",
      "train loss:1.0323297681127164\n",
      "train loss:1.1213463413227234\n",
      "train loss:1.0199875611479796\n",
      "train loss:1.0076776261143794\n",
      "train loss:0.9445628831129114\n",
      "train loss:1.1420018848563014\n",
      "train loss:1.1460257559052467\n",
      "train loss:1.1431259672734126\n",
      "train loss:1.2288579493515255\n",
      "train loss:0.9795639490623796\n",
      "train loss:0.9867003382908299\n",
      "train loss:0.8649974526754767\n",
      "train loss:1.0754760516571233\n",
      "train loss:1.0240189343638257\n",
      "train loss:0.8470393059826636\n",
      "train loss:0.8724909962466617\n",
      "train loss:1.2540989873183828\n",
      "train loss:0.9970217093722996\n",
      "train loss:1.076915558160571\n",
      "train loss:1.0082881040193576\n",
      "train loss:1.1061083039215165\n",
      "train loss:1.1374474555723066\n",
      "train loss:0.9561368093140449\n",
      "train loss:0.9088936792796874\n",
      "train loss:0.9820882464885236\n",
      "train loss:0.9251473768436758\n",
      "train loss:1.1003985521487432\n",
      "train loss:0.9927418720396151\n",
      "train loss:1.0303009332466646\n",
      "train loss:0.9509045851849713\n",
      "train loss:1.18721395126219\n",
      "train loss:1.1804997685603418\n",
      "train loss:0.9948776741531415\n",
      "train loss:1.2458446768140754\n",
      "train loss:0.8681839334274725\n",
      "train loss:1.0864081262802836\n",
      "train loss:1.0391688739511242\n",
      "train loss:0.8587394643423596\n",
      "train loss:0.9382631111111754\n",
      "train loss:1.0565170684956355\n",
      "train loss:1.0789365995303624\n",
      "train loss:1.0598022643650804\n",
      "train loss:0.896141541942169\n",
      "train loss:0.9951329706751595\n",
      "train loss:1.1225378302296143\n",
      "train loss:1.0497791851157694\n",
      "train loss:0.8907292645753624\n",
      "train loss:1.0949617228860182\n",
      "train loss:0.8482768646325118\n",
      "train loss:1.1201864145858906\n",
      "train loss:0.9644395993161018\n",
      "train loss:0.9758539556370874\n",
      "train loss:0.9688667134705159\n",
      "train loss:1.1135435199784598\n",
      "train loss:1.2646599208623435\n",
      "train loss:1.086564140275673\n",
      "train loss:0.9983647873217905\n",
      "train loss:1.022214989555349\n",
      "train loss:0.8623196749794977\n",
      "train loss:0.9397028657037627\n",
      "train loss:0.911930422469744\n",
      "train loss:0.9543017992681583\n",
      "train loss:0.9662595208983327\n",
      "train loss:0.9723246862588433\n",
      "train loss:1.063054725169299\n",
      "train loss:0.955871869116788\n",
      "train loss:1.1385361467264552\n",
      "train loss:1.1236068744618728\n",
      "train loss:0.9442916626762201\n",
      "train loss:1.0673226630600416\n",
      "train loss:0.9966018547860039\n",
      "train loss:0.9992995837205021\n",
      "train loss:0.9706663872117811\n",
      "train loss:0.9991175098395736\n",
      "train loss:0.9712166686057473\n",
      "train loss:1.1214490103695658\n",
      "train loss:1.1366228359774615\n",
      "train loss:1.2426220666820538\n",
      "train loss:0.9225546822072175\n",
      "train loss:0.9485141233237931\n",
      "train loss:0.9357542812352471\n",
      "train loss:1.2738038012610469\n",
      "train loss:0.9611364121984544\n",
      "train loss:0.957617204708066\n",
      "train loss:0.8447347222529225\n",
      "train loss:0.9773025935818676\n",
      "train loss:1.0409293773097656\n",
      "train loss:0.934609997853003\n",
      "train loss:1.108140662687027\n",
      "train loss:1.0059386429886532\n",
      "train loss:1.021423656926476\n",
      "train loss:0.8337689415734268\n",
      "train loss:1.2516379717176518\n",
      "train loss:0.9977120622958577\n",
      "train loss:1.0577812417455288\n",
      "train loss:1.0885503217845978\n",
      "train loss:1.173971549955612\n",
      "train loss:1.0966871264290634\n",
      "train loss:1.0236034484196284\n",
      "train loss:0.8753488734014867\n",
      "train loss:1.0079997316801277\n",
      "train loss:0.890224462428204\n",
      "train loss:0.8296223495718488\n",
      "train loss:0.9708022103580691\n",
      "train loss:0.9802083333896817\n",
      "train loss:0.979518531089168\n",
      "train loss:0.8373673078865761\n",
      "train loss:0.9995557770902779\n",
      "train loss:0.9860450468211245\n",
      "train loss:1.064805602836633\n",
      "train loss:1.1043068047600253\n",
      "train loss:1.0317303505177586\n",
      "train loss:1.0988065343640538\n",
      "train loss:0.9075473121944693\n",
      "train loss:1.0453014930960227\n",
      "train loss:0.8676628899332974\n",
      "train loss:1.106791679979783\n",
      "train loss:0.9694644452712623\n",
      "train loss:0.9447074031230944\n",
      "train loss:1.1006192022183243\n",
      "train loss:1.1098850221177863\n",
      "train loss:1.0420251857901857\n",
      "train loss:1.0265773754816183\n",
      "train loss:1.0404334530654713\n",
      "train loss:0.7952954536892116\n",
      "train loss:0.8903229115080374\n",
      "train loss:1.0194613977993823\n",
      "train loss:1.0326455448073009\n",
      "train loss:1.222184471265185\n",
      "train loss:1.1426795461777632\n",
      "train loss:1.065795369335054\n",
      "train loss:1.142978237188814\n",
      "train loss:0.8987787818559425\n",
      "train loss:0.9615928868466898\n",
      "train loss:0.939351121423554\n",
      "train loss:0.9411295996636798\n",
      "train loss:0.9361874411635981\n",
      "train loss:0.8327107011909262\n",
      "train loss:1.0023454506229776\n",
      "train loss:0.806101803732733\n",
      "train loss:0.9632622710290051\n",
      "train loss:1.1127974517104608\n",
      "train loss:1.0541170860090072\n",
      "train loss:1.0194981035577433\n",
      "train loss:1.178699483596407\n",
      "train loss:1.0848010354859365\n",
      "train loss:1.1138989782418334\n",
      "train loss:0.9132837369437696\n",
      "train loss:0.9114917582206382\n",
      "train loss:1.1146159537710596\n",
      "train loss:1.0178539611497035\n",
      "train loss:0.9759977216779344\n",
      "train loss:0.9987885390827911\n",
      "train loss:0.8872148015370246\n",
      "train loss:1.0374558235091944\n",
      "train loss:1.1653616491627539\n",
      "train loss:1.060195591711625\n",
      "train loss:1.1122981795911944\n",
      "train loss:1.008097196488446\n",
      "train loss:1.0189815960366828\n",
      "train loss:0.8934411185729166\n",
      "train loss:0.8567149318711809\n",
      "train loss:0.9796328828092372\n",
      "train loss:1.0869675661246323\n",
      "train loss:1.0880521219400452\n",
      "train loss:0.988823962052471\n",
      "train loss:0.9145310590912591\n",
      "train loss:1.005606511337813\n",
      "train loss:1.1511367879791699\n",
      "train loss:0.8837158365603729\n",
      "train loss:0.9828538944893609\n",
      "train loss:0.924218263726058\n",
      "train loss:1.03734569762109\n",
      "train loss:0.7527149738703638\n",
      "train loss:0.9824699856057825\n",
      "train loss:0.9039649309312752\n",
      "train loss:1.0799867041859728\n",
      "train loss:0.9239379249279243\n",
      "train loss:0.8834767077881395\n",
      "train loss:0.9638332842780989\n",
      "train loss:1.0905890303392844\n",
      "train loss:0.898048046629291\n",
      "train loss:0.9822942296586844\n",
      "train loss:0.8574432136681956\n",
      "train loss:0.930823449955735\n",
      "train loss:0.9659157412767392\n",
      "train loss:0.8624358506855802\n",
      "train loss:0.8096018674710167\n",
      "train loss:0.9756329857451944\n",
      "train loss:1.083535263851019\n",
      "train loss:0.9690597362376104\n",
      "train loss:1.1274331827460073\n",
      "train loss:1.046538879707407\n",
      "train loss:0.9817479061399055\n",
      "train loss:0.9238933736350073\n",
      "train loss:1.0340297374251295\n",
      "train loss:0.9821143764047503\n",
      "train loss:1.0524399904740236\n",
      "train loss:0.9261874842293351\n",
      "train loss:1.0782961869459378\n",
      "train loss:0.8221507359865554\n",
      "train loss:1.041876632996086\n",
      "train loss:1.0889372581723358\n",
      "train loss:0.9870283191651105\n",
      "train loss:1.1952155735894612\n",
      "train loss:1.003187741505136\n",
      "train loss:0.9649721963412007\n",
      "train loss:1.0120474643146216\n",
      "train loss:1.0504869068561988\n",
      "train loss:0.9187107216545916\n",
      "train loss:0.8994081796918669\n",
      "train loss:0.8591517997490515\n",
      "train loss:1.0222730027113343\n",
      "train loss:1.0597828832125737\n",
      "train loss:0.8961185562554748\n",
      "train loss:0.8866513083704025\n",
      "train loss:1.1229401991707335\n",
      "train loss:1.0552148195994075\n",
      "train loss:1.1093867564748914\n",
      "train loss:1.067809741002705\n",
      "train loss:0.9515270873907756\n",
      "train loss:0.8549063080926201\n",
      "train loss:0.9912834494274795\n",
      "train loss:0.7984096361166872\n",
      "train loss:1.172736867000503\n",
      "train loss:0.970838005778417\n",
      "train loss:0.9617459952174786\n",
      "train loss:1.0392593160733443\n",
      "train loss:1.0427377753426401\n",
      "train loss:1.1141921226558984\n",
      "train loss:0.9077842984301471\n",
      "train loss:0.8921058774517998\n",
      "train loss:1.1135146099932165\n",
      "train loss:0.9193048422952289\n",
      "train loss:0.9784506417186338\n",
      "train loss:0.9029872564386483\n",
      "train loss:0.9593507034822253\n",
      "train loss:0.9343560731353163\n",
      "train loss:0.9781675322750938\n",
      "train loss:1.1798012170039232\n",
      "train loss:1.1004009747057173\n",
      "train loss:0.943022166416758\n",
      "train loss:1.149469837445468\n",
      "train loss:0.9515337916366776\n",
      "train loss:1.0007517198758051\n",
      "train loss:1.0297654496694744\n",
      "train loss:1.02864783204233\n",
      "train loss:1.0103567251291339\n",
      "train loss:0.9727566215486508\n",
      "train loss:1.045476142809961\n",
      "train loss:0.9266124797564064\n",
      "train loss:1.0626055406693111\n",
      "train loss:1.1033850403681575\n",
      "train loss:1.0534336305680319\n",
      "train loss:0.9778984882712399\n",
      "train loss:1.0087954100776342\n",
      "train loss:0.824213330276821\n",
      "train loss:0.9778954913700231\n",
      "train loss:1.1317817564465442\n",
      "train loss:0.9022447765831656\n",
      "train loss:0.8935752456717294\n",
      "train loss:0.8346244681693499\n",
      "train loss:0.8851301968142363\n",
      "train loss:0.9605563759412337\n",
      "train loss:0.8875871886475472\n",
      "train loss:0.9081328669119862\n",
      "train loss:0.8532529012097427\n",
      "train loss:1.0810905867816814\n",
      "train loss:0.9393507519893882\n",
      "train loss:1.0004342682586316\n",
      "train loss:0.9464373788788645\n",
      "train loss:0.960865411383947\n",
      "train loss:1.2407603211244902\n",
      "train loss:0.9729067612919495\n",
      "train loss:0.8964051817344867\n",
      "train loss:0.9987964494112113\n",
      "train loss:1.1076754110156362\n",
      "train loss:0.7924573968219432\n",
      "train loss:0.8347976004289123\n",
      "train loss:0.8415117482916462\n",
      "train loss:1.0731013610354883\n",
      "train loss:1.1813156290817113\n",
      "train loss:1.0254208774590914\n",
      "train loss:1.0257086464181495\n",
      "train loss:1.0327717058237535\n",
      "train loss:1.0484439676546788\n",
      "train loss:1.079945865056385\n",
      "train loss:0.9050226530410509\n",
      "train loss:1.20328205055489\n",
      "train loss:1.0344739660962687\n",
      "train loss:1.017852329815321\n",
      "train loss:0.8425565114612068\n",
      "train loss:0.9966444121465454\n",
      "train loss:0.9933640410955611\n",
      "train loss:1.2126877484033234\n",
      "train loss:1.017791052686937\n",
      "train loss:0.9362264257315976\n",
      "train loss:0.9183825348675545\n",
      "train loss:0.9656463851279217\n",
      "train loss:1.0156277590729397\n",
      "train loss:1.0792656602213706\n",
      "train loss:1.0695721543665897\n",
      "train loss:0.8749720640784945\n",
      "train loss:1.0051422176714353\n",
      "train loss:1.000385894931702\n",
      "train loss:0.9118481311123097\n",
      "train loss:0.8571643396946836\n",
      "train loss:1.077528500963233\n",
      "train loss:0.9423259109715416\n",
      "train loss:1.1752173823996739\n",
      "train loss:1.0412898748214408\n",
      "train loss:1.103253060126739\n",
      "train loss:0.818621572955216\n",
      "train loss:0.8760902456907226\n",
      "train loss:1.000583789858436\n",
      "train loss:1.008000888612203\n",
      "train loss:1.0592577542129717\n",
      "train loss:1.0253005406267468\n",
      "train loss:1.0498678935652417\n",
      "train loss:0.8022201658952451\n",
      "train loss:0.9084030973749497\n",
      "train loss:1.022322973783747\n",
      "train loss:1.0200792249688728\n",
      "train loss:1.0352547506755274\n",
      "train loss:1.0195355972624593\n",
      "train loss:1.0457331111845964\n",
      "train loss:0.9348958905859286\n",
      "train loss:0.9578544358348209\n",
      "train loss:0.8979132478758018\n",
      "train loss:0.8909339748714441\n",
      "train loss:0.8447366868788392\n",
      "train loss:0.9074509125013169\n",
      "train loss:1.146618462245916\n",
      "train loss:0.9672151035506876\n",
      "train loss:0.9591444508649175\n",
      "train loss:1.073003194105859\n",
      "train loss:1.1218577889562358\n",
      "train loss:1.0008355689500765\n",
      "train loss:1.0171854071859001\n",
      "train loss:0.9171931027570381\n",
      "train loss:0.9440963478828962\n",
      "train loss:1.0918065383877644\n",
      "train loss:0.7763486569769067\n",
      "=== epoch:3, train acc:0.982, test acc:0.984 ===\n",
      "train loss:1.074893452842941\n",
      "train loss:0.7882018445406672\n",
      "train loss:1.1421827407322156\n",
      "train loss:1.0163008384642715\n",
      "train loss:0.899015531584851\n",
      "train loss:0.8867080356365019\n",
      "train loss:0.9466318998814277\n",
      "train loss:0.9454914211927548\n",
      "train loss:0.9923813372629781\n",
      "train loss:1.0536819328342362\n",
      "train loss:1.0991841347954918\n",
      "train loss:0.9983373113638158\n",
      "train loss:1.047161975117462\n",
      "train loss:1.1072560650362768\n",
      "train loss:0.8577777251583741\n",
      "train loss:1.14776736096675\n",
      "train loss:1.022486065107481\n",
      "train loss:0.850970171870524\n",
      "train loss:1.206774093516682\n",
      "train loss:1.0693287345668103\n",
      "train loss:1.0152315687305855\n",
      "train loss:0.8833147299630091\n",
      "train loss:1.0466952013333681\n",
      "train loss:0.9253250464036465\n",
      "train loss:0.9154563402993184\n",
      "train loss:1.174781910558158\n",
      "train loss:0.8598618276255996\n",
      "train loss:1.0652460611968626\n",
      "train loss:0.9129753770375848\n",
      "train loss:1.1039052381954209\n",
      "train loss:0.8417591319641149\n",
      "train loss:1.0943211145596254\n",
      "train loss:0.9938533584698783\n",
      "train loss:0.9300930206650225\n",
      "train loss:0.938044880214809\n",
      "train loss:0.9192455008453331\n",
      "train loss:0.9807334779613882\n",
      "train loss:0.7733202940491073\n",
      "train loss:1.024433602527725\n",
      "train loss:0.9320300517351622\n",
      "train loss:0.9189986460760876\n",
      "train loss:1.1263356073787787\n",
      "train loss:0.8701826740278095\n",
      "train loss:0.8921595456468198\n",
      "train loss:0.8321255386922821\n",
      "train loss:0.7858425369935718\n",
      "train loss:1.0301297796050606\n",
      "train loss:0.9080564248656213\n",
      "train loss:0.9060216005321962\n",
      "train loss:0.9848810558050868\n",
      "train loss:0.9623384243438337\n",
      "train loss:0.9808161717213211\n",
      "train loss:0.9981121998910859\n",
      "train loss:1.0439046680311657\n",
      "train loss:0.9219871297976369\n",
      "train loss:0.8927899742099997\n",
      "train loss:1.0786742035427923\n",
      "train loss:0.9833612518276175\n",
      "train loss:1.0337408469076497\n",
      "train loss:0.9663199039223933\n",
      "train loss:0.9195969822221273\n",
      "train loss:1.0996957458463947\n",
      "train loss:1.0341576585195806\n",
      "train loss:0.7819730342385053\n",
      "train loss:0.9791739689268063\n",
      "train loss:0.905029650203782\n",
      "train loss:1.0448401448590328\n",
      "train loss:0.9497082835121554\n",
      "train loss:1.1595062397193643\n",
      "train loss:0.9207697063611738\n",
      "train loss:1.018190452966829\n",
      "train loss:0.9499823385976254\n",
      "train loss:1.0238235378251723\n",
      "train loss:1.1814683986097805\n",
      "train loss:0.8434982898506778\n",
      "train loss:0.7645893297054787\n",
      "train loss:0.8981160441118685\n",
      "train loss:0.9522363810138986\n",
      "train loss:0.9962017583300528\n",
      "train loss:0.9440237839396407\n",
      "train loss:0.8301429003199875\n",
      "train loss:0.950707246269689\n",
      "train loss:1.125213256089701\n",
      "train loss:0.9250793237925453\n",
      "train loss:1.059570766247707\n",
      "train loss:0.9034252787327383\n",
      "train loss:1.0118407886178005\n",
      "train loss:0.9270423815293811\n",
      "train loss:0.9001205570997989\n",
      "train loss:1.0208549795382256\n",
      "train loss:1.089230488547204\n",
      "train loss:1.0304830068217135\n",
      "train loss:1.000230594464086\n",
      "train loss:1.1499043780781237\n",
      "train loss:0.9758579565316842\n",
      "train loss:0.9504535264472969\n",
      "train loss:1.062292209095164\n",
      "train loss:1.0040353734401073\n",
      "train loss:0.9555089544711223\n",
      "train loss:0.8788143656098377\n",
      "train loss:0.9732256803380193\n",
      "train loss:1.0264962527915795\n",
      "train loss:1.2264525379608757\n",
      "train loss:1.047417549322162\n",
      "train loss:1.0102528693640693\n",
      "train loss:1.0100249214628487\n",
      "train loss:1.0375696564336978\n",
      "train loss:1.0237148034336194\n",
      "train loss:0.9574682797767664\n",
      "train loss:0.9751379852847368\n",
      "train loss:0.9906027775192974\n",
      "train loss:1.0200576183087429\n",
      "train loss:0.9119970406583896\n",
      "train loss:0.9944936672570877\n",
      "train loss:1.0855332411163907\n",
      "train loss:0.8422920903407829\n",
      "train loss:0.9722231404574603\n",
      "train loss:0.9959252047822872\n",
      "train loss:0.859715392772342\n",
      "train loss:0.9950068001342648\n",
      "train loss:0.8673797720787827\n",
      "train loss:0.9475815512605424\n",
      "train loss:1.0423249234057208\n",
      "train loss:1.0520479225155188\n",
      "train loss:0.9636404759740289\n",
      "train loss:1.0414105519695867\n",
      "train loss:0.9196240347066161\n",
      "train loss:1.3017184326049787\n",
      "train loss:0.9495428601078367\n",
      "train loss:1.01255249107042\n",
      "train loss:0.9168377497182972\n",
      "train loss:0.8645359475241037\n",
      "train loss:0.9844881384887627\n",
      "train loss:1.0725864542830836\n",
      "train loss:0.9996351429118921\n",
      "train loss:0.771999395383896\n",
      "train loss:0.9227665996280769\n",
      "train loss:0.9671208565437529\n",
      "train loss:0.8550556077454599\n",
      "train loss:0.9684453032970056\n",
      "train loss:1.0924724022482275\n",
      "train loss:0.9960568514039718\n",
      "train loss:1.0408502609788097\n",
      "train loss:0.9929587799913897\n",
      "train loss:0.9680483533141236\n",
      "train loss:0.953263778630891\n",
      "train loss:0.8097919283625596\n",
      "train loss:0.8859357505076002\n",
      "train loss:1.1073782416550884\n",
      "train loss:0.8350400851594696\n",
      "train loss:0.8560058448252131\n",
      "train loss:0.9382216746215082\n",
      "train loss:0.9155434694329665\n",
      "train loss:0.9198834406631542\n",
      "train loss:1.1049785278268651\n",
      "train loss:1.0209071386905495\n",
      "train loss:1.0208619415591638\n",
      "train loss:0.781169452216656\n",
      "train loss:0.8244413297120166\n",
      "train loss:0.9793260040173309\n",
      "train loss:0.9986847275342199\n",
      "train loss:1.0369714998950308\n",
      "train loss:0.9803961102531997\n",
      "train loss:0.9531979111464832\n",
      "train loss:0.9242672262218489\n",
      "train loss:0.9819034624591718\n",
      "train loss:0.9277141902729416\n",
      "train loss:0.9206003594066045\n",
      "train loss:1.0330224016940728\n",
      "train loss:1.047057643192841\n",
      "train loss:0.9720778261062241\n",
      "train loss:0.8409216303594047\n",
      "train loss:1.0411663772468516\n",
      "train loss:1.1360804928863166\n",
      "train loss:0.7563325567360982\n",
      "train loss:0.8606789137276338\n",
      "train loss:0.9789699933972326\n",
      "train loss:0.9511839166342041\n",
      "train loss:0.9979936059174787\n",
      "train loss:0.819143180788722\n",
      "train loss:0.9681706456056486\n",
      "train loss:0.8983721662963579\n",
      "train loss:1.0644167016300943\n",
      "train loss:0.9678005788798225\n",
      "train loss:1.0196490464423764\n",
      "train loss:0.9506922247742483\n",
      "train loss:0.9535676715471704\n",
      "train loss:0.8409185994599622\n",
      "train loss:0.8703600727586835\n",
      "train loss:1.0861967536961676\n",
      "train loss:1.0821739359125364\n",
      "train loss:1.0936065114322484\n",
      "train loss:1.0238582991242182\n",
      "train loss:0.9737967558697543\n",
      "train loss:1.093673570748557\n",
      "train loss:0.9818719735849578\n",
      "train loss:0.7853276760440564\n",
      "train loss:1.1458283844995267\n",
      "train loss:0.8994764243281789\n",
      "train loss:1.079811114686294\n",
      "train loss:0.9840836534029576\n",
      "train loss:0.9653518421531706\n",
      "train loss:1.0412057221020223\n",
      "train loss:0.8857232079531017\n",
      "train loss:0.9634328129290921\n",
      "train loss:0.8719046982996536\n",
      "train loss:1.0312908860578915\n",
      "train loss:0.9646088857077101\n",
      "train loss:0.7955745505577244\n",
      "train loss:0.9197818359707963\n",
      "train loss:0.8962586630141487\n",
      "train loss:0.9341859152048646\n",
      "train loss:0.8437264616305812\n",
      "train loss:0.9373739540912557\n",
      "train loss:0.8871055978937105\n",
      "train loss:0.853248664060985\n",
      "train loss:0.9580830136278071\n",
      "train loss:0.6681414232930695\n",
      "train loss:0.9498291371485672\n",
      "train loss:1.0365773852852744\n",
      "train loss:1.0383835175196672\n",
      "train loss:0.9491426388715216\n",
      "train loss:1.290431493631562\n",
      "train loss:1.0635686772770783\n",
      "train loss:0.7502695846516754\n",
      "train loss:0.8551286301866543\n",
      "train loss:0.8931127105986171\n",
      "train loss:1.0079659669502232\n",
      "train loss:0.958336871749465\n",
      "train loss:0.9417975271592546\n",
      "train loss:1.0260994976984728\n",
      "train loss:0.9046138558819602\n",
      "train loss:0.9910811385603552\n",
      "train loss:1.0004611927410798\n",
      "train loss:0.9293659475786079\n",
      "train loss:0.8662226361340235\n",
      "train loss:0.9222558849496905\n",
      "train loss:0.897273868275144\n",
      "train loss:0.9551900847701061\n",
      "train loss:1.034573426506497\n",
      "train loss:1.0349602893231082\n",
      "train loss:0.743035879977743\n",
      "train loss:1.0150007302590602\n",
      "train loss:0.8573645987256482\n",
      "train loss:1.155403030116944\n",
      "train loss:1.0248436879470293\n",
      "train loss:0.8420643202564332\n",
      "train loss:0.9344584510337256\n",
      "train loss:0.806339269507862\n",
      "train loss:0.7671736039761601\n",
      "train loss:0.9732238215907413\n",
      "train loss:1.0796995953478192\n",
      "train loss:1.0266646807495738\n",
      "train loss:1.227963404970331\n",
      "train loss:1.1016124674763506\n",
      "train loss:1.1473092718974656\n",
      "train loss:0.7592540510263269\n",
      "train loss:0.9819520694890186\n",
      "train loss:0.879137155381876\n",
      "train loss:0.9407124366132193\n",
      "train loss:0.9615294975582884\n",
      "train loss:1.1673892393021246\n",
      "train loss:0.9222736577115461\n",
      "train loss:1.0115069539041033\n",
      "train loss:0.9443554923890897\n",
      "train loss:0.9522982211855342\n",
      "train loss:1.069989624297868\n",
      "train loss:0.956484938602549\n",
      "train loss:0.8896892573603293\n",
      "train loss:0.9005122306642436\n",
      "train loss:0.8709398090144681\n",
      "train loss:0.970888582585342\n",
      "train loss:0.9375130721886836\n",
      "train loss:0.8488775581307987\n",
      "train loss:1.02724703663513\n",
      "train loss:0.9296985365451326\n",
      "train loss:0.9288714277807728\n",
      "train loss:1.0082589437914915\n",
      "train loss:0.9806431104830823\n",
      "train loss:0.8599697369154252\n",
      "train loss:0.9253170118747015\n",
      "train loss:0.9533484897718075\n",
      "train loss:1.0315357352630483\n",
      "train loss:0.8234158677353703\n",
      "train loss:1.0652916227092615\n",
      "train loss:1.0424631020730495\n",
      "train loss:1.1391000972883103\n",
      "train loss:0.9833161621468725\n",
      "train loss:0.9425877882675399\n",
      "train loss:0.8979579558097858\n",
      "train loss:1.0257039991741985\n",
      "train loss:0.8779349728660872\n",
      "train loss:0.9328329958589714\n",
      "train loss:0.9169372006732516\n",
      "train loss:0.824263187713382\n",
      "train loss:1.1013815703548984\n",
      "train loss:0.8765353378487427\n",
      "train loss:1.0366384512400784\n",
      "train loss:0.898656901165011\n",
      "train loss:0.9209472349373152\n",
      "train loss:0.953321934205826\n",
      "train loss:0.8906268967133113\n",
      "train loss:0.8652072795843309\n",
      "train loss:1.0860372510146539\n",
      "train loss:0.8674673973473247\n",
      "train loss:0.8659415915284336\n",
      "train loss:0.9545370485542297\n",
      "train loss:0.9844312782129081\n",
      "train loss:1.0127350635652572\n",
      "train loss:1.006291195963391\n",
      "train loss:0.8357881779753339\n",
      "train loss:0.9261732725718441\n",
      "train loss:0.9014748194327292\n",
      "train loss:0.9898188259892754\n",
      "train loss:1.0405840758761258\n",
      "train loss:1.0218778226196876\n",
      "train loss:0.9326167763990094\n",
      "train loss:0.9521503391006176\n",
      "train loss:0.7989393910981406\n",
      "train loss:0.8523433615935477\n",
      "train loss:0.877488639416698\n",
      "train loss:0.9800022627134463\n",
      "train loss:0.8857191790644526\n",
      "train loss:1.0750685372231725\n",
      "train loss:1.0711486598779265\n",
      "train loss:1.0231011356845134\n",
      "train loss:1.097955520562551\n",
      "train loss:1.0062414168884473\n",
      "train loss:0.8866885281225265\n",
      "train loss:1.1008239523741559\n",
      "train loss:0.9810638191809647\n",
      "train loss:1.1089841477704627\n",
      "train loss:0.9193073621275513\n",
      "train loss:0.9092952512662168\n",
      "train loss:1.1159672466975397\n",
      "train loss:0.9524987790307015\n",
      "train loss:0.9706545263379712\n",
      "train loss:1.0006664906410376\n",
      "train loss:1.0014577986741688\n",
      "train loss:0.8899772627205362\n",
      "train loss:0.7733430165844304\n",
      "train loss:0.9760155914929889\n",
      "train loss:0.8745413810047846\n",
      "train loss:0.8960138235644213\n",
      "train loss:0.8186190676622345\n",
      "train loss:0.8586392022182614\n",
      "train loss:1.0079971938075178\n",
      "train loss:1.0842496153134344\n",
      "train loss:1.109158198850836\n",
      "train loss:1.0115279765040888\n",
      "train loss:1.059981627165839\n",
      "train loss:0.8904667922448155\n",
      "train loss:0.8955570798417621\n",
      "train loss:1.0212621010824605\n",
      "train loss:0.9612418884235631\n",
      "train loss:0.7462028740411414\n",
      "train loss:0.8999061560487713\n",
      "train loss:0.9184789892363111\n",
      "train loss:0.8073656967207028\n",
      "train loss:0.8593137539301763\n",
      "train loss:0.7813861341573717\n",
      "train loss:1.052865212395505\n",
      "train loss:0.9434374939257301\n",
      "train loss:0.7692408866016288\n",
      "train loss:0.998748408541951\n",
      "train loss:0.8807784395125191\n",
      "train loss:1.0626286904864037\n",
      "train loss:1.057850593534081\n",
      "train loss:0.9447883451452913\n",
      "train loss:0.9680953941716222\n",
      "train loss:1.0105262814640055\n",
      "train loss:0.9786402250474656\n",
      "train loss:0.9332110846377917\n",
      "train loss:0.8632790488691482\n",
      "train loss:0.7410616787132898\n",
      "train loss:0.8443021585378172\n",
      "train loss:1.0324080497221282\n",
      "train loss:0.975249565373624\n",
      "train loss:0.8995848052210677\n",
      "train loss:0.966466757913711\n",
      "train loss:1.029093607650713\n",
      "train loss:0.872934596250448\n",
      "train loss:1.0030096346829216\n",
      "train loss:1.080443687571495\n",
      "train loss:1.0222757729077097\n",
      "train loss:1.1225231359017032\n",
      "train loss:1.0354698154517359\n",
      "train loss:1.0343905300287215\n",
      "train loss:0.8885537051245879\n",
      "train loss:0.8044072201591556\n",
      "train loss:0.9915580376616393\n",
      "train loss:0.9605031252807852\n",
      "train loss:0.9578862027016518\n",
      "train loss:0.9537947696653772\n",
      "train loss:1.2312439348973785\n",
      "train loss:1.0314713364184458\n",
      "train loss:0.9933864449574478\n",
      "train loss:0.8368195708039547\n",
      "train loss:0.9663872282825149\n",
      "train loss:0.932564191837332\n",
      "train loss:0.9949806902737309\n",
      "train loss:1.0597461395683014\n",
      "train loss:1.1318793953265576\n",
      "train loss:0.9844699767272033\n",
      "train loss:0.9965474276464151\n",
      "train loss:0.8842846511220077\n",
      "train loss:0.9852961585626572\n",
      "train loss:1.0829908893709779\n",
      "train loss:0.927505977471794\n",
      "train loss:0.8206366634454645\n",
      "train loss:0.961592460633466\n",
      "train loss:0.9369693889596169\n",
      "train loss:1.0540037160607059\n",
      "train loss:0.9623582692541168\n",
      "train loss:1.0416687257929496\n",
      "train loss:0.9152270619063206\n",
      "train loss:0.799301472456317\n",
      "train loss:0.9523512696622582\n",
      "train loss:1.080308956412243\n",
      "train loss:0.9621923727459993\n",
      "train loss:0.9946959867398546\n",
      "train loss:0.9505192631662014\n",
      "train loss:1.0607847342227184\n",
      "train loss:0.9564336495272776\n",
      "train loss:1.1256381311506685\n",
      "train loss:1.0259951188833412\n",
      "train loss:1.2358541416054158\n",
      "train loss:1.0249811019805868\n",
      "train loss:1.030622445421632\n",
      "train loss:1.0034243369102103\n",
      "train loss:0.847834579177143\n",
      "train loss:0.9940372182343716\n",
      "train loss:1.0379501742307133\n",
      "train loss:0.9879855986946545\n",
      "train loss:0.9168264046829112\n",
      "train loss:0.9380341220953352\n",
      "train loss:0.9929584527076599\n",
      "train loss:0.9581997689955017\n",
      "train loss:0.8797428025347876\n",
      "train loss:0.9414127177864596\n",
      "train loss:1.1878162014494098\n",
      "train loss:0.951331579047853\n",
      "train loss:0.982661492695246\n",
      "train loss:1.009321408987348\n",
      "train loss:0.8814624591877153\n",
      "train loss:1.045752761681746\n",
      "train loss:0.9223061072963077\n",
      "train loss:1.072765629303456\n",
      "train loss:0.958503817182861\n",
      "train loss:1.005244829087244\n",
      "train loss:0.8901788959980569\n",
      "train loss:1.1436020781292395\n",
      "train loss:1.0495608174118236\n",
      "train loss:0.9746214044116789\n",
      "train loss:0.7899724708432698\n",
      "train loss:0.7737299760683656\n",
      "train loss:1.028558444279637\n",
      "train loss:0.9998845796480231\n",
      "train loss:0.9727594626170643\n",
      "train loss:1.0230217443121417\n",
      "train loss:0.9864468371926681\n",
      "train loss:1.049611863619644\n",
      "train loss:1.0190615685077413\n",
      "train loss:0.8971872258098393\n",
      "train loss:1.1194667086246932\n",
      "train loss:0.8721556937180804\n",
      "train loss:0.927608302152053\n",
      "train loss:0.8483862891559548\n",
      "train loss:0.9223390010759853\n",
      "train loss:0.9681498144020335\n",
      "train loss:0.8986533161679615\n",
      "train loss:0.9570451192205579\n",
      "train loss:1.034488480905391\n",
      "train loss:0.957855965992738\n",
      "train loss:0.8909128036758962\n",
      "train loss:0.936002507856297\n",
      "train loss:1.019641437815651\n",
      "train loss:0.7562217879535522\n",
      "train loss:1.0088976224286106\n",
      "train loss:0.8619506565118261\n",
      "train loss:0.9678323007100478\n",
      "train loss:0.9300511303508204\n",
      "train loss:0.9413765982041642\n",
      "train loss:0.9780570564255054\n",
      "train loss:1.1253610283287534\n",
      "train loss:1.0049698845703863\n",
      "train loss:0.807007954621428\n",
      "train loss:0.895791136990047\n",
      "train loss:1.1008916965728723\n",
      "train loss:0.9311438444056037\n",
      "train loss:0.9357302714862158\n",
      "train loss:1.0802614911204536\n",
      "train loss:0.8069066053911943\n",
      "train loss:0.8975922279076342\n",
      "train loss:1.0115062668482684\n",
      "train loss:0.9160172487008151\n",
      "train loss:0.9507947426147919\n",
      "train loss:0.7480036417373306\n",
      "train loss:1.0557747357192113\n",
      "train loss:0.973490151231852\n",
      "train loss:1.0623427492842636\n",
      "train loss:0.9109555844488666\n",
      "train loss:0.8800469845157666\n",
      "train loss:0.917083844995086\n",
      "train loss:1.1235306758868318\n",
      "train loss:0.9853351246768921\n",
      "train loss:1.0741090746581456\n",
      "train loss:0.8967923171136566\n",
      "train loss:1.1514998312598994\n",
      "train loss:0.8800657120928608\n",
      "train loss:0.9930379201155691\n",
      "train loss:0.9930102585983519\n",
      "train loss:0.9164819035553236\n",
      "train loss:0.9981803943478903\n",
      "train loss:0.8727658463121586\n",
      "train loss:0.848688046401376\n",
      "train loss:1.0039577753157085\n",
      "train loss:1.0192443688557478\n",
      "train loss:0.9676403008072626\n",
      "train loss:1.0669241358488148\n",
      "train loss:0.9886623877763232\n",
      "train loss:0.7971956429031234\n",
      "train loss:0.9057982158236905\n",
      "train loss:0.902398620011592\n",
      "train loss:0.9498725636166505\n",
      "train loss:0.9784991547837782\n",
      "train loss:0.8549795942452127\n",
      "train loss:1.0494191614571846\n",
      "train loss:0.9269239266499076\n",
      "train loss:1.0626202909514024\n",
      "train loss:1.0197244442099107\n",
      "train loss:0.8622083905217146\n",
      "train loss:0.8427894924858318\n",
      "train loss:0.8037228565207907\n",
      "train loss:0.8422851122754114\n",
      "train loss:1.0795983930995439\n",
      "train loss:0.9786183202208103\n",
      "train loss:0.914086587649373\n",
      "train loss:1.0278870070206123\n",
      "train loss:0.9600327599827296\n",
      "train loss:1.0677800373395294\n",
      "train loss:0.9236459383193788\n",
      "train loss:1.0613613901204817\n",
      "train loss:0.8582682969976554\n",
      "train loss:0.9880092284845852\n",
      "train loss:1.080434203907346\n",
      "train loss:0.796399671241637\n",
      "train loss:0.9169328895390261\n",
      "train loss:0.997196943279435\n",
      "train loss:0.8709190903292316\n",
      "train loss:0.9059396316560541\n",
      "train loss:0.9087057664568341\n",
      "train loss:0.9105534055094505\n",
      "train loss:0.8841590942739113\n",
      "train loss:1.0982984850635615\n",
      "train loss:0.9690491840470717\n",
      "train loss:0.9690218186924732\n",
      "train loss:0.9214440990078941\n",
      "train loss:0.8427263630322308\n",
      "train loss:0.9626380689984437\n",
      "train loss:0.9072214922014997\n",
      "train loss:1.0748432219026938\n",
      "train loss:0.9576881235332528\n",
      "train loss:0.8837137860213297\n",
      "train loss:0.7952435783494581\n",
      "train loss:0.7923232316712628\n",
      "train loss:0.834199339683952\n",
      "train loss:1.0320389800848333\n",
      "train loss:0.8075110591520445\n",
      "train loss:1.2285442302092306\n",
      "train loss:0.9632448267026418\n",
      "train loss:0.8882141381211349\n",
      "train loss:0.9615250649317275\n",
      "train loss:0.9494342176063584\n",
      "train loss:1.1152848784483615\n",
      "train loss:0.9048522830233161\n",
      "train loss:0.8288513745727344\n",
      "train loss:1.0524089795219025\n",
      "train loss:1.0148920010179452\n",
      "train loss:0.9046908711099942\n",
      "train loss:0.8581814684974803\n",
      "train loss:0.9970915879257827\n",
      "train loss:0.88296269277929\n",
      "train loss:1.0135220242462435\n",
      "train loss:0.9685292787571055\n",
      "train loss:1.0094884081320457\n",
      "train loss:0.8134566207625501\n",
      "train loss:0.7372280609563907\n",
      "train loss:0.8851993459296065\n",
      "train loss:1.0039047892196784\n",
      "train loss:0.9354851303400706\n",
      "train loss:0.9578503225335868\n",
      "train loss:0.9351223561814934\n",
      "train loss:0.9656156264168682\n",
      "train loss:0.9529654550634639\n",
      "train loss:0.9167103248525328\n",
      "train loss:0.9242916253508021\n",
      "train loss:0.8250032518056417\n",
      "train loss:0.9822937429899347\n",
      "train loss:1.071422033222254\n",
      "=== epoch:4, train acc:0.989, test acc:0.987 ===\n",
      "train loss:0.9595068637328257\n",
      "train loss:1.1284651233908773\n",
      "train loss:0.8905131049445062\n",
      "train loss:0.8940105500314975\n",
      "train loss:1.0209739602660548\n",
      "train loss:1.0915391541355997\n",
      "train loss:0.9020310226056015\n",
      "train loss:0.9442479542079393\n",
      "train loss:1.0509074641880252\n",
      "train loss:0.8678821041606358\n",
      "train loss:1.0150871322188955\n",
      "train loss:0.7986488943863109\n",
      "train loss:1.1417346430838704\n",
      "train loss:0.9947508335731419\n",
      "train loss:0.9461447269341144\n",
      "train loss:0.9883797422896151\n",
      "train loss:1.0275341837270506\n",
      "train loss:0.8552411607023012\n",
      "train loss:1.0785290437704567\n",
      "train loss:0.9160285758534947\n",
      "train loss:1.0758994849819314\n",
      "train loss:0.9046075682849856\n",
      "train loss:1.0101241527199991\n",
      "train loss:0.9403692586376077\n",
      "train loss:0.8675747461022751\n",
      "train loss:0.8381512856675544\n",
      "train loss:0.837138211901664\n",
      "train loss:0.7752371663937048\n",
      "train loss:0.9784694569063987\n",
      "train loss:0.9192991717889388\n",
      "train loss:1.0044016635475475\n",
      "train loss:0.896552994404906\n",
      "train loss:0.7828105633186239\n",
      "train loss:0.9664726401549076\n",
      "train loss:1.033387623184947\n",
      "train loss:0.9729182540838189\n",
      "train loss:0.8129252938870307\n",
      "train loss:1.0459861210100898\n",
      "train loss:0.9943258200241712\n",
      "train loss:0.9427532664077636\n",
      "train loss:0.9059472262101969\n",
      "train loss:0.9715640416323701\n",
      "train loss:0.9121829348593984\n",
      "train loss:1.0383093902396912\n",
      "train loss:0.9201931866348981\n",
      "train loss:1.0254199024795954\n",
      "train loss:0.9539409896408462\n",
      "train loss:0.9535293039379468\n",
      "train loss:0.9098713829611522\n",
      "train loss:1.0022196097251261\n",
      "train loss:0.8780262370422488\n",
      "train loss:0.9685604997136437\n",
      "train loss:0.9943103987599972\n",
      "train loss:0.8741309675342821\n",
      "train loss:0.8830991415880799\n",
      "train loss:0.7335958620059476\n",
      "train loss:0.955071600474037\n",
      "train loss:0.9402053385330514\n",
      "train loss:0.8169955720708812\n",
      "train loss:1.1024001936180765\n",
      "train loss:0.9845697905968255\n",
      "train loss:0.8931867872493274\n",
      "train loss:0.8095218874644423\n",
      "train loss:0.8870010635835471\n",
      "train loss:0.9759321199916815\n",
      "train loss:0.8499042925062684\n",
      "train loss:1.0502365155939364\n",
      "train loss:0.7198751495853039\n",
      "train loss:0.7591292307021711\n",
      "train loss:0.974949297301442\n",
      "train loss:0.9357482390370386\n",
      "train loss:0.9174705026375475\n",
      "train loss:0.988905348682068\n",
      "train loss:0.9024177003629437\n",
      "train loss:0.9953648837446658\n",
      "train loss:0.9725460715459758\n",
      "train loss:0.9710647640179694\n",
      "train loss:0.9967227891124546\n",
      "train loss:0.8930097822748625\n",
      "train loss:0.937992123710952\n",
      "train loss:0.9274378392707342\n",
      "train loss:0.935307781008526\n",
      "train loss:1.0471257589234841\n",
      "train loss:0.9271235567405341\n",
      "train loss:0.9288559472442668\n",
      "train loss:0.9896814927441128\n",
      "train loss:1.0918761572147853\n",
      "train loss:0.9878979546067275\n",
      "train loss:0.9140826947850552\n",
      "train loss:0.9509018904776911\n",
      "train loss:0.9033692078361704\n",
      "train loss:0.8777775508441192\n",
      "train loss:0.9167409880973308\n",
      "train loss:0.9691046538167032\n",
      "train loss:0.8943446702766967\n",
      "train loss:0.9510493750566641\n",
      "train loss:1.0352770234216564\n",
      "train loss:0.7286655598663512\n",
      "train loss:1.0317408388551519\n",
      "train loss:0.9033898920225798\n",
      "train loss:0.9474386106754565\n",
      "train loss:0.9931126511688749\n",
      "train loss:0.9354027050086848\n",
      "train loss:1.0205245948163273\n",
      "train loss:1.0044673816327125\n",
      "train loss:0.7685337376221626\n",
      "train loss:0.9474091647796764\n",
      "train loss:0.9905584120584513\n",
      "train loss:1.1044355372846755\n",
      "train loss:1.0850545144022206\n",
      "train loss:1.130981431203655\n",
      "train loss:0.69104597852192\n",
      "train loss:0.8641026405945484\n",
      "train loss:0.9901587675213668\n",
      "train loss:0.774557605119925\n",
      "train loss:1.1854956129940755\n",
      "train loss:0.9246902233196278\n",
      "train loss:1.0392522126009303\n",
      "train loss:1.0461950376942661\n",
      "train loss:1.1031149329695962\n",
      "train loss:1.0425529335678834\n",
      "train loss:0.9769028486943654\n",
      "train loss:0.9213092014535146\n",
      "train loss:0.9716008529295621\n",
      "train loss:0.8830949234232809\n",
      "train loss:0.9620487654536791\n",
      "train loss:1.1293659438167558\n",
      "train loss:0.8565678113317411\n",
      "train loss:0.9124624544765547\n",
      "train loss:0.9070914854033151\n",
      "train loss:0.9292600717396544\n",
      "train loss:0.9286260972669363\n",
      "train loss:0.8775590942712487\n",
      "train loss:0.8970118201114918\n",
      "train loss:1.0298186214366138\n",
      "train loss:1.0640887755685138\n",
      "train loss:0.9237520112419797\n",
      "train loss:0.8934785899948475\n",
      "train loss:1.093776558526806\n",
      "train loss:0.869413889927134\n",
      "train loss:0.8410367991600315\n",
      "train loss:0.8460107525702968\n",
      "train loss:0.9477934023677939\n",
      "train loss:0.9954071524714924\n",
      "train loss:0.9238650595906129\n",
      "train loss:1.0510692589099486\n",
      "train loss:0.9897011999630917\n",
      "train loss:0.841791590894904\n",
      "train loss:0.9238955873218352\n",
      "train loss:1.129703169785487\n",
      "train loss:0.9415017595785179\n",
      "train loss:0.8345027475996808\n",
      "train loss:0.8967867222012252\n",
      "train loss:0.9213335653580655\n",
      "train loss:0.9053444511207531\n",
      "train loss:0.8634523133813151\n",
      "train loss:1.0317224484254326\n",
      "train loss:1.018823838022411\n",
      "train loss:0.9964528748617894\n",
      "train loss:0.8059575697258144\n",
      "train loss:1.014621046068152\n",
      "train loss:0.8168571624414431\n",
      "train loss:0.929207316023824\n",
      "train loss:1.0699290063919946\n",
      "train loss:0.9504542339816605\n",
      "train loss:0.80021284426354\n",
      "train loss:1.0169212131188246\n",
      "train loss:0.9816664764185922\n",
      "train loss:1.013077360719551\n",
      "train loss:0.8336615018454965\n",
      "train loss:1.0267173755768737\n",
      "train loss:0.8941359181998094\n",
      "train loss:1.0375539838010663\n",
      "train loss:0.9722201225599156\n",
      "train loss:0.8651073897313245\n",
      "train loss:0.7777773765141843\n",
      "train loss:0.9170999867144005\n",
      "train loss:1.1450781910827583\n",
      "train loss:0.8352461252691633\n",
      "train loss:0.9632310457838446\n",
      "train loss:1.0205897291606234\n",
      "train loss:0.9596163842434929\n",
      "train loss:0.9502037330739113\n",
      "train loss:0.7881705609567595\n",
      "train loss:0.8949748360552442\n",
      "train loss:1.0072165327071463\n",
      "train loss:0.8034034153766352\n",
      "train loss:0.9645855130747039\n",
      "train loss:0.9571255434589938\n",
      "train loss:0.8588368439470193\n",
      "train loss:0.9961337351232263\n",
      "train loss:1.00207533927465\n",
      "train loss:1.0956668589968235\n",
      "train loss:0.8634913413489828\n",
      "train loss:0.8590872694224477\n",
      "train loss:0.8591972237397582\n",
      "train loss:1.0765638072622175\n",
      "train loss:0.733303441626992\n",
      "train loss:0.9213923438845099\n",
      "train loss:0.9918087521792348\n",
      "train loss:1.1929481554755443\n",
      "train loss:0.886890336113155\n",
      "train loss:1.0503736899875613\n",
      "train loss:1.0159833318720184\n",
      "train loss:0.955027260734538\n",
      "train loss:0.84291771784061\n",
      "train loss:1.0059765445457172\n",
      "train loss:0.8752492915697444\n",
      "train loss:0.8603316441514116\n",
      "train loss:0.816916193260295\n",
      "train loss:1.1268303803138697\n",
      "train loss:1.013070989776206\n",
      "train loss:0.8194901153049817\n",
      "train loss:0.8984115886975392\n",
      "train loss:0.7589182758437275\n",
      "train loss:1.0481527988045258\n",
      "train loss:1.0508854747902012\n",
      "train loss:1.0858665642802132\n",
      "train loss:0.8181014275122915\n",
      "train loss:0.8437669649933774\n",
      "train loss:0.9435194577313877\n",
      "train loss:1.0579529704955524\n",
      "train loss:1.0019170983689563\n",
      "train loss:0.8223374286310728\n",
      "train loss:0.8748419838304379\n",
      "train loss:0.869776642479864\n",
      "train loss:1.139432059620979\n",
      "train loss:0.8809129831913642\n",
      "train loss:1.0303702460967237\n",
      "train loss:1.270193334649523\n",
      "train loss:0.9694921108703903\n",
      "train loss:0.8957044886484599\n",
      "train loss:1.0072239451340808\n",
      "train loss:0.9831791826448177\n",
      "train loss:0.8172808588773226\n",
      "train loss:1.0012640055517978\n",
      "train loss:0.9644075498828797\n",
      "train loss:0.8037480006851456\n",
      "train loss:0.9084502532947251\n",
      "train loss:0.9256561278321245\n",
      "train loss:0.8544173455087589\n",
      "train loss:0.9853087417785455\n",
      "train loss:0.8394329332120246\n",
      "train loss:0.8540630284805404\n",
      "train loss:0.8799167009356605\n",
      "train loss:0.903160801625948\n",
      "train loss:0.8163878925165433\n",
      "train loss:0.9509606162119695\n",
      "train loss:0.9461634524384879\n",
      "train loss:0.9072361716875228\n",
      "train loss:0.9759004064805861\n",
      "train loss:1.0314567694673102\n",
      "train loss:0.9509806496838642\n",
      "train loss:1.0135674748288839\n",
      "train loss:1.0317608040726745\n",
      "train loss:0.9604283599793283\n",
      "train loss:0.8408931443899743\n",
      "train loss:0.9976600166579931\n",
      "train loss:0.8257375919975445\n",
      "train loss:0.8047619989666801\n",
      "train loss:0.8205223516730732\n",
      "train loss:0.9339269879216948\n",
      "train loss:0.9308189732154019\n",
      "train loss:0.9303841369640453\n",
      "train loss:1.0659162802487707\n",
      "train loss:0.7770295220658572\n",
      "train loss:0.885357229696395\n",
      "train loss:0.9643239248354698\n",
      "train loss:0.7424563763932547\n",
      "train loss:0.8893048710971897\n",
      "train loss:0.8931861245909913\n",
      "train loss:0.8476974483515072\n",
      "train loss:0.8960455221534193\n",
      "train loss:0.876000771581861\n",
      "train loss:1.0969746778976104\n",
      "train loss:0.9958341418495351\n",
      "train loss:0.9159007101407965\n",
      "train loss:0.8786673788341355\n",
      "train loss:1.1164724049940744\n",
      "train loss:0.9999319997261665\n",
      "train loss:0.8757501911712124\n",
      "train loss:0.8426108559942789\n",
      "train loss:0.836565800818299\n",
      "train loss:0.9447148726197476\n",
      "train loss:0.9072566298009351\n",
      "train loss:1.0024058192433931\n",
      "train loss:0.8642373866763658\n",
      "train loss:0.733551198764025\n",
      "train loss:1.0153653470228792\n",
      "train loss:0.9788017546211321\n",
      "train loss:0.7465387521914778\n",
      "train loss:0.8279187830530158\n",
      "train loss:0.8693137720543814\n",
      "train loss:0.909901596333996\n",
      "train loss:0.7978424081758846\n",
      "train loss:0.9563120056739529\n",
      "train loss:0.7989160218139273\n",
      "train loss:0.9018052957006774\n",
      "train loss:0.9540928690823267\n",
      "train loss:1.0481863939154539\n",
      "train loss:1.0750444860534036\n",
      "train loss:0.8833764111422721\n",
      "train loss:0.8307829387014085\n",
      "train loss:0.792455825757995\n",
      "train loss:1.0927310311080136\n",
      "train loss:0.9511341829980516\n",
      "train loss:0.9367013012894401\n",
      "train loss:0.8088967550106987\n",
      "train loss:0.792931038722123\n",
      "train loss:0.8934468723385018\n",
      "train loss:0.9683511459278523\n",
      "train loss:0.9193848241231413\n",
      "train loss:0.9564091600304265\n",
      "train loss:0.9130080426271799\n",
      "train loss:0.8782117197628395\n",
      "train loss:1.0169463416225648\n",
      "train loss:1.0715854741511799\n",
      "train loss:0.9069666234379083\n",
      "train loss:1.052380002205301\n",
      "train loss:0.9730849066676143\n",
      "train loss:1.1519984169094948\n",
      "train loss:0.9394547816852274\n",
      "train loss:0.9247449016476481\n",
      "train loss:0.8914322766877593\n",
      "train loss:0.799920928594799\n",
      "train loss:0.8559441161905332\n",
      "train loss:0.8035643593491854\n",
      "train loss:0.8397136378245151\n",
      "train loss:0.8624308218015595\n",
      "train loss:0.8653748145844987\n",
      "train loss:0.9028967130781119\n",
      "train loss:0.938622467343399\n",
      "train loss:0.8746233492086453\n",
      "train loss:0.9473897702813047\n",
      "train loss:0.9062132596127941\n",
      "train loss:0.8591729554061363\n",
      "train loss:0.9777444658823575\n",
      "train loss:0.9892093061231946\n",
      "train loss:0.8311766027337144\n",
      "train loss:0.8469055654141375\n",
      "train loss:0.7896279944740837\n",
      "train loss:0.9603971906939328\n",
      "train loss:1.037157590707178\n",
      "train loss:1.0128042222988412\n",
      "train loss:0.9995384332032949\n",
      "train loss:0.9899737596854911\n",
      "train loss:1.046018789685421\n",
      "train loss:1.1279198582007874\n",
      "train loss:1.0695666006857798\n",
      "train loss:0.8833281223874565\n",
      "train loss:0.9626237980893868\n",
      "train loss:0.9397867705093319\n",
      "train loss:0.8643413084917195\n",
      "train loss:0.9483197473201868\n",
      "train loss:1.028682158899583\n",
      "train loss:0.9137094326210434\n",
      "train loss:0.9078760083082099\n",
      "train loss:0.9784111712775045\n",
      "train loss:0.7714358907417045\n",
      "train loss:0.9705443452904171\n",
      "train loss:0.879755936030376\n",
      "train loss:0.7133657787605527\n",
      "train loss:0.8837906659868127\n",
      "train loss:1.0029424086520187\n",
      "train loss:0.931781879743686\n",
      "train loss:0.7093991169850139\n",
      "train loss:0.7336434661037589\n",
      "train loss:0.9602360784280082\n",
      "train loss:0.8714054123384284\n",
      "train loss:0.8987420287040675\n",
      "train loss:0.8746513494361949\n",
      "train loss:0.7923985422557287\n",
      "train loss:0.9783641106124387\n",
      "train loss:0.9724003003184264\n",
      "train loss:0.9142910766460127\n",
      "train loss:1.009200277859722\n",
      "train loss:0.9720911732815953\n",
      "train loss:0.8077652355823551\n",
      "train loss:1.0053242346309208\n",
      "train loss:0.797834791929312\n",
      "train loss:0.9333726421289567\n",
      "train loss:0.8072799725173314\n",
      "train loss:0.9135134179786758\n",
      "train loss:0.9381747168839132\n",
      "train loss:0.8638376200873256\n",
      "train loss:0.9684315074653059\n",
      "train loss:0.877401381362517\n",
      "train loss:1.0514234235146644\n",
      "train loss:0.8794591441209647\n",
      "train loss:0.9381744528010293\n",
      "train loss:0.9798818891463277\n",
      "train loss:0.9003385031033757\n",
      "train loss:0.8044302889410821\n",
      "train loss:0.9308395978803041\n",
      "train loss:0.8701654736150646\n",
      "train loss:0.9721748217009114\n",
      "train loss:0.8334708023058165\n",
      "train loss:0.9155160157081645\n",
      "train loss:1.0226514165465204\n",
      "train loss:0.812829993191015\n",
      "train loss:0.9565764720986771\n",
      "train loss:0.8961874991002651\n",
      "train loss:0.9683211672785914\n",
      "train loss:0.943099314979505\n",
      "train loss:0.9524843144705284\n",
      "train loss:0.8757002306439836\n",
      "train loss:0.9848782373470633\n",
      "train loss:0.7317896397546242\n",
      "train loss:0.7344757467902372\n",
      "train loss:1.0070226975803032\n",
      "train loss:0.9517073037071553\n",
      "train loss:0.9037362072828482\n",
      "train loss:0.8266290522868424\n",
      "train loss:0.8610617741017434\n",
      "train loss:1.029272840844911\n",
      "train loss:0.9119400095442783\n",
      "train loss:0.887343537964602\n",
      "train loss:0.8613696319098332\n",
      "train loss:0.981762614552094\n",
      "train loss:0.941588587882367\n",
      "train loss:0.9931637481554639\n",
      "train loss:0.9822501043637706\n",
      "train loss:0.9357340115677799\n",
      "train loss:1.0134103326887425\n",
      "train loss:0.8722436805562128\n",
      "train loss:1.0439141829632599\n",
      "train loss:0.8224310399042275\n",
      "train loss:0.9786250202444664\n",
      "train loss:0.9152639541042561\n",
      "train loss:0.7320836001107314\n",
      "train loss:0.8549085038640274\n",
      "train loss:0.8957592731704059\n",
      "train loss:0.9483616502338027\n",
      "train loss:0.9009384705301415\n",
      "train loss:0.810302473162879\n",
      "train loss:0.8788676898602104\n",
      "train loss:1.042852908093082\n",
      "train loss:0.8296884946461641\n",
      "train loss:0.9353139888520601\n",
      "train loss:1.037084988523983\n",
      "train loss:0.8681685983207146\n",
      "train loss:0.7945840078426225\n",
      "train loss:0.9187499318695516\n",
      "train loss:0.9039816999604321\n",
      "train loss:0.900108177691464\n",
      "train loss:1.0241812797258831\n",
      "train loss:0.9605057436413128\n",
      "train loss:0.8642268958683905\n",
      "train loss:1.0781924287207116\n",
      "train loss:1.0156886552304416\n",
      "train loss:0.696088874523709\n",
      "train loss:0.888498654350707\n",
      "train loss:0.8911487737126784\n",
      "train loss:0.8332601244034072\n",
      "train loss:0.8549173234289558\n",
      "train loss:0.9002731356059721\n",
      "train loss:0.8453968120935188\n",
      "train loss:1.0221492902287053\n",
      "train loss:1.0486775450225114\n",
      "train loss:0.7349787605340122\n",
      "train loss:1.0568314738510265\n",
      "train loss:0.9939463338911082\n",
      "train loss:0.8887959386184078\n",
      "train loss:1.0633554280420112\n",
      "train loss:0.8911116810695067\n",
      "train loss:0.9964119678985017\n",
      "train loss:1.039967414225499\n",
      "train loss:0.8420107390685924\n",
      "train loss:0.8525742367516144\n",
      "train loss:0.9740297730448999\n",
      "train loss:0.9929408048388351\n",
      "train loss:0.8724354807979234\n",
      "train loss:0.9000444140875417\n",
      "train loss:0.9152557401358511\n",
      "train loss:1.1132690756300319\n",
      "train loss:1.009308532635425\n",
      "train loss:0.8698188502088816\n",
      "train loss:1.0479623534517608\n",
      "train loss:0.9656568133906618\n",
      "train loss:0.9088737494649252\n",
      "train loss:0.9174283048547871\n",
      "train loss:0.981733338447928\n",
      "train loss:0.8756216046332674\n",
      "train loss:0.84335687836407\n",
      "train loss:0.7322227131468851\n",
      "train loss:0.9233162666123306\n",
      "train loss:0.826250108566225\n",
      "train loss:0.8724398104610555\n",
      "train loss:0.8397033208559054\n",
      "train loss:1.0894481431736962\n",
      "train loss:1.0079474927314103\n",
      "train loss:0.863419972105193\n",
      "train loss:0.7806834716980857\n",
      "train loss:0.8686684191637601\n",
      "train loss:0.9331619770964692\n",
      "train loss:1.075295594465364\n",
      "train loss:1.0741043615868278\n",
      "train loss:0.7786733758763745\n",
      "train loss:0.7901406354413486\n",
      "train loss:0.9282793677873546\n",
      "train loss:0.8974626645047303\n",
      "train loss:0.973847725754882\n",
      "train loss:0.8693544308760444\n",
      "train loss:0.8304589020416532\n",
      "train loss:0.7848731224656014\n",
      "train loss:1.1065484229160776\n",
      "train loss:0.8541755152901502\n",
      "train loss:0.861872709367033\n",
      "train loss:0.7339951614652566\n",
      "train loss:0.9578898019330458\n",
      "train loss:0.9075891966512062\n",
      "train loss:0.9034035373697837\n",
      "train loss:0.9237539154842344\n",
      "train loss:0.8762804882819668\n",
      "train loss:0.8692060083329585\n",
      "train loss:0.9574066916814711\n",
      "train loss:0.8966933160842785\n",
      "train loss:0.8074805387731929\n",
      "train loss:0.8900019085577915\n",
      "train loss:0.7877458197453028\n",
      "train loss:0.8400575113866361\n",
      "train loss:0.986642499342336\n",
      "train loss:0.8706388232064742\n",
      "train loss:0.8971296347805823\n",
      "train loss:0.8135457194369334\n",
      "train loss:0.7918992696145416\n",
      "train loss:0.8465675764405102\n",
      "train loss:0.9315458909830278\n",
      "train loss:0.8021146581644014\n",
      "train loss:0.8593537084431359\n",
      "train loss:0.8452081060258244\n",
      "train loss:0.9081399561491669\n",
      "train loss:1.0921095007804853\n",
      "train loss:0.8645520575115332\n",
      "train loss:0.8675287281347666\n",
      "train loss:0.8966515486207234\n",
      "train loss:0.8124889389426891\n",
      "train loss:1.071776331407067\n",
      "train loss:0.9026481998461304\n",
      "train loss:0.9310320932527536\n",
      "train loss:0.974600632816055\n",
      "train loss:0.8224353803223532\n",
      "train loss:0.9780090047703288\n",
      "train loss:0.9992029900737623\n",
      "train loss:0.8340357918476725\n",
      "train loss:0.9707113758430814\n",
      "train loss:0.8971195568498842\n",
      "train loss:0.9549909550983715\n",
      "train loss:0.6940998877104715\n",
      "train loss:1.1990035967289367\n",
      "train loss:0.9054094380257078\n",
      "train loss:0.9898632268225485\n",
      "train loss:0.8175835293790108\n",
      "train loss:0.9612357297893223\n",
      "train loss:0.8186783980913094\n",
      "train loss:0.9193202853073594\n",
      "train loss:0.7909557394149713\n",
      "train loss:0.9090754495560992\n",
      "train loss:0.8729203007407975\n",
      "train loss:0.7948227942359618\n",
      "train loss:0.9643489044587444\n",
      "train loss:0.8829853624568921\n",
      "train loss:0.9433310074518019\n",
      "train loss:0.9519450157485084\n",
      "train loss:0.9320589524585341\n",
      "train loss:0.9229401054629979\n",
      "train loss:0.8109605515189571\n",
      "train loss:0.8487171250902648\n",
      "train loss:0.9877031200074289\n",
      "train loss:0.9378938650949078\n",
      "train loss:0.7423379898212672\n",
      "train loss:0.9625867749700864\n",
      "train loss:1.079218173219063\n",
      "train loss:0.9077056491620301\n",
      "train loss:0.8581962731399235\n",
      "train loss:1.0198764088292651\n",
      "train loss:0.8351776233760065\n",
      "train loss:1.0850141135214395\n",
      "train loss:0.8312436639632494\n",
      "train loss:0.8341333945144787\n",
      "train loss:0.9649423034672897\n",
      "train loss:1.0243146854065721\n",
      "train loss:0.9856693651638027\n",
      "train loss:0.9007483171945587\n",
      "train loss:0.9920915132166925\n",
      "train loss:0.8945869226538314\n",
      "train loss:0.9201498600419725\n",
      "train loss:0.9508927161382879\n",
      "train loss:0.962631468771585\n",
      "train loss:0.9944841998347491\n",
      "train loss:0.9146106986318862\n",
      "train loss:1.0513894519827969\n",
      "train loss:0.8421364302347765\n",
      "train loss:0.7175301148151318\n",
      "train loss:0.8410214610317872\n",
      "train loss:0.797434307887076\n",
      "train loss:0.9009125056077444\n",
      "train loss:0.9561655097106707\n",
      "train loss:0.7824939867406708\n",
      "train loss:0.904193087192586\n",
      "=== epoch:5, train acc:0.992, test acc:0.991 ===\n",
      "train loss:1.0528961915386266\n",
      "train loss:0.7661563993915742\n",
      "train loss:0.7735988814974094\n",
      "train loss:0.8737320935650094\n",
      "train loss:1.028363467341547\n",
      "train loss:0.7800666743916009\n",
      "train loss:0.8777824481002756\n",
      "train loss:0.9663290101543407\n",
      "train loss:0.9807875645014988\n",
      "train loss:1.0781643646644679\n",
      "train loss:1.077974498619466\n",
      "train loss:1.001020610699592\n",
      "train loss:0.9536982461972776\n",
      "train loss:0.8076481972761155\n",
      "train loss:0.8834668798937372\n",
      "train loss:0.756096745662846\n",
      "train loss:0.8757001837628922\n",
      "train loss:0.9780353634994228\n",
      "train loss:0.8056970368706553\n",
      "train loss:0.9916075193625628\n",
      "train loss:0.9910392299977369\n",
      "train loss:0.9905904115169867\n",
      "train loss:1.1330074884022479\n",
      "train loss:0.8827713283670029\n",
      "train loss:0.89673705136148\n",
      "train loss:1.0627498651634104\n",
      "train loss:1.0277275528465877\n",
      "train loss:1.163717689876946\n",
      "train loss:0.9047388087423779\n",
      "train loss:0.7042550441407052\n",
      "train loss:0.8062991121062939\n",
      "train loss:0.8797908629211306\n",
      "train loss:0.8985866357217516\n",
      "train loss:1.0183836004884903\n",
      "train loss:0.9343795940497174\n",
      "train loss:0.8555609729289213\n",
      "train loss:0.8260852727870156\n",
      "train loss:0.8791305303994542\n",
      "train loss:0.903617852564136\n",
      "train loss:0.7637083003612113\n",
      "train loss:1.0912730788248564\n",
      "train loss:0.8329382075975229\n",
      "train loss:0.904717937955308\n",
      "train loss:0.9436025555338802\n",
      "train loss:0.9780553528907648\n",
      "train loss:0.963935096439279\n",
      "train loss:1.1758907577108677\n",
      "train loss:1.0092692935797225\n",
      "train loss:0.8631475858124105\n",
      "train loss:0.7019935995005016\n",
      "train loss:0.9274111865769511\n",
      "train loss:0.7782784921113576\n",
      "train loss:0.8924808248832793\n",
      "train loss:0.8556004150692432\n",
      "train loss:0.809263246254895\n",
      "train loss:0.9329193457195433\n",
      "train loss:0.848080707354621\n",
      "train loss:1.0205881637700258\n",
      "train loss:1.0124511968393746\n",
      "train loss:0.9118639576927385\n",
      "train loss:0.9817834320928469\n",
      "train loss:0.957394843142524\n",
      "train loss:1.0235786406484282\n",
      "train loss:0.9851739080385568\n",
      "train loss:0.9015728896765859\n",
      "train loss:0.9502449007512106\n",
      "train loss:0.9353934767832552\n",
      "train loss:0.8741113841684492\n",
      "train loss:0.8707436925855998\n",
      "train loss:1.0490214752722984\n",
      "train loss:1.0264240944408758\n",
      "train loss:0.8272990925486395\n",
      "train loss:0.9251712858352603\n",
      "train loss:0.9764221706944615\n",
      "train loss:1.1117504402766099\n",
      "train loss:0.8904995323805781\n",
      "train loss:0.660857746228081\n",
      "train loss:0.8797315699452054\n",
      "train loss:0.8911742263255181\n",
      "train loss:1.132582429877037\n",
      "train loss:0.8707945358634979\n",
      "train loss:1.0688097320953016\n",
      "train loss:0.7808491241171923\n",
      "train loss:0.8267957308391394\n",
      "train loss:1.0324576494468372\n",
      "train loss:0.767772790905907\n",
      "train loss:0.8571048210163584\n",
      "train loss:0.7988707896681543\n",
      "train loss:0.8530774026263643\n",
      "train loss:0.9052391086340106\n",
      "train loss:0.7939622530340747\n",
      "train loss:0.9123995918083965\n",
      "train loss:0.7843352418784297\n",
      "train loss:0.9766111276294152\n",
      "train loss:0.9459808335520162\n",
      "train loss:1.0511564902353734\n",
      "train loss:0.9257744020307769\n",
      "train loss:0.9545169712115321\n",
      "train loss:0.9414134814763763\n",
      "train loss:0.8220770681648731\n",
      "train loss:0.936558640013528\n",
      "train loss:0.8184082637458796\n",
      "train loss:0.9815619048085569\n",
      "train loss:0.8836657284130776\n",
      "train loss:1.0424004459640317\n",
      "train loss:0.978609494038852\n",
      "train loss:1.0393776074280208\n",
      "train loss:1.0174318383725223\n",
      "train loss:0.9820131735013442\n",
      "train loss:0.8724293494333045\n",
      "train loss:0.8592155294157502\n",
      "train loss:0.8530915566021346\n",
      "train loss:0.9430182326811455\n",
      "train loss:0.9271889949429493\n",
      "train loss:0.9327192605870281\n",
      "train loss:0.9033221594106878\n",
      "train loss:0.9307729233682916\n",
      "train loss:0.9707411492800938\n",
      "train loss:0.9073240630711923\n",
      "train loss:1.0216374579232115\n",
      "train loss:0.8598871024438273\n",
      "train loss:1.078590833153694\n",
      "train loss:1.1053757520729628\n",
      "train loss:1.0735668476693545\n",
      "train loss:1.002504647377676\n",
      "train loss:0.9269522585335346\n",
      "train loss:0.8154415646427349\n",
      "train loss:0.8397778597944113\n",
      "train loss:0.8158692028347424\n",
      "train loss:1.113354696865203\n",
      "train loss:0.935658469344512\n",
      "train loss:0.9393337884005412\n",
      "train loss:0.9946951941510812\n",
      "train loss:0.9356220908681371\n",
      "train loss:0.875785453777623\n",
      "train loss:0.7781155048620988\n",
      "train loss:0.8121745494679153\n",
      "train loss:0.9055419497041464\n",
      "train loss:0.8729621404564136\n",
      "train loss:0.9446037588402995\n",
      "train loss:0.837942207634768\n",
      "train loss:1.1032234764295532\n",
      "train loss:0.8483119371307167\n",
      "train loss:0.8758397307529058\n",
      "train loss:0.8830206240077232\n",
      "train loss:0.8375876672890036\n",
      "train loss:0.8434709731098404\n",
      "train loss:1.0169280152663063\n",
      "train loss:0.8525374263029579\n",
      "train loss:0.9067820997951246\n",
      "train loss:0.9499657707096338\n",
      "train loss:0.9899141361324308\n",
      "train loss:0.946028390669611\n",
      "train loss:0.9469300022223395\n",
      "train loss:0.9180155950080957\n",
      "train loss:1.0622462610348573\n",
      "train loss:0.7580145785120403\n",
      "train loss:0.8648360150701063\n",
      "train loss:0.9966039844489871\n",
      "train loss:0.9753653684732694\n",
      "train loss:0.874780828257489\n",
      "train loss:1.0022611597342328\n",
      "train loss:0.9493152502997403\n",
      "train loss:0.9512124710017885\n",
      "train loss:0.9683137884186577\n",
      "train loss:0.9076026788347087\n",
      "train loss:0.7761041532512258\n",
      "train loss:1.00034150671008\n",
      "train loss:0.9516963009110877\n",
      "train loss:0.9356172846804108\n",
      "train loss:0.9835748854435151\n",
      "train loss:0.9726327822303098\n",
      "train loss:0.8734068423216909\n",
      "train loss:0.8497244667733453\n",
      "train loss:0.9923479613251684\n",
      "train loss:0.9411022992805439\n",
      "train loss:0.8578118017151813\n",
      "train loss:0.8360133277790834\n",
      "train loss:0.9168549591963905\n",
      "train loss:0.9226961193834475\n",
      "train loss:1.0218923572387155\n",
      "train loss:0.7834813544084857\n",
      "train loss:0.8566681869673141\n",
      "train loss:1.019371775564651\n",
      "train loss:0.9561482482361251\n",
      "train loss:0.8047980530383093\n",
      "train loss:0.9247315216826383\n",
      "train loss:1.0413989343185308\n",
      "train loss:0.9597281349781138\n",
      "train loss:0.848050146231236\n",
      "train loss:0.9512046265353988\n",
      "train loss:1.1476891318513855\n",
      "train loss:0.9851338460266139\n",
      "train loss:0.8318352227820514\n",
      "train loss:0.8921773264860158\n",
      "train loss:0.8647417222185255\n",
      "train loss:0.9865254981831147\n",
      "train loss:0.8970615316859896\n",
      "train loss:0.9363306475712281\n",
      "train loss:0.8405544990017778\n",
      "train loss:0.9129979221239747\n",
      "train loss:0.9666561314857322\n",
      "train loss:0.835995036514959\n",
      "train loss:0.7726379200596698\n",
      "train loss:0.7487530824571899\n",
      "train loss:0.8753796345262242\n",
      "train loss:0.7984068283527245\n",
      "train loss:0.9341439834072763\n",
      "train loss:0.8921254751595782\n",
      "train loss:0.8874828501763997\n",
      "train loss:0.7703929217608427\n",
      "train loss:0.8683244460721282\n",
      "train loss:0.9076046606506639\n",
      "train loss:0.786045833274425\n",
      "train loss:0.9389270187588269\n",
      "train loss:0.9779322528436596\n",
      "train loss:1.0681853051376278\n",
      "train loss:0.9579346463562852\n",
      "train loss:0.7951152123418349\n",
      "train loss:0.9954850723679676\n",
      "train loss:0.9358510086599645\n",
      "train loss:0.985236632406188\n",
      "train loss:0.7614489699956403\n",
      "train loss:0.8784710138252284\n",
      "train loss:0.9467491362205155\n",
      "train loss:1.117626652987412\n",
      "train loss:0.8974594919685515\n",
      "train loss:0.8697697179563331\n",
      "train loss:0.9875655645161109\n",
      "train loss:0.9901105536580284\n",
      "train loss:0.9840059725094018\n",
      "train loss:1.0535735292929362\n",
      "train loss:0.9526570326522702\n",
      "train loss:0.9469030693602595\n",
      "train loss:1.0928385161353442\n",
      "train loss:0.9803799906492715\n",
      "train loss:0.948282839012533\n",
      "train loss:1.0366579213331173\n",
      "train loss:0.9964714305986107\n",
      "train loss:0.9912954384294375\n",
      "train loss:0.9047642240973423\n",
      "train loss:0.9600029720490487\n",
      "train loss:0.9946138184199254\n",
      "train loss:0.9064795857145859\n",
      "train loss:0.890038894742678\n",
      "train loss:1.080706944656237\n",
      "train loss:0.806562919373565\n",
      "train loss:1.1598493189842838\n",
      "train loss:0.9189404207814204\n",
      "train loss:0.8447795690760523\n",
      "train loss:0.7580561094956636\n",
      "train loss:1.0276753049949063\n",
      "train loss:0.8227596666520399\n",
      "train loss:0.9159411352342436\n",
      "train loss:0.9119393537898268\n",
      "train loss:0.7763634063906492\n",
      "train loss:1.101349252787801\n",
      "train loss:0.8771434090485163\n",
      "train loss:0.8367818234069384\n",
      "train loss:0.7530002016021392\n",
      "train loss:0.8026563368437462\n",
      "train loss:0.8910178871182858\n",
      "train loss:1.0189675331946304\n",
      "train loss:0.8663688216961413\n",
      "train loss:0.9233915114192014\n",
      "train loss:1.0190826574034497\n",
      "train loss:0.865328722793941\n",
      "train loss:0.9658217454075806\n",
      "train loss:0.9031688296017896\n",
      "train loss:1.0274812930919852\n",
      "train loss:0.8918695802018789\n",
      "train loss:0.9879161545737806\n",
      "train loss:0.7759401142881635\n",
      "train loss:0.9679327219660244\n",
      "train loss:0.907830137253912\n",
      "train loss:0.8712261683029608\n",
      "train loss:0.9041425111440418\n",
      "train loss:0.8357968995617568\n",
      "train loss:0.8998835701273294\n",
      "train loss:1.019437915670369\n",
      "train loss:0.8696480450901596\n",
      "train loss:0.9189007212667949\n",
      "train loss:0.7269350285806905\n",
      "train loss:0.9124368986509437\n",
      "train loss:0.9336829095639351\n",
      "train loss:1.0414037004881223\n",
      "train loss:0.8232961208963708\n",
      "train loss:0.8039913615105213\n",
      "train loss:0.6851855211580623\n",
      "train loss:0.9454185651028107\n",
      "train loss:0.9786847514273908\n",
      "train loss:0.834971625790779\n",
      "train loss:1.004414289885654\n",
      "train loss:1.039515418696518\n",
      "train loss:0.9246321621583665\n",
      "train loss:1.198545707773175\n",
      "train loss:0.8400894987776301\n",
      "train loss:0.9291343179862444\n",
      "train loss:0.9193393954110314\n",
      "train loss:0.7889833270563561\n",
      "train loss:1.0251486294278351\n",
      "train loss:0.8901070218371352\n",
      "train loss:1.0763025250408713\n",
      "train loss:1.099447881922102\n",
      "train loss:1.0929796858823664\n",
      "train loss:0.9745252621890126\n",
      "train loss:1.0439134678065907\n",
      "train loss:0.8652085187885524\n",
      "train loss:0.9825552548494736\n",
      "train loss:0.843815556172144\n",
      "train loss:0.7180129700613835\n",
      "train loss:1.0338308859923417\n",
      "train loss:1.0423308624463505\n",
      "train loss:0.8205836168649334\n",
      "train loss:0.7675972368254055\n",
      "train loss:0.8155191383515823\n",
      "train loss:0.932661400442301\n",
      "train loss:0.8561221576997272\n",
      "train loss:0.9094368028333791\n",
      "train loss:0.8372750060289339\n",
      "train loss:0.7994172155334386\n",
      "train loss:0.8644604342483743\n",
      "train loss:0.8318503761405772\n",
      "train loss:0.8082289559197023\n",
      "train loss:0.8342237230502281\n",
      "train loss:0.7652373580786699\n",
      "train loss:1.0293296992315255\n",
      "train loss:0.8302728693116853\n",
      "train loss:0.9574881189037108\n",
      "train loss:0.7399779475910239\n",
      "train loss:0.9293883011708783\n",
      "train loss:0.993099326011153\n",
      "train loss:0.7357942038899594\n",
      "train loss:0.8072744863250573\n",
      "train loss:0.9124189543874784\n",
      "train loss:0.9386832072449386\n",
      "train loss:0.96017663103127\n",
      "train loss:0.8392761393085236\n",
      "train loss:0.9367700172823464\n",
      "train loss:0.8415785993287437\n",
      "train loss:0.84724862717623\n",
      "train loss:0.7759539690736665\n",
      "train loss:0.8103659592034398\n",
      "train loss:0.932561064369512\n",
      "train loss:0.8703008733261787\n",
      "train loss:0.852698872622314\n",
      "train loss:0.8639366946529289\n",
      "train loss:0.8697780895003032\n",
      "train loss:0.9985191235296953\n",
      "train loss:0.8618399858765653\n",
      "train loss:0.9849970242041848\n",
      "train loss:0.7850595756971641\n",
      "train loss:1.0375590047795678\n",
      "train loss:0.9061005324796256\n",
      "train loss:0.9404202482135139\n",
      "train loss:1.00751391116825\n",
      "train loss:0.9171538401204933\n",
      "train loss:0.9469793878532151\n",
      "train loss:0.8760497631645688\n",
      "train loss:0.8958344747496764\n",
      "train loss:0.9949776634561748\n",
      "train loss:0.7835885844190595\n",
      "train loss:0.9662847692243435\n",
      "train loss:1.016524998135961\n",
      "train loss:1.0022685061514531\n",
      "train loss:0.9324946267624561\n",
      "train loss:0.9308126490479312\n",
      "train loss:0.7290651077352169\n",
      "train loss:1.1698099970402145\n",
      "train loss:0.9383476840513625\n",
      "train loss:0.9069992212878717\n",
      "train loss:0.8575586517726304\n",
      "train loss:0.9428876684164734\n",
      "train loss:0.896882932862543\n",
      "train loss:1.165059773141702\n",
      "train loss:0.7337264867434216\n",
      "train loss:0.9447785258513416\n",
      "train loss:0.8347757299362124\n",
      "train loss:0.9644781179353603\n",
      "train loss:0.9859063090528677\n",
      "train loss:0.9881377922924612\n",
      "train loss:0.8024280200430606\n",
      "train loss:0.9835180994183714\n",
      "train loss:0.9759188717424437\n",
      "train loss:0.9730424923641585\n",
      "train loss:1.037432238734703\n",
      "train loss:0.8378351603965929\n",
      "train loss:0.8068607695383121\n",
      "train loss:0.834483003643803\n",
      "train loss:0.9210365060047317\n",
      "train loss:0.9041951354692185\n",
      "train loss:0.8472677050719163\n",
      "train loss:0.9015352413139456\n",
      "train loss:1.0772835559606297\n",
      "train loss:0.8195351766512238\n",
      "train loss:0.8384822194713916\n",
      "train loss:0.8334713420285056\n",
      "train loss:0.857049722011773\n",
      "train loss:0.8592244680332816\n",
      "train loss:0.9701558318995869\n",
      "train loss:0.8738677256247557\n",
      "train loss:0.9812713611195146\n",
      "train loss:0.8878102164267212\n",
      "train loss:0.9672274457257376\n",
      "train loss:0.8911486235890804\n",
      "train loss:0.9423049278680192\n",
      "train loss:0.846328703624111\n",
      "train loss:0.9647279487895564\n",
      "train loss:0.8970472291402964\n",
      "train loss:0.8697977422519086\n",
      "train loss:1.0540357753565608\n",
      "train loss:0.9825380796682149\n",
      "train loss:0.8592091165437995\n",
      "train loss:0.9492569785799708\n",
      "train loss:0.8165704734536061\n",
      "train loss:0.7874711823649793\n",
      "train loss:0.7354553400966403\n",
      "train loss:1.0706720790457256\n",
      "train loss:1.0062213341199604\n",
      "train loss:0.854170407174674\n",
      "train loss:1.015548048475978\n",
      "train loss:0.8701695489622492\n",
      "train loss:0.8666287115459432\n",
      "train loss:0.8608858601674789\n",
      "train loss:0.9982779369793425\n",
      "train loss:0.9673285302581022\n",
      "train loss:0.8807750364434785\n",
      "train loss:0.8813260113637734\n",
      "train loss:0.8551487312490648\n",
      "train loss:1.0678501329694046\n",
      "train loss:0.87424606343129\n",
      "train loss:0.9603686017054635\n",
      "train loss:0.9497107100872423\n",
      "train loss:0.768623628277862\n",
      "train loss:0.936788065259691\n",
      "train loss:0.8008387383495679\n",
      "train loss:0.9402847341238362\n",
      "train loss:0.923559760969332\n",
      "train loss:1.000211106233812\n",
      "train loss:0.824724551356925\n",
      "train loss:1.0081265849982852\n",
      "train loss:0.9273572103424746\n",
      "train loss:0.9219883797065895\n",
      "train loss:0.9566165749288029\n",
      "train loss:0.7191915613833642\n",
      "train loss:0.9954914933233241\n",
      "train loss:1.0600383669087947\n",
      "train loss:1.1358537793603378\n",
      "train loss:0.861613098663971\n",
      "train loss:0.9298197292087174\n",
      "train loss:0.828192537677754\n",
      "train loss:0.7682235703920651\n",
      "train loss:0.8599745161643172\n",
      "train loss:0.9341014083494563\n",
      "train loss:1.0036704853386178\n",
      "train loss:0.8350632337853754\n",
      "train loss:0.7329835242306559\n",
      "train loss:0.9692273929958067\n",
      "train loss:0.7827945870787275\n",
      "train loss:0.8342765417792787\n",
      "train loss:0.8893020595462757\n",
      "train loss:0.7518567531000079\n",
      "train loss:1.1443996029835508\n",
      "train loss:0.8414471751748223\n",
      "train loss:0.9224711701692769\n",
      "train loss:1.0827894074379538\n",
      "train loss:0.9245411172959617\n",
      "train loss:0.9102941995267583\n",
      "train loss:1.1166840905338389\n",
      "train loss:0.8684639299723679\n",
      "train loss:1.0602428272663074\n",
      "train loss:0.8109753736343852\n",
      "train loss:0.8157095850075428\n",
      "train loss:0.835396031078754\n",
      "train loss:0.965297375262507\n",
      "train loss:0.9068991702424976\n",
      "train loss:0.9661891486304538\n",
      "train loss:0.9868577372902482\n",
      "train loss:1.0838063677463032\n",
      "train loss:0.8718759550232797\n",
      "train loss:0.9696125647791987\n",
      "train loss:0.8409042779712411\n",
      "train loss:1.0078618244867161\n",
      "train loss:0.8542292177225\n",
      "train loss:0.96944349242248\n",
      "train loss:0.900665994334195\n",
      "train loss:0.9847089193907026\n",
      "train loss:0.9393282093976469\n",
      "train loss:0.9943083784110119\n",
      "train loss:0.7290703471925979\n",
      "train loss:0.8794441181234961\n",
      "train loss:1.0044380420553074\n",
      "train loss:0.7698009695790529\n",
      "train loss:0.9217579379262772\n",
      "train loss:0.8450172343075443\n",
      "train loss:1.0464677727635232\n",
      "train loss:1.031062988818799\n",
      "train loss:0.9011913829624484\n",
      "train loss:0.9539228756532279\n",
      "train loss:1.0134053250104578\n",
      "train loss:0.720436408517664\n",
      "train loss:0.9097618206188767\n",
      "train loss:0.7984655461318643\n",
      "train loss:0.8270231785782665\n",
      "train loss:1.0101920911283668\n",
      "train loss:0.9486931956701286\n",
      "train loss:0.9027269741135697\n",
      "train loss:0.9702580450840866\n",
      "train loss:0.8371666781464288\n",
      "train loss:0.8225076927593206\n",
      "train loss:1.0029496543926069\n",
      "train loss:0.8523620196748243\n",
      "train loss:0.8239636960020313\n",
      "train loss:1.0034374134641808\n",
      "train loss:1.0103734955898322\n",
      "train loss:0.9877150951211483\n",
      "train loss:0.9667439634428118\n",
      "train loss:1.0358306470150114\n",
      "train loss:1.009329976839976\n",
      "train loss:0.988076916673655\n",
      "train loss:0.8950393761380091\n",
      "train loss:0.9367930471993329\n",
      "train loss:0.9135667310738484\n",
      "train loss:0.9335697690061306\n",
      "train loss:0.7952391529581311\n",
      "train loss:0.8481745772803958\n",
      "train loss:0.8591850171875133\n",
      "train loss:0.8961377559153074\n",
      "train loss:0.7710282267191418\n",
      "train loss:0.7573737636027086\n",
      "train loss:0.8514619469833283\n",
      "train loss:0.871477244381994\n",
      "train loss:0.8620994221188445\n",
      "train loss:0.8336436671111562\n",
      "train loss:0.9436318912696258\n",
      "train loss:0.7279463146339453\n",
      "train loss:0.8944189809434802\n",
      "train loss:0.8835678715485055\n",
      "train loss:0.9316465535050571\n",
      "train loss:0.9104159472464909\n",
      "train loss:0.7807062602335209\n",
      "train loss:0.87202123981642\n",
      "train loss:0.884883058302957\n",
      "train loss:0.983286743144763\n",
      "train loss:1.0037848742583402\n",
      "train loss:0.8287795044459874\n",
      "train loss:0.9889018519940221\n",
      "train loss:0.9051297451453623\n",
      "train loss:0.9004812307736769\n",
      "train loss:0.8547889197267495\n",
      "train loss:0.9098337176555362\n",
      "train loss:0.8316182818668107\n",
      "train loss:0.9024674234350022\n",
      "train loss:0.8490157706155327\n",
      "train loss:1.0107053185586556\n",
      "train loss:0.8517811459678059\n",
      "train loss:0.995173408538769\n",
      "train loss:0.8990859186516745\n",
      "train loss:1.0354072804482046\n",
      "train loss:1.038694441960741\n",
      "train loss:1.0905042244190029\n",
      "train loss:1.1206518643930257\n",
      "train loss:0.8825578368841637\n",
      "train loss:1.0146738930560708\n",
      "train loss:0.9329297102770664\n",
      "train loss:1.0092170859906464\n",
      "train loss:0.897373467659687\n",
      "train loss:0.8756695127698554\n",
      "train loss:0.8075256266290637\n",
      "train loss:0.9899765165827727\n",
      "train loss:0.8895702922036489\n",
      "train loss:0.9274693506842564\n",
      "train loss:0.9787234613389534\n",
      "train loss:0.787637728342044\n",
      "train loss:0.8113270502446666\n",
      "train loss:0.9858323234564268\n",
      "train loss:0.7690350429534846\n",
      "train loss:0.9334080881960031\n",
      "train loss:0.947541919615441\n",
      "train loss:1.0944031129249763\n",
      "train loss:0.8256403686026144\n",
      "train loss:0.9397847014648484\n",
      "train loss:1.0413824816603587\n",
      "train loss:0.8256229366935802\n",
      "train loss:0.8960781783750476\n",
      "train loss:0.7612004811740638\n",
      "train loss:1.0086694666073273\n",
      "train loss:0.8448266395237822\n",
      "train loss:0.9426639963976793\n",
      "train loss:0.8418744700320918\n",
      "train loss:0.8369105188649253\n",
      "train loss:0.9831479803355928\n",
      "train loss:0.7899179852882463\n",
      "train loss:0.9528281063765821\n",
      "train loss:1.1050140462119022\n",
      "train loss:0.8659930523042305\n",
      "train loss:1.018636504894876\n",
      "train loss:0.8168972186369483\n",
      "train loss:0.9697202992709799\n",
      "train loss:0.7690912563919148\n",
      "=== epoch:6, train acc:0.991, test acc:0.991 ===\n",
      "train loss:0.7901064999400735\n",
      "train loss:0.9154163385256705\n",
      "train loss:0.8190862692540918\n",
      "train loss:0.853140210943986\n",
      "train loss:0.9318693504580335\n",
      "train loss:0.9635133715833171\n",
      "train loss:0.9089031475866158\n",
      "train loss:1.0106673192591606\n",
      "train loss:0.8350891965863437\n",
      "train loss:0.9302724990266148\n",
      "train loss:0.9269391780277644\n",
      "train loss:0.8152502946553213\n",
      "train loss:1.0066167045483758\n",
      "train loss:0.9339497439648303\n",
      "train loss:1.0087130635960915\n",
      "train loss:1.1269046969719982\n",
      "train loss:0.973083199585008\n",
      "train loss:1.0732200633875477\n",
      "train loss:0.9190514713296034\n",
      "train loss:0.9149270784988153\n",
      "train loss:0.9121673079771765\n",
      "train loss:0.7700630765940458\n",
      "train loss:0.8220216408067671\n",
      "train loss:1.0291039237053936\n",
      "train loss:0.9381558807753045\n",
      "train loss:1.0201634264192707\n",
      "train loss:0.9200316580046878\n",
      "train loss:0.7355382729333858\n",
      "train loss:0.8570740811153508\n",
      "train loss:0.8400520749568947\n",
      "train loss:1.0386302109003773\n",
      "train loss:0.7578684524934333\n",
      "train loss:0.9540287619645592\n",
      "train loss:0.8395081736829288\n",
      "train loss:0.9127547439201646\n",
      "train loss:1.0276819483318769\n",
      "train loss:0.9575194452647391\n",
      "train loss:0.8303753158662591\n",
      "train loss:0.9428977855458431\n",
      "train loss:0.9697047125465741\n",
      "train loss:1.0152010598467207\n",
      "train loss:0.9781730833641602\n",
      "train loss:0.7913775177121966\n",
      "train loss:0.851637179008392\n",
      "train loss:0.8985921492165535\n",
      "train loss:0.80435227845781\n",
      "train loss:0.9452347869463837\n",
      "train loss:0.8663853392975522\n",
      "train loss:0.9529788725235041\n",
      "train loss:0.667999882928616\n",
      "train loss:0.9094261187429986\n",
      "train loss:1.0373917868935358\n",
      "train loss:0.8538496605311563\n",
      "train loss:0.9883098287662753\n",
      "train loss:0.8524350199403798\n",
      "train loss:0.9003871920034722\n",
      "train loss:0.7651365140627836\n",
      "train loss:0.8218974193009845\n",
      "train loss:0.9143825137899014\n",
      "train loss:0.9787647993095642\n",
      "train loss:0.9972192469276794\n",
      "train loss:0.9459647676921854\n",
      "train loss:0.9522282319900244\n",
      "train loss:0.7526366246828815\n",
      "train loss:1.1597044314844367\n",
      "train loss:0.7752101609991676\n",
      "train loss:0.9075679024066098\n",
      "train loss:0.8684973570493212\n",
      "train loss:0.9102288746319711\n",
      "train loss:0.8147824599613527\n",
      "train loss:0.8717492424519002\n",
      "train loss:1.0654374344288358\n",
      "train loss:1.027888868778404\n",
      "train loss:0.7605469677959974\n",
      "train loss:0.99634482898703\n",
      "train loss:0.8686573056081676\n",
      "train loss:0.897729888217978\n",
      "train loss:1.014448727903642\n",
      "train loss:0.9898106973790445\n",
      "train loss:0.7927546774977755\n",
      "train loss:0.8855738698945449\n",
      "train loss:0.9666734138719336\n",
      "train loss:0.9464436383848868\n",
      "train loss:0.8143358755957132\n",
      "train loss:0.9567834159483664\n",
      "train loss:0.8127814481828236\n",
      "train loss:0.8147558861121127\n",
      "train loss:0.9533319726631718\n",
      "train loss:0.7590583316774594\n",
      "train loss:0.8521366802214532\n",
      "train loss:1.031885992083162\n",
      "train loss:0.7904884186736584\n",
      "train loss:0.8879264066284867\n",
      "train loss:0.8715827281582545\n",
      "train loss:0.9069739234589125\n",
      "train loss:1.1361009731975422\n",
      "train loss:0.8712310905181774\n",
      "train loss:1.004356770141215\n",
      "train loss:0.9353569560263222\n",
      "train loss:0.8331856282459456\n",
      "train loss:0.9137012962533856\n",
      "train loss:0.8385123510570712\n",
      "train loss:0.8848934592158811\n",
      "train loss:0.946665407949684\n",
      "train loss:0.9930754376688236\n",
      "train loss:0.86927182822018\n",
      "train loss:0.9504931912539293\n",
      "train loss:0.9021300501253507\n",
      "train loss:0.9287080898646641\n",
      "train loss:0.8869211826218744\n",
      "train loss:0.9103025250351888\n",
      "train loss:1.1172859696552395\n",
      "train loss:0.8612947075465877\n",
      "train loss:0.731106035181591\n",
      "train loss:0.9532531299042509\n",
      "train loss:0.864859995776297\n",
      "train loss:0.8743201994374329\n",
      "train loss:0.9620497139691602\n",
      "train loss:0.7764194413667976\n",
      "train loss:0.923959300306738\n",
      "train loss:0.9533397469142912\n",
      "train loss:1.1232240193905632\n",
      "train loss:0.9322511311552159\n",
      "train loss:0.8893236662770542\n",
      "train loss:0.8109336574518783\n",
      "train loss:1.003915170867035\n",
      "train loss:0.916130733975553\n",
      "train loss:0.9020575887366162\n",
      "train loss:0.8340378214886718\n",
      "train loss:0.9442334447683775\n",
      "train loss:0.9788897417184823\n",
      "train loss:1.0452525255121008\n",
      "train loss:0.9252298377891257\n",
      "train loss:0.8015978370246757\n",
      "train loss:0.8776756715578338\n",
      "train loss:0.839855824286465\n",
      "train loss:0.885506806666361\n",
      "train loss:0.7828517333210832\n",
      "train loss:0.7774296909151647\n",
      "train loss:0.9936439809183468\n",
      "train loss:0.8571354622010595\n",
      "train loss:0.9467733336183874\n",
      "train loss:0.7462319324632497\n",
      "train loss:0.8927638763827292\n",
      "train loss:0.8270118236456742\n",
      "train loss:0.8653922698775535\n",
      "train loss:0.8806471866798755\n",
      "train loss:0.8842925958965004\n",
      "train loss:1.0745262009776275\n",
      "train loss:1.081549058677702\n",
      "train loss:0.8786550908333319\n",
      "train loss:0.9787797183810438\n",
      "train loss:0.8076649104913354\n",
      "train loss:0.948166983779499\n",
      "train loss:0.9007809481378527\n",
      "train loss:1.0368182901291785\n",
      "train loss:0.8590205547130134\n",
      "train loss:0.9332129955317936\n",
      "train loss:0.8202223135077458\n",
      "train loss:0.834269749497055\n",
      "train loss:0.8289170323094049\n",
      "train loss:0.9922223627185516\n",
      "train loss:1.0425084341685371\n",
      "train loss:0.8223425256483758\n",
      "train loss:0.9525230022445125\n",
      "train loss:0.8734726700908888\n",
      "train loss:1.0084923876057368\n",
      "train loss:0.9842769831785627\n",
      "train loss:0.7885820673435577\n",
      "train loss:0.8871110251701912\n",
      "train loss:0.9789060338450555\n",
      "train loss:0.7812531600171064\n",
      "train loss:0.9825009407248106\n",
      "train loss:0.7417770326274145\n",
      "train loss:0.9882815588549159\n",
      "train loss:0.8048452960526032\n",
      "train loss:0.8132610479792514\n",
      "train loss:0.908913473438792\n",
      "train loss:0.9341296376899504\n",
      "train loss:0.887565194701979\n",
      "train loss:0.8142976217106964\n",
      "train loss:0.9215067102359593\n",
      "train loss:1.0402059073955308\n",
      "train loss:0.8062612984413338\n",
      "train loss:0.9681309482517675\n",
      "train loss:0.8410493919796549\n",
      "train loss:0.973767732408328\n",
      "train loss:0.8510858593405045\n",
      "train loss:0.9498949365682546\n",
      "train loss:1.017755403071866\n",
      "train loss:0.9990118635945376\n",
      "train loss:0.830542132654079\n",
      "train loss:0.8754380813767191\n",
      "train loss:1.0958469114286589\n",
      "train loss:0.8108262680518915\n",
      "train loss:0.8713593589175516\n",
      "train loss:0.9951377503378253\n",
      "train loss:1.0398911346532218\n",
      "train loss:0.8902719195632995\n",
      "train loss:0.8347321027822283\n",
      "train loss:0.8856205078727578\n",
      "train loss:1.0690891011419148\n",
      "train loss:0.8758034986703271\n",
      "train loss:0.8130087633003322\n",
      "train loss:0.7530957187799047\n",
      "train loss:0.9988154252135231\n",
      "train loss:0.9541813585397027\n",
      "train loss:0.9120573890659375\n",
      "train loss:0.9101570653527653\n",
      "train loss:0.9012531922545035\n",
      "train loss:0.7946600231704919\n",
      "train loss:0.6227331935661478\n",
      "train loss:0.9350578577372094\n",
      "train loss:0.954292704293435\n",
      "train loss:0.8157612032275467\n",
      "train loss:0.9514682097977921\n",
      "train loss:0.8801231533312652\n",
      "train loss:1.0419166819839334\n",
      "train loss:0.914211534333781\n",
      "train loss:0.8349888316716404\n",
      "train loss:0.9239637135271596\n",
      "train loss:0.8861495214356364\n",
      "train loss:1.112947703577423\n",
      "train loss:1.0242101651873998\n",
      "train loss:0.8552972277059219\n",
      "train loss:0.9356148155420669\n",
      "train loss:0.9394015494974726\n",
      "train loss:0.7930603932878421\n",
      "train loss:0.7475732302361573\n",
      "train loss:1.00272834708626\n",
      "train loss:0.9049206055177831\n",
      "train loss:0.9740917403889757\n",
      "train loss:0.8522641569838265\n",
      "train loss:0.8440256586464517\n",
      "train loss:1.0024290877671143\n",
      "train loss:1.0043045029370563\n",
      "train loss:0.858625649769194\n",
      "train loss:0.9075906289056681\n",
      "train loss:0.9197594784829216\n",
      "train loss:0.6499834743992048\n",
      "train loss:0.8388903043713196\n",
      "train loss:0.8006430967820042\n",
      "train loss:1.0197399928600048\n",
      "train loss:0.7998760592226857\n",
      "train loss:0.9163793357385573\n",
      "train loss:0.938391481913415\n",
      "train loss:0.9282698726852715\n",
      "train loss:0.8831297320953982\n",
      "train loss:1.1208043884532335\n",
      "train loss:0.8353115819801846\n",
      "train loss:0.8298420461443196\n",
      "train loss:0.7916073357299631\n",
      "train loss:0.991738379089249\n",
      "train loss:0.9233232273656955\n",
      "train loss:0.9652381920204097\n",
      "train loss:0.8867673337485411\n",
      "train loss:1.029245977798044\n",
      "train loss:0.967609563991958\n",
      "train loss:0.8123788002876681\n",
      "train loss:1.0193498363889502\n",
      "train loss:0.9734186713132275\n",
      "train loss:0.8562273388963924\n",
      "train loss:0.9062247469045341\n",
      "train loss:0.8821209883831436\n",
      "train loss:0.9430443363368552\n",
      "train loss:0.8400107459870102\n",
      "train loss:0.9813044281524627\n",
      "train loss:0.8636265252829749\n",
      "train loss:0.9251243791236489\n",
      "train loss:0.9347385464288746\n",
      "train loss:0.78563443091615\n",
      "train loss:0.8720124240391229\n",
      "train loss:0.7858266454070372\n",
      "train loss:0.9366716513656574\n",
      "train loss:0.8581939918738616\n",
      "train loss:0.8397758846954163\n",
      "train loss:0.9935570200550888\n",
      "train loss:0.7807962860183667\n",
      "train loss:0.9447494024553535\n",
      "train loss:0.9335083486488643\n",
      "train loss:1.0647727175228119\n",
      "train loss:0.7851553829981834\n",
      "train loss:0.9714865014963814\n",
      "train loss:0.9348774621745303\n",
      "train loss:0.9858904122388837\n",
      "train loss:0.979159674815257\n",
      "train loss:0.8511955315042252\n",
      "train loss:0.9838327412231014\n",
      "train loss:0.9188729632306551\n",
      "train loss:0.9430346252519489\n",
      "train loss:0.9103729803643492\n",
      "train loss:0.9373637017686162\n",
      "train loss:1.0097697178034581\n",
      "train loss:0.8247832305677126\n",
      "train loss:1.0430368603462434\n",
      "train loss:0.9038030230335324\n",
      "train loss:1.0302277375574886\n",
      "train loss:0.9412794015050483\n",
      "train loss:0.7910589519407003\n",
      "train loss:0.7492036438548209\n",
      "train loss:0.8971257901573857\n",
      "train loss:0.9103910983885437\n",
      "train loss:1.0668257661061198\n",
      "train loss:1.0980848493774666\n",
      "train loss:0.9991530248252112\n",
      "train loss:0.9367429262558502\n",
      "train loss:0.8023714062986269\n",
      "train loss:0.9225271280108287\n",
      "train loss:0.8908101688587373\n",
      "train loss:0.9583869684006207\n",
      "train loss:0.8978102323441602\n",
      "train loss:0.9371577205112618\n",
      "train loss:1.1164956637147525\n",
      "train loss:1.0152802006817054\n",
      "train loss:1.0733113585438352\n",
      "train loss:0.8484524067008289\n",
      "train loss:0.8584300705520066\n",
      "train loss:0.9095926393418129\n",
      "train loss:0.937783412441944\n",
      "train loss:0.9058499706414922\n",
      "train loss:0.8279108827101203\n",
      "train loss:0.8091207365529608\n",
      "train loss:0.9270782958612174\n",
      "train loss:0.9759567825726512\n",
      "train loss:0.9745134005915158\n",
      "train loss:0.870135468684447\n",
      "train loss:0.9733863501390787\n",
      "train loss:0.8450477347146514\n",
      "train loss:0.9236649525366076\n",
      "train loss:0.964352135839667\n",
      "train loss:0.785970008668173\n",
      "train loss:0.8488834069305077\n",
      "train loss:0.7146449597857017\n",
      "train loss:0.8760576278914357\n",
      "train loss:0.844382827357605\n",
      "train loss:0.8769409778815974\n",
      "train loss:0.8382814691828293\n",
      "train loss:1.070504186946771\n",
      "train loss:0.8903520044937693\n",
      "train loss:0.9062257353091906\n",
      "train loss:0.9779758137892302\n",
      "train loss:1.0089656313100455\n",
      "train loss:1.011518682102893\n",
      "train loss:1.0041145616125795\n",
      "train loss:0.8714759091980256\n",
      "train loss:0.9679377843075155\n",
      "train loss:1.0573122413297327\n",
      "train loss:0.9725610052527819\n",
      "train loss:0.7449084745627514\n",
      "train loss:0.9966554807272893\n",
      "train loss:0.872800434591149\n",
      "train loss:0.8168606850368433\n",
      "train loss:1.1477393185076261\n",
      "train loss:0.9349120161090596\n",
      "train loss:0.6976656567487385\n",
      "train loss:0.7791049711797514\n",
      "train loss:0.9597158622209437\n",
      "train loss:0.9286269845664081\n",
      "train loss:0.9825661765887319\n",
      "train loss:0.7291924152709808\n",
      "train loss:0.8721811076824842\n",
      "train loss:1.0539256317005783\n",
      "train loss:0.8041636079178044\n",
      "train loss:0.94050853427544\n",
      "train loss:0.9309797509638567\n",
      "train loss:1.0551590666734538\n",
      "train loss:0.7806966027432849\n",
      "train loss:0.7622298227784021\n",
      "train loss:0.7559406004144494\n",
      "train loss:0.9931232674994032\n",
      "train loss:1.127184099041648\n",
      "train loss:0.9008421613880531\n",
      "train loss:0.8244187090325021\n",
      "train loss:0.8917707415252627\n",
      "train loss:0.8691999132029896\n",
      "train loss:0.8960753165425399\n",
      "train loss:0.9161237791919241\n",
      "train loss:0.8534036020193152\n",
      "train loss:0.9177970710355021\n",
      "train loss:0.9439142047390453\n",
      "train loss:0.9369439523120286\n",
      "train loss:0.8660111365340716\n",
      "train loss:0.7773101194349182\n",
      "train loss:0.7760411123427597\n",
      "train loss:0.836327858590797\n",
      "train loss:0.964939204470409\n",
      "train loss:0.9078046450730051\n",
      "train loss:0.9894599986932064\n",
      "train loss:0.7545861491980499\n",
      "train loss:0.9754218981631307\n",
      "train loss:0.965377446670695\n",
      "train loss:0.8891808527706982\n",
      "train loss:0.8790453786781341\n",
      "train loss:0.9110548608228443\n",
      "train loss:0.8402011677356378\n",
      "train loss:1.0445139144398576\n",
      "train loss:0.7494597561644634\n",
      "train loss:0.9638133212619542\n",
      "train loss:0.9583100806478565\n",
      "train loss:0.797293694374385\n",
      "train loss:0.9522598469067711\n",
      "train loss:0.9189623167935066\n",
      "train loss:1.002688384006707\n",
      "train loss:0.8283805449069398\n",
      "train loss:0.713014723100616\n",
      "train loss:0.7289869988444287\n",
      "train loss:0.8029946406189041\n",
      "train loss:0.8911635799745641\n",
      "train loss:0.9854633730024865\n",
      "train loss:0.871250913320377\n",
      "train loss:0.8633542909576832\n",
      "train loss:0.9377275687927193\n",
      "train loss:1.1375135931287677\n",
      "train loss:0.9708769796155111\n",
      "train loss:1.062681376167379\n",
      "train loss:0.6611237890807337\n",
      "train loss:0.9196850901140098\n",
      "train loss:0.9864895428650452\n",
      "train loss:0.9944621710678461\n",
      "train loss:0.7787168359479744\n",
      "train loss:1.0192313507015769\n",
      "train loss:0.824687225866371\n",
      "train loss:0.8394026096073212\n",
      "train loss:0.7773629940256416\n",
      "train loss:0.9383486243685678\n",
      "train loss:1.0067676560902614\n",
      "train loss:1.024032346770297\n",
      "train loss:0.9913517040388499\n",
      "train loss:0.8359073349457133\n",
      "train loss:0.9377691157006673\n",
      "train loss:0.7898724363377965\n",
      "train loss:0.8601143811901159\n",
      "train loss:0.9158078931966862\n",
      "train loss:0.8343349487161044\n",
      "train loss:0.8140705024401121\n",
      "train loss:0.8927934462849124\n",
      "train loss:0.7887442597448725\n",
      "train loss:0.8506053967035929\n",
      "train loss:0.8744989743942901\n",
      "train loss:0.9467521972816613\n",
      "train loss:0.9367850994274072\n",
      "train loss:0.8405252546491399\n",
      "train loss:0.9510670154729399\n",
      "train loss:0.9306104346769244\n",
      "train loss:0.7819983110600797\n",
      "train loss:0.9420929806373209\n",
      "train loss:1.0183108063300284\n",
      "train loss:0.9380909584690681\n",
      "train loss:0.8159141973585922\n",
      "train loss:0.8927991163595845\n",
      "train loss:0.7711127510587891\n",
      "train loss:0.8467675464679479\n",
      "train loss:0.8777040713600529\n",
      "train loss:0.8107186078987817\n",
      "train loss:0.9366092701756762\n",
      "train loss:0.9006826388647882\n",
      "train loss:1.1531918657474185\n",
      "train loss:1.048652916076429\n",
      "train loss:0.8142098894238446\n",
      "train loss:0.8091295264467767\n",
      "train loss:0.8971203108099439\n",
      "train loss:0.9721313735807202\n",
      "train loss:0.9965005760888873\n",
      "train loss:0.8508201927867186\n",
      "train loss:1.1217246921595907\n",
      "train loss:0.9240450440383231\n",
      "train loss:1.1282179043869176\n",
      "train loss:0.8962127918820775\n",
      "train loss:0.70249726490996\n",
      "train loss:0.9773944641610968\n",
      "train loss:0.7759791402818799\n",
      "train loss:0.7478561179822989\n",
      "train loss:1.0587694458366184\n",
      "train loss:0.9645609829548737\n",
      "train loss:0.9001977450427526\n",
      "train loss:0.9618824800840047\n",
      "train loss:0.9708783849908452\n",
      "train loss:0.9422534900258451\n",
      "train loss:1.0176888970767441\n",
      "train loss:0.8944320665101431\n",
      "train loss:1.0301384021743178\n",
      "train loss:1.0704089366089822\n",
      "train loss:0.9074672335308926\n",
      "train loss:1.0117989131313383\n",
      "train loss:1.0042184521317643\n",
      "train loss:0.9061282660670831\n",
      "train loss:1.0243504411794913\n",
      "train loss:1.0898257198261119\n",
      "train loss:0.9241640248948542\n",
      "train loss:0.9329039950704024\n",
      "train loss:1.0149142477962811\n",
      "train loss:1.0267612969693802\n",
      "train loss:0.8679453495499981\n",
      "train loss:1.038177715532461\n",
      "train loss:0.8829656659696375\n",
      "train loss:0.9469284015857788\n",
      "train loss:0.9977627982406072\n",
      "train loss:0.9985332903475106\n",
      "train loss:0.95483969171735\n",
      "train loss:0.9101232143284738\n",
      "train loss:0.8960003664742447\n",
      "train loss:0.8747155277338566\n",
      "train loss:0.9891405737709849\n",
      "train loss:0.802033013502708\n",
      "train loss:0.9414418652478227\n",
      "train loss:0.7513877525147835\n",
      "train loss:1.0113871206554392\n",
      "train loss:0.8264227234600368\n",
      "train loss:0.893540883827947\n",
      "train loss:0.8856158395738983\n",
      "train loss:0.9070796784655003\n",
      "train loss:0.8893833442004234\n",
      "train loss:0.9729702942303665\n",
      "train loss:0.9449654823797854\n",
      "train loss:0.9356393201201156\n",
      "train loss:0.8591954857646698\n",
      "train loss:0.7534720001082428\n",
      "train loss:0.9210951184868017\n",
      "train loss:0.8163933051347319\n",
      "train loss:0.7388733833518069\n",
      "train loss:0.8526858285881745\n",
      "train loss:0.8680393364210434\n",
      "train loss:0.8492895169614468\n",
      "train loss:0.9154360634789179\n",
      "train loss:0.8638595258804217\n",
      "train loss:0.7940551497750212\n",
      "train loss:1.0892713891312167\n",
      "train loss:0.8401775600235148\n",
      "train loss:0.8200616027522445\n",
      "train loss:0.9173415003542965\n",
      "train loss:0.7470103242227796\n",
      "train loss:0.9146065182110565\n",
      "train loss:0.7215094833106481\n",
      "train loss:0.8956545646206976\n",
      "train loss:0.8290904977858433\n",
      "train loss:1.0238462869793148\n",
      "train loss:0.9552916072986022\n",
      "train loss:0.9211305643859022\n",
      "train loss:0.9282153094629535\n",
      "train loss:0.9690092136724531\n",
      "train loss:0.8774343603674538\n",
      "train loss:0.9572283876162243\n",
      "train loss:0.9189819814123997\n",
      "train loss:0.8629579874298053\n",
      "train loss:0.8899318780654408\n",
      "train loss:0.9085294227440259\n",
      "train loss:0.850982476816131\n",
      "train loss:0.8977037248874331\n",
      "train loss:0.9620740247758383\n",
      "train loss:0.6852236801122364\n",
      "train loss:0.898187224490124\n",
      "train loss:0.8549175294514763\n",
      "train loss:0.7629377835905938\n",
      "train loss:0.8518416122582806\n",
      "train loss:0.8714268302394279\n",
      "train loss:0.8111279266340209\n",
      "train loss:0.6715528687696208\n",
      "train loss:0.7970968389689026\n",
      "train loss:0.8763723193715697\n",
      "train loss:0.8796000605075212\n",
      "train loss:0.96088941926148\n",
      "train loss:0.9648546610555839\n",
      "train loss:0.7311143839417629\n",
      "train loss:0.867979990182011\n",
      "train loss:0.7624748180068237\n",
      "train loss:1.007176588138684\n",
      "train loss:0.761601550675868\n",
      "train loss:0.9379177085053796\n",
      "train loss:0.9255030001614094\n",
      "train loss:0.8830605233862434\n",
      "train loss:0.9497612962795995\n",
      "train loss:0.9099201594079085\n",
      "train loss:0.9096679725915798\n",
      "train loss:0.8971156302152152\n",
      "train loss:0.751399372232926\n",
      "train loss:1.0772988740175666\n",
      "train loss:1.0209776776311559\n",
      "train loss:0.9432496934812743\n",
      "train loss:0.78832152461708\n",
      "train loss:0.8344235326334012\n",
      "train loss:1.0268787333806766\n",
      "train loss:0.7652370315968305\n",
      "train loss:0.846181275683548\n",
      "train loss:0.8157415794762122\n",
      "train loss:1.005867320848907\n",
      "train loss:0.9637116434029442\n",
      "train loss:0.9750118021830275\n",
      "train loss:0.8069417634367657\n",
      "train loss:0.8618136892148343\n",
      "train loss:0.8758640964074733\n",
      "train loss:0.6871946204589905\n",
      "train loss:0.7140059471398252\n",
      "train loss:0.8521707458827318\n",
      "train loss:1.0035901132073777\n",
      "train loss:0.8743969967500697\n",
      "train loss:0.9564935865406261\n",
      "train loss:0.7939380998307027\n",
      "train loss:1.1589886204243078\n",
      "train loss:0.872539582788299\n",
      "train loss:0.945030952677397\n",
      "=== epoch:7, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.8257923852040654\n",
      "train loss:0.9474511495443073\n",
      "train loss:0.7216965582635497\n",
      "train loss:0.8686407932232023\n",
      "train loss:0.7424437908378902\n",
      "train loss:0.8889385706861365\n",
      "train loss:0.9551495613487215\n",
      "train loss:1.0351285446270886\n",
      "train loss:0.9370448952823988\n",
      "train loss:0.905534539807621\n",
      "train loss:0.8569925151482467\n",
      "train loss:0.8419780192649468\n",
      "train loss:0.8690625842326001\n",
      "train loss:0.8736650557993163\n",
      "train loss:0.9553404559427687\n",
      "train loss:0.8111479748741728\n",
      "train loss:0.8389284611140491\n",
      "train loss:0.9095812661442554\n",
      "train loss:0.9011376749377622\n",
      "train loss:0.8619521905427421\n",
      "train loss:0.8669495062031474\n",
      "train loss:0.7978968168314075\n",
      "train loss:0.8646443930855738\n",
      "train loss:0.7511492612446505\n",
      "train loss:0.769698463068726\n",
      "train loss:0.8016682685225766\n",
      "train loss:0.8750080715759481\n",
      "train loss:0.9938694084052773\n",
      "train loss:0.778580142985614\n",
      "train loss:0.7773592323245841\n",
      "train loss:1.0765202118795083\n",
      "train loss:0.8639235366087895\n",
      "train loss:0.7496743441600789\n",
      "train loss:0.8664594871548681\n",
      "train loss:0.9939770175572805\n",
      "train loss:0.94053360704869\n",
      "train loss:1.018462033003889\n",
      "train loss:0.7412363485480995\n",
      "train loss:0.9071731723570842\n",
      "train loss:0.9091400813954457\n",
      "train loss:0.9279638643912352\n",
      "train loss:0.8767982548034499\n",
      "train loss:1.0802895364666478\n",
      "train loss:0.9246940995283819\n",
      "train loss:0.836944419043907\n",
      "train loss:0.9397833153504827\n",
      "train loss:0.8508410589276161\n",
      "train loss:0.9571318550527416\n",
      "train loss:1.0351217382575326\n",
      "train loss:1.0635740641007632\n",
      "train loss:0.9928485272158716\n",
      "train loss:0.9011257338271959\n",
      "train loss:0.9146877876015028\n",
      "train loss:0.8814802641511434\n",
      "train loss:0.8977024863962031\n",
      "train loss:0.974890110265778\n",
      "train loss:0.9011148001440703\n",
      "train loss:1.0155974650634092\n",
      "train loss:1.0316265668232782\n",
      "train loss:0.7662739149697075\n",
      "train loss:0.8679075782590218\n",
      "train loss:0.8817395421644021\n",
      "train loss:1.0222535596775553\n",
      "train loss:0.8136166699652327\n",
      "train loss:0.7923353435030996\n",
      "train loss:1.0222858991844443\n",
      "train loss:0.7959040960126886\n",
      "train loss:0.6954784285719087\n",
      "train loss:0.8839564539929191\n",
      "train loss:0.7571582263628575\n",
      "train loss:0.9780125703475222\n",
      "train loss:0.8479566485936993\n",
      "train loss:0.7849674146326683\n",
      "train loss:0.8058038377312449\n",
      "train loss:0.9270836340002873\n",
      "train loss:0.8069231397311246\n",
      "train loss:1.0057288311940855\n",
      "train loss:0.9368717030408945\n",
      "train loss:1.0427574397717407\n",
      "train loss:0.8328116186799923\n",
      "train loss:0.9258844445266686\n",
      "train loss:1.0015221467398532\n",
      "train loss:1.0028465446007266\n",
      "train loss:0.8590530411848423\n",
      "train loss:0.9401314495605747\n",
      "train loss:0.9218310493627706\n",
      "train loss:0.9343204143997353\n",
      "train loss:0.8847283720344223\n",
      "train loss:0.8760601836632439\n",
      "train loss:0.9776171228330436\n",
      "train loss:0.8785576863808561\n",
      "train loss:0.7917645974496288\n",
      "train loss:0.6813238974686154\n",
      "train loss:0.8779055705684509\n",
      "train loss:0.8549593907070503\n",
      "train loss:0.8427841805268242\n",
      "train loss:0.9333951325798715\n",
      "train loss:1.0118846201093377\n",
      "train loss:0.8868226603062956\n",
      "train loss:0.6483477012700818\n",
      "train loss:0.7679715164965447\n",
      "train loss:0.7656883341874787\n",
      "train loss:0.9758240616138498\n",
      "train loss:0.984731482248303\n",
      "train loss:0.9361610346868163\n",
      "train loss:0.82526993926293\n",
      "train loss:0.926626187819709\n",
      "train loss:1.0515694776963684\n",
      "train loss:0.7940712755414584\n",
      "train loss:0.9765134175212659\n",
      "train loss:1.0932066816994663\n",
      "train loss:0.7927354920252668\n",
      "train loss:1.0567080861651093\n",
      "train loss:0.8166070697595346\n",
      "train loss:0.9143181116069995\n",
      "train loss:0.9207001498354006\n",
      "train loss:0.8928250651302285\n",
      "train loss:0.896926246403419\n",
      "train loss:0.729212803231995\n",
      "train loss:0.8428249943236028\n",
      "train loss:0.9127135100781298\n",
      "train loss:0.9121624691106445\n",
      "train loss:0.7751415481728702\n",
      "train loss:1.039329498020393\n",
      "train loss:0.8882809586876297\n",
      "train loss:0.9864251861280051\n",
      "train loss:0.7931117179828445\n",
      "train loss:0.9662851871728657\n",
      "train loss:0.7660918615689521\n",
      "train loss:0.8896872867690062\n",
      "train loss:0.7377285633304208\n",
      "train loss:0.8243849496617071\n",
      "train loss:0.8672466279730497\n",
      "train loss:0.7248175494026593\n",
      "train loss:0.8521517418335671\n",
      "train loss:0.8265908094875969\n",
      "train loss:0.8088393289780264\n",
      "train loss:1.0830801710913684\n",
      "train loss:0.879362079881282\n",
      "train loss:0.9571683413421131\n",
      "train loss:0.8349838201661446\n",
      "train loss:0.8402629591651055\n",
      "train loss:0.946404331407275\n",
      "train loss:1.012503664628683\n",
      "train loss:0.9737833317647826\n",
      "train loss:1.0854752924785995\n",
      "train loss:1.0412083633329972\n",
      "train loss:1.0452628152252945\n",
      "train loss:0.8922229655965666\n",
      "train loss:0.782710323511256\n",
      "train loss:0.9596541909016149\n",
      "train loss:0.624727130323162\n",
      "train loss:0.7661032640942761\n",
      "train loss:0.9818291984038642\n",
      "train loss:0.7978104821160674\n",
      "train loss:0.9889386324468019\n",
      "train loss:0.9137001325733476\n",
      "train loss:0.9385611093224054\n",
      "train loss:1.0682228796864341\n",
      "train loss:0.6930389859395354\n",
      "train loss:0.7556779264949541\n",
      "train loss:0.8425232790599945\n",
      "train loss:0.9312955570852592\n",
      "train loss:0.6233615992341808\n",
      "train loss:0.8482169895357309\n",
      "train loss:1.1341662035049498\n",
      "train loss:0.9580338750428258\n",
      "train loss:0.9112404703058543\n",
      "train loss:0.9514905318138424\n",
      "train loss:1.1049217971750998\n",
      "train loss:1.082035201528099\n",
      "train loss:0.9294978591786687\n",
      "train loss:0.9255152654958008\n",
      "train loss:0.9178763272414323\n",
      "train loss:0.8838640462661564\n",
      "train loss:0.8994097143003017\n",
      "train loss:0.8711978153957277\n",
      "train loss:0.9437545680847527\n",
      "train loss:0.9490885305807104\n",
      "train loss:0.8220641606529386\n",
      "train loss:0.8014421930511278\n",
      "train loss:1.0329822090162517\n",
      "train loss:0.9300586470024751\n",
      "train loss:0.9127136635786519\n",
      "train loss:0.8202699149567013\n",
      "train loss:0.8374053400527667\n",
      "train loss:0.8759219204236584\n",
      "train loss:1.1087758379817974\n",
      "train loss:1.025898414519963\n",
      "train loss:0.8516626797308596\n",
      "train loss:0.8875083701471833\n",
      "train loss:0.8478076511812245\n",
      "train loss:1.1128128708883838\n",
      "train loss:0.7586160157229936\n",
      "train loss:0.8181807984423082\n",
      "train loss:0.7792235347101818\n",
      "train loss:0.9109493247955388\n",
      "train loss:0.9029603308937755\n",
      "train loss:0.7593223951238143\n",
      "train loss:1.0579583909503765\n",
      "train loss:0.9636425890474066\n",
      "train loss:0.8424593718141077\n",
      "train loss:1.0452422317549102\n",
      "train loss:0.8097387940980613\n",
      "train loss:0.8294029269972671\n",
      "train loss:0.8050974252243429\n",
      "train loss:0.7985975097068075\n",
      "train loss:0.892324728649868\n",
      "train loss:0.7977145301673775\n",
      "train loss:0.9034130227429684\n",
      "train loss:0.9092106857673103\n",
      "train loss:0.6610728055165032\n",
      "train loss:0.8481954144618095\n",
      "train loss:0.8806892753677991\n",
      "train loss:0.9517566524638861\n",
      "train loss:0.8588933881014803\n",
      "train loss:0.986461230937669\n",
      "train loss:0.7938191761168656\n",
      "train loss:1.0039956158438852\n",
      "train loss:0.7847416366811474\n",
      "train loss:0.9869383318931579\n",
      "train loss:0.8583617037898184\n",
      "train loss:0.7768331616919524\n",
      "train loss:0.8648372947737499\n",
      "train loss:0.8474432045287927\n",
      "train loss:0.8889257893600138\n",
      "train loss:0.9872147091081882\n",
      "train loss:0.9299351579795165\n",
      "train loss:0.9203955270348263\n",
      "train loss:1.0137571998912451\n",
      "train loss:0.9602719706095454\n",
      "train loss:0.844404672479718\n",
      "train loss:0.7484492576808387\n",
      "train loss:0.886251240981005\n",
      "train loss:0.8890596562858092\n",
      "train loss:0.9983085973365925\n",
      "train loss:0.9057394094126535\n",
      "train loss:1.0069119350321845\n",
      "train loss:0.9101155857227767\n",
      "train loss:0.9881435728184635\n",
      "train loss:0.8937928899423753\n",
      "train loss:0.9066431099944693\n",
      "train loss:0.9258698400820734\n",
      "train loss:0.941938229003966\n",
      "train loss:0.8304171874459304\n",
      "train loss:0.8581027871103319\n",
      "train loss:0.9698457477998406\n",
      "train loss:0.8211346886572518\n",
      "train loss:0.9536889413593042\n",
      "train loss:0.8320379302978952\n",
      "train loss:0.9423898551196835\n",
      "train loss:0.9180058234395077\n",
      "train loss:1.0070757929154506\n",
      "train loss:0.7297460941991077\n",
      "train loss:0.7389150572864129\n",
      "train loss:0.8736587834136329\n",
      "train loss:0.8669587767801586\n",
      "train loss:0.9082736399191481\n",
      "train loss:0.8410191103306701\n",
      "train loss:0.9264363834857587\n",
      "train loss:1.1424704493300075\n",
      "train loss:0.894574600447206\n",
      "train loss:1.0232534201772032\n",
      "train loss:0.9466264013835729\n",
      "train loss:0.9344627648865281\n",
      "train loss:0.9148728417244327\n",
      "train loss:0.8168117327356751\n",
      "train loss:0.9130728069844908\n",
      "train loss:0.9939725580971225\n",
      "train loss:0.6804533139901019\n",
      "train loss:0.8929001104106794\n",
      "train loss:0.8987639052970898\n",
      "train loss:0.9591400658033733\n",
      "train loss:0.8526885878148173\n",
      "train loss:0.9235004947782638\n",
      "train loss:1.0055610181349492\n",
      "train loss:0.9002258623413879\n",
      "train loss:0.8261007676195384\n",
      "train loss:0.809909168557409\n",
      "train loss:0.9963684525796356\n",
      "train loss:0.9075425821382105\n",
      "train loss:0.9000162139656597\n",
      "train loss:0.9756946992752159\n",
      "train loss:0.8988382770425845\n",
      "train loss:0.9212621257557515\n",
      "train loss:0.9923666635568115\n",
      "train loss:0.848668227576979\n",
      "train loss:0.9001302605444826\n",
      "train loss:0.8945357049619349\n",
      "train loss:0.7704804693702288\n",
      "train loss:0.9077705720546543\n",
      "train loss:0.8658646555739284\n",
      "train loss:0.8627476963210846\n",
      "train loss:0.987886890600212\n",
      "train loss:0.8352998197099398\n",
      "train loss:0.99415451474156\n",
      "train loss:0.9589620175595834\n",
      "train loss:1.0769020877316293\n",
      "train loss:1.0792410722592212\n",
      "train loss:0.9190573139568451\n",
      "train loss:0.8122331375270122\n",
      "train loss:0.9718420651007678\n",
      "train loss:0.9618345648918738\n",
      "train loss:1.0074529770277936\n",
      "train loss:0.8837901153478042\n",
      "train loss:0.9711517852388358\n",
      "train loss:0.9535321728979151\n",
      "train loss:0.9910682448613067\n",
      "train loss:0.9901997844171254\n",
      "train loss:0.9740064500307355\n",
      "train loss:0.8600952887975754\n",
      "train loss:0.8346275368299442\n",
      "train loss:0.9812717151859114\n",
      "train loss:0.902993257655127\n",
      "train loss:0.9374233946508193\n",
      "train loss:0.8432747707461904\n",
      "train loss:0.8635433993100297\n",
      "train loss:0.9019425159961628\n",
      "train loss:0.8902362416513726\n",
      "train loss:0.8290789550475895\n",
      "train loss:0.9575745132931749\n",
      "train loss:0.769846700365849\n",
      "train loss:0.8578593858292782\n",
      "train loss:1.1410201502847925\n",
      "train loss:0.8318555056214352\n",
      "train loss:0.9099300089663598\n",
      "train loss:1.049516476950612\n",
      "train loss:0.8009954205438058\n",
      "train loss:0.8163107765010271\n",
      "train loss:0.8603941311545681\n",
      "train loss:0.9231669821136831\n",
      "train loss:0.9293610204709049\n",
      "train loss:0.915616464908884\n",
      "train loss:1.0532482137781525\n",
      "train loss:1.0723297653799158\n",
      "train loss:0.8378144187372625\n",
      "train loss:0.6899169004385156\n",
      "train loss:1.124919327451525\n",
      "train loss:0.811839125402566\n",
      "train loss:1.0216954635802364\n",
      "train loss:0.8719185933988607\n",
      "train loss:0.8926862734736539\n",
      "train loss:0.9225796768646842\n",
      "train loss:0.6628765180972138\n",
      "train loss:0.8477225056799966\n",
      "train loss:0.7919159605197414\n",
      "train loss:0.8752927574634461\n",
      "train loss:0.8915307137734544\n",
      "train loss:0.8185970763114726\n",
      "train loss:0.8854173621971784\n",
      "train loss:0.7832867750817359\n",
      "train loss:0.8359848148394309\n",
      "train loss:0.7771907246683017\n",
      "train loss:0.853038440803537\n",
      "train loss:1.0248098613164813\n",
      "train loss:0.9559251206149345\n",
      "train loss:0.7997181171221861\n",
      "train loss:1.0801832677995113\n",
      "train loss:0.935703899568569\n",
      "train loss:0.8004410155403988\n",
      "train loss:0.8523279320299495\n",
      "train loss:0.8751009458686826\n",
      "train loss:0.800565220123925\n",
      "train loss:0.8388396650631901\n",
      "train loss:1.0345261361719618\n",
      "train loss:0.8383102043502829\n",
      "train loss:0.8387137228833376\n",
      "train loss:0.8475456727172654\n",
      "train loss:0.8077123124435623\n",
      "train loss:0.8660326140623524\n",
      "train loss:0.9546477910371718\n",
      "train loss:0.9875295602397738\n",
      "train loss:1.1287763743747943\n",
      "train loss:0.8837112634078825\n",
      "train loss:0.9705212801159806\n",
      "train loss:1.0870985386655039\n",
      "train loss:0.985430223137531\n",
      "train loss:0.7633499793696917\n",
      "train loss:0.8835800520852594\n",
      "train loss:0.8598615470874297\n",
      "train loss:0.7612002787789244\n",
      "train loss:0.9326024171744771\n",
      "train loss:0.8484878993879006\n",
      "train loss:0.9198560979463586\n",
      "train loss:0.7003899363105853\n",
      "train loss:0.9454281324441887\n",
      "train loss:0.7961324970985594\n",
      "train loss:0.8874231700942995\n",
      "train loss:0.9414400992728551\n",
      "train loss:1.0279227497962957\n",
      "train loss:0.9479743600476617\n",
      "train loss:1.0049390569801533\n",
      "train loss:0.7667007027978247\n",
      "train loss:0.9706179417822437\n",
      "train loss:0.9169354498291241\n",
      "train loss:0.9122208218257687\n",
      "train loss:0.7794788889760754\n",
      "train loss:1.0125054719291855\n",
      "train loss:1.0460110671834857\n",
      "train loss:0.7910254770568876\n",
      "train loss:0.6954006326524695\n",
      "train loss:0.9632981902742572\n",
      "train loss:0.9790285738479979\n",
      "train loss:0.8901528017523891\n",
      "train loss:0.9836161065394584\n",
      "train loss:0.7560015110145318\n",
      "train loss:0.8643167811066895\n",
      "train loss:0.9074643227031782\n",
      "train loss:0.9661849727891118\n",
      "train loss:1.0640496877119485\n",
      "train loss:0.7925563254687542\n",
      "train loss:0.9859977695813497\n",
      "train loss:0.9491617207220705\n",
      "train loss:0.9546984597409539\n",
      "train loss:0.9201953814378914\n",
      "train loss:1.0203528662761732\n",
      "train loss:0.8694747743992869\n",
      "train loss:0.8943799723449921\n",
      "train loss:0.7950012894396488\n",
      "train loss:0.919360807462085\n",
      "train loss:0.939585430844152\n",
      "train loss:0.8494711753888309\n",
      "train loss:0.7507212393437698\n",
      "train loss:0.8057582923323113\n",
      "train loss:0.8060387867631138\n",
      "train loss:0.9744247256558204\n",
      "train loss:0.829816221040805\n",
      "train loss:0.863351533120717\n",
      "train loss:0.7883639614795611\n",
      "train loss:0.8949925641774408\n",
      "train loss:0.7353832389221815\n",
      "train loss:0.8938549623247906\n",
      "train loss:0.9609412040903487\n",
      "train loss:0.809885751196813\n",
      "train loss:1.0064328585343802\n",
      "train loss:0.9860806736896005\n",
      "train loss:0.7689879332125018\n",
      "train loss:0.9652923106671093\n",
      "train loss:0.7470890277558209\n",
      "train loss:0.8308700567084323\n",
      "train loss:0.9083786181295413\n",
      "train loss:1.0567497655070652\n",
      "train loss:0.8502964770079475\n",
      "train loss:0.8443130753335376\n",
      "train loss:0.7645143952132655\n",
      "train loss:0.9209858616009636\n",
      "train loss:0.8685189164098126\n",
      "train loss:0.887161408216911\n",
      "train loss:0.9550842016111781\n",
      "train loss:0.8417798712227881\n",
      "train loss:0.6781975931399967\n",
      "train loss:0.7567778104773498\n",
      "train loss:0.8586890555256163\n",
      "train loss:0.9045507450307197\n",
      "train loss:0.7777366702931632\n",
      "train loss:0.9697138660324001\n",
      "train loss:0.9494298908589112\n",
      "train loss:0.7692893255694222\n",
      "train loss:0.6874045023710488\n",
      "train loss:0.9895422326318999\n",
      "train loss:0.7973856901268362\n",
      "train loss:0.778250864881976\n",
      "train loss:0.9124055546428542\n",
      "train loss:0.7860115214014816\n",
      "train loss:0.9569357891747886\n",
      "train loss:0.6436077832530196\n",
      "train loss:0.7975506933712692\n",
      "train loss:0.9154590795129556\n",
      "train loss:0.8917216229447117\n",
      "train loss:0.7809237214185575\n",
      "train loss:0.7384442204601638\n",
      "train loss:1.0464548627747867\n",
      "train loss:0.799881948652577\n",
      "train loss:0.80537623580861\n",
      "train loss:0.9261101222259106\n",
      "train loss:0.8818102176904185\n",
      "train loss:0.891263489261992\n",
      "train loss:0.7712781430356531\n",
      "train loss:0.9357956150406633\n",
      "train loss:0.8820906868024183\n",
      "train loss:0.8451826429164855\n",
      "train loss:0.923831297713865\n",
      "train loss:0.9825843707786879\n",
      "train loss:0.7815084566995456\n",
      "train loss:0.7549404316101196\n",
      "train loss:1.0118254164097003\n",
      "train loss:0.8231463285264359\n",
      "train loss:0.8172881658632397\n",
      "train loss:0.8499368986419047\n",
      "train loss:0.8516255634320897\n",
      "train loss:0.8465218302633378\n",
      "train loss:1.0110689192558007\n",
      "train loss:1.0103388377100746\n",
      "train loss:0.8554381262225326\n",
      "train loss:0.9775234055407589\n",
      "train loss:0.8136723443912188\n",
      "train loss:0.7823950588905775\n",
      "train loss:0.9782767282655365\n",
      "train loss:0.7406498734787438\n",
      "train loss:0.7875489192803192\n",
      "train loss:0.9355305571372645\n",
      "train loss:0.8586117722543655\n",
      "train loss:1.1190942400279362\n",
      "train loss:0.9727979031807132\n",
      "train loss:0.7287593134807641\n",
      "train loss:0.711142208341048\n",
      "train loss:0.8866896673424174\n",
      "train loss:0.9116624376167687\n",
      "train loss:0.8304458070055509\n",
      "train loss:0.9031601047839094\n",
      "train loss:0.9487829190935031\n",
      "train loss:0.8934788435778005\n",
      "train loss:0.9106242282128966\n",
      "train loss:0.8044371330436253\n",
      "train loss:1.1047671174502995\n",
      "train loss:0.8288483149105158\n",
      "train loss:0.7573158087787146\n",
      "train loss:1.1061881675109329\n",
      "train loss:0.9592049342917555\n",
      "train loss:0.7713448761963376\n",
      "train loss:0.8489135448156963\n",
      "train loss:0.9415365905205012\n",
      "train loss:1.0144541445827873\n",
      "train loss:0.8846910987395675\n",
      "train loss:0.7860634808493602\n",
      "train loss:0.9550220784122895\n",
      "train loss:0.9448927620774231\n",
      "train loss:0.7751513313343547\n",
      "train loss:0.9364755402395939\n",
      "train loss:0.7655285587618422\n",
      "train loss:0.9132685151727897\n",
      "train loss:0.9198473051079469\n",
      "train loss:0.7579517300611343\n",
      "train loss:0.9389448159882915\n",
      "train loss:0.8216427105247464\n",
      "train loss:0.8322901085248613\n",
      "train loss:0.918437706097623\n",
      "train loss:0.9992388981691165\n",
      "train loss:0.7483546701960148\n",
      "train loss:0.9141435839590337\n",
      "train loss:0.8739496849749291\n",
      "train loss:0.8843440894096354\n",
      "train loss:0.9993021628022538\n",
      "train loss:1.005534759668051\n",
      "train loss:0.8398169911678649\n",
      "train loss:0.9888681056955869\n",
      "train loss:0.9786133299907993\n",
      "train loss:0.6988734658812333\n",
      "train loss:0.9171086523738466\n",
      "train loss:0.8788478617273929\n",
      "train loss:0.8707102461249459\n",
      "train loss:0.9461814488960779\n",
      "train loss:0.9342359296147045\n",
      "train loss:0.7797448012382877\n",
      "train loss:0.8537923426583204\n",
      "train loss:0.7687361894356874\n",
      "train loss:0.9069162313622894\n",
      "train loss:0.9238604904546817\n",
      "train loss:0.8564488283085402\n",
      "train loss:0.9036634980576602\n",
      "train loss:0.8955092117982976\n",
      "train loss:0.8389870327047467\n",
      "train loss:0.9498013125498939\n",
      "train loss:0.9055686868402762\n",
      "train loss:0.824522517375936\n",
      "train loss:0.9345206030727502\n",
      "train loss:0.9066279853089705\n",
      "train loss:0.8887787448655373\n",
      "train loss:0.8786094521982687\n",
      "train loss:0.8575166293868652\n",
      "train loss:0.8256059861817101\n",
      "train loss:1.100897655327885\n",
      "train loss:0.9248724357972933\n",
      "train loss:0.9066071478450085\n",
      "train loss:0.7788652632520823\n",
      "train loss:0.7425325798557764\n",
      "train loss:0.9781710430308432\n",
      "train loss:0.9089047185542085\n",
      "train loss:0.9638795352181471\n",
      "train loss:0.8638028539082053\n",
      "train loss:0.9010911361537562\n",
      "train loss:0.8094821835457996\n",
      "train loss:1.0190903411674546\n",
      "train loss:0.9301548924861583\n",
      "train loss:0.9445339412248798\n",
      "train loss:0.8258616895196655\n",
      "train loss:0.9112696648124363\n",
      "train loss:0.8280720245399645\n",
      "train loss:0.6912770940585448\n",
      "train loss:0.9107603964285894\n",
      "train loss:0.7437801242315213\n",
      "train loss:1.0644702809343007\n",
      "train loss:0.9089677529096813\n",
      "train loss:0.9561703803175974\n",
      "train loss:0.9508335261149574\n",
      "train loss:1.108292143825898\n",
      "train loss:0.9017588672560525\n",
      "train loss:0.8266360618046594\n",
      "train loss:1.0181558872049368\n",
      "train loss:0.9311846851470112\n",
      "=== epoch:8, train acc:0.993, test acc:0.992 ===\n",
      "train loss:0.9718107879046556\n",
      "train loss:1.0953575786777356\n",
      "train loss:0.9279441466594751\n",
      "train loss:0.9431936078846589\n",
      "train loss:0.7619548190940566\n",
      "train loss:0.947195955281673\n",
      "train loss:0.8847411439652487\n",
      "train loss:0.8669848055711868\n",
      "train loss:0.8227567050374922\n",
      "train loss:0.9070616984997438\n",
      "train loss:0.7679429168426252\n",
      "train loss:0.7455572684483535\n",
      "train loss:1.0593400219607754\n",
      "train loss:0.8218196685555725\n",
      "train loss:0.9193744905502546\n",
      "train loss:0.9470514392370013\n",
      "train loss:0.9645245516865942\n",
      "train loss:0.7735302147145531\n",
      "train loss:0.7982813128436886\n",
      "train loss:0.9563580041901362\n",
      "train loss:0.7786510938634743\n",
      "train loss:0.9946236060957719\n",
      "train loss:0.7797334336418957\n",
      "train loss:0.7826284930550894\n",
      "train loss:0.9188093986974692\n",
      "train loss:0.8979937510008759\n",
      "train loss:0.795032828517124\n",
      "train loss:0.8685660138545669\n",
      "train loss:0.8727666768195251\n",
      "train loss:1.0695715930154663\n",
      "train loss:0.8299146299930353\n",
      "train loss:1.0088404386435874\n",
      "train loss:0.8879435706254141\n",
      "train loss:0.8723984993181912\n",
      "train loss:0.866956081311072\n",
      "train loss:1.0348608974716427\n",
      "train loss:0.8937037079465394\n",
      "train loss:0.9177765854070935\n",
      "train loss:0.8288138774416888\n",
      "train loss:0.9886489015288913\n",
      "train loss:0.8741902795458372\n",
      "train loss:0.7976887059752713\n",
      "train loss:0.8646087903417893\n",
      "train loss:0.9170229433957812\n",
      "train loss:0.9832224125375063\n",
      "train loss:0.9779495711906321\n",
      "train loss:0.9226080677227856\n",
      "train loss:0.7732843118453425\n",
      "train loss:0.8530942672718159\n",
      "train loss:1.0175590488843738\n",
      "train loss:0.8462459100313127\n",
      "train loss:1.0223778150464513\n",
      "train loss:0.8577350754560888\n",
      "train loss:1.1396936708784913\n",
      "train loss:0.8338991339710792\n",
      "train loss:0.8746293653502029\n",
      "train loss:0.9491641837957145\n",
      "train loss:0.955451992656471\n",
      "train loss:0.6893599620779399\n",
      "train loss:0.8265491019837569\n",
      "train loss:0.8118164415634098\n",
      "train loss:0.8995464468244362\n",
      "train loss:0.9490226484732796\n",
      "train loss:0.9459344458481934\n",
      "train loss:0.7455082541781249\n",
      "train loss:0.7766557415066327\n",
      "train loss:0.8832413460445254\n",
      "train loss:0.972796357520202\n",
      "train loss:0.8466506911763899\n",
      "train loss:0.8996283888372776\n",
      "train loss:0.8956865566895\n",
      "train loss:0.8867383410404004\n",
      "train loss:0.7718226101604035\n",
      "train loss:0.6895655784699833\n",
      "train loss:1.114719236384547\n",
      "train loss:0.866938785466648\n",
      "train loss:0.8019929390391672\n",
      "train loss:0.9536461016803957\n",
      "train loss:0.8588469599018818\n",
      "train loss:0.8874790714186307\n",
      "train loss:0.9665346869733722\n",
      "train loss:0.8800277739180247\n",
      "train loss:0.8211119768778083\n",
      "train loss:0.8475020750950137\n",
      "train loss:0.8877798317542955\n",
      "train loss:1.0617098500248048\n",
      "train loss:1.0324280527804002\n",
      "train loss:0.9261889343635776\n",
      "train loss:0.7281833125020661\n",
      "train loss:0.9964316806376832\n",
      "train loss:0.9948935675143877\n",
      "train loss:0.985850631913956\n",
      "train loss:0.8817906789441037\n",
      "train loss:0.7756993951364619\n",
      "train loss:0.746610811645443\n",
      "train loss:0.9459039572420277\n",
      "train loss:0.9045101543682691\n",
      "train loss:0.840083637173182\n",
      "train loss:0.938753962403965\n",
      "train loss:0.8650882712063739\n",
      "train loss:0.859605301416004\n",
      "train loss:0.7805347156828195\n",
      "train loss:0.8875497842672965\n",
      "train loss:0.9171923600756416\n",
      "train loss:0.9428749161920613\n",
      "train loss:0.853703745269109\n",
      "train loss:0.9174427685320359\n",
      "train loss:0.8664690992840934\n",
      "train loss:0.9188395283341697\n",
      "train loss:0.8003721604047561\n",
      "train loss:0.9555455892953003\n",
      "train loss:0.9117232267823695\n",
      "train loss:1.0132678810867848\n",
      "train loss:0.7800925758894922\n",
      "train loss:1.0522097488652344\n",
      "train loss:0.8789682007342879\n",
      "train loss:0.8942185265678555\n",
      "train loss:0.7447666022010471\n",
      "train loss:0.9284929906235743\n",
      "train loss:0.8774429036139836\n",
      "train loss:0.8251250210494082\n",
      "train loss:0.9652094503491833\n",
      "train loss:0.8302688693621615\n",
      "train loss:0.9161897713663325\n",
      "train loss:1.064956221241563\n",
      "train loss:0.8373945247427773\n",
      "train loss:0.9620438945103884\n",
      "train loss:0.7478561310516845\n",
      "train loss:0.8244170874133467\n",
      "train loss:0.8979474192759586\n",
      "train loss:0.8482363476992041\n",
      "train loss:0.9043162685436436\n",
      "train loss:0.8238473108584757\n",
      "train loss:0.935584138177768\n",
      "train loss:0.8580056933410524\n",
      "train loss:0.8574147712998871\n",
      "train loss:0.9330463810807244\n",
      "train loss:0.9860263357486897\n",
      "train loss:0.8149386263312938\n",
      "train loss:0.8775375542294823\n",
      "train loss:0.9982244702583413\n",
      "train loss:0.8626329185462057\n",
      "train loss:0.9116598414720335\n",
      "train loss:0.7002424651356648\n",
      "train loss:0.8721580211713619\n",
      "train loss:0.8002750814187638\n",
      "train loss:0.9093507343181976\n",
      "train loss:1.0691176856526297\n",
      "train loss:0.9226051870164476\n",
      "train loss:0.805797514945914\n",
      "train loss:0.8754058864325335\n",
      "train loss:0.708552099379984\n",
      "train loss:0.9596523540934139\n",
      "train loss:0.9314334667336307\n",
      "train loss:0.9144834638983713\n",
      "train loss:0.9763452040173703\n",
      "train loss:0.9841757820524282\n",
      "train loss:0.9282737737061458\n",
      "train loss:0.9191806066648074\n",
      "train loss:0.8887344031591846\n",
      "train loss:0.8994758262246729\n",
      "train loss:0.7849760511044195\n",
      "train loss:0.789250219534232\n",
      "train loss:0.8741286983201693\n",
      "train loss:0.8878598850044933\n",
      "train loss:0.9748219454802384\n",
      "train loss:0.8089610427308433\n",
      "train loss:0.996086410325264\n",
      "train loss:0.9400345576695313\n",
      "train loss:0.9761160705477784\n",
      "train loss:0.7988039332487114\n",
      "train loss:1.0349687475014562\n",
      "train loss:0.9427170481282187\n",
      "train loss:0.6108110834802284\n",
      "train loss:0.67889262217518\n",
      "train loss:0.9559914159528627\n",
      "train loss:0.8260364603121245\n",
      "train loss:0.9024368195825403\n",
      "train loss:0.9946208644774793\n",
      "train loss:0.9222592285469533\n",
      "train loss:0.7935347729327235\n",
      "train loss:0.778723084841619\n",
      "train loss:0.9930888027142815\n",
      "train loss:0.9803222387117964\n",
      "train loss:0.9808773759408089\n",
      "train loss:0.917030264389224\n",
      "train loss:0.8774141030525991\n",
      "train loss:0.8778739599041117\n",
      "train loss:0.9545719154714463\n",
      "train loss:0.9488657849478878\n",
      "train loss:0.9186746120663735\n",
      "train loss:0.8652888507311144\n",
      "train loss:0.9694753654297099\n",
      "train loss:0.8180286270963338\n",
      "train loss:0.884070798595079\n",
      "train loss:0.882033001297318\n",
      "train loss:0.8040164679700013\n",
      "train loss:0.8615940966663616\n",
      "train loss:0.9369529040981225\n",
      "train loss:0.804661514197019\n",
      "train loss:0.8241591553717059\n",
      "train loss:0.9019499811297316\n",
      "train loss:0.9655082314497556\n",
      "train loss:0.8877670613454872\n",
      "train loss:0.8820225534401325\n",
      "train loss:0.9152391469433799\n",
      "train loss:0.8097569350610292\n",
      "train loss:0.9832976729819063\n",
      "train loss:0.9727416675628855\n",
      "train loss:0.8481429624423119\n",
      "train loss:0.8360947313398682\n",
      "train loss:0.8624400727703343\n",
      "train loss:1.0170102052466647\n",
      "train loss:0.8360149350522091\n",
      "train loss:0.7998058030301316\n",
      "train loss:0.9557541953283841\n",
      "train loss:0.9256385539066803\n",
      "train loss:0.9345956547747732\n",
      "train loss:0.9153020741648554\n",
      "train loss:1.0159606898681828\n",
      "train loss:0.9062794846809173\n",
      "train loss:0.9250041715595336\n",
      "train loss:0.9026708563478504\n",
      "train loss:0.9497526976146986\n",
      "train loss:0.9141921765300419\n",
      "train loss:0.7882640089056193\n",
      "train loss:0.963416406095085\n",
      "train loss:1.041490459578248\n",
      "train loss:0.8030823640729732\n",
      "train loss:1.0450978174585064\n",
      "train loss:0.8314100918334403\n",
      "train loss:0.8587668428790022\n",
      "train loss:0.9530987113639167\n",
      "train loss:0.8379377780029151\n",
      "train loss:0.8034962447340463\n",
      "train loss:0.8520068675609782\n",
      "train loss:0.8658620030754922\n",
      "train loss:1.0301585901648125\n",
      "train loss:0.9087203606111365\n",
      "train loss:0.9065569759975858\n",
      "train loss:1.0620688292025842\n",
      "train loss:0.8834895801510827\n",
      "train loss:0.8163039279024693\n",
      "train loss:0.8675263547143666\n",
      "train loss:0.9839521211340784\n",
      "train loss:0.8668487176435677\n",
      "train loss:0.8803742552567855\n",
      "train loss:0.824960331665392\n",
      "train loss:0.8497870552788578\n",
      "train loss:0.8884359667321103\n",
      "train loss:0.7613286597725469\n",
      "train loss:0.9565332794916068\n",
      "train loss:0.8267404135338452\n",
      "train loss:0.8679362407701283\n",
      "train loss:0.9557547982192439\n",
      "train loss:0.976683264282738\n",
      "train loss:0.8536126682792985\n",
      "train loss:1.020330061659394\n",
      "train loss:0.9012583577847266\n",
      "train loss:0.9685939407764811\n",
      "train loss:0.9874965784921579\n",
      "train loss:0.8996976443137015\n",
      "train loss:0.9084411722030947\n",
      "train loss:1.0145361747886312\n",
      "train loss:0.8310139006868497\n",
      "train loss:0.9112806871181256\n",
      "train loss:0.9314607030123585\n",
      "train loss:0.9068166430877102\n",
      "train loss:0.8192649049507543\n",
      "train loss:0.9148864795469024\n",
      "train loss:0.7949490003337881\n",
      "train loss:0.8940950571994698\n",
      "train loss:0.8958806677064896\n",
      "train loss:0.97141555581613\n",
      "train loss:0.7856801400690573\n",
      "train loss:0.7787658072752515\n",
      "train loss:0.8229855751844057\n",
      "train loss:0.7505346815156806\n",
      "train loss:0.9146997931003646\n",
      "train loss:0.8542585409135843\n",
      "train loss:0.8992441363190733\n",
      "train loss:0.8323066155312389\n",
      "train loss:0.9340070414315196\n",
      "train loss:0.8427101880458007\n",
      "train loss:0.6398081243105689\n",
      "train loss:0.7852045398295379\n",
      "train loss:1.0015139338367498\n",
      "train loss:0.8685060118321671\n",
      "train loss:0.967268538330235\n",
      "train loss:0.8381001713353428\n",
      "train loss:0.8823705034065847\n",
      "train loss:0.8135719222297945\n",
      "train loss:0.7907235532947365\n",
      "train loss:0.9456242992283124\n",
      "train loss:0.8811008301367254\n",
      "train loss:1.0549162945050259\n",
      "train loss:0.8899732728400219\n",
      "train loss:1.0950713076688687\n",
      "train loss:0.9185571867160724\n",
      "train loss:0.6484367338283501\n",
      "train loss:0.7885361377837451\n",
      "train loss:0.8325161143526841\n",
      "train loss:1.0289880915982534\n",
      "train loss:0.9365506446155404\n",
      "train loss:0.9508834141044137\n",
      "train loss:0.985768967028769\n",
      "train loss:0.8754004797696527\n",
      "train loss:0.9425131346631036\n",
      "train loss:0.9347974079281937\n",
      "train loss:0.904370223049593\n",
      "train loss:0.8220598073298411\n",
      "train loss:0.8533938081323775\n",
      "train loss:0.9358676725269344\n",
      "train loss:0.7750412790084475\n",
      "train loss:0.9352608529036622\n",
      "train loss:0.9076436556516956\n",
      "train loss:0.8554434251006151\n",
      "train loss:1.005450889656518\n",
      "train loss:0.8671503452179526\n",
      "train loss:1.0445832154876489\n",
      "train loss:0.8730448942257756\n",
      "train loss:0.8830813476451774\n",
      "train loss:0.7600687526560211\n",
      "train loss:0.9472886260572168\n",
      "train loss:0.9414560946133282\n",
      "train loss:0.8282259657548927\n",
      "train loss:0.8297698485094966\n",
      "train loss:0.735243503916589\n",
      "train loss:0.9574664466246263\n",
      "train loss:0.9118867196137427\n",
      "train loss:0.7771420323980466\n",
      "train loss:0.9499563644034822\n",
      "train loss:0.6978137091511043\n",
      "train loss:0.8919446924954301\n",
      "train loss:0.8094557648860203\n",
      "train loss:0.9086589363368693\n",
      "train loss:0.7750463384386295\n",
      "train loss:0.8231614663384128\n",
      "train loss:0.855423228451287\n",
      "train loss:1.0136645834658478\n",
      "train loss:0.881837688479934\n",
      "train loss:0.8767311701711813\n",
      "train loss:0.8348973647059857\n",
      "train loss:0.7988250767935535\n",
      "train loss:0.7366410757839423\n",
      "train loss:0.8497769958948698\n",
      "train loss:0.8965951890074093\n",
      "train loss:0.7200516570263915\n",
      "train loss:0.8612254312479071\n",
      "train loss:0.9372872977442317\n",
      "train loss:0.8540794420056007\n",
      "train loss:1.0341000960458664\n",
      "train loss:0.8747463851726774\n",
      "train loss:0.7426649239099329\n",
      "train loss:0.7755805321843458\n",
      "train loss:0.8613458270169133\n",
      "train loss:0.8368129277635833\n",
      "train loss:0.7077954152984661\n",
      "train loss:0.7937853498432844\n",
      "train loss:0.8618793452599638\n",
      "train loss:0.8835638493815872\n",
      "train loss:0.8154937004029972\n",
      "train loss:0.7838813018197109\n",
      "train loss:0.8301020033009477\n",
      "train loss:0.9687057978759493\n",
      "train loss:1.0281637384150963\n",
      "train loss:0.941970809807632\n",
      "train loss:0.8881811558140094\n",
      "train loss:0.938690354300681\n",
      "train loss:0.9575635975361139\n",
      "train loss:0.8550669264400891\n",
      "train loss:0.8667684006115529\n",
      "train loss:0.6513299433227361\n",
      "train loss:0.8788784164362492\n",
      "train loss:0.7328950265919566\n",
      "train loss:0.8604693162153118\n",
      "train loss:1.0011620782223143\n",
      "train loss:0.814007934614137\n",
      "train loss:0.8046498289114651\n",
      "train loss:0.8576404868986696\n",
      "train loss:0.9395127566409223\n",
      "train loss:0.8734646822594812\n",
      "train loss:0.9971873874198209\n",
      "train loss:0.8897690887766226\n",
      "train loss:0.877844375683488\n",
      "train loss:0.8902806408412803\n",
      "train loss:1.0616296413728623\n",
      "train loss:0.7948633742840632\n",
      "train loss:0.6591150963818657\n",
      "train loss:0.8988150276439093\n",
      "train loss:1.0566475369902626\n",
      "train loss:0.8537957912714491\n",
      "train loss:0.9288685059563896\n",
      "train loss:0.8865376833541752\n",
      "train loss:0.8613326772411571\n",
      "train loss:0.8919594337073049\n",
      "train loss:0.8841124876816402\n",
      "train loss:0.9466061935113479\n",
      "train loss:0.8000498501414173\n",
      "train loss:0.6859819414772932\n",
      "train loss:0.9226260890463318\n",
      "train loss:0.8522020656092792\n",
      "train loss:0.7040091366522548\n",
      "train loss:0.7516276823830351\n",
      "train loss:0.7611721923463776\n",
      "train loss:0.8327834612597281\n",
      "train loss:0.6865170843639791\n",
      "train loss:1.0648018909099968\n",
      "train loss:0.7514421616443577\n",
      "train loss:1.0307516156957992\n",
      "train loss:0.8183388676780207\n",
      "train loss:0.8127730896448839\n",
      "train loss:1.1207493981115864\n",
      "train loss:0.8893004624011741\n",
      "train loss:0.8712532174473919\n",
      "train loss:0.8573973865965882\n",
      "train loss:0.7986121084376337\n",
      "train loss:0.7743121884036407\n",
      "train loss:0.927167165417264\n",
      "train loss:0.9403307029401431\n",
      "train loss:0.9140766909811765\n",
      "train loss:0.8678527496106778\n",
      "train loss:0.9183528827358818\n",
      "train loss:0.9965980642671286\n",
      "train loss:0.8078670196535974\n",
      "train loss:0.8125130924636078\n",
      "train loss:0.9270668898822234\n",
      "train loss:0.9745099924670866\n",
      "train loss:0.9694712097294962\n",
      "train loss:0.8618781105835156\n",
      "train loss:0.832024459228647\n",
      "train loss:0.8545783896404641\n",
      "train loss:0.9010993685685126\n",
      "train loss:0.9009021530895563\n",
      "train loss:0.8730470932802024\n",
      "train loss:0.8366331440085477\n",
      "train loss:1.0517930442915024\n",
      "train loss:0.9555808328774499\n",
      "train loss:0.7521078687750224\n",
      "train loss:0.8402035883040899\n",
      "train loss:0.8255662811259442\n",
      "train loss:0.8001304202845904\n",
      "train loss:0.9500055870525708\n",
      "train loss:1.0136436775620012\n",
      "train loss:0.9299814286938667\n",
      "train loss:0.889071271477675\n",
      "train loss:0.9499197547222628\n",
      "train loss:1.092830178756354\n",
      "train loss:0.7868599995330554\n",
      "train loss:0.914324244275341\n",
      "train loss:0.9676982301462234\n",
      "train loss:0.8253663546464538\n",
      "train loss:0.891606281254703\n",
      "train loss:1.0087778943835979\n",
      "train loss:0.92045868355298\n",
      "train loss:0.9405150758484266\n",
      "train loss:0.8978472644671917\n",
      "train loss:0.9066093218302782\n",
      "train loss:1.0259748956073278\n",
      "train loss:0.6949966347073129\n",
      "train loss:1.0789889059124684\n",
      "train loss:0.9343060396809213\n",
      "train loss:0.7331808086126343\n",
      "train loss:0.8149621716195965\n",
      "train loss:0.9039448021190504\n",
      "train loss:0.9379270425328776\n",
      "train loss:0.8916253362873454\n",
      "train loss:1.011784989729624\n",
      "train loss:0.987078644209516\n",
      "train loss:0.897004125068079\n",
      "train loss:0.8667955744981285\n",
      "train loss:0.8323391984368655\n",
      "train loss:0.8519744911132113\n",
      "train loss:0.9267498351962071\n",
      "train loss:0.9415980664992989\n",
      "train loss:0.95473452964667\n",
      "train loss:0.8537807827743087\n",
      "train loss:0.9491753401586913\n",
      "train loss:0.9037101751458637\n",
      "train loss:0.8152135056116695\n",
      "train loss:0.7881942470679794\n",
      "train loss:1.0138532538095708\n",
      "train loss:0.8325144563515073\n",
      "train loss:0.9732571798334081\n",
      "train loss:0.7671355744831122\n",
      "train loss:0.9731239042789713\n",
      "train loss:0.8646279307155411\n",
      "train loss:0.8506647015342348\n",
      "train loss:0.7956574534706391\n",
      "train loss:0.8530731442489242\n",
      "train loss:1.0724360394968262\n",
      "train loss:0.8804790899659095\n",
      "train loss:0.9561669803502346\n",
      "train loss:0.9096491590429268\n",
      "train loss:0.8985047463282023\n",
      "train loss:0.8483806174086942\n",
      "train loss:0.9859865551808135\n",
      "train loss:1.0199877598062574\n",
      "train loss:0.9468228546773778\n",
      "train loss:0.8573110621787151\n",
      "train loss:0.680726628324938\n",
      "train loss:0.8898686970980718\n",
      "train loss:0.8426990518854667\n",
      "train loss:0.8505327833051922\n",
      "train loss:0.9479816368780465\n",
      "train loss:0.8988131251619933\n",
      "train loss:0.8316361966335978\n",
      "train loss:0.978780874275411\n",
      "train loss:0.8937041202808286\n",
      "train loss:0.8363230422728586\n",
      "train loss:0.7670795816410683\n",
      "train loss:0.834035555839927\n",
      "train loss:0.8331922182224508\n",
      "train loss:0.7957701094325992\n",
      "train loss:0.8146068450718414\n",
      "train loss:0.9710101490622874\n",
      "train loss:0.8809931992176139\n",
      "train loss:0.9794966707742019\n",
      "train loss:0.8989956310812174\n",
      "train loss:0.8790356641407097\n",
      "train loss:0.8108906016753487\n",
      "train loss:0.9370561279268924\n",
      "train loss:0.7598599664016318\n",
      "train loss:0.9659350319753236\n",
      "train loss:0.9168970727036299\n",
      "train loss:0.9822177012297806\n",
      "train loss:1.061317436376549\n",
      "train loss:0.8487818299614497\n",
      "train loss:0.7771980536126768\n",
      "train loss:0.8023856532944563\n",
      "train loss:0.9508632346398141\n",
      "train loss:0.9486411941680271\n",
      "train loss:0.841026807965202\n",
      "train loss:0.6841479838987163\n",
      "train loss:0.8233358586258607\n",
      "train loss:0.8076777450657434\n",
      "train loss:1.0553270971339996\n",
      "train loss:0.845121783599463\n",
      "train loss:0.7481473172314526\n",
      "train loss:0.7314838444239136\n",
      "train loss:0.839672847656125\n",
      "train loss:0.9805060869503032\n",
      "train loss:0.9480957284285988\n",
      "train loss:0.8949282126133142\n",
      "train loss:0.980271485340224\n",
      "train loss:0.7785442939971319\n",
      "train loss:0.7279899153320615\n",
      "train loss:0.8454634353830649\n",
      "train loss:0.7300345578563919\n",
      "train loss:0.8172302759684306\n",
      "train loss:0.9824858300727314\n",
      "train loss:0.6856850694107856\n",
      "train loss:0.8441482097562854\n",
      "train loss:0.9171817035555878\n",
      "train loss:1.06030617166477\n",
      "train loss:0.8899868790420687\n",
      "train loss:0.9336795276541474\n",
      "train loss:0.8959083874270312\n",
      "train loss:0.7969217085243144\n",
      "train loss:0.9438843409006956\n",
      "train loss:0.8209699438138709\n",
      "train loss:0.9269623082769901\n",
      "train loss:0.8417716022225794\n",
      "train loss:0.9702986320544201\n",
      "train loss:0.9468342966016398\n",
      "train loss:1.0047368460608492\n",
      "train loss:0.8782945930883693\n",
      "train loss:0.9730512693524591\n",
      "train loss:0.8293148993071254\n",
      "train loss:1.0468405216989176\n",
      "train loss:0.8237798301256559\n",
      "train loss:0.8067051212726574\n",
      "train loss:0.9598733813491462\n",
      "train loss:0.9030283041897563\n",
      "train loss:1.0368724514078251\n",
      "train loss:0.9390404303716156\n",
      "train loss:0.8593572704108433\n",
      "train loss:1.0362145301644978\n",
      "train loss:1.030250390431864\n",
      "train loss:0.8379517251080791\n",
      "train loss:0.8855600444806538\n",
      "train loss:1.1178849670438387\n",
      "train loss:0.9554828146324236\n",
      "train loss:0.8046127386285413\n",
      "train loss:0.8556821406526681\n",
      "train loss:0.9650015188144809\n",
      "train loss:0.7682279303475588\n",
      "train loss:0.95431624734361\n",
      "train loss:0.8808216506854109\n",
      "train loss:0.7200679421331165\n",
      "train loss:0.8652302513923884\n",
      "train loss:0.8806654443577088\n",
      "train loss:1.007796911728366\n",
      "train loss:0.9926994650081552\n",
      "train loss:0.9010178163143785\n",
      "train loss:1.0479654180000906\n",
      "train loss:0.7025547066980817\n",
      "train loss:0.7523979242215849\n",
      "train loss:0.8294207970984886\n",
      "train loss:0.9715176027706051\n",
      "=== epoch:9, train acc:0.995, test acc:0.993 ===\n",
      "train loss:0.9280974428626578\n",
      "train loss:0.9296157595954139\n",
      "train loss:0.9653582076738297\n",
      "train loss:0.7986054556084541\n",
      "train loss:0.8350628399984269\n",
      "train loss:0.8529396362577206\n",
      "train loss:0.8350823099603045\n",
      "train loss:0.752325268270955\n",
      "train loss:0.7691503213407018\n",
      "train loss:0.9790972157151013\n",
      "train loss:0.8360815857123585\n",
      "train loss:0.9092374713390299\n",
      "train loss:0.9175736102229496\n",
      "train loss:0.7938090527862849\n",
      "train loss:0.8937529418806419\n",
      "train loss:0.9743598790758948\n",
      "train loss:0.8155180380519462\n",
      "train loss:0.9874304133361531\n",
      "train loss:0.7877774031660842\n",
      "train loss:0.9222962164429709\n",
      "train loss:0.7857231365250021\n",
      "train loss:0.7725395989668813\n",
      "train loss:0.8965107639181271\n",
      "train loss:0.8621428277049086\n",
      "train loss:0.850253658013266\n",
      "train loss:0.8828733772972983\n",
      "train loss:0.9606216160069969\n",
      "train loss:0.9946383710193569\n",
      "train loss:0.8446877875085151\n",
      "train loss:0.8051429029716006\n",
      "train loss:0.8023044511749863\n",
      "train loss:0.8751009551231619\n",
      "train loss:0.9579201317038026\n",
      "train loss:0.8241884591674132\n",
      "train loss:0.9836753507841403\n",
      "train loss:0.7302282022804301\n",
      "train loss:0.8865491453670618\n",
      "train loss:0.842928841842964\n",
      "train loss:0.7902660402139416\n",
      "train loss:0.9769534882958734\n",
      "train loss:0.9303735501086671\n",
      "train loss:0.8462672034006258\n",
      "train loss:0.8482675124507933\n",
      "train loss:0.9201865361112257\n",
      "train loss:0.9904345107373738\n",
      "train loss:0.9452233977572821\n",
      "train loss:0.8140631994563137\n",
      "train loss:0.8066793685064853\n",
      "train loss:0.774328714210666\n",
      "train loss:0.7891674814435018\n",
      "train loss:0.9523581797902237\n",
      "train loss:0.7428127216328168\n",
      "train loss:0.7645726846533636\n",
      "train loss:0.9222053403625966\n",
      "train loss:0.737232077275385\n",
      "train loss:0.8123459376363553\n",
      "train loss:0.8283675180034052\n",
      "train loss:0.8577509141994903\n",
      "train loss:0.7187882904752806\n",
      "train loss:0.8755191861284672\n",
      "train loss:0.8852543780893657\n",
      "train loss:0.8983498597721024\n",
      "train loss:0.9465703489887677\n",
      "train loss:0.9809494469352851\n",
      "train loss:1.1137513745317988\n",
      "train loss:0.8905164835735839\n",
      "train loss:0.838528035761469\n",
      "train loss:0.7517921508177693\n",
      "train loss:0.8276661874900961\n",
      "train loss:0.8513875072503277\n",
      "train loss:0.8613262839061312\n",
      "train loss:1.0061357357219953\n",
      "train loss:0.7834949846387163\n",
      "train loss:0.8926084850493214\n",
      "train loss:0.866459970999757\n",
      "train loss:0.8501517782590323\n",
      "train loss:0.7589441117441115\n",
      "train loss:0.7675614746365159\n",
      "train loss:1.110896266491237\n",
      "train loss:0.9432256843631692\n",
      "train loss:1.0595914834208975\n",
      "train loss:0.8269026177480839\n",
      "train loss:0.895792094217851\n",
      "train loss:0.8252553692022707\n",
      "train loss:0.8418873045579311\n",
      "train loss:0.9510143326652317\n",
      "train loss:0.8134833803903728\n",
      "train loss:0.7864625611648799\n",
      "train loss:0.839704208290446\n",
      "train loss:0.8582485030046689\n",
      "train loss:0.8711029502205524\n",
      "train loss:0.850272131607713\n",
      "train loss:0.9977583296473095\n",
      "train loss:1.0104155889497815\n",
      "train loss:0.8148411271607975\n",
      "train loss:0.9352721272354871\n",
      "train loss:0.8868285222185027\n",
      "train loss:0.9554142584386851\n",
      "train loss:0.9016236702467046\n",
      "train loss:0.8593194725185588\n",
      "train loss:0.9283423879197228\n",
      "train loss:0.8519276484221804\n",
      "train loss:0.9046576578672719\n",
      "train loss:0.8762098487076078\n",
      "train loss:0.8685927425718848\n",
      "train loss:0.8309722721188476\n",
      "train loss:0.9468778338479571\n",
      "train loss:0.7717841102683439\n",
      "train loss:0.898017732143354\n",
      "train loss:1.0340944046608762\n",
      "train loss:0.9057500117104117\n",
      "train loss:0.8738425549539676\n",
      "train loss:0.9316778218332827\n",
      "train loss:0.7805751874480106\n",
      "train loss:0.8360427567276046\n",
      "train loss:0.7791802535071478\n",
      "train loss:0.7883791211241118\n",
      "train loss:0.8593114685246794\n",
      "train loss:0.8296609963719201\n",
      "train loss:0.779195755739908\n",
      "train loss:0.887587567857345\n",
      "train loss:0.8178132800206649\n",
      "train loss:0.9055361699035509\n",
      "train loss:0.7799365189343282\n",
      "train loss:0.8687762888472578\n",
      "train loss:0.8761638892265566\n",
      "train loss:0.930168561962586\n",
      "train loss:0.8553195211709859\n",
      "train loss:0.8233598310856758\n",
      "train loss:0.7353934021141028\n",
      "train loss:0.9033544515807945\n",
      "train loss:0.9287793583597141\n",
      "train loss:0.8669654817778167\n",
      "train loss:0.9630726705398942\n",
      "train loss:0.8011837746491524\n",
      "train loss:0.8407819851698461\n",
      "train loss:0.8696040236474901\n",
      "train loss:0.8796412560056086\n",
      "train loss:0.7793933841903997\n",
      "train loss:0.9311100810781923\n",
      "train loss:0.8854675849197541\n",
      "train loss:0.8352099450352624\n",
      "train loss:0.8975430071749478\n",
      "train loss:0.9749642938732722\n",
      "train loss:0.7168871049489556\n",
      "train loss:0.9685115721904921\n",
      "train loss:0.8391154179026546\n",
      "train loss:1.007718857005595\n",
      "train loss:0.9231548770658038\n",
      "train loss:0.9611261052154572\n",
      "train loss:0.9161733369900104\n",
      "train loss:1.033608455475195\n",
      "train loss:0.8316855793885953\n",
      "train loss:0.9259992638207933\n",
      "train loss:1.0176772013042905\n",
      "train loss:0.8835309932633245\n",
      "train loss:0.9067191587404014\n",
      "train loss:0.8983087018159347\n",
      "train loss:0.8696361221095269\n",
      "train loss:0.781171620243595\n",
      "train loss:0.9409664736982056\n",
      "train loss:0.8824821660147089\n",
      "train loss:0.8272704464193207\n",
      "train loss:0.8909321595975858\n",
      "train loss:0.9503412576652217\n",
      "train loss:0.7465963929076201\n",
      "train loss:0.7878826953229834\n",
      "train loss:0.9138543227092142\n",
      "train loss:0.8430173264406088\n",
      "train loss:0.8087618533863111\n",
      "train loss:1.0574869553952437\n",
      "train loss:1.047485369068764\n",
      "train loss:0.7747284444420308\n",
      "train loss:0.8716218580682856\n",
      "train loss:0.9059168905013207\n",
      "train loss:0.8686556372753189\n",
      "train loss:0.9956364068782713\n",
      "train loss:0.8426559648302129\n",
      "train loss:0.7838898833889513\n",
      "train loss:0.7370048766190243\n",
      "train loss:0.91285616941008\n",
      "train loss:0.7904712885522117\n",
      "train loss:0.952145440455809\n",
      "train loss:0.8081978625000248\n",
      "train loss:0.8132602037171494\n",
      "train loss:1.1238334254973459\n",
      "train loss:0.9231789390483709\n",
      "train loss:0.8332569010949905\n",
      "train loss:1.114657430165988\n",
      "train loss:0.9925487351134602\n",
      "train loss:0.8047248966338354\n",
      "train loss:0.651877504718011\n",
      "train loss:0.9009383613671317\n",
      "train loss:0.8483246904952206\n",
      "train loss:0.9425944475947664\n",
      "train loss:1.036275732359413\n",
      "train loss:0.8216523597527471\n",
      "train loss:0.8873477456789807\n",
      "train loss:0.7840474330803461\n",
      "train loss:0.9537352164787805\n",
      "train loss:0.8228075948529459\n",
      "train loss:0.9526029065170626\n",
      "train loss:0.9017044007751568\n",
      "train loss:0.9996974184454237\n",
      "train loss:0.9830007771799311\n",
      "train loss:0.9588207639259859\n",
      "train loss:0.9309563712337967\n",
      "train loss:0.8768574207670389\n",
      "train loss:0.7936844104421686\n",
      "train loss:0.9028229147787421\n",
      "train loss:0.8735337296608165\n",
      "train loss:0.9074830534640793\n",
      "train loss:0.887631742595292\n",
      "train loss:1.0207732844535173\n",
      "train loss:0.942527342552196\n",
      "train loss:0.8611214622594713\n",
      "train loss:0.9554451322325703\n",
      "train loss:0.757455493222046\n",
      "train loss:0.8559605864887766\n",
      "train loss:1.0417476927144944\n",
      "train loss:0.8697274604425631\n",
      "train loss:0.8852237594366672\n",
      "train loss:0.9569171235810288\n",
      "train loss:0.9486609978277886\n",
      "train loss:0.843257015110189\n",
      "train loss:1.0558749990614027\n",
      "train loss:0.8688541240511892\n",
      "train loss:0.6914688532203729\n",
      "train loss:0.8855169210271001\n",
      "train loss:0.6910097515193762\n",
      "train loss:1.0064225431079563\n",
      "train loss:0.8085513634084168\n",
      "train loss:0.9796091455321095\n",
      "train loss:0.8599682352327309\n",
      "train loss:0.8543911449348287\n",
      "train loss:0.9756474044537875\n",
      "train loss:1.0034338718719606\n",
      "train loss:1.0740795163689085\n",
      "train loss:0.7751755617282224\n",
      "train loss:0.9189761687920321\n",
      "train loss:1.0042035812391603\n",
      "train loss:0.9184692396841452\n",
      "train loss:0.9781366395113438\n",
      "train loss:0.8554245294891518\n",
      "train loss:0.8994097423393022\n",
      "train loss:0.9166945411474076\n",
      "train loss:0.9073016418651632\n",
      "train loss:0.8420034729339307\n",
      "train loss:0.7497069038878582\n",
      "train loss:0.9879964887083464\n",
      "train loss:0.8881308909930429\n",
      "train loss:1.025203711954\n",
      "train loss:0.8263691706040285\n",
      "train loss:0.7297693642019614\n",
      "train loss:0.9157388878873429\n",
      "train loss:1.0228339400527608\n",
      "train loss:0.8691642837558523\n",
      "train loss:0.9716789861702866\n",
      "train loss:0.9701165261284541\n",
      "train loss:0.982241739863544\n",
      "train loss:0.6904168723064049\n",
      "train loss:0.9013654390320757\n",
      "train loss:0.7868094617565612\n",
      "train loss:0.7749915487638133\n",
      "train loss:0.806445034872833\n",
      "train loss:0.9015098287303914\n",
      "train loss:0.8903768013138721\n",
      "train loss:0.8914123611651874\n",
      "train loss:0.9040326275094485\n",
      "train loss:0.9840046331960741\n",
      "train loss:0.8034132460568251\n",
      "train loss:0.863800518654832\n",
      "train loss:0.8695869057656522\n",
      "train loss:0.8224390299132125\n",
      "train loss:0.8964139634348928\n",
      "train loss:1.0407510822217925\n",
      "train loss:1.0329847421894192\n",
      "train loss:0.7882107414947646\n",
      "train loss:0.7316197094444781\n",
      "train loss:1.0651462675280998\n",
      "train loss:1.0026194014500605\n",
      "train loss:0.8977391832679636\n",
      "train loss:1.0248908677228692\n",
      "train loss:0.8665912034382072\n",
      "train loss:0.7444689798023668\n",
      "train loss:0.8023452219802012\n",
      "train loss:0.9959096730654852\n",
      "train loss:0.9209619046398891\n",
      "train loss:0.9118084742611887\n",
      "train loss:0.7538825806575518\n",
      "train loss:0.8180045686862841\n",
      "train loss:0.728031494944873\n",
      "train loss:0.849829171477906\n",
      "train loss:0.9597335326414719\n",
      "train loss:0.9335025603018375\n",
      "train loss:0.875477049096702\n",
      "train loss:0.9044510024732039\n",
      "train loss:0.9428244014198076\n",
      "train loss:0.9216882447972548\n",
      "train loss:1.0530367259074194\n",
      "train loss:0.7941105140271624\n",
      "train loss:0.9148842898267968\n",
      "train loss:0.9414997229421761\n",
      "train loss:0.6712652136690348\n",
      "train loss:0.7812553220022963\n",
      "train loss:0.9016450434514418\n",
      "train loss:1.0103263618052243\n",
      "train loss:1.0240613471029647\n",
      "train loss:1.0682608719839681\n",
      "train loss:0.9194375085692689\n",
      "train loss:0.888584057794987\n",
      "train loss:0.8401013292869476\n",
      "train loss:0.7998258000841464\n",
      "train loss:1.0167251134064594\n",
      "train loss:0.8639810091478463\n",
      "train loss:0.9153782710480636\n",
      "train loss:0.6812982962177339\n",
      "train loss:0.9259414846229316\n",
      "train loss:0.8601775869628809\n",
      "train loss:0.7926621355094106\n",
      "train loss:0.7556891541007793\n",
      "train loss:0.8920234966817633\n",
      "train loss:0.9695822836428725\n",
      "train loss:0.7698444329972951\n",
      "train loss:0.8363566034336164\n",
      "train loss:0.9382709104283481\n",
      "train loss:0.7205932585713914\n",
      "train loss:0.9101123151801521\n",
      "train loss:0.8125346194835592\n",
      "train loss:0.9007203303913068\n",
      "train loss:0.9167821494260293\n",
      "train loss:0.6574753546362524\n",
      "train loss:1.0267556474893391\n",
      "train loss:1.032293184509344\n",
      "train loss:0.9548099519567218\n",
      "train loss:0.7812493566324923\n",
      "train loss:0.6546316711645414\n",
      "train loss:1.0210249645948677\n",
      "train loss:0.8812534235657707\n",
      "train loss:0.9434201307922976\n",
      "train loss:0.9137673938529954\n",
      "train loss:0.8312104731030773\n",
      "train loss:0.9375743343689976\n",
      "train loss:0.8498892660316302\n",
      "train loss:1.0239547543924963\n",
      "train loss:1.0114510631129552\n",
      "train loss:0.7600193672159193\n",
      "train loss:0.9326971417911047\n",
      "train loss:0.9851069107080594\n",
      "train loss:0.8765092118435763\n",
      "train loss:0.9431861825964545\n",
      "train loss:0.9110595920436321\n",
      "train loss:0.8428525343744068\n",
      "train loss:0.7965841221869632\n",
      "train loss:0.9208558417434726\n",
      "train loss:0.9837862007159001\n",
      "train loss:0.883801811620468\n",
      "train loss:0.8778762855147794\n",
      "train loss:0.8986595962308874\n",
      "train loss:0.8650614725216813\n",
      "train loss:0.7733619940371952\n",
      "train loss:0.8444915786181052\n",
      "train loss:0.8401889969580053\n",
      "train loss:0.6413420084611434\n",
      "train loss:0.7610757618894393\n",
      "train loss:0.7421044949362126\n",
      "train loss:0.890349826911121\n",
      "train loss:0.8676447032756498\n",
      "train loss:1.055680192140614\n",
      "train loss:0.6658320859084167\n",
      "train loss:1.0223503232396234\n",
      "train loss:0.9337033019697766\n",
      "train loss:0.8004267669774695\n",
      "train loss:0.9741873424616646\n",
      "train loss:0.9647321276815367\n",
      "train loss:0.8701462488587376\n",
      "train loss:0.8293468273697894\n",
      "train loss:0.8756687965006555\n",
      "train loss:0.9632262270736003\n",
      "train loss:0.8144082390752263\n",
      "train loss:0.8519335389162274\n",
      "train loss:0.9480399641846086\n",
      "train loss:1.0304890933231305\n",
      "train loss:0.8600949781893735\n",
      "train loss:0.9744893813988516\n",
      "train loss:0.9277456938019586\n",
      "train loss:0.9901075688137876\n",
      "train loss:0.8170948003163998\n",
      "train loss:0.8682547490604694\n",
      "train loss:0.9062905894079522\n",
      "train loss:1.0269721528629128\n",
      "train loss:0.9574622067948257\n",
      "train loss:0.9293944520371278\n",
      "train loss:0.7838703459172122\n",
      "train loss:0.8043491636054694\n",
      "train loss:0.8332135300323508\n",
      "train loss:0.7727555412243258\n",
      "train loss:0.7458057717414683\n",
      "train loss:0.8397818500549126\n",
      "train loss:0.738684716120764\n",
      "train loss:0.9490406290227367\n",
      "train loss:0.9773507414470202\n",
      "train loss:1.0031976921629304\n",
      "train loss:0.8831089487697606\n",
      "train loss:0.9208947813656267\n",
      "train loss:0.8976802297526096\n",
      "train loss:0.670667042591646\n",
      "train loss:0.9446062852245644\n",
      "train loss:1.2479568443665638\n",
      "train loss:0.845009023277721\n",
      "train loss:0.966218618826924\n",
      "train loss:0.9477522870308783\n",
      "train loss:0.8195790357136791\n",
      "train loss:0.8801990243296551\n",
      "train loss:1.0456287809050218\n",
      "train loss:0.9066736531776961\n",
      "train loss:0.9921957517799792\n",
      "train loss:0.9925651409326093\n",
      "train loss:1.007922694665937\n",
      "train loss:0.961266513757723\n",
      "train loss:0.9566917843789097\n",
      "train loss:0.8249247032780105\n",
      "train loss:0.8596352987665431\n",
      "train loss:0.8401434970134715\n",
      "train loss:0.8154731923246733\n",
      "train loss:0.9305279542298552\n",
      "train loss:0.9384543636712881\n",
      "train loss:0.9396056866284532\n",
      "train loss:0.9013715168174471\n",
      "train loss:0.7922229823343733\n",
      "train loss:1.0096404313565857\n",
      "train loss:0.9735995349841343\n",
      "train loss:0.8714134898640157\n",
      "train loss:0.9695925264079652\n",
      "train loss:0.8196555684308986\n",
      "train loss:0.8025857295974874\n",
      "train loss:0.804281567249251\n",
      "train loss:0.761298227352561\n",
      "train loss:0.9904409151046665\n",
      "train loss:0.6924816855919285\n",
      "train loss:0.9232261025660412\n",
      "train loss:0.8247450969277063\n",
      "train loss:1.0119839482345183\n",
      "train loss:0.9105570034462959\n",
      "train loss:0.9082863051066983\n",
      "train loss:0.8690457878132282\n",
      "train loss:0.8652875400661658\n",
      "train loss:1.0451073255015655\n",
      "train loss:0.958775021827045\n",
      "train loss:0.8737753086611962\n",
      "train loss:0.8291799940005024\n",
      "train loss:0.7119430063010754\n",
      "train loss:1.0430429474694591\n",
      "train loss:0.7587953668122523\n",
      "train loss:0.8875067482221177\n",
      "train loss:0.8487871116450078\n",
      "train loss:0.829985255245323\n",
      "train loss:0.841308416886175\n",
      "train loss:0.8701051396788625\n",
      "train loss:1.0161156017763238\n",
      "train loss:0.866928145236809\n",
      "train loss:0.6888558229319173\n",
      "train loss:0.8730161281508318\n",
      "train loss:0.9676795741884415\n",
      "train loss:0.9558698716896871\n",
      "train loss:0.779851934498226\n",
      "train loss:0.8592284519195195\n",
      "train loss:0.8123830032540514\n",
      "train loss:1.0734687890172707\n",
      "train loss:0.9526768961773384\n",
      "train loss:0.7142515765486693\n",
      "train loss:0.8397324234575073\n",
      "train loss:0.8185380363116431\n",
      "train loss:1.092514690200455\n",
      "train loss:1.010829390809988\n",
      "train loss:0.8568805059796922\n",
      "train loss:0.8845655903641262\n",
      "train loss:0.8177434286814548\n",
      "train loss:0.7929092551884079\n",
      "train loss:0.8123672320925454\n",
      "train loss:0.781926701749833\n",
      "train loss:1.1000862774840892\n",
      "train loss:0.7625328459247936\n",
      "train loss:0.8772255083480605\n",
      "train loss:0.8650386326874795\n",
      "train loss:0.861539875536452\n",
      "train loss:1.018020035774466\n",
      "train loss:0.7397866279340302\n",
      "train loss:0.9648952983975237\n",
      "train loss:0.9624975484318499\n",
      "train loss:0.7970691883191207\n",
      "train loss:0.7948771955335308\n",
      "train loss:0.7653511370110408\n",
      "train loss:0.939704378398213\n",
      "train loss:0.7728066496781821\n",
      "train loss:0.9447211793058525\n",
      "train loss:0.9433164085548\n",
      "train loss:0.7100055138151832\n",
      "train loss:0.8802772508525151\n",
      "train loss:0.7269031745264476\n",
      "train loss:1.0070152334147513\n",
      "train loss:0.7897782327296861\n",
      "train loss:0.8248947408031851\n",
      "train loss:0.9351715685295922\n",
      "train loss:0.9666648761561984\n",
      "train loss:0.8763887964718673\n",
      "train loss:0.74564891199999\n",
      "train loss:0.7189769582483652\n",
      "train loss:0.9893920854186237\n",
      "train loss:0.7786462808320845\n",
      "train loss:0.7308115994835294\n",
      "train loss:0.9403776298771399\n",
      "train loss:0.7939149697634977\n",
      "train loss:0.9526272303235818\n",
      "train loss:0.9383445964037759\n",
      "train loss:0.7550594898732749\n",
      "train loss:0.7264019417732716\n",
      "train loss:1.0010386966816018\n",
      "train loss:0.7277430055357651\n",
      "train loss:1.0709961882106305\n",
      "train loss:0.9003213335440831\n",
      "train loss:0.8601236132628083\n",
      "train loss:0.8472471956977455\n",
      "train loss:0.9615637364082532\n",
      "train loss:0.7981403894062327\n",
      "train loss:0.8222588583704037\n",
      "train loss:0.9165648165694529\n",
      "train loss:0.694969902240351\n",
      "train loss:0.9281536309994223\n",
      "train loss:0.9817335029388569\n",
      "train loss:0.7753356893466585\n",
      "train loss:0.8122844219083324\n",
      "train loss:0.9557124435480415\n",
      "train loss:0.8822152070024188\n",
      "train loss:1.0726178531077113\n",
      "train loss:0.9214380535379999\n",
      "train loss:0.8190269319027582\n",
      "train loss:0.8190144066308009\n",
      "train loss:0.7474314018616812\n",
      "train loss:1.0951753559311193\n",
      "train loss:0.8740793758237835\n",
      "train loss:1.0559354369025598\n",
      "train loss:1.0699495964078833\n",
      "train loss:0.8789929930088838\n",
      "train loss:0.8442811926901856\n",
      "train loss:0.8602373569401466\n",
      "train loss:1.00624020968772\n",
      "train loss:0.963799862136934\n",
      "train loss:0.9441463785797467\n",
      "train loss:0.8806387056960538\n",
      "train loss:0.9493420057123592\n",
      "train loss:0.9895744219262811\n",
      "train loss:0.902764779578405\n",
      "train loss:0.8704031554584748\n",
      "train loss:0.9492109587068442\n",
      "train loss:0.8428097419885904\n",
      "train loss:1.0667627845506467\n",
      "train loss:0.9606190970006306\n",
      "train loss:0.897700016570437\n",
      "train loss:0.8066345239477133\n",
      "train loss:0.9077526559901046\n",
      "train loss:0.7953647885399491\n",
      "train loss:0.9138349435092497\n",
      "train loss:0.6989796160144373\n",
      "train loss:0.9000998392919706\n",
      "train loss:0.9289081810735088\n",
      "train loss:0.8047840057241302\n",
      "train loss:0.7876762641657054\n",
      "train loss:0.9157855702598432\n",
      "train loss:0.7539566523398306\n",
      "train loss:0.8426020312753316\n",
      "train loss:0.9572491774757647\n",
      "train loss:0.9203771021482653\n",
      "train loss:1.0134685276441582\n",
      "train loss:0.8167947455244916\n",
      "train loss:0.899802824961939\n",
      "train loss:0.9383884194130058\n",
      "train loss:0.8340751040833588\n",
      "train loss:0.9172810765299547\n",
      "train loss:0.9510007191018195\n",
      "train loss:0.8118106557757088\n",
      "train loss:0.8948303580506314\n",
      "train loss:0.8913691082130133\n",
      "train loss:0.9057908266972271\n",
      "train loss:0.9316813351716727\n",
      "train loss:1.0406885774458332\n",
      "train loss:0.7790820837758343\n",
      "train loss:0.8668751850966134\n",
      "train loss:0.8575964944893372\n",
      "train loss:0.8028735635860823\n",
      "train loss:0.8796986724314536\n",
      "train loss:0.8335645614481144\n",
      "train loss:0.994710867782474\n",
      "train loss:0.8206541289048738\n",
      "train loss:0.9431165922426659\n",
      "train loss:0.9626956521269372\n",
      "train loss:0.9870962031517712\n",
      "train loss:0.8117171725844347\n",
      "train loss:0.9052678657160358\n",
      "train loss:0.8866097984045682\n",
      "=== epoch:10, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.9427143343248845\n",
      "train loss:0.8364076392247562\n",
      "train loss:0.7386314179776409\n",
      "train loss:0.783569383691194\n",
      "train loss:1.09683427032554\n",
      "train loss:0.7622265847415028\n",
      "train loss:0.8980328001930533\n",
      "train loss:0.8649351859182569\n",
      "train loss:0.8714908059461033\n",
      "train loss:0.9937164548531975\n",
      "train loss:0.6790579958774545\n",
      "train loss:0.884509384675647\n",
      "train loss:0.9547084002335267\n",
      "train loss:0.8289800281211288\n",
      "train loss:1.0811627011379876\n",
      "train loss:0.8075457957815699\n",
      "train loss:0.9441224548756098\n",
      "train loss:0.899807370732789\n",
      "train loss:0.8898787032487389\n",
      "train loss:0.7747133600225043\n",
      "train loss:0.9659349742606038\n",
      "train loss:0.8546518791741046\n",
      "train loss:0.7933083989943154\n",
      "train loss:0.7966391146940643\n",
      "train loss:0.8974203350573846\n",
      "train loss:0.9569858115550867\n",
      "train loss:0.8086641473021067\n",
      "train loss:0.7838390840669861\n",
      "train loss:1.0483323924844496\n",
      "train loss:0.9646070100331906\n",
      "train loss:0.9254076572914972\n",
      "train loss:0.816518867737431\n",
      "train loss:0.9332838277645555\n",
      "train loss:0.837925666517895\n",
      "train loss:0.9639040878815587\n",
      "train loss:0.958697002391376\n",
      "train loss:0.9236634223997525\n",
      "train loss:0.8111768798412737\n",
      "train loss:0.9840313325201261\n",
      "train loss:0.8196987513826811\n",
      "train loss:0.8889749708960869\n",
      "train loss:0.7682437116676292\n",
      "train loss:0.7662373917666956\n",
      "train loss:0.8666082469047599\n",
      "train loss:0.9064265073892227\n",
      "train loss:0.7847281582987471\n",
      "train loss:0.9036028278138183\n",
      "train loss:0.7817650526621407\n",
      "train loss:1.0120225682417534\n",
      "train loss:1.2763424393072136\n",
      "train loss:0.8688710182482962\n",
      "train loss:0.7989996435768751\n",
      "train loss:0.7521898917776199\n",
      "train loss:0.9954368640146961\n",
      "train loss:0.9269136897839939\n",
      "train loss:0.9026072811586391\n",
      "train loss:0.9150320253673716\n",
      "train loss:0.8182900872281728\n",
      "train loss:0.8491646862954716\n",
      "train loss:0.7970202399867149\n",
      "train loss:0.9118845527524683\n",
      "train loss:0.7793913256403642\n",
      "train loss:0.8417891331231574\n",
      "train loss:1.028392368697493\n",
      "train loss:0.8553688066946542\n",
      "train loss:0.7934395382773792\n",
      "train loss:0.9069456370295798\n",
      "train loss:0.818983759956246\n",
      "train loss:0.9575040955622725\n",
      "train loss:0.844435923785032\n",
      "train loss:0.8786251720819618\n",
      "train loss:0.857592869964286\n",
      "train loss:0.8100711227027828\n",
      "train loss:0.8535805871938856\n",
      "train loss:0.8499327656252723\n",
      "train loss:0.7312194008641906\n",
      "train loss:0.8965313707323946\n",
      "train loss:0.9693539746519426\n",
      "train loss:0.8833832036695354\n",
      "train loss:1.0257006385548209\n",
      "train loss:0.9629823722420277\n",
      "train loss:0.9710114909650251\n",
      "train loss:0.9783073301035364\n",
      "train loss:0.8402777245957966\n",
      "train loss:0.8790503976960155\n",
      "train loss:0.9489103025765574\n",
      "train loss:0.8539583930310907\n",
      "train loss:0.8058505708710508\n",
      "train loss:0.870749517470268\n",
      "train loss:0.9243087176311409\n",
      "train loss:0.8795400509017055\n",
      "train loss:0.8258728520291644\n",
      "train loss:0.7828401569137136\n",
      "train loss:0.8906256896951307\n",
      "train loss:0.7142323252548812\n",
      "train loss:0.9113674152307795\n",
      "train loss:0.9176559378455578\n",
      "train loss:0.9400231890071943\n",
      "train loss:0.7759295872330213\n",
      "train loss:0.7165943534666885\n",
      "train loss:0.8773901108846467\n",
      "train loss:0.9029620466414596\n",
      "train loss:0.9500590691816754\n",
      "train loss:0.9770114974282369\n",
      "train loss:0.8975429891613373\n",
      "train loss:0.884981012299521\n",
      "train loss:0.8281742770819457\n",
      "train loss:0.8780278968387283\n",
      "train loss:1.07069610130122\n",
      "train loss:0.9427132847982064\n",
      "train loss:0.8063921931669907\n",
      "train loss:0.8284414235661848\n",
      "train loss:0.9270034974499055\n",
      "train loss:0.9635982948435511\n",
      "train loss:0.9198455779812034\n",
      "train loss:0.7480296635002318\n",
      "train loss:0.9348550679332126\n",
      "train loss:0.8662373340121852\n",
      "train loss:0.8723058944310629\n",
      "train loss:0.8085506247496558\n",
      "train loss:0.8929993895721818\n",
      "train loss:0.9668124199471165\n",
      "train loss:0.8047320942917068\n",
      "train loss:0.9191941727629263\n",
      "train loss:0.9365340660366044\n",
      "train loss:0.7828258674705789\n",
      "train loss:0.7169271195711545\n",
      "train loss:0.9418198149822087\n",
      "train loss:0.9995974228160937\n",
      "train loss:1.0170331768070726\n",
      "train loss:0.9480785203066897\n",
      "train loss:0.8623338254486917\n",
      "train loss:0.9483719562096793\n",
      "train loss:0.774751686565946\n",
      "train loss:0.7506647367423689\n",
      "train loss:0.8589695701188532\n",
      "train loss:0.8309342787822254\n",
      "train loss:0.7982224289021548\n",
      "train loss:0.8306961894751601\n",
      "train loss:0.6951276986516938\n",
      "train loss:0.9300655915107405\n",
      "train loss:0.8474744851919208\n",
      "train loss:0.8314996678939082\n",
      "train loss:0.7479523282913\n",
      "train loss:1.0048900767126794\n",
      "train loss:0.7980472557511473\n",
      "train loss:0.9861730403514534\n",
      "train loss:0.8290250930252508\n",
      "train loss:0.7789691833414467\n",
      "train loss:0.816837530925165\n",
      "train loss:0.9997369782481822\n",
      "train loss:0.9554837339229019\n",
      "train loss:0.8527099004564473\n",
      "train loss:1.0077239052074645\n",
      "train loss:0.8404600204809793\n",
      "train loss:0.9935620436617083\n",
      "train loss:0.783643421662097\n",
      "train loss:0.8900023205492716\n",
      "train loss:0.8193048434845167\n",
      "train loss:0.8329499836273471\n",
      "train loss:0.7495136648409475\n",
      "train loss:0.9004285474128434\n",
      "train loss:0.8537779413506157\n",
      "train loss:0.9473054258441516\n",
      "train loss:1.009312722925084\n",
      "train loss:0.6452331628155064\n",
      "train loss:0.9388085143512964\n",
      "train loss:0.8956517815866917\n",
      "train loss:0.79718329292995\n",
      "train loss:0.831224259487492\n",
      "train loss:0.9097001699022296\n",
      "train loss:0.9158126089118263\n",
      "train loss:0.9729202650037568\n",
      "train loss:0.9592199097763596\n",
      "train loss:0.8280189131395652\n",
      "train loss:0.8235103018965236\n",
      "train loss:1.1599157948721786\n",
      "train loss:0.9185595653034869\n",
      "train loss:0.8538367757943834\n",
      "train loss:0.8483470646752203\n",
      "train loss:0.9797575416546972\n",
      "train loss:1.0190754258351504\n",
      "train loss:0.7322668934605012\n",
      "train loss:0.8762950022884327\n",
      "train loss:0.929044782026104\n",
      "train loss:0.900770291914519\n",
      "train loss:0.7939983406458042\n",
      "train loss:0.7785493141382966\n",
      "train loss:0.7714236913709551\n",
      "train loss:0.9376937447293031\n",
      "train loss:0.8342131177118877\n",
      "train loss:1.0297495378508792\n",
      "train loss:0.8595511665955332\n",
      "train loss:0.9123508943722274\n",
      "train loss:0.7491152158857267\n",
      "train loss:0.8655064614942642\n",
      "train loss:1.0030060639279246\n",
      "train loss:0.9820696968971164\n",
      "train loss:0.8484967532147211\n",
      "train loss:0.943082833488636\n",
      "train loss:1.0082660539738857\n",
      "train loss:0.8894940562104375\n",
      "train loss:0.9756668954369114\n",
      "train loss:0.7905783591632296\n",
      "train loss:0.923947809493769\n",
      "train loss:0.7961668698490654\n",
      "train loss:1.107444914298518\n",
      "train loss:0.945432805118087\n",
      "train loss:0.9029527841232324\n",
      "train loss:0.8314794854209068\n",
      "train loss:0.8308226080045383\n",
      "train loss:0.9684487054169355\n",
      "train loss:0.7220199954389147\n",
      "train loss:1.047342853181256\n",
      "train loss:0.8096298323076582\n",
      "train loss:1.1123840906486722\n",
      "train loss:0.9042029797662794\n",
      "train loss:0.8185678082763714\n",
      "train loss:0.7805409798555487\n",
      "train loss:0.962199611875539\n",
      "train loss:0.9102463883400098\n",
      "train loss:0.8958643442818891\n",
      "train loss:0.7908208653658249\n",
      "train loss:0.8087112489902912\n",
      "train loss:0.866948157121504\n",
      "train loss:0.9533774813479036\n",
      "train loss:1.0447925109113458\n",
      "train loss:0.8031380030751982\n",
      "train loss:0.8284128220409223\n",
      "train loss:0.8530655027647498\n",
      "train loss:0.8913834937454185\n",
      "train loss:0.765497780765067\n",
      "train loss:0.8356010082390584\n",
      "train loss:0.909706493342929\n",
      "train loss:0.7737205755644713\n",
      "train loss:0.8346230402487456\n",
      "train loss:0.9961630381838598\n",
      "train loss:0.9249704473692576\n",
      "train loss:0.9760582761617816\n",
      "train loss:0.8896789391272957\n",
      "train loss:0.9042992164969192\n",
      "train loss:0.7730685688953267\n",
      "train loss:0.8192816921894814\n",
      "train loss:0.9003995694414695\n",
      "train loss:1.0034575526035596\n",
      "train loss:0.864639862725914\n",
      "train loss:0.7962592289011259\n",
      "train loss:0.9238134544358647\n",
      "train loss:0.9727960489596732\n",
      "train loss:0.8813306574921208\n",
      "train loss:0.8507085847251079\n",
      "train loss:1.0149002805190181\n",
      "train loss:0.7593520203538674\n",
      "train loss:0.9585409902800105\n",
      "train loss:0.8168207062687712\n",
      "train loss:0.9251067271969333\n",
      "train loss:0.8603993351578341\n",
      "train loss:0.8213058398733247\n",
      "train loss:0.724805116754886\n",
      "train loss:0.8792385773940028\n",
      "train loss:0.9829222284748401\n",
      "train loss:0.9357051749510031\n",
      "train loss:0.8331767286765198\n",
      "train loss:0.8627484559821766\n",
      "train loss:0.8776553431422711\n",
      "train loss:0.913054684246526\n",
      "train loss:0.7598069722164074\n",
      "train loss:0.7376942108303248\n",
      "train loss:0.9606543477774758\n",
      "train loss:0.8161215107214069\n",
      "train loss:0.904989587685258\n",
      "train loss:0.7513833462336984\n",
      "train loss:0.9450600501272496\n",
      "train loss:0.8052078066131105\n",
      "train loss:0.8617700905915292\n",
      "train loss:0.8026694286204753\n",
      "train loss:0.9680109850718336\n",
      "train loss:0.9344355114040535\n",
      "train loss:0.9416076753066353\n",
      "train loss:0.9493981359325884\n",
      "train loss:0.751646968741822\n",
      "train loss:0.8472677998117508\n",
      "train loss:0.6752181397456709\n",
      "train loss:0.7911639958303427\n",
      "train loss:0.8852189427306183\n",
      "train loss:0.9550908870003565\n",
      "train loss:1.0032437957039655\n",
      "train loss:0.8223263970496825\n",
      "train loss:0.8877918711131774\n",
      "train loss:1.008106877238138\n",
      "train loss:0.8071535522392014\n",
      "train loss:0.7100185485010752\n",
      "train loss:0.982600299336293\n",
      "train loss:0.925240877761552\n",
      "train loss:0.7356774337984846\n",
      "train loss:0.8350016676353151\n",
      "train loss:0.8077375754448859\n",
      "train loss:0.9301376176731909\n",
      "train loss:0.8313803202621675\n",
      "train loss:0.9458928487712293\n",
      "train loss:0.8611639694494548\n",
      "train loss:1.0104574422585482\n",
      "train loss:0.9682490535589168\n",
      "train loss:0.8580497218282656\n",
      "train loss:0.8894823700529519\n",
      "train loss:0.8313753373460616\n",
      "train loss:0.7344520039163009\n",
      "train loss:0.9964706896956718\n",
      "train loss:0.7138668522392176\n",
      "train loss:0.8529104367089605\n",
      "train loss:0.8145300396193682\n",
      "train loss:0.9179654549933554\n",
      "train loss:0.9038692366784626\n",
      "train loss:0.7481678871498079\n",
      "train loss:0.793202821094002\n",
      "train loss:0.9771144781022074\n",
      "train loss:0.9398743995923404\n",
      "train loss:0.9532876985052248\n",
      "train loss:0.7598084779465389\n",
      "train loss:0.946481607624148\n",
      "train loss:0.8896375177891691\n",
      "train loss:0.9393509451583002\n",
      "train loss:0.7771174754962216\n",
      "train loss:1.0600717720124109\n",
      "train loss:0.881476186300416\n",
      "train loss:0.8797551704131611\n",
      "train loss:0.854057712858928\n",
      "train loss:0.9708445665454529\n",
      "train loss:0.9816583777601593\n",
      "train loss:0.933886053453179\n",
      "train loss:0.6175292849610626\n",
      "train loss:1.0187302725855973\n",
      "train loss:0.8292869029881278\n",
      "train loss:0.8469226018389034\n",
      "train loss:0.8456333161944853\n",
      "train loss:0.7190957535631815\n",
      "train loss:0.9538085977940546\n",
      "train loss:0.9387728097971205\n",
      "train loss:0.9235889307462276\n",
      "train loss:0.7508921078573372\n",
      "train loss:0.9205339842779219\n",
      "train loss:0.8061095626929489\n",
      "train loss:0.8748292167710244\n",
      "train loss:0.8047466822791404\n",
      "train loss:0.9305803862002766\n",
      "train loss:0.7242620869013521\n",
      "train loss:0.8670647218663422\n",
      "train loss:0.8784840860702243\n",
      "train loss:0.8583129683918023\n",
      "train loss:0.8840153186298777\n",
      "train loss:0.9132046364133666\n",
      "train loss:1.043030978478748\n",
      "train loss:0.8867234768518014\n",
      "train loss:0.8323938592569544\n",
      "train loss:0.7641229658518437\n",
      "train loss:0.7996077439025607\n",
      "train loss:0.8157692882600902\n",
      "train loss:0.9131300242019667\n",
      "train loss:0.7422317916127517\n",
      "train loss:0.766937312444505\n",
      "train loss:0.9461655770286054\n",
      "train loss:0.9021485277469872\n",
      "train loss:0.8017323264852814\n",
      "train loss:0.7230677328335865\n",
      "train loss:0.863818264970301\n",
      "train loss:0.829146678883133\n",
      "train loss:0.8024796440004436\n",
      "train loss:0.9608838294108708\n",
      "train loss:0.7704607179345143\n",
      "train loss:0.8878062340799733\n",
      "train loss:0.7707952441536615\n",
      "train loss:1.1370237851080214\n",
      "train loss:1.0081432052240686\n",
      "train loss:0.8847515497483264\n",
      "train loss:0.7728213147343088\n",
      "train loss:0.8750628137659399\n",
      "train loss:0.8229613264422452\n",
      "train loss:1.006020306184689\n",
      "train loss:0.9688700177462186\n",
      "train loss:0.7894306811830417\n",
      "train loss:0.9517810063922307\n",
      "train loss:0.8137857591781321\n",
      "train loss:0.713746940560734\n",
      "train loss:1.0142040768529959\n",
      "train loss:0.9072751113431488\n",
      "train loss:0.916963016828671\n",
      "train loss:0.895932176784116\n",
      "train loss:0.8391876090496874\n",
      "train loss:0.8375771272617492\n",
      "train loss:0.9651630089333116\n",
      "train loss:0.8339843808591969\n",
      "train loss:0.8014307595135801\n",
      "train loss:0.8815490406506666\n",
      "train loss:0.9177089257518743\n",
      "train loss:0.9985129934984013\n",
      "train loss:0.8351166036820168\n",
      "train loss:0.7982465333038411\n",
      "train loss:0.8173335872017895\n",
      "train loss:0.6966650377537686\n",
      "train loss:0.7818795531880512\n",
      "train loss:0.8137597872019778\n",
      "train loss:0.8190798057042847\n",
      "train loss:1.0476123192342854\n",
      "train loss:0.8981258858603652\n",
      "train loss:0.941635645494994\n",
      "train loss:0.8560959312194497\n",
      "train loss:0.7975645330965102\n",
      "train loss:0.8963899664335073\n",
      "train loss:0.94600170626863\n",
      "train loss:0.8258361230837703\n",
      "train loss:0.9850657393284394\n",
      "train loss:0.9351373219402117\n",
      "train loss:0.7724534367711644\n",
      "train loss:0.808637140311693\n",
      "train loss:0.8579711448282832\n",
      "train loss:1.0474599012610266\n",
      "train loss:0.8674609503883903\n",
      "train loss:0.8391008898121121\n",
      "train loss:0.8227893295892593\n",
      "train loss:0.968628749452292\n",
      "train loss:0.8376415486427349\n",
      "train loss:0.7015397981683372\n",
      "train loss:0.9195718610266317\n",
      "train loss:0.8906972850168826\n",
      "train loss:0.9639353358738812\n",
      "train loss:0.7341720093743472\n",
      "train loss:0.720220902940774\n",
      "train loss:0.7723904367426558\n",
      "train loss:0.8130797699405727\n",
      "train loss:0.9672287434148015\n",
      "train loss:0.7917430946477618\n",
      "train loss:0.9562122966922287\n",
      "train loss:0.9552833438505364\n",
      "train loss:1.0733083545522306\n",
      "train loss:0.9217794386169699\n",
      "train loss:1.037270761813355\n",
      "train loss:0.9893497470080237\n",
      "train loss:0.8214722501367535\n",
      "train loss:0.8748848153806464\n",
      "train loss:0.8127965545374183\n",
      "train loss:0.9269108719099642\n",
      "train loss:0.8124471392455996\n",
      "train loss:0.8533395568288613\n",
      "train loss:0.7148085559970717\n",
      "train loss:0.7674923909853436\n",
      "train loss:0.8588537442393489\n",
      "train loss:0.9227364690838574\n",
      "train loss:1.0051192539899487\n",
      "train loss:0.9452352379863798\n",
      "train loss:0.7523907219610713\n",
      "train loss:0.9426871800123966\n",
      "train loss:0.8305644464751025\n",
      "train loss:0.9452190078348162\n",
      "train loss:0.8106810731186583\n",
      "train loss:0.6954771809298517\n",
      "train loss:0.792500855409318\n",
      "train loss:0.8195349772983522\n",
      "train loss:0.8647087549932599\n",
      "train loss:0.990517456158606\n",
      "train loss:1.1666608356064687\n",
      "train loss:1.0043125049890038\n",
      "train loss:0.8911498301624412\n",
      "train loss:0.8222854723047982\n",
      "train loss:1.0472387362838151\n",
      "train loss:0.9980894383226427\n",
      "train loss:0.8679905785590578\n",
      "train loss:0.8344702538896148\n",
      "train loss:0.7934681587726409\n",
      "train loss:0.8414367259428359\n",
      "train loss:0.7960481878755828\n",
      "train loss:0.9101404829198497\n",
      "train loss:0.7022450891082164\n",
      "train loss:0.9045048276773252\n",
      "train loss:0.9819984354055998\n",
      "train loss:0.9288164247060304\n",
      "train loss:0.8854046645292121\n",
      "train loss:0.985814737301332\n",
      "train loss:0.8392526082860303\n",
      "train loss:0.9951621163161394\n",
      "train loss:0.6922507156819548\n",
      "train loss:0.8131990829605542\n",
      "train loss:0.6791693933324063\n",
      "train loss:0.7631103425194141\n",
      "train loss:1.110724949540206\n",
      "train loss:0.6351043381414727\n",
      "train loss:0.7635701615421558\n",
      "train loss:0.8552389939709469\n",
      "train loss:0.9147945404486006\n",
      "train loss:1.0537896115755314\n",
      "train loss:0.8689610030530096\n",
      "train loss:0.8320195192847517\n",
      "train loss:0.9232230439012226\n",
      "train loss:0.7696409533367965\n",
      "train loss:1.1319256849744403\n",
      "train loss:0.7721610316183662\n",
      "train loss:0.8757933185460228\n",
      "train loss:0.9903734496523543\n",
      "train loss:0.8909439467379304\n",
      "train loss:0.9569122536865032\n",
      "train loss:0.9749526270702862\n",
      "train loss:0.935524587064046\n",
      "train loss:0.8728035428721838\n",
      "train loss:0.8201307910225643\n",
      "train loss:0.8741766406518711\n",
      "train loss:1.0405805312279552\n",
      "train loss:0.8061035730581132\n",
      "train loss:0.9519995731501228\n",
      "train loss:0.8035771971449124\n",
      "train loss:0.8760394413543001\n",
      "train loss:0.8202723206400588\n",
      "train loss:0.909018073194094\n",
      "train loss:0.791566115514922\n",
      "train loss:0.8460606499445743\n",
      "train loss:0.8438265631560692\n",
      "train loss:0.839003468430199\n",
      "train loss:0.9048086135677927\n",
      "train loss:0.8751898108631617\n",
      "train loss:1.1069615001152013\n",
      "train loss:0.8271615185518608\n",
      "train loss:0.8355732869683908\n",
      "train loss:0.930293242710235\n",
      "train loss:0.964389064301165\n",
      "train loss:0.7829725156305336\n",
      "train loss:0.8462979287901108\n",
      "train loss:0.8402694034506599\n",
      "train loss:0.8313911006974831\n",
      "train loss:0.7759553480806437\n",
      "train loss:0.8788886267107994\n",
      "train loss:0.8163294035633005\n",
      "train loss:0.8327506545793159\n",
      "train loss:0.9051757856378292\n",
      "train loss:0.7053237924442054\n",
      "train loss:0.7884636895131928\n",
      "train loss:1.0055548253309945\n",
      "train loss:0.8317834557860847\n",
      "train loss:0.9617958515287377\n",
      "train loss:0.844582697624945\n",
      "train loss:0.9149327822898933\n",
      "train loss:0.8007443373691793\n",
      "train loss:0.7781812472757272\n",
      "train loss:0.7761979210194938\n",
      "train loss:0.892019504029327\n",
      "train loss:0.8163746105397874\n",
      "train loss:0.729444514407266\n",
      "train loss:0.8895641669007148\n",
      "train loss:0.8342308357753389\n",
      "train loss:0.6749485123546617\n",
      "train loss:1.0254744873795714\n",
      "train loss:0.875430523396611\n",
      "train loss:0.7685449978387637\n",
      "train loss:0.767460945388072\n",
      "train loss:0.9526459496976136\n",
      "train loss:0.7864665827915732\n",
      "train loss:1.0644486559998827\n",
      "train loss:0.943936410206621\n",
      "train loss:0.8852966611379803\n",
      "train loss:0.9115491168316054\n",
      "train loss:1.120895334477284\n",
      "train loss:0.8538397890071484\n",
      "train loss:0.7819106770778995\n",
      "train loss:0.9965974753447998\n",
      "train loss:0.8320791708918597\n",
      "train loss:0.7600139536772452\n",
      "train loss:1.027944845578339\n",
      "train loss:0.7445018247784412\n",
      "train loss:0.9232392763212777\n",
      "train loss:0.8711515532394202\n",
      "train loss:1.0816787144476054\n",
      "train loss:0.7332977672522916\n",
      "train loss:0.8697792610202008\n",
      "train loss:0.9177746442325221\n",
      "train loss:0.7084161471389328\n",
      "train loss:0.9641804706102001\n",
      "train loss:0.7820274457011718\n",
      "train loss:0.9633398523111165\n",
      "train loss:1.0282883944438164\n",
      "train loss:0.9765800644427991\n",
      "train loss:0.8503982447975115\n",
      "train loss:1.0357120007051175\n",
      "train loss:0.9567221343554906\n",
      "train loss:0.715933856021337\n",
      "train loss:0.6512982678724012\n",
      "train loss:0.91854215458472\n",
      "train loss:0.9151149246854771\n",
      "train loss:0.7769474007999736\n",
      "train loss:0.8228948224529181\n",
      "train loss:0.7757352663017215\n",
      "train loss:0.945281859324422\n",
      "train loss:0.7355430406940775\n",
      "train loss:0.9599253602078403\n",
      "train loss:0.8261713967323518\n",
      "train loss:1.0113159602214887\n",
      "train loss:0.7796367736792721\n",
      "train loss:1.0377642820161834\n",
      "train loss:0.7097189893394917\n",
      "train loss:0.9625599437947363\n",
      "train loss:0.8654280898051963\n",
      "train loss:0.8348273501681269\n",
      "train loss:0.9859615706197296\n",
      "train loss:0.8085800643694153\n",
      "=== epoch:11, train acc:0.997, test acc:0.993 ===\n",
      "train loss:0.8370272471132593\n",
      "train loss:0.9632930607776522\n",
      "train loss:0.8501429405930377\n",
      "train loss:1.0354069986701133\n",
      "train loss:0.9319225510328148\n",
      "train loss:0.8409878917875183\n",
      "train loss:0.9136533839942311\n",
      "train loss:0.9623746900804633\n",
      "train loss:0.9276110363911301\n",
      "train loss:0.7999331261650906\n",
      "train loss:0.9238109624790363\n",
      "train loss:0.8096087104042177\n",
      "train loss:0.7705966717488647\n",
      "train loss:0.8523608441482804\n",
      "train loss:0.919459626769277\n",
      "train loss:1.137317800593194\n",
      "train loss:0.7616271638322766\n",
      "train loss:0.7832054574194411\n",
      "train loss:0.9721537909722072\n",
      "train loss:0.9359046515582921\n",
      "train loss:0.7295352309031666\n",
      "train loss:1.0327108081994556\n",
      "train loss:0.9209310736233505\n",
      "train loss:0.7609201893019601\n",
      "train loss:0.873531557814086\n",
      "train loss:0.827160001020965\n",
      "train loss:0.882376566660238\n",
      "train loss:0.9204145272389088\n",
      "train loss:0.9976346948663003\n",
      "train loss:0.8633326264048891\n",
      "train loss:0.8657134066597457\n",
      "train loss:0.8997961055176188\n",
      "train loss:0.9234723807996468\n",
      "train loss:0.7872117287352672\n",
      "train loss:0.7530432071977243\n",
      "train loss:0.8697069898851588\n",
      "train loss:1.031403503522319\n",
      "train loss:0.6528464513686936\n",
      "train loss:0.9870619911247143\n",
      "train loss:0.838673519935029\n",
      "train loss:0.9210531879349573\n",
      "train loss:0.9416343865147216\n",
      "train loss:0.7770337008263275\n",
      "train loss:0.8210225270347443\n",
      "train loss:0.6185201516042266\n",
      "train loss:0.9123052119964434\n",
      "train loss:0.9570879772490615\n",
      "train loss:0.9123782599610483\n",
      "train loss:0.825784685641364\n",
      "train loss:0.7224906088045379\n",
      "train loss:0.7500992131333795\n",
      "train loss:0.7976263734572667\n",
      "train loss:0.7152753607191312\n",
      "train loss:0.957630295273756\n",
      "train loss:1.0555159019026015\n",
      "train loss:0.8600840409768273\n",
      "train loss:0.7505172047307106\n",
      "train loss:0.8619547217471499\n",
      "train loss:0.828878999468168\n",
      "train loss:0.7938127513161494\n",
      "train loss:0.883765259727142\n",
      "train loss:0.9538891989146479\n",
      "train loss:0.887841059687107\n",
      "train loss:0.7906806507534193\n",
      "train loss:0.8546906320622347\n",
      "train loss:0.8308244399225069\n",
      "train loss:0.8948110013421388\n",
      "train loss:0.9127834957129198\n",
      "train loss:0.862163297037388\n",
      "train loss:0.8937289702683635\n",
      "train loss:0.8389674185940857\n",
      "train loss:1.038803459436042\n",
      "train loss:0.9423499456183916\n",
      "train loss:0.87735004530508\n",
      "train loss:0.7261363124978003\n",
      "train loss:0.8610361695316826\n",
      "train loss:0.8834933199192035\n",
      "train loss:0.9654267335016865\n",
      "train loss:0.8696772455380973\n",
      "train loss:0.8995205562000643\n",
      "train loss:0.8841592348769806\n",
      "train loss:0.9786226396355326\n",
      "train loss:0.9102061731701923\n",
      "train loss:0.7805928582302648\n",
      "train loss:0.8146229914980521\n",
      "train loss:1.0739540938016\n",
      "train loss:1.0462809265690889\n",
      "train loss:0.8312258122283481\n",
      "train loss:0.7777630594381277\n",
      "train loss:0.7163642402747947\n",
      "train loss:0.6897039652666248\n",
      "train loss:1.035153731887446\n",
      "train loss:0.9129742791523596\n",
      "train loss:0.7412798201341539\n",
      "train loss:0.9194804833878042\n",
      "train loss:0.8844389943954087\n",
      "train loss:0.7794659622251133\n",
      "train loss:0.9484393967186642\n",
      "train loss:0.9656635359216118\n",
      "train loss:0.7415648567903154\n",
      "train loss:0.9447373860464969\n",
      "train loss:0.9533150187178014\n",
      "train loss:0.899817823429805\n",
      "train loss:0.6636829751530223\n",
      "train loss:0.8520237552150473\n",
      "train loss:0.9077126091044303\n",
      "train loss:0.8197438556774358\n",
      "train loss:0.8177510778983758\n",
      "train loss:0.9406907355640521\n",
      "train loss:0.8241790269039204\n",
      "train loss:0.8598995413633986\n",
      "train loss:0.8520267607742773\n",
      "train loss:0.9260761269579249\n",
      "train loss:0.9901956536886725\n",
      "train loss:0.9384858804945405\n",
      "train loss:0.7890200845864971\n",
      "train loss:0.855653880095786\n",
      "train loss:0.8681551209942227\n",
      "train loss:0.8049593586058517\n",
      "train loss:0.799868727102283\n",
      "train loss:0.8703353436122845\n",
      "train loss:0.8127026228839267\n",
      "train loss:0.9183617702432355\n",
      "train loss:0.666893113789688\n",
      "train loss:0.8948682225363912\n",
      "train loss:0.9361870079157923\n",
      "train loss:0.8055681801887482\n",
      "train loss:0.7515176360784515\n",
      "train loss:0.8964964286673197\n",
      "train loss:1.0511973120793368\n",
      "train loss:0.9136189034536649\n",
      "train loss:0.8639572169662314\n",
      "train loss:0.9472022655206251\n",
      "train loss:0.8403215491686689\n",
      "train loss:0.9979606070162464\n",
      "train loss:0.8113787426727233\n",
      "train loss:0.8331788242262569\n",
      "train loss:0.9390613710461732\n",
      "train loss:0.9171450747670962\n",
      "train loss:0.8351663047566494\n",
      "train loss:0.9160940314027429\n",
      "train loss:0.7496434571847028\n",
      "train loss:0.7486344889456147\n",
      "train loss:0.7872974334860064\n",
      "train loss:0.8116155438477785\n",
      "train loss:1.0024134584007747\n",
      "train loss:1.0228111461138851\n",
      "train loss:0.7474446739034574\n",
      "train loss:1.0619272063006748\n",
      "train loss:0.9042179684372106\n",
      "train loss:0.9672268095608328\n",
      "train loss:0.9508022459110823\n",
      "train loss:0.7711365324927694\n",
      "train loss:0.9900721967549887\n",
      "train loss:0.8496046151407054\n",
      "train loss:0.7608302806115984\n",
      "train loss:0.8156187499762398\n",
      "train loss:0.8389790133389085\n",
      "train loss:0.884297026375831\n",
      "train loss:0.8866638075403327\n",
      "train loss:0.7863351617596908\n",
      "train loss:0.7804442823249772\n",
      "train loss:0.9557645887307054\n",
      "train loss:0.8628390359288436\n",
      "train loss:0.8558414212671823\n",
      "train loss:0.875901980840759\n",
      "train loss:0.8306980649658606\n",
      "train loss:0.7814616674374064\n",
      "train loss:0.8906875597835184\n",
      "train loss:0.823287762763567\n",
      "train loss:0.9358027460402393\n",
      "train loss:0.8523376479519834\n",
      "train loss:0.9248897783255008\n",
      "train loss:0.8343242788741553\n",
      "train loss:0.7428015660371993\n",
      "train loss:0.9445406539892727\n",
      "train loss:0.7054606967682944\n",
      "train loss:0.9407801630320318\n",
      "train loss:0.8075298683837258\n",
      "train loss:0.8309268285583471\n",
      "train loss:0.9104731149069063\n",
      "train loss:0.828127065512955\n",
      "train loss:1.080052740945812\n",
      "train loss:0.9530220669815109\n",
      "train loss:0.9409529808097651\n",
      "train loss:0.8611274236353494\n",
      "train loss:1.0172172700785411\n",
      "train loss:0.8757937676358186\n",
      "train loss:0.7279422789636212\n",
      "train loss:0.9957194699260721\n",
      "train loss:0.8003684597413755\n",
      "train loss:0.9828070076209277\n",
      "train loss:0.9071120473831834\n",
      "train loss:0.918952858344596\n",
      "train loss:0.8954803800580876\n",
      "train loss:0.9397482161266834\n",
      "train loss:0.8615022064663536\n",
      "train loss:0.7633790831468862\n",
      "train loss:0.931578860951656\n",
      "train loss:0.9671139894410002\n",
      "train loss:0.9639311613003106\n",
      "train loss:0.9206428555229087\n",
      "train loss:0.822738099755741\n",
      "train loss:0.8710157201386758\n",
      "train loss:0.8862471219943723\n",
      "train loss:0.8584918675149835\n",
      "train loss:0.8843600431067\n",
      "train loss:0.7453635313455308\n",
      "train loss:1.010704476803727\n",
      "train loss:0.7574501257201592\n",
      "train loss:0.8519348742357105\n",
      "train loss:1.061825828162211\n",
      "train loss:1.10015802554304\n",
      "train loss:1.0067152525100134\n",
      "train loss:0.7612718048277725\n",
      "train loss:0.8105599850903991\n",
      "train loss:0.9969177985315397\n",
      "train loss:0.9201157575320833\n",
      "train loss:0.7729169659017059\n",
      "train loss:1.026919360498131\n",
      "train loss:0.7595205837427538\n",
      "train loss:0.979789739291185\n",
      "train loss:0.9229287799230861\n",
      "train loss:0.9192365591162504\n",
      "train loss:1.0450487755169677\n",
      "train loss:0.9040720149933855\n",
      "train loss:0.7879277972790106\n",
      "train loss:0.8543394346924131\n",
      "train loss:0.8671082705856392\n",
      "train loss:0.775737027969081\n",
      "train loss:0.9371226406038287\n",
      "train loss:0.9017179645470315\n",
      "train loss:0.8225433018342394\n",
      "train loss:0.9297767925761958\n",
      "train loss:0.8598338271911227\n",
      "train loss:0.6864039617797795\n",
      "train loss:0.7943778283961962\n",
      "train loss:0.7288049598759457\n",
      "train loss:0.9194358693331395\n",
      "train loss:0.7556156222407363\n",
      "train loss:0.9191414829986465\n",
      "train loss:0.8684255001934169\n",
      "train loss:0.8656706240520151\n",
      "train loss:1.0662504053544375\n",
      "train loss:0.9519995927388301\n",
      "train loss:0.8731304847619932\n",
      "train loss:0.8469310273205619\n",
      "train loss:0.7063676972404183\n",
      "train loss:0.7776575246705043\n",
      "train loss:0.6924227987979796\n",
      "train loss:0.7429782980512996\n",
      "train loss:0.9691720140445566\n",
      "train loss:0.9728711438533314\n",
      "train loss:1.075518085010152\n",
      "train loss:0.8959774837409452\n",
      "train loss:0.8515332652122002\n",
      "train loss:0.9501603310286069\n",
      "train loss:0.9611566792587152\n",
      "train loss:0.800707076849979\n",
      "train loss:0.7069943504988094\n",
      "train loss:0.8028755429938584\n",
      "train loss:0.8100123342607013\n",
      "train loss:0.8382996870853033\n",
      "train loss:0.9167635151807311\n",
      "train loss:0.8347325695437813\n",
      "train loss:0.798864454053118\n",
      "train loss:0.9247983001310409\n",
      "train loss:0.8100803871671468\n",
      "train loss:0.9265901098328646\n",
      "train loss:1.145275743644705\n",
      "train loss:1.0168812411485453\n",
      "train loss:0.6854571841833657\n",
      "train loss:0.7455003436958259\n",
      "train loss:0.7248762438421624\n",
      "train loss:0.976949026955289\n",
      "train loss:0.7462684224987349\n",
      "train loss:0.814606775779918\n",
      "train loss:0.8926951742184813\n",
      "train loss:0.8651643996810314\n",
      "train loss:0.9821985083524041\n",
      "train loss:0.94284834453556\n",
      "train loss:0.7158287491162569\n",
      "train loss:0.8346954534221815\n",
      "train loss:0.9056848263786005\n",
      "train loss:1.021033512629751\n",
      "train loss:0.9762572646254192\n",
      "train loss:0.7430804384984698\n",
      "train loss:1.0100813871210186\n",
      "train loss:0.8582181492327653\n",
      "train loss:1.1048508872722105\n",
      "train loss:0.8790654998485955\n",
      "train loss:0.9285776921939721\n",
      "train loss:0.9090943909475278\n",
      "train loss:0.8582886839461339\n",
      "train loss:0.741018809949765\n",
      "train loss:0.8888447658610391\n",
      "train loss:0.790857398526516\n",
      "train loss:0.7044009865466869\n",
      "train loss:0.7502005804441247\n",
      "train loss:0.893382965020797\n",
      "train loss:0.8889274769510742\n",
      "train loss:0.8871198740465881\n",
      "train loss:1.063519211108078\n",
      "train loss:0.8640245252575416\n",
      "train loss:0.9632139246953912\n",
      "train loss:0.824751568160893\n",
      "train loss:0.6796770140836692\n",
      "train loss:0.9143214690212335\n",
      "train loss:0.9066434681126652\n",
      "train loss:0.8232506396609526\n",
      "train loss:0.8418895684898132\n",
      "train loss:0.8355054418074781\n",
      "train loss:0.9144739674071937\n",
      "train loss:0.7196573987808135\n",
      "train loss:0.9911013048262177\n",
      "train loss:0.9765101339750266\n",
      "train loss:0.831981330927895\n",
      "train loss:1.149855229213098\n",
      "train loss:0.7444743762796442\n",
      "train loss:0.7833916177492185\n",
      "train loss:1.1360310386327253\n",
      "train loss:0.7186557708792446\n",
      "train loss:0.9182762738585604\n",
      "train loss:0.8961072875136913\n",
      "train loss:0.7716166538576285\n",
      "train loss:1.0597242045497668\n",
      "train loss:0.793286271117877\n",
      "train loss:0.8430024779385461\n",
      "train loss:0.9085749344735912\n",
      "train loss:0.77092357748186\n",
      "train loss:0.9699433156850656\n",
      "train loss:0.7684931869475854\n",
      "train loss:0.9316827039762015\n",
      "train loss:0.8383147098994539\n",
      "train loss:0.8123136230712852\n",
      "train loss:0.9399152430354786\n",
      "train loss:0.7613014997044658\n",
      "train loss:0.8081791960062985\n",
      "train loss:0.8164815225327879\n",
      "train loss:1.0716743045661956\n",
      "train loss:0.8197091040997333\n",
      "train loss:0.8620870561049881\n",
      "train loss:0.8298276218316053\n",
      "train loss:0.8410548960465657\n",
      "train loss:0.8688558040487735\n",
      "train loss:1.018244070657877\n",
      "train loss:0.8728807196970605\n",
      "train loss:0.9403635768109336\n",
      "train loss:0.9042336960741078\n",
      "train loss:0.8943438269353365\n",
      "train loss:0.944222300610912\n",
      "train loss:0.7706731071380867\n",
      "train loss:0.8226942933893286\n",
      "train loss:0.8004572664126909\n",
      "train loss:0.6040611183479626\n",
      "train loss:1.0527717507160796\n",
      "train loss:0.9137096524068496\n",
      "train loss:0.7376282134074836\n",
      "train loss:0.992418063252809\n",
      "train loss:0.8382729870467671\n",
      "train loss:0.8468166707035267\n",
      "train loss:0.8162011736105882\n",
      "train loss:0.8429713895756542\n",
      "train loss:1.0205058833216591\n",
      "train loss:0.8639746493378244\n",
      "train loss:0.9021517626848053\n",
      "train loss:0.8280188682813998\n",
      "train loss:0.7997807779864468\n",
      "train loss:0.7587652129678724\n",
      "train loss:0.804374346537324\n",
      "train loss:0.8690523002674017\n",
      "train loss:0.9844464343827444\n",
      "train loss:0.716229843194257\n",
      "train loss:0.8722803910090434\n",
      "train loss:1.0547353315881143\n",
      "train loss:0.776768679247895\n",
      "train loss:0.8645106036730185\n",
      "train loss:0.9404320391172454\n",
      "train loss:0.7630162785916229\n",
      "train loss:0.9540672748123903\n",
      "train loss:0.6883517738780729\n",
      "train loss:0.8311210216173552\n",
      "train loss:0.9682324854179274\n",
      "train loss:0.8153998256650735\n",
      "train loss:0.8262381345052638\n",
      "train loss:0.9424279201275328\n",
      "train loss:0.8822385073072039\n",
      "train loss:0.8634932183458642\n",
      "train loss:0.9238554273832963\n",
      "train loss:0.7543785937244871\n",
      "train loss:0.9667229647516342\n",
      "train loss:0.6944050696126531\n",
      "train loss:0.7882751227909579\n",
      "train loss:0.8522285355490282\n",
      "train loss:0.8160935689907558\n",
      "train loss:0.8277494307179752\n",
      "train loss:0.7527490277028182\n",
      "train loss:0.8706334329185441\n",
      "train loss:0.8739737333022967\n",
      "train loss:0.861669191785456\n",
      "train loss:0.9119287178493747\n",
      "train loss:0.7434268903025074\n",
      "train loss:0.847415192725941\n",
      "train loss:0.8643535773876129\n",
      "train loss:0.7465057749750362\n",
      "train loss:0.9538539715290808\n",
      "train loss:0.9434043186412728\n",
      "train loss:0.7340826890601213\n",
      "train loss:0.8041176794568766\n",
      "train loss:1.008067887224132\n",
      "train loss:0.8490294586332291\n",
      "train loss:0.8873540275010283\n",
      "train loss:0.8230986630141841\n",
      "train loss:0.9863879625509953\n",
      "train loss:0.9319018067096506\n",
      "train loss:0.9734290251027393\n",
      "train loss:0.8408938424462948\n",
      "train loss:0.8471362851700194\n",
      "train loss:0.7818177809994828\n",
      "train loss:0.8619458213504985\n",
      "train loss:0.8043276568832681\n",
      "train loss:0.8969381056735738\n",
      "train loss:0.9554352922784541\n",
      "train loss:0.8564405063509157\n",
      "train loss:1.0221555467421204\n",
      "train loss:0.7956305900705126\n",
      "train loss:0.9503425354039307\n",
      "train loss:0.7445829026025392\n",
      "train loss:0.9722476227872392\n",
      "train loss:0.9303000061008204\n",
      "train loss:0.8419904704144605\n",
      "train loss:0.8903464708551012\n",
      "train loss:0.9074797834819579\n",
      "train loss:0.938873151011478\n",
      "train loss:0.740587309119551\n",
      "train loss:0.9120477051551521\n",
      "train loss:0.7623250127417694\n",
      "train loss:1.0469051582964541\n",
      "train loss:0.8927240549523137\n",
      "train loss:0.7343645940768478\n",
      "train loss:0.900343550078755\n",
      "train loss:1.0389021154046603\n",
      "train loss:0.6641489490349606\n",
      "train loss:0.9928830940094467\n",
      "train loss:0.9133882833918634\n",
      "train loss:0.8374719009952158\n",
      "train loss:0.8828637964729437\n",
      "train loss:0.7841335677876329\n",
      "train loss:0.9340211334659709\n",
      "train loss:0.9330604422496571\n",
      "train loss:0.7156521935567675\n",
      "train loss:0.7441746923378328\n",
      "train loss:0.9289873966203143\n",
      "train loss:0.8529393108821844\n",
      "train loss:0.7474769281916642\n",
      "train loss:0.9964468682972187\n",
      "train loss:0.9600054133013632\n",
      "train loss:0.9884138319259709\n",
      "train loss:0.9841863913723684\n",
      "train loss:0.7741596629686758\n",
      "train loss:0.9322705452048363\n",
      "train loss:0.778536767132797\n",
      "train loss:0.8490100529435796\n",
      "train loss:0.905650225714926\n",
      "train loss:0.8312907612072569\n",
      "train loss:0.9406699124830687\n",
      "train loss:1.071714202137433\n",
      "train loss:0.8708077430523998\n",
      "train loss:0.8271469781428382\n",
      "train loss:0.903958593610323\n",
      "train loss:0.8139435191268711\n",
      "train loss:0.7417203086670817\n",
      "train loss:0.9056461898421727\n",
      "train loss:0.7474725985512525\n",
      "train loss:0.9556282194559838\n",
      "train loss:0.7013010297670306\n",
      "train loss:0.8049169119723083\n",
      "train loss:0.8795355736872773\n",
      "train loss:0.7458932153274912\n",
      "train loss:0.8476792749245932\n",
      "train loss:0.7945820320246932\n",
      "train loss:0.9196389235720978\n",
      "train loss:0.7933899613216924\n",
      "train loss:0.7757699345294129\n",
      "train loss:0.8646234975582943\n",
      "train loss:0.9249761058880359\n",
      "train loss:0.8786186794755193\n",
      "train loss:0.8396865471501919\n",
      "train loss:0.8845333767362077\n",
      "train loss:0.8373889210157545\n",
      "train loss:0.8234212831483597\n",
      "train loss:0.8611884539770727\n",
      "train loss:0.8929300964846861\n",
      "train loss:0.885932499070742\n",
      "train loss:0.8789321736912941\n",
      "train loss:0.8946206702962407\n",
      "train loss:0.9718494040365853\n",
      "train loss:0.9283808270345177\n",
      "train loss:1.136160482570863\n",
      "train loss:1.0208247698809816\n",
      "train loss:0.8701115957685919\n",
      "train loss:0.9619890286303162\n",
      "train loss:0.8058874613158987\n",
      "train loss:0.8119360422594173\n",
      "train loss:0.8918795420236612\n",
      "train loss:0.8328374752439732\n",
      "train loss:0.802631693590573\n",
      "train loss:1.0208387106431507\n",
      "train loss:0.9852495061635471\n",
      "train loss:0.8257692200316279\n",
      "train loss:0.8911160869233185\n",
      "train loss:0.8518437592219072\n",
      "train loss:0.8486862864265429\n",
      "train loss:0.7143207534727313\n",
      "train loss:0.8020536508184558\n",
      "train loss:1.0194361905797655\n",
      "train loss:0.9019096756915497\n",
      "train loss:0.7567258410735467\n",
      "train loss:0.9064784467817769\n",
      "train loss:0.7628370036887617\n",
      "train loss:0.9299544723160443\n",
      "train loss:0.8900994732647152\n",
      "train loss:0.8558081897567102\n",
      "train loss:0.8043809341111006\n",
      "train loss:0.8966544185399522\n",
      "train loss:0.8737103941649633\n",
      "train loss:0.8856077960191567\n",
      "train loss:1.006226873913446\n",
      "train loss:0.7935484911678694\n",
      "train loss:0.9823542936875197\n",
      "train loss:0.9955293055475787\n",
      "train loss:0.8733737919967592\n",
      "train loss:0.648590291545204\n",
      "train loss:0.9785963652344443\n",
      "train loss:0.8644026648023061\n",
      "train loss:0.8891866203000832\n",
      "train loss:0.9657473020038205\n",
      "train loss:0.9146384706334229\n",
      "train loss:0.6742595592198269\n",
      "train loss:0.9323933369458273\n",
      "train loss:0.8972278088160062\n",
      "train loss:0.7139694447130526\n",
      "train loss:0.8667208943440362\n",
      "train loss:0.9568017414254619\n",
      "train loss:0.8048205861655456\n",
      "train loss:0.9271853976478411\n",
      "train loss:0.9271604435379927\n",
      "train loss:0.7530177857030638\n",
      "train loss:1.0040954761089993\n",
      "train loss:0.9425246260408449\n",
      "train loss:0.7620140985116742\n",
      "train loss:0.922471639896364\n",
      "train loss:0.9751554337619569\n",
      "train loss:0.9667830478517438\n",
      "train loss:0.9355091934589983\n",
      "train loss:0.8032393557270425\n",
      "train loss:0.9181661538979706\n",
      "train loss:0.9320683859369383\n",
      "train loss:0.7504766540807809\n",
      "train loss:0.8776946701215715\n",
      "train loss:0.9233842862162931\n",
      "train loss:0.7585053068409847\n",
      "train loss:0.7284025809966137\n",
      "train loss:0.7947149390833255\n",
      "train loss:0.9702219284041876\n",
      "train loss:0.830645101226192\n",
      "train loss:0.8881570137621179\n",
      "train loss:0.9541097327533002\n",
      "train loss:0.8306524654425483\n",
      "train loss:0.793194856128255\n",
      "train loss:1.0929567043968822\n",
      "train loss:0.7489344031994979\n",
      "train loss:0.8324104374094314\n",
      "train loss:0.8075876565225484\n",
      "train loss:0.8890263142249502\n",
      "train loss:0.8018718620464389\n",
      "train loss:0.8746413694393709\n",
      "train loss:0.7418257879990044\n",
      "train loss:0.9139491667596304\n",
      "train loss:0.8311136012769641\n",
      "train loss:0.8809790146574095\n",
      "train loss:0.9508598998908083\n",
      "train loss:0.9516761466393585\n",
      "train loss:0.8530422192908301\n",
      "train loss:0.8114252666137136\n",
      "train loss:0.9137688236593742\n",
      "train loss:0.889796287168457\n",
      "train loss:0.8115397606723317\n",
      "train loss:0.8467575503663909\n",
      "train loss:0.937374391142633\n",
      "train loss:0.8971931225906958\n",
      "train loss:1.0816635277373188\n",
      "train loss:0.9082857194243736\n",
      "train loss:0.87986094926779\n",
      "train loss:0.9917471197008679\n",
      "train loss:1.039342992757937\n",
      "train loss:0.8574147176597227\n",
      "train loss:0.81310837071458\n",
      "train loss:0.8027423366256068\n",
      "train loss:0.8400610005930735\n",
      "=== epoch:12, train acc:0.998, test acc:0.992 ===\n",
      "train loss:0.9550888908903019\n",
      "train loss:0.8014512941776419\n",
      "train loss:0.8787294432824146\n",
      "train loss:0.8885497133068732\n",
      "train loss:1.072282574892598\n",
      "train loss:0.8380486536159951\n",
      "train loss:0.956195508948595\n",
      "train loss:0.9364266903353757\n",
      "train loss:0.8263019167015092\n",
      "train loss:0.849688672826493\n",
      "train loss:0.937156041872662\n",
      "train loss:1.0429088528884802\n",
      "train loss:0.8681135978318619\n",
      "train loss:0.9963727054662824\n",
      "train loss:0.7863116549338142\n",
      "train loss:0.8211947872231707\n",
      "train loss:0.8718564230692024\n",
      "train loss:0.6476183219626057\n",
      "train loss:1.0165644115558194\n",
      "train loss:0.9115080416972124\n",
      "train loss:0.8776257406714665\n",
      "train loss:0.8905997270786505\n",
      "train loss:0.8750076340849201\n",
      "train loss:0.719867639851295\n",
      "train loss:0.7870136213588151\n",
      "train loss:0.8453533466396883\n",
      "train loss:0.833396699818879\n",
      "train loss:0.835903229955982\n",
      "train loss:0.9172999774542195\n",
      "train loss:0.7890409918136218\n",
      "train loss:0.8932868522164984\n",
      "train loss:0.8908941855855733\n",
      "train loss:1.2886986655803647\n",
      "train loss:0.8714997738761673\n",
      "train loss:0.851530794590915\n",
      "train loss:0.8599431647335944\n",
      "train loss:0.862203476011106\n",
      "train loss:0.9381045525787854\n",
      "train loss:0.732309976820502\n",
      "train loss:0.7582310469919107\n",
      "train loss:0.9675940136949653\n",
      "train loss:0.9241244118445197\n",
      "train loss:0.8193985323926769\n",
      "train loss:1.0437241933549224\n",
      "train loss:0.7404503887179801\n",
      "train loss:0.8584469910166083\n",
      "train loss:0.8381540144481096\n",
      "train loss:0.8709557248308972\n",
      "train loss:0.7804862055079426\n",
      "train loss:0.7704069729026314\n",
      "train loss:0.856529842681982\n",
      "train loss:0.9051359408357498\n",
      "train loss:0.7721017352786715\n",
      "train loss:0.7421621025025184\n",
      "train loss:0.7849863982792692\n",
      "train loss:0.8752119098419054\n",
      "train loss:1.0151006822639503\n",
      "train loss:0.9835034930883687\n",
      "train loss:0.9016178922980965\n",
      "train loss:0.8579530433715806\n",
      "train loss:0.9086667756392263\n",
      "train loss:0.748646834731128\n",
      "train loss:0.6924017277275436\n",
      "train loss:0.8964661897753685\n",
      "train loss:0.7981545726819977\n",
      "train loss:0.9398906176576773\n",
      "train loss:0.8627229379028318\n",
      "train loss:1.080114895892818\n",
      "train loss:0.9249367339260505\n",
      "train loss:0.8212728535682158\n",
      "train loss:0.7272734470890023\n",
      "train loss:0.8242800959162147\n",
      "train loss:0.9978064946465834\n",
      "train loss:0.8717538818607983\n",
      "train loss:0.805875716919468\n",
      "train loss:0.7335535399900486\n",
      "train loss:0.9206269418344414\n",
      "train loss:0.8578629953710071\n",
      "train loss:1.0024869504735454\n",
      "train loss:0.9259137658347941\n",
      "train loss:0.8332566530628127\n",
      "train loss:1.0803380844883135\n",
      "train loss:0.992265548532808\n",
      "train loss:0.8437940761369385\n",
      "train loss:0.8352894251037831\n",
      "train loss:0.8443682423081704\n",
      "train loss:1.020956424131658\n",
      "train loss:0.8063951607987712\n",
      "train loss:0.9418435660336237\n",
      "train loss:0.8289507689000452\n",
      "train loss:0.8650937011823756\n",
      "train loss:0.9330944446796465\n",
      "train loss:0.8303631254182355\n",
      "train loss:0.9327288549414745\n",
      "train loss:1.0541746010921482\n",
      "train loss:0.7737042187207177\n",
      "train loss:0.827217398262785\n",
      "train loss:0.8735888249699868\n",
      "train loss:1.0270002669739107\n",
      "train loss:0.9255493704118807\n",
      "train loss:0.8836598699216677\n",
      "train loss:0.7540180710373032\n",
      "train loss:0.8115381616946975\n",
      "train loss:0.9851470400086869\n",
      "train loss:0.8349944004859856\n",
      "train loss:0.7443549315714039\n",
      "train loss:0.8390326666111513\n",
      "train loss:0.8663876556034095\n",
      "train loss:0.8161173989198037\n",
      "train loss:0.9382603883982111\n",
      "train loss:0.852720480407838\n",
      "train loss:0.872643008621693\n",
      "train loss:0.6955110512752891\n",
      "train loss:0.9119359522095496\n",
      "train loss:0.8453610352140447\n",
      "train loss:0.692232572168631\n",
      "train loss:1.075778781709605\n",
      "train loss:0.903770624759927\n",
      "train loss:0.9850564196211751\n",
      "train loss:0.7726732216373038\n",
      "train loss:0.8302089720679529\n",
      "train loss:0.9305501717205675\n",
      "train loss:1.0963051197150997\n",
      "train loss:0.6715611424477639\n",
      "train loss:0.771198658437178\n",
      "train loss:0.8217166461389362\n",
      "train loss:0.9740574859234826\n",
      "train loss:0.9287003792962922\n",
      "train loss:0.9123640261651087\n",
      "train loss:0.8522527306902893\n",
      "train loss:0.9039132731863377\n",
      "train loss:0.8105926393171812\n",
      "train loss:0.9302654035053836\n",
      "train loss:0.9140875164386489\n",
      "train loss:0.7028681931112051\n",
      "train loss:0.9388378213173654\n",
      "train loss:0.7588735618287076\n",
      "train loss:0.9942891994396237\n",
      "train loss:0.7494227756426042\n",
      "train loss:0.7556229784192664\n",
      "train loss:0.9809949208410158\n",
      "train loss:0.8979142467389898\n",
      "train loss:0.890737543860918\n",
      "train loss:0.806129741498608\n",
      "train loss:0.7975477255641674\n",
      "train loss:0.9573639226535449\n",
      "train loss:0.7931732561685917\n",
      "train loss:0.7622090340162699\n",
      "train loss:0.7834883527183707\n",
      "train loss:0.7201097631497783\n",
      "train loss:0.7996474865510983\n",
      "train loss:0.8906891528867874\n",
      "train loss:0.9452662344607191\n",
      "train loss:0.785586114962062\n",
      "train loss:0.8075165718482635\n",
      "train loss:0.9192591120538672\n",
      "train loss:0.9216179925623622\n",
      "train loss:0.8848871576716951\n",
      "train loss:0.8065329012498714\n",
      "train loss:0.7635097725024187\n",
      "train loss:0.7801382083568982\n",
      "train loss:0.9644370872480448\n",
      "train loss:0.9559685035436558\n",
      "train loss:0.8526095424911607\n",
      "train loss:0.7633691368489868\n",
      "train loss:0.7937935016926201\n",
      "train loss:0.91701628763352\n",
      "train loss:0.8823222182631757\n",
      "train loss:1.0042543263894081\n",
      "train loss:0.7858709206098295\n",
      "train loss:1.0125985218924447\n",
      "train loss:0.7554707829551649\n",
      "train loss:0.9007256419257985\n",
      "train loss:0.850735911085383\n",
      "train loss:0.8320269430045717\n",
      "train loss:0.7820817944943755\n",
      "train loss:0.9339921434698162\n",
      "train loss:0.7053923526314001\n",
      "train loss:1.0260832491298801\n",
      "train loss:1.0767435506988794\n",
      "train loss:0.7606163766378299\n",
      "train loss:0.9023647033186127\n",
      "train loss:0.8760263654474696\n",
      "train loss:1.0866765952649073\n",
      "train loss:0.7841404792911933\n",
      "train loss:0.9849347577393517\n",
      "train loss:0.9049895694935074\n",
      "train loss:0.8595416723592239\n",
      "train loss:0.9144310393352744\n",
      "train loss:0.9968463069419657\n",
      "train loss:0.6995906046060208\n",
      "train loss:0.9779808278058434\n",
      "train loss:0.8679902051124038\n",
      "train loss:0.9144450657589364\n",
      "train loss:0.8086936326158305\n",
      "train loss:0.8212953101326614\n",
      "train loss:1.026863558762967\n",
      "train loss:1.1209644393907228\n",
      "train loss:0.9417941118900691\n",
      "train loss:0.855111808031964\n",
      "train loss:0.8716133792781099\n",
      "train loss:0.8520425138962865\n",
      "train loss:0.9009378855226079\n",
      "train loss:0.9591803151090484\n",
      "train loss:0.8381316473390017\n",
      "train loss:0.8131208798553518\n",
      "train loss:0.8224312007609056\n",
      "train loss:0.849938444899548\n",
      "train loss:0.8165652770017072\n",
      "train loss:0.9154341791826662\n",
      "train loss:0.777597898419187\n",
      "train loss:0.9157995576883653\n",
      "train loss:0.7935822137713266\n",
      "train loss:0.8839049906951835\n",
      "train loss:0.8175680759234837\n",
      "train loss:0.8799234683661414\n",
      "train loss:0.8063870537965356\n",
      "train loss:0.988664283377764\n",
      "train loss:0.7799556761766354\n",
      "train loss:0.9643930712354851\n",
      "train loss:0.7703544506051542\n",
      "train loss:1.0059399677514582\n",
      "train loss:1.0265004868847885\n",
      "train loss:0.8850723290987661\n",
      "train loss:0.9411106851050586\n",
      "train loss:0.9912406805718811\n",
      "train loss:0.8537526078990364\n",
      "train loss:0.9080647526306805\n",
      "train loss:0.8647006545502304\n",
      "train loss:0.7010196597012637\n",
      "train loss:1.0238064611781406\n",
      "train loss:0.8606669929309899\n",
      "train loss:0.7956706626728502\n",
      "train loss:0.9129883067643684\n",
      "train loss:0.88550341919511\n",
      "train loss:0.8483485477458972\n",
      "train loss:0.8441844833631933\n",
      "train loss:0.8976826330641064\n",
      "train loss:0.7915354536135599\n",
      "train loss:0.9570799316246129\n",
      "train loss:0.9022801075818334\n",
      "train loss:0.740636968220687\n",
      "train loss:0.8607172496901532\n",
      "train loss:0.8955392825114012\n",
      "train loss:0.8561094617726417\n",
      "train loss:1.067587534997209\n",
      "train loss:0.9864971964749683\n",
      "train loss:0.8414474669134178\n",
      "train loss:0.8879777064416909\n",
      "train loss:0.8342479813958856\n",
      "train loss:0.871485035878001\n",
      "train loss:0.974705369032574\n",
      "train loss:0.806680321176857\n",
      "train loss:0.7249743925827241\n",
      "train loss:0.967737023926807\n",
      "train loss:0.7657891975262417\n",
      "train loss:0.875352622760526\n",
      "train loss:0.8608345522973835\n",
      "train loss:0.910408891739027\n",
      "train loss:0.8563137349628039\n",
      "train loss:0.7361535457977813\n",
      "train loss:0.8798509801936149\n",
      "train loss:0.8717160311150061\n",
      "train loss:0.9335918820610967\n",
      "train loss:1.1192023328808525\n",
      "train loss:0.8535653571162886\n",
      "train loss:0.7156276728295744\n",
      "train loss:0.7928848179456989\n",
      "train loss:0.7941481761192474\n",
      "train loss:1.0128227221930615\n",
      "train loss:0.93353855731444\n",
      "train loss:0.7469858385492499\n",
      "train loss:0.893138803606587\n",
      "train loss:0.8507529099083141\n",
      "train loss:0.8399818377748572\n",
      "train loss:0.9034293562505717\n",
      "train loss:0.9727514443856667\n",
      "train loss:0.7950948850630914\n",
      "train loss:0.9686753459347373\n",
      "train loss:0.7957259840829038\n",
      "train loss:0.9166701612468009\n",
      "train loss:0.810683212342846\n",
      "train loss:0.780361603206775\n",
      "train loss:0.8854947542065256\n",
      "train loss:0.8458686713778382\n",
      "train loss:0.793435136400481\n",
      "train loss:0.9355482280142536\n",
      "train loss:0.8349533428337799\n",
      "train loss:0.6947395153184721\n",
      "train loss:1.023059223120827\n",
      "train loss:0.830053060338059\n",
      "train loss:0.9383105477281726\n",
      "train loss:0.7605798844073806\n",
      "train loss:0.832791305625268\n",
      "train loss:0.9387861951996106\n",
      "train loss:0.8044935573484396\n",
      "train loss:0.811989090251708\n",
      "train loss:0.8280240568861262\n",
      "train loss:0.8045242730864753\n",
      "train loss:0.90809137757946\n",
      "train loss:0.8172809383134145\n",
      "train loss:0.9006761553620748\n",
      "train loss:0.8193254124688195\n",
      "train loss:0.86539762555529\n",
      "train loss:0.9148748770295773\n",
      "train loss:0.7936946882255493\n",
      "train loss:0.962305123427922\n",
      "train loss:0.8537333611714412\n",
      "train loss:0.9177378731188629\n",
      "train loss:0.9093176627516195\n",
      "train loss:0.8034356837121328\n",
      "train loss:0.9828776909446134\n",
      "train loss:0.6710973619741385\n",
      "train loss:0.7868680827230667\n",
      "train loss:0.6528416651441072\n",
      "train loss:0.9137271516124436\n",
      "train loss:0.8596284272290737\n",
      "train loss:0.843914157575307\n",
      "train loss:0.8176817957375886\n",
      "train loss:0.8779834086357502\n",
      "train loss:0.8379649064639453\n",
      "train loss:0.8286588908278013\n",
      "train loss:0.7398336093005848\n",
      "train loss:0.9703161065111433\n",
      "train loss:0.8861631926433776\n",
      "train loss:0.8469604601691203\n",
      "train loss:0.7701780764975807\n",
      "train loss:0.8790492243569978\n",
      "train loss:0.7018818412618435\n",
      "train loss:0.8460124313903645\n",
      "train loss:0.8818044287109408\n",
      "train loss:0.8482046920420093\n",
      "train loss:0.8017824783679747\n",
      "train loss:0.8933249903010434\n",
      "train loss:0.744555454376733\n",
      "train loss:0.9470611128489539\n",
      "train loss:0.8268039972338032\n",
      "train loss:0.8873049717310473\n",
      "train loss:0.7169454569059885\n",
      "train loss:0.8671054269239442\n",
      "train loss:1.0511072347688275\n",
      "train loss:0.9953422948485283\n",
      "train loss:0.9580515393889675\n",
      "train loss:0.8261660523337311\n",
      "train loss:0.8928964461103236\n",
      "train loss:0.8013411288536738\n",
      "train loss:1.0282180486493349\n",
      "train loss:0.8901127164597104\n",
      "train loss:1.0216774217385745\n",
      "train loss:0.8784688862191433\n",
      "train loss:0.7314509130284021\n",
      "train loss:0.6815658773143342\n",
      "train loss:0.8516816801065263\n",
      "train loss:0.8147078855472101\n",
      "train loss:0.7423407615858959\n",
      "train loss:0.7343467233048061\n",
      "train loss:0.8956441955418109\n",
      "train loss:0.8985816064594272\n",
      "train loss:0.7809795355570869\n",
      "train loss:0.8674552949064533\n",
      "train loss:0.906750450618959\n",
      "train loss:0.9483345750874212\n",
      "train loss:0.7762995883716699\n",
      "train loss:0.9323952903339037\n",
      "train loss:0.7796967010600633\n",
      "train loss:0.8213234086690052\n",
      "train loss:0.7304121473837236\n",
      "train loss:1.0713901232835878\n",
      "train loss:1.0349661571597955\n",
      "train loss:1.0374050745272212\n",
      "train loss:0.9087811796232402\n",
      "train loss:0.8753049261289472\n",
      "train loss:1.0128694456607552\n",
      "train loss:0.6938325087203553\n",
      "train loss:0.7334174953594953\n",
      "train loss:0.7555979751919343\n",
      "train loss:0.8047346908249605\n",
      "train loss:0.9408943190347376\n",
      "train loss:0.8712722881184517\n",
      "train loss:0.9838019676652635\n",
      "train loss:0.7876268600982876\n",
      "train loss:0.7041898542519658\n",
      "train loss:0.8566936953779749\n",
      "train loss:0.9572357753151838\n",
      "train loss:0.9307623432633949\n",
      "train loss:1.0923149845639402\n",
      "train loss:0.7040666994695626\n",
      "train loss:0.7602468580269659\n",
      "train loss:0.9484320695443934\n",
      "train loss:0.8905064684202163\n",
      "train loss:0.8593335627370732\n",
      "train loss:1.0239409881818369\n",
      "train loss:1.0296178333109272\n",
      "train loss:1.0545501707875924\n",
      "train loss:0.9275399123477858\n",
      "train loss:0.8813806985296366\n",
      "train loss:0.785510349943074\n",
      "train loss:0.793434157943085\n",
      "train loss:0.7933126488598355\n",
      "train loss:0.8866495509319092\n",
      "train loss:0.9684390456896859\n",
      "train loss:0.9748113993908977\n",
      "train loss:0.8419576439437968\n",
      "train loss:0.8306990757658506\n",
      "train loss:1.0179514266764251\n",
      "train loss:0.9982425566702432\n",
      "train loss:0.8293388920641255\n",
      "train loss:0.9179109201456416\n",
      "train loss:0.6754744796949383\n",
      "train loss:0.9380246347259447\n",
      "train loss:0.9388622109627813\n",
      "train loss:0.8367084121256717\n",
      "train loss:0.7779464690159206\n",
      "train loss:0.8573573954015352\n",
      "train loss:0.7703360195595862\n",
      "train loss:0.8779936651205597\n",
      "train loss:0.9456629240913645\n",
      "train loss:0.8157940289160248\n",
      "train loss:0.8546882309586714\n",
      "train loss:0.8858511188433441\n",
      "train loss:0.8483420372119397\n",
      "train loss:0.8233580130383126\n",
      "train loss:0.7437148094908193\n",
      "train loss:0.8672942813459126\n",
      "train loss:0.7483438562788812\n",
      "train loss:0.7360645906713674\n",
      "train loss:0.9378925195481496\n",
      "train loss:0.8557280521584003\n",
      "train loss:0.8746509577014829\n",
      "train loss:0.8905728542445769\n",
      "train loss:0.7581389287333903\n",
      "train loss:0.9814023366828418\n",
      "train loss:0.7724342048268666\n",
      "train loss:0.8904144554605752\n",
      "train loss:0.9242585088407108\n",
      "train loss:0.9879735104602703\n",
      "train loss:0.864747277399728\n",
      "train loss:0.9427037647486547\n",
      "train loss:0.6024264715622989\n",
      "train loss:0.8665333451698187\n",
      "train loss:0.8808662873732068\n",
      "train loss:0.9043723814424223\n",
      "train loss:0.7650669480996553\n",
      "train loss:0.7261631637767203\n",
      "train loss:0.7736275135744077\n",
      "train loss:0.9291986192615217\n",
      "train loss:0.8093979721029683\n",
      "train loss:0.7665992704675125\n",
      "train loss:0.9045443494568356\n",
      "train loss:0.9075374892717012\n",
      "train loss:0.957685200992061\n",
      "train loss:0.7543415910706206\n",
      "train loss:0.7891003375948195\n",
      "train loss:0.7738943052800654\n",
      "train loss:0.8102263080922103\n",
      "train loss:0.8808720972142031\n",
      "train loss:0.8907031913971735\n",
      "train loss:1.0236659875002558\n",
      "train loss:0.8541832053544987\n",
      "train loss:0.8927496105802818\n",
      "train loss:0.9604855318085831\n",
      "train loss:0.8760132125970919\n",
      "train loss:0.7094941310087873\n",
      "train loss:0.8277023657775014\n",
      "train loss:0.927723796459507\n",
      "train loss:0.9493060451712142\n",
      "train loss:0.833710747793236\n",
      "train loss:0.9148855021055611\n",
      "train loss:0.7869414132082462\n",
      "train loss:0.9758656379522105\n",
      "train loss:0.7550553338850482\n",
      "train loss:0.8734870602723258\n",
      "train loss:0.7340736816213632\n",
      "train loss:0.7684755212110648\n",
      "train loss:0.9025603581663586\n",
      "train loss:0.7979598971838103\n",
      "train loss:0.8245799241217565\n",
      "train loss:0.9486795288586782\n",
      "train loss:0.8881078026507977\n",
      "train loss:0.7699238440012113\n",
      "train loss:0.9046096167382093\n",
      "train loss:1.0153119449645978\n",
      "train loss:0.7622897659544695\n",
      "train loss:0.7168168223478223\n",
      "train loss:0.8735185266714598\n",
      "train loss:0.8062057625652801\n",
      "train loss:0.7444502766391206\n",
      "train loss:0.8579931037997846\n",
      "train loss:0.6921472703514019\n",
      "train loss:0.7877900240939358\n",
      "train loss:0.9783459382652093\n",
      "train loss:1.118784683845721\n",
      "train loss:0.9406968820119046\n",
      "train loss:0.882187777558334\n",
      "train loss:0.9562182727246815\n",
      "train loss:0.7821352836198655\n",
      "train loss:0.8702917665965322\n",
      "train loss:0.9436683732770008\n",
      "train loss:0.9674191564297868\n",
      "train loss:0.9126563422730604\n",
      "train loss:0.8334007127221141\n",
      "train loss:0.8902228594576915\n",
      "train loss:0.7868555882743823\n",
      "train loss:0.8826117981803848\n",
      "train loss:0.821121729291147\n",
      "train loss:0.9040105785466198\n",
      "train loss:0.8902987781083154\n",
      "train loss:0.8600435389564134\n",
      "train loss:0.746504926959691\n",
      "train loss:0.7687591167630207\n",
      "train loss:0.822091754145627\n",
      "train loss:0.8056666394331486\n",
      "train loss:0.8363432041605179\n",
      "train loss:0.7748710875452456\n",
      "train loss:0.826360034003846\n",
      "train loss:0.924791673670092\n",
      "train loss:0.9888247159603032\n",
      "train loss:0.8280208519015234\n",
      "train loss:0.9141567853719954\n",
      "train loss:1.0459804047170518\n",
      "train loss:0.7707720718471832\n",
      "train loss:0.821467213457967\n",
      "train loss:0.831704405957054\n",
      "train loss:0.8212128564437008\n",
      "train loss:0.8657925660266794\n",
      "train loss:0.7845643596676459\n",
      "train loss:0.8997824206592937\n",
      "train loss:0.8332018790705605\n",
      "train loss:0.807896246830415\n",
      "train loss:0.9873669736113905\n",
      "train loss:0.9228437698116773\n",
      "train loss:0.8642037242759492\n",
      "train loss:0.9194852001009468\n",
      "train loss:0.7905673650591702\n",
      "train loss:0.8388412188291012\n",
      "train loss:0.919125873200995\n",
      "train loss:0.7895231686629127\n",
      "train loss:0.9051487835832627\n",
      "train loss:0.9495040898130473\n",
      "train loss:0.8066649459103523\n",
      "train loss:0.9601373914562303\n",
      "train loss:0.8130531746300896\n",
      "train loss:0.8735350145168924\n",
      "train loss:0.9181129652745849\n",
      "train loss:0.964444148744977\n",
      "train loss:0.9876220428988118\n",
      "train loss:0.8067977039784492\n",
      "train loss:0.7753434084642368\n",
      "train loss:1.0281325891730018\n",
      "train loss:0.9938509683215702\n",
      "train loss:0.9440841030527021\n",
      "train loss:0.6413629643686221\n",
      "train loss:0.8372162102003388\n",
      "train loss:0.88797742484476\n",
      "train loss:0.9995764232605435\n",
      "train loss:0.8121676097354115\n",
      "train loss:0.7195246417828475\n",
      "train loss:0.8966723337946321\n",
      "train loss:0.8429277096240082\n",
      "train loss:0.7439253597893106\n",
      "train loss:0.9867694934980082\n",
      "train loss:0.7589348991623511\n",
      "train loss:0.9864068314615421\n",
      "train loss:0.8409230801404519\n",
      "train loss:0.7485828082411163\n",
      "train loss:0.9311560903836302\n",
      "train loss:0.9081633047710431\n",
      "train loss:0.9534464222319708\n",
      "train loss:0.8695404197977742\n",
      "train loss:0.8841552722506368\n",
      "train loss:0.8594655732352634\n",
      "train loss:0.9030436876365527\n",
      "train loss:0.8302158307542398\n",
      "train loss:1.082458558436909\n",
      "train loss:0.8458323840858257\n",
      "train loss:0.8286314484368953\n",
      "train loss:0.8884666074080991\n",
      "train loss:0.7477658953906473\n",
      "train loss:0.7604314349177919\n",
      "train loss:0.7952398062432714\n",
      "train loss:0.8096655545661646\n",
      "train loss:0.8727564935023534\n",
      "train loss:1.0648903657697153\n",
      "train loss:0.9240623345737778\n",
      "train loss:0.9610373224461324\n",
      "train loss:0.6938251396108249\n",
      "train loss:0.9905704999154876\n",
      "train loss:0.9286187660776537\n",
      "train loss:0.8001983472881659\n",
      "train loss:0.9201078393984092\n",
      "train loss:0.792736634926889\n",
      "train loss:0.8948378323983124\n",
      "train loss:0.8904556659679703\n",
      "train loss:0.9018331584187693\n",
      "train loss:0.8257903060758613\n",
      "train loss:0.9394509813223313\n",
      "train loss:0.7960883105218393\n",
      "train loss:0.7850936071041221\n",
      "train loss:1.0854998377431628\n",
      "train loss:0.8214309595555846\n",
      "=== epoch:13, train acc:0.996, test acc:0.991 ===\n",
      "train loss:0.8348761409385682\n",
      "train loss:1.048634114982995\n",
      "train loss:0.8860588754077622\n",
      "train loss:0.7657452439943527\n",
      "train loss:0.9504893026946699\n",
      "train loss:1.0217372108897347\n",
      "train loss:0.8797480090998298\n",
      "train loss:0.763313603982936\n",
      "train loss:0.8699111679158602\n",
      "train loss:0.8031448772828425\n",
      "train loss:0.9710028562529124\n",
      "train loss:0.9146947455315432\n",
      "train loss:0.9621508976584309\n",
      "train loss:0.6744162817579143\n",
      "train loss:0.7568991894521773\n",
      "train loss:0.8808593220124736\n",
      "train loss:0.902329147434653\n",
      "train loss:0.8372989076199214\n",
      "train loss:0.8007953887483155\n",
      "train loss:0.8248361940547443\n",
      "train loss:0.9563133898027956\n",
      "train loss:0.9949755328298838\n",
      "train loss:0.7479981324993591\n",
      "train loss:0.8846837739058485\n",
      "train loss:0.9530457033527172\n",
      "train loss:0.9427952713114658\n",
      "train loss:0.9221387995643998\n",
      "train loss:0.7149283693745351\n",
      "train loss:0.7291182084706507\n",
      "train loss:0.865403343677035\n",
      "train loss:0.8535673588836954\n",
      "train loss:0.9430641050290863\n",
      "train loss:0.8231690342192824\n",
      "train loss:0.8600798345716137\n",
      "train loss:0.8787477297537873\n",
      "train loss:0.93323843909508\n",
      "train loss:0.7742827458116497\n",
      "train loss:0.7493266555231415\n",
      "train loss:0.9220753748828479\n",
      "train loss:0.890597605612124\n",
      "train loss:0.8427524766539166\n",
      "train loss:0.9758300983881791\n",
      "train loss:0.7985258956097241\n",
      "train loss:0.8694359854267184\n",
      "train loss:0.7991385069221344\n",
      "train loss:1.0377485751986226\n",
      "train loss:0.8523963894754811\n",
      "train loss:0.9280266057095332\n",
      "train loss:0.9922490653407366\n",
      "train loss:0.7858764809389158\n",
      "train loss:0.9804305050752966\n",
      "train loss:0.8751926328894478\n",
      "train loss:0.9031670735139969\n",
      "train loss:0.9664913942584705\n",
      "train loss:0.8960197927100109\n",
      "train loss:1.1226694020774926\n",
      "train loss:0.863458073428691\n",
      "train loss:0.8938135198716215\n",
      "train loss:0.9499134070924212\n",
      "train loss:0.6893738081505087\n",
      "train loss:0.9565460175078251\n",
      "train loss:0.9402273750926072\n",
      "train loss:0.9671961039981386\n",
      "train loss:0.8277935388162537\n",
      "train loss:0.7882724723967661\n",
      "train loss:0.924677018503558\n",
      "train loss:0.9689137675872752\n",
      "train loss:0.8336132009925065\n",
      "train loss:0.8590521117462682\n",
      "train loss:1.0317115603133669\n",
      "train loss:1.04282117373572\n",
      "train loss:0.8814755092277404\n",
      "train loss:0.9150024562487051\n",
      "train loss:0.8494842989809728\n",
      "train loss:0.8759181362429845\n",
      "train loss:0.8914950235429834\n",
      "train loss:0.8274023566994007\n",
      "train loss:0.8170706656017717\n",
      "train loss:0.7389727856094\n",
      "train loss:0.843129842852003\n",
      "train loss:0.8245293865094344\n",
      "train loss:0.8642822862482261\n",
      "train loss:0.7649362315445011\n",
      "train loss:0.9134314409256727\n",
      "train loss:0.9277959252016739\n",
      "train loss:0.9118151438859121\n",
      "train loss:0.8826403041365283\n",
      "train loss:0.9104976099016818\n",
      "train loss:0.7553158252121709\n",
      "train loss:0.911431972363892\n",
      "train loss:1.0116520125875477\n",
      "train loss:0.7899756097439807\n",
      "train loss:0.8540827537805543\n",
      "train loss:0.8630558092229822\n",
      "train loss:0.9594059573492077\n",
      "train loss:0.8832538753031294\n",
      "train loss:0.8886339492665914\n",
      "train loss:0.870135876978856\n",
      "train loss:0.7977066509922283\n",
      "train loss:0.7773733281047669\n",
      "train loss:0.7824362450854793\n",
      "train loss:0.8772663041681895\n",
      "train loss:0.8588818378699701\n",
      "train loss:0.8935666610306767\n",
      "train loss:0.8506302496513601\n",
      "train loss:0.6707877437661373\n",
      "train loss:0.8791701499337481\n",
      "train loss:0.8352624682050259\n",
      "train loss:0.918384889315767\n",
      "train loss:0.8550146213507956\n",
      "train loss:0.8418327569215563\n",
      "train loss:0.8146841021148907\n",
      "train loss:0.992860314822893\n",
      "train loss:0.8238626769193786\n",
      "train loss:0.8373876557440902\n",
      "train loss:0.9159233640714052\n",
      "train loss:1.01780031756692\n",
      "train loss:0.8481721736481643\n",
      "train loss:0.8773857040362182\n",
      "train loss:0.7911736495075021\n",
      "train loss:0.7930966804288875\n",
      "train loss:0.8258265394508543\n",
      "train loss:0.8700858524254409\n",
      "train loss:0.737443598653671\n",
      "train loss:0.9144155175068422\n",
      "train loss:0.7878212097000195\n",
      "train loss:0.779412334452609\n",
      "train loss:0.8267465854569874\n",
      "train loss:0.8857451210322107\n",
      "train loss:0.8682796598319906\n",
      "train loss:0.8627799888202264\n",
      "train loss:0.8155949279307619\n",
      "train loss:0.8853341096815309\n",
      "train loss:1.0092360455918874\n",
      "train loss:0.7783193819034219\n",
      "train loss:0.8113202982114167\n",
      "train loss:0.9195545632226654\n",
      "train loss:0.6843185293179236\n",
      "train loss:0.8014629952703075\n",
      "train loss:0.7482654124235241\n",
      "train loss:0.8914290473501051\n",
      "train loss:0.9603873513900738\n",
      "train loss:0.9603163628620309\n",
      "train loss:0.8828163754447742\n",
      "train loss:0.7700601626837431\n",
      "train loss:0.8419403722617111\n",
      "train loss:0.7639973645544318\n",
      "train loss:0.9786158574926095\n",
      "train loss:0.7659932939124746\n",
      "train loss:0.8171059119797266\n",
      "train loss:0.8811436910909332\n",
      "train loss:0.8422531892911125\n",
      "train loss:0.9328968419741299\n",
      "train loss:0.7947435840041385\n",
      "train loss:0.9698373444778865\n",
      "train loss:0.8602372693049319\n",
      "train loss:0.7235168783156053\n",
      "train loss:0.9501553423207004\n",
      "train loss:0.8307597472823792\n",
      "train loss:1.0333556623411067\n",
      "train loss:0.8069040672251248\n",
      "train loss:0.9030597597241716\n",
      "train loss:0.8587721952983606\n",
      "train loss:0.8971551916456214\n",
      "train loss:0.8753245960869965\n",
      "train loss:0.8917475440004516\n",
      "train loss:0.8492584370062137\n",
      "train loss:0.8021014073424805\n",
      "train loss:0.7466854841724985\n",
      "train loss:0.9380113918204658\n",
      "train loss:0.8251727858236392\n",
      "train loss:0.7737936998544419\n",
      "train loss:0.8274649261507365\n",
      "train loss:0.9743108487205832\n",
      "train loss:0.8679431460105367\n",
      "train loss:0.8861791024126865\n",
      "train loss:0.8725518123595932\n",
      "train loss:0.7767843137770605\n",
      "train loss:0.8578225724673731\n",
      "train loss:0.822360613445046\n",
      "train loss:0.7923386151007257\n",
      "train loss:0.8389586499480661\n",
      "train loss:0.8729817329135279\n",
      "train loss:0.81754116916531\n",
      "train loss:0.7893239064678852\n",
      "train loss:0.8641934394902759\n",
      "train loss:0.8914917411940456\n",
      "train loss:0.7248489348438624\n",
      "train loss:0.721675808183909\n",
      "train loss:0.8698058534792149\n",
      "train loss:0.9848569865592518\n",
      "train loss:0.8474596585341415\n",
      "train loss:0.8775738191097942\n",
      "train loss:0.9154658485084807\n",
      "train loss:0.7290816469575861\n",
      "train loss:0.7729814395120274\n",
      "train loss:0.9872277556506937\n",
      "train loss:0.9599813677120386\n",
      "train loss:0.921339817177472\n",
      "train loss:0.8838736219831377\n",
      "train loss:0.8583294461494121\n",
      "train loss:0.8537538430692483\n",
      "train loss:0.9594482074683864\n",
      "train loss:0.8223298712135932\n",
      "train loss:0.8492858214493273\n",
      "train loss:0.9760382066714206\n",
      "train loss:0.9673544977214097\n",
      "train loss:0.809891869763761\n",
      "train loss:0.7374899133281739\n",
      "train loss:0.9459920052743327\n",
      "train loss:0.9534611482040006\n",
      "train loss:0.7575703936785694\n",
      "train loss:0.9374409773588297\n",
      "train loss:0.9297456445146466\n",
      "train loss:0.8201692073817507\n",
      "train loss:0.9269281138092852\n",
      "train loss:0.7403059360780199\n",
      "train loss:0.7707342106117665\n",
      "train loss:0.645264749409059\n",
      "train loss:0.7989651545132602\n",
      "train loss:0.8697280084879294\n",
      "train loss:0.8238913402287353\n",
      "train loss:0.9096662734718034\n",
      "train loss:1.1437599869083659\n",
      "train loss:0.8857642616242232\n",
      "train loss:0.7981466090140553\n",
      "train loss:0.8284416951423943\n",
      "train loss:0.9473203543400017\n",
      "train loss:1.0063696885290496\n",
      "train loss:0.6926329532937225\n",
      "train loss:0.8232021774266012\n",
      "train loss:0.8010235195875641\n",
      "train loss:0.8644902638637025\n",
      "train loss:1.1212230968461416\n",
      "train loss:0.893408674082301\n",
      "train loss:0.789218837645703\n",
      "train loss:0.7773071237584053\n",
      "train loss:0.7610122662275255\n",
      "train loss:0.9234190522567292\n",
      "train loss:0.9897418481672777\n",
      "train loss:0.8170998223236924\n",
      "train loss:0.9268671096449925\n",
      "train loss:0.6807770983298638\n",
      "train loss:0.7897519575324159\n",
      "train loss:0.9576058638438879\n",
      "train loss:0.9120503652594932\n",
      "train loss:0.909520755447837\n",
      "train loss:0.8202533432875313\n",
      "train loss:0.7867782758221307\n",
      "train loss:0.938068221546097\n",
      "train loss:0.7344535040922067\n",
      "train loss:0.9505320919290011\n",
      "train loss:0.7918125935913284\n",
      "train loss:0.7571168131851751\n",
      "train loss:0.9073688364690462\n",
      "train loss:0.7778139169818025\n",
      "train loss:0.8541369382743516\n",
      "train loss:0.7424682670669616\n",
      "train loss:0.9577447599192821\n",
      "train loss:0.8260212137500862\n",
      "train loss:0.9151750809409408\n",
      "train loss:1.0144961273393003\n",
      "train loss:0.7773292617511484\n",
      "train loss:0.8913979334189086\n",
      "train loss:0.9619196906654505\n",
      "train loss:0.8252983220549537\n",
      "train loss:0.8610115489088034\n",
      "train loss:0.8561095812114761\n",
      "train loss:0.7076651536276058\n",
      "train loss:0.9357651259771553\n",
      "train loss:0.9491784686430207\n",
      "train loss:0.893002920402168\n",
      "train loss:0.8326354725021939\n",
      "train loss:0.867241722532691\n",
      "train loss:0.7963509999296073\n",
      "train loss:0.9313083569689996\n",
      "train loss:0.9186844273890911\n",
      "train loss:0.8639752580832365\n",
      "train loss:0.789678722557607\n",
      "train loss:0.9329902001759267\n",
      "train loss:0.8886168065085797\n",
      "train loss:0.8725832506360292\n",
      "train loss:0.9653765126492548\n",
      "train loss:0.7120327399959394\n",
      "train loss:0.6799645706562464\n",
      "train loss:0.8283456596586497\n",
      "train loss:0.9079836269382278\n",
      "train loss:0.6430273485756914\n",
      "train loss:0.8160863642860663\n",
      "train loss:0.8083530921458015\n",
      "train loss:0.9844722986152645\n",
      "train loss:0.8967347868458255\n",
      "train loss:0.8230960015190624\n",
      "train loss:0.9201090537104086\n",
      "train loss:0.8191435282346976\n",
      "train loss:0.8478285092119796\n",
      "train loss:1.0675995314937794\n",
      "train loss:0.9072006071080538\n",
      "train loss:0.9554095560589615\n",
      "train loss:1.014332654283591\n",
      "train loss:0.7557742869230186\n",
      "train loss:0.851234428622164\n",
      "train loss:0.917714993170542\n",
      "train loss:0.9959537142324402\n",
      "train loss:0.9714133877622463\n",
      "train loss:0.8515319687622548\n",
      "train loss:0.7384410091385116\n",
      "train loss:0.8080070882467872\n",
      "train loss:0.7976973268317942\n",
      "train loss:0.7936684986834776\n",
      "train loss:0.9777467562368671\n",
      "train loss:0.7774876302069493\n",
      "train loss:1.0273162320631166\n",
      "train loss:0.7899826825180126\n",
      "train loss:0.8255528271262647\n",
      "train loss:0.8050760417780147\n",
      "train loss:0.8986082364501489\n",
      "train loss:0.7660820199853435\n",
      "train loss:0.7322672472552105\n",
      "train loss:0.8627080784326527\n",
      "train loss:0.7706455884993544\n",
      "train loss:0.8705934298613731\n",
      "train loss:0.6842812448386514\n",
      "train loss:0.8734316279894216\n",
      "train loss:0.9666770791966816\n",
      "train loss:0.7299190073419684\n",
      "train loss:0.739888821724788\n",
      "train loss:0.9440173099056609\n",
      "train loss:0.6598295998116618\n",
      "train loss:0.9507103550234832\n",
      "train loss:0.8446452723589105\n",
      "train loss:0.7667247170689064\n",
      "train loss:0.8140039653520209\n",
      "train loss:0.936841817525279\n",
      "train loss:0.953263347413948\n",
      "train loss:0.9797178082532703\n",
      "train loss:0.9108807806794371\n",
      "train loss:0.9258918566772081\n",
      "train loss:0.7063536848479647\n",
      "train loss:0.7451309623538254\n",
      "train loss:0.823287216426607\n",
      "train loss:0.6684176972565303\n",
      "train loss:0.8962217284805475\n",
      "train loss:0.9733324717206476\n",
      "train loss:0.9725535375937377\n",
      "train loss:0.8488211910186741\n",
      "train loss:0.9156521933163378\n",
      "train loss:1.0199523082161261\n",
      "train loss:0.7594533214601428\n",
      "train loss:0.7474277526441895\n",
      "train loss:0.7385544076105837\n",
      "train loss:0.8487629025184253\n",
      "train loss:0.7960720650859592\n",
      "train loss:0.7484129001492552\n",
      "train loss:0.9451315288744123\n",
      "train loss:1.025070111070083\n",
      "train loss:0.6528914140784849\n",
      "train loss:0.8776574641592262\n",
      "train loss:0.7439776691023797\n",
      "train loss:0.9622647052228838\n",
      "train loss:0.887174110543434\n",
      "train loss:0.9911943767402142\n",
      "train loss:0.8708091875281846\n",
      "train loss:0.9401692999614504\n",
      "train loss:0.8620657964720614\n",
      "train loss:0.889329943221099\n",
      "train loss:0.9826204535235733\n",
      "train loss:0.7972834316689528\n",
      "train loss:0.7429313343639378\n",
      "train loss:0.7801560358487436\n",
      "train loss:0.9267928360744522\n",
      "train loss:0.7929916880155045\n",
      "train loss:0.8590292234048954\n",
      "train loss:1.0454245344306545\n",
      "train loss:0.7820490097828222\n",
      "train loss:0.7853863246673324\n",
      "train loss:0.9190557591386179\n",
      "train loss:0.9253771048968676\n",
      "train loss:0.8807489029265269\n",
      "train loss:0.8086056494963298\n",
      "train loss:0.8389022157122714\n",
      "train loss:0.9569575739108536\n",
      "train loss:1.1464098932239424\n",
      "train loss:0.774306900541419\n",
      "train loss:0.9464525366428626\n",
      "train loss:0.806659827793129\n",
      "train loss:0.8241662860505996\n",
      "train loss:0.6863863536459476\n",
      "train loss:0.726480069037862\n",
      "train loss:0.7374631139125296\n",
      "train loss:0.9182043076414255\n",
      "train loss:0.8697102007137678\n",
      "train loss:0.8986946234938661\n",
      "train loss:0.8874075234967143\n",
      "train loss:0.961132028639263\n",
      "train loss:0.9825762043213776\n",
      "train loss:0.8138353780767291\n",
      "train loss:0.795358608361908\n",
      "train loss:0.9477553590236089\n",
      "train loss:0.9879474651701692\n",
      "train loss:1.0133780432739354\n",
      "train loss:0.9150465165832843\n",
      "train loss:0.9581596213352641\n",
      "train loss:0.9263132757017799\n",
      "train loss:0.8473134142099099\n",
      "train loss:0.8712988190495987\n",
      "train loss:0.8744902701848984\n",
      "train loss:0.9177187463803358\n",
      "train loss:0.8295197910439899\n",
      "train loss:0.7824371158633427\n",
      "train loss:0.9782179766398843\n",
      "train loss:0.7740589920222\n",
      "train loss:0.8368149977673528\n",
      "train loss:0.8984774330437986\n",
      "train loss:0.8826510601062827\n",
      "train loss:0.9931857383988598\n",
      "train loss:0.8660994953768624\n",
      "train loss:0.696701162287487\n",
      "train loss:0.9177766915050456\n",
      "train loss:0.873518868030093\n",
      "train loss:0.8252179333129558\n",
      "train loss:0.8252184605637521\n",
      "train loss:0.713427750458541\n",
      "train loss:0.7689564087847361\n",
      "train loss:0.8970984133933723\n",
      "train loss:0.9376052790227088\n",
      "train loss:0.8567900679465439\n",
      "train loss:0.9750109748627245\n",
      "train loss:0.7657235785257575\n",
      "train loss:0.912615968209084\n",
      "train loss:0.8980815478530644\n",
      "train loss:1.089661629780709\n",
      "train loss:0.8185851680597419\n",
      "train loss:0.9000953170505983\n",
      "train loss:0.9676049141396926\n",
      "train loss:0.7458445989596661\n",
      "train loss:0.691018376465209\n",
      "train loss:0.8161559130461778\n",
      "train loss:1.0380676636586066\n",
      "train loss:0.8533494163656735\n",
      "train loss:0.8677782951413578\n",
      "train loss:0.8365372711700519\n",
      "train loss:0.7031901351619143\n",
      "train loss:0.9267429684475362\n",
      "train loss:0.9660888887505393\n",
      "train loss:0.8686274169408074\n",
      "train loss:0.8973661186981536\n",
      "train loss:0.8621611935587024\n",
      "train loss:0.901795619796979\n",
      "train loss:0.8752172155533199\n",
      "train loss:1.0154796511264712\n",
      "train loss:0.6693777013544043\n",
      "train loss:0.7949359907416255\n",
      "train loss:0.9516067092830898\n",
      "train loss:0.9788163539177346\n",
      "train loss:0.9267121916900252\n",
      "train loss:0.760199916692295\n",
      "train loss:0.919565962111009\n",
      "train loss:0.9370847963154282\n",
      "train loss:1.053221504878592\n",
      "train loss:0.8426050945910489\n",
      "train loss:0.8749083161842671\n",
      "train loss:0.6968525509525909\n",
      "train loss:0.8848811692822593\n",
      "train loss:0.853162193107849\n",
      "train loss:0.9792413598952467\n",
      "train loss:0.7316788030682584\n",
      "train loss:0.817633130526405\n",
      "train loss:0.8432148287732947\n",
      "train loss:0.9944883736347311\n",
      "train loss:0.9792904513986679\n",
      "train loss:0.9197581561384403\n",
      "train loss:0.9860419839703625\n",
      "train loss:1.0145431937655267\n",
      "train loss:0.8622236667380683\n",
      "train loss:0.8844087010657605\n",
      "train loss:0.8716037457412844\n",
      "train loss:0.8480055961078579\n",
      "train loss:0.7953684948730548\n",
      "train loss:0.8991936680594912\n",
      "train loss:0.9686826201919149\n",
      "train loss:0.7348059841153187\n",
      "train loss:0.8396780994921315\n",
      "train loss:1.0177282107297743\n",
      "train loss:0.9491854774293655\n",
      "train loss:0.8222135558285718\n",
      "train loss:0.9830267786240507\n",
      "train loss:0.8898037668993714\n",
      "train loss:0.9982248217110672\n",
      "train loss:0.6734752620977402\n",
      "train loss:0.9065391481605966\n",
      "train loss:1.0889613227431938\n",
      "train loss:0.9041853731753846\n",
      "train loss:0.8892069536087387\n",
      "train loss:0.866078049910109\n",
      "train loss:0.9663483900220083\n",
      "train loss:0.8832622993019583\n",
      "train loss:0.8171176029746963\n",
      "train loss:0.9090528517346637\n",
      "train loss:0.8421254213830558\n",
      "train loss:0.9763612677619914\n",
      "train loss:0.8392026050700738\n",
      "train loss:0.7755969218991122\n",
      "train loss:0.6877081793212017\n",
      "train loss:0.8646902629861186\n",
      "train loss:0.9279650849096701\n",
      "train loss:0.8768962670100743\n",
      "train loss:0.7592272294361648\n",
      "train loss:0.9345886102726166\n",
      "train loss:0.7572443569770212\n",
      "train loss:0.799138022228303\n",
      "train loss:0.8216523284354164\n",
      "train loss:0.9723097932831247\n",
      "train loss:0.8024657200964006\n",
      "train loss:1.038081896781122\n",
      "train loss:0.9605802388766682\n",
      "train loss:0.837159966386301\n",
      "train loss:0.8914071702440814\n",
      "train loss:0.9213404033739753\n",
      "train loss:0.8667471469155461\n",
      "train loss:0.78618677517106\n",
      "train loss:0.8034366001093458\n",
      "train loss:1.0143241924727762\n",
      "train loss:0.8731141759679314\n",
      "train loss:0.9163351246986058\n",
      "train loss:0.8255990010015831\n",
      "train loss:0.8177207372189585\n",
      "train loss:0.7653513913154503\n",
      "train loss:0.8940166133011733\n",
      "train loss:0.7380786057130312\n",
      "train loss:0.8208999389594076\n",
      "train loss:1.015697477577543\n",
      "train loss:0.7459494893964386\n",
      "train loss:0.8769964875976132\n",
      "train loss:0.8871851791032479\n",
      "train loss:1.0024288827368444\n",
      "train loss:0.9614805889397523\n",
      "train loss:0.7804357552996036\n",
      "train loss:0.9873285139690051\n",
      "train loss:0.7932453249503274\n",
      "train loss:0.758527203701442\n",
      "train loss:0.7230469042659154\n",
      "train loss:0.7551916036786805\n",
      "train loss:0.9064413531912081\n",
      "train loss:0.7686121023196801\n",
      "train loss:0.894569802596331\n",
      "train loss:0.9192543656731312\n",
      "train loss:0.8941160990506234\n",
      "train loss:0.892603884932551\n",
      "train loss:0.7649083962433543\n",
      "train loss:0.7974760495212118\n",
      "train loss:0.8483185760082683\n",
      "train loss:0.8128398208839747\n",
      "train loss:0.8950667034284333\n",
      "train loss:0.8556247942354088\n",
      "train loss:0.8386667653105002\n",
      "train loss:0.8917742746174937\n",
      "train loss:0.8430425550485363\n",
      "train loss:0.8225966241393037\n",
      "train loss:0.8147931467882513\n",
      "train loss:0.7836568406021982\n",
      "train loss:0.8468361907576677\n",
      "train loss:0.9338718043098188\n",
      "train loss:0.7047381702337786\n",
      "train loss:0.8593316037451397\n",
      "train loss:0.7734470339776485\n",
      "train loss:0.9460113820648749\n",
      "train loss:0.7390337881029448\n",
      "train loss:0.7419854948302629\n",
      "train loss:0.9726217135161029\n",
      "train loss:0.8163700717815301\n",
      "train loss:0.7817830417598144\n",
      "train loss:0.878571809137052\n",
      "train loss:0.8591676080054969\n",
      "train loss:0.842382872964799\n",
      "train loss:0.8695348327208431\n",
      "train loss:0.6795426417688364\n",
      "train loss:1.000505757970637\n",
      "train loss:0.8792723557286246\n",
      "train loss:0.6872480524453571\n",
      "train loss:0.8983309640327782\n",
      "train loss:0.8465036564846102\n",
      "train loss:0.9202839605858393\n",
      "train loss:0.7932207605650204\n",
      "train loss:0.84456892316453\n",
      "train loss:0.7367552248825815\n",
      "train loss:0.62506742096024\n",
      "train loss:0.9112005202141507\n",
      "train loss:0.9236364301259943\n",
      "train loss:0.851725991321689\n",
      "train loss:0.7947868994977427\n",
      "train loss:0.9397843893394393\n",
      "train loss:0.580512780443415\n",
      "train loss:0.8680579755526435\n",
      "train loss:0.7434388710994585\n",
      "train loss:0.8673286146204527\n",
      "train loss:0.8601258431189109\n",
      "train loss:1.0006404788810606\n",
      "train loss:0.7965926270778\n",
      "train loss:0.882310814834716\n",
      "=== epoch:14, train acc:0.999, test acc:0.991 ===\n",
      "train loss:0.8033540103984527\n",
      "train loss:0.8662373931843885\n",
      "train loss:0.7716840212173942\n",
      "train loss:0.9522155057475362\n",
      "train loss:0.8277775428260848\n",
      "train loss:0.7965331288955408\n",
      "train loss:0.8879919510998278\n",
      "train loss:0.8505557636417735\n",
      "train loss:0.8666546407342705\n",
      "train loss:0.8869453015297952\n",
      "train loss:1.0204658557697874\n",
      "train loss:0.9923699876825612\n",
      "train loss:0.7158761902340768\n",
      "train loss:0.8126521271185045\n",
      "train loss:1.0107615868935742\n",
      "train loss:0.9185294958396194\n",
      "train loss:0.9852805782793653\n",
      "train loss:0.933562657896066\n",
      "train loss:0.7877245285176016\n",
      "train loss:0.8666286356780065\n",
      "train loss:0.7715528840375606\n",
      "train loss:0.7972132705226851\n",
      "train loss:0.8299199639544298\n",
      "train loss:0.9203821537770323\n",
      "train loss:0.9707596027846053\n",
      "train loss:0.842829906675685\n",
      "train loss:0.9671268794008935\n",
      "train loss:0.7533637124837785\n",
      "train loss:0.979744583184961\n",
      "train loss:0.9437137900746565\n",
      "train loss:0.6927904325596179\n",
      "train loss:0.7944726073703143\n",
      "train loss:0.7633013236518306\n",
      "train loss:0.8568640791025718\n",
      "train loss:0.881765542270729\n",
      "train loss:0.915837533934222\n",
      "train loss:0.8972796767794174\n",
      "train loss:0.7214073473375943\n",
      "train loss:0.8817567208668222\n",
      "train loss:1.1146061588767557\n",
      "train loss:0.8874550081750086\n",
      "train loss:0.8805641609072774\n",
      "train loss:0.8727162559713763\n",
      "train loss:0.8329226557333057\n",
      "train loss:0.7900059126571253\n",
      "train loss:1.1099450861691513\n",
      "train loss:0.7573597632774102\n",
      "train loss:0.9676042939566414\n",
      "train loss:0.8635983552754429\n",
      "train loss:1.0301498445744393\n",
      "train loss:0.8753104567731191\n",
      "train loss:0.865821393655568\n",
      "train loss:0.8914362888816888\n",
      "train loss:0.8470960507844703\n",
      "train loss:0.9617329408583314\n",
      "train loss:0.8182249276172988\n",
      "train loss:0.9263833706527415\n",
      "train loss:0.8901097954698999\n",
      "train loss:0.8448237275955774\n",
      "train loss:0.9598729183820918\n",
      "train loss:0.8794785210375662\n",
      "train loss:0.9170430413439047\n",
      "train loss:0.7660043053478651\n",
      "train loss:0.8712776992157235\n",
      "train loss:0.8926959687394854\n",
      "train loss:0.9964009153240369\n",
      "train loss:0.5961446346830204\n",
      "train loss:0.9362805423958619\n",
      "train loss:1.0267364664763217\n",
      "train loss:0.8241486936582824\n",
      "train loss:0.9676346956815778\n",
      "train loss:1.1050590748308413\n",
      "train loss:0.8981710177981259\n",
      "train loss:0.7934509108672403\n",
      "train loss:0.8031714746631531\n",
      "train loss:0.803235518056806\n",
      "train loss:0.9862373434314422\n",
      "train loss:0.752672282476532\n",
      "train loss:0.7760497103465496\n",
      "train loss:0.7611970138130296\n",
      "train loss:0.9010133579002262\n",
      "train loss:0.993371274192403\n",
      "train loss:0.8579758056592133\n",
      "train loss:0.8220362670047305\n",
      "train loss:0.9151234134768528\n",
      "train loss:0.8687253277482934\n",
      "train loss:0.7845786188906422\n",
      "train loss:0.8163690299261578\n",
      "train loss:0.7320721942774874\n",
      "train loss:0.847428189701615\n",
      "train loss:0.6737952687437341\n",
      "train loss:0.8921920622083579\n",
      "train loss:0.9272503824035411\n",
      "train loss:0.9947522518430199\n",
      "train loss:1.0136799964707164\n",
      "train loss:1.042113083109246\n",
      "train loss:0.7697028957751594\n",
      "train loss:0.766624093261456\n",
      "train loss:0.8773708155184903\n",
      "train loss:0.8088264215434725\n",
      "train loss:0.8220468469117174\n",
      "train loss:0.8939880435841462\n",
      "train loss:0.780301532378486\n",
      "train loss:0.8880900260197043\n",
      "train loss:0.737997084090922\n",
      "train loss:0.9126535999915313\n",
      "train loss:0.7819695299458419\n",
      "train loss:0.7072818369773386\n",
      "train loss:1.0085237211031186\n",
      "train loss:0.7532436534486286\n",
      "train loss:0.7694326593460136\n",
      "train loss:0.7777638330963843\n",
      "train loss:0.7710379877447545\n",
      "train loss:0.7283787111336625\n",
      "train loss:0.8591434227174902\n",
      "train loss:0.7042099857946958\n",
      "train loss:0.8978239432267736\n",
      "train loss:0.8868735755931505\n",
      "train loss:0.8459373102837404\n",
      "train loss:0.8530673890613103\n",
      "train loss:0.7719181330589425\n",
      "train loss:0.7554470017894568\n",
      "train loss:0.9406766506336234\n",
      "train loss:0.9754278689405231\n",
      "train loss:0.815105304340857\n",
      "train loss:0.8041413493868386\n",
      "train loss:0.8133531548889485\n",
      "train loss:0.8864393388236548\n",
      "train loss:0.7938494637498015\n",
      "train loss:0.7620337453633894\n",
      "train loss:0.8258672039366349\n",
      "train loss:0.9027656608722339\n",
      "train loss:0.7848777375929479\n",
      "train loss:0.9837308568720516\n",
      "train loss:0.9654185899053556\n",
      "train loss:0.7620959506405026\n",
      "train loss:0.8346515302255787\n",
      "train loss:0.9657137478357117\n",
      "train loss:0.8246477327195916\n",
      "train loss:0.9270725876989648\n",
      "train loss:0.9245060745623358\n",
      "train loss:0.9449660088112815\n",
      "train loss:0.6938505434518356\n",
      "train loss:0.9333020934188557\n",
      "train loss:0.8561916875632629\n",
      "train loss:0.8330308949014659\n",
      "train loss:0.9083873267600915\n",
      "train loss:0.7913595142907337\n",
      "train loss:0.9222560447779847\n",
      "train loss:0.9884017360948535\n",
      "train loss:0.8630705105713848\n",
      "train loss:0.8794306999213475\n",
      "train loss:0.9115681725412967\n",
      "train loss:1.0123699699539424\n",
      "train loss:0.7009452603029281\n",
      "train loss:0.8016259836434287\n",
      "train loss:0.869487811288899\n",
      "train loss:0.9615014687768315\n",
      "train loss:0.8021560400231758\n",
      "train loss:0.7000010734184489\n",
      "train loss:0.8318171779501278\n",
      "train loss:0.8683976398096809\n",
      "train loss:0.9112499577656323\n",
      "train loss:0.8832846670709324\n",
      "train loss:1.0204948013656958\n",
      "train loss:1.0611557784405588\n",
      "train loss:0.9258406043636572\n",
      "train loss:0.835009069211528\n",
      "train loss:0.7889032800802857\n",
      "train loss:0.8374389429612563\n",
      "train loss:0.9389187363471337\n",
      "train loss:0.7593965957262394\n",
      "train loss:0.8417807456646229\n",
      "train loss:0.8249676470805184\n",
      "train loss:0.9052889062654071\n",
      "train loss:0.8751240878303712\n",
      "train loss:0.7780088901682346\n",
      "train loss:0.8627767039639578\n",
      "train loss:0.7876222297655149\n",
      "train loss:0.7190715836831749\n",
      "train loss:0.9426439846672746\n",
      "train loss:0.7989777752007292\n",
      "train loss:0.883509210601135\n",
      "train loss:0.90830753346126\n",
      "train loss:0.9431425561529743\n",
      "train loss:0.7870713757190064\n",
      "train loss:0.9082872704765275\n",
      "train loss:1.012843721917469\n",
      "train loss:1.017014520498205\n",
      "train loss:0.9373829650131437\n",
      "train loss:0.9238070090726782\n",
      "train loss:0.8418423465486887\n",
      "train loss:0.7914003226708324\n",
      "train loss:0.8656037249854235\n",
      "train loss:0.7511944381941695\n",
      "train loss:0.8277113977488187\n",
      "train loss:0.6656049314861063\n",
      "train loss:0.9002788427590961\n",
      "train loss:0.768166744748843\n",
      "train loss:0.9986945870984537\n",
      "train loss:0.9578638221358026\n",
      "train loss:0.7510634811025746\n",
      "train loss:0.8132023446174231\n",
      "train loss:0.9112446158746969\n",
      "train loss:0.950216200280436\n",
      "train loss:0.817432547510271\n",
      "train loss:0.7084423427805426\n",
      "train loss:0.8760804589857066\n",
      "train loss:0.8683390222891696\n",
      "train loss:0.9309921614298037\n",
      "train loss:0.7868873465948708\n",
      "train loss:0.830340493503933\n",
      "train loss:0.9491814314995836\n",
      "train loss:0.9324226978122908\n",
      "train loss:0.8822659023655127\n",
      "train loss:0.9027063067003519\n",
      "train loss:1.0242485361984792\n",
      "train loss:1.0158200884797637\n",
      "train loss:0.9045941877967857\n",
      "train loss:0.9589755255934739\n",
      "train loss:0.8004143275433927\n",
      "train loss:0.872083702324572\n",
      "train loss:0.8073925403251812\n",
      "train loss:0.846832430591498\n",
      "train loss:0.7621340560332277\n",
      "train loss:0.8957051579481993\n",
      "train loss:0.8649306081890535\n",
      "train loss:0.8292735998515532\n",
      "train loss:0.7250339778334184\n",
      "train loss:0.8114328426898626\n",
      "train loss:0.9167707744473256\n",
      "train loss:0.8296039339508104\n",
      "train loss:0.8634462110727309\n",
      "train loss:0.6920491115962857\n",
      "train loss:0.8963327600069202\n",
      "train loss:0.9327443154604067\n",
      "train loss:0.9963647751287372\n",
      "train loss:0.7790742505615854\n",
      "train loss:0.6938769826884696\n",
      "train loss:0.6894221418360245\n",
      "train loss:0.8372715526702837\n",
      "train loss:0.7033724633428722\n",
      "train loss:0.8194979207338016\n",
      "train loss:0.966675686684695\n",
      "train loss:1.0348707559626957\n",
      "train loss:0.7470438686808226\n",
      "train loss:0.8644811395428769\n",
      "train loss:0.9070429679762277\n",
      "train loss:0.8439246496450038\n",
      "train loss:0.9018047461362498\n",
      "train loss:0.7900896586460884\n",
      "train loss:0.8081350394872647\n",
      "train loss:0.7538555127352342\n",
      "train loss:0.7489038362650285\n",
      "train loss:1.0036044777193156\n",
      "train loss:0.999194874808053\n",
      "train loss:0.8462820486455326\n",
      "train loss:0.8241768894546473\n",
      "train loss:0.9222731173247797\n",
      "train loss:0.9562244409296629\n",
      "train loss:0.9168400012731058\n",
      "train loss:0.7773253609783743\n",
      "train loss:0.8411112757993603\n",
      "train loss:0.7682185000630168\n",
      "train loss:0.9250022687775757\n",
      "train loss:0.6431435320006348\n",
      "train loss:0.8426880774164681\n",
      "train loss:0.904732277506401\n",
      "train loss:0.8822302225091299\n",
      "train loss:0.9129469504594175\n",
      "train loss:0.8603055323429015\n",
      "train loss:0.7389767192294971\n",
      "train loss:0.8130292351362062\n",
      "train loss:0.8840297529231147\n",
      "train loss:0.8464900749121024\n",
      "train loss:0.9322874522158703\n",
      "train loss:0.8564924768789471\n",
      "train loss:0.7487704754885314\n",
      "train loss:0.8515377957032446\n",
      "train loss:0.9066081535094969\n",
      "train loss:0.715105231989289\n",
      "train loss:0.848040558353761\n",
      "train loss:0.8828075137523099\n",
      "train loss:0.8241218508476258\n",
      "train loss:0.8979955727378127\n",
      "train loss:0.7123505083132831\n",
      "train loss:0.8723866335622086\n",
      "train loss:0.848051670795124\n",
      "train loss:0.917020448564906\n",
      "train loss:0.7375048270409773\n",
      "train loss:0.825279338516523\n",
      "train loss:0.8566790217552448\n",
      "train loss:0.9283433168773407\n",
      "train loss:0.8984868216452778\n",
      "train loss:0.6905057196038881\n",
      "train loss:0.8866450495161275\n",
      "train loss:1.0199920915345213\n",
      "train loss:0.7542287488418522\n",
      "train loss:0.8925064113803208\n",
      "train loss:0.7216592895234075\n",
      "train loss:0.9004472750182916\n",
      "train loss:0.899567260867064\n",
      "train loss:0.7212272618615745\n",
      "train loss:0.925675402104694\n",
      "train loss:0.7093645777001479\n",
      "train loss:0.905859015263368\n",
      "train loss:0.8157447658858479\n",
      "train loss:0.9858536389970376\n",
      "train loss:0.9756712140001076\n",
      "train loss:0.6701870153419199\n",
      "train loss:1.2020789345213463\n",
      "train loss:0.9096628804276063\n",
      "train loss:0.8047841921096246\n",
      "train loss:0.871777745793857\n",
      "train loss:0.897480601769557\n",
      "train loss:0.8391721401588679\n",
      "train loss:0.6988249322279281\n",
      "train loss:0.8070779240631523\n",
      "train loss:1.0418899559498676\n",
      "train loss:0.7372834078661569\n",
      "train loss:0.8315160103439782\n",
      "train loss:0.8166520054501089\n",
      "train loss:0.8753577493311223\n",
      "train loss:0.9647687513627673\n",
      "train loss:0.9463738007741138\n",
      "train loss:0.8767479080057781\n",
      "train loss:0.9352614136377909\n",
      "train loss:0.893270159797937\n",
      "train loss:0.8324289740921299\n",
      "train loss:0.91070992195101\n",
      "train loss:0.8206460973389423\n",
      "train loss:0.638557395727507\n",
      "train loss:0.8868487501514504\n",
      "train loss:0.8995199778609596\n",
      "train loss:0.8415522287658994\n",
      "train loss:0.7714043881370055\n",
      "train loss:0.8279282827121819\n",
      "train loss:0.789565672010622\n",
      "train loss:0.9202026083947631\n",
      "train loss:0.9409794842958576\n",
      "train loss:0.8528244585793384\n",
      "train loss:0.699263523445996\n",
      "train loss:0.8962690302882541\n",
      "train loss:0.8747874132098518\n",
      "train loss:0.8986267284547167\n",
      "train loss:0.8558973525909127\n",
      "train loss:0.7870724740141419\n",
      "train loss:0.9042145071240637\n",
      "train loss:0.6486189586196309\n",
      "train loss:0.9972872268998519\n",
      "train loss:0.7597877584501788\n",
      "train loss:0.757459647330187\n",
      "train loss:0.6791745108745474\n",
      "train loss:0.817910008579241\n",
      "train loss:0.8226052704758089\n",
      "train loss:0.9803640033392677\n",
      "train loss:0.9299018546371481\n",
      "train loss:0.9037329337103998\n",
      "train loss:0.9079257446678655\n",
      "train loss:0.8393389265898429\n",
      "train loss:0.8345504133533906\n",
      "train loss:1.0023830093985369\n",
      "train loss:0.8667145236486236\n",
      "train loss:0.9851721891767455\n",
      "train loss:0.6572659311083204\n",
      "train loss:0.9350763213536177\n",
      "train loss:0.8541415575252392\n",
      "train loss:0.8505949282389915\n",
      "train loss:0.7968642848179635\n",
      "train loss:0.8247314579756265\n",
      "train loss:0.9767823826177292\n",
      "train loss:1.0609207643263054\n",
      "train loss:0.8791082222847649\n",
      "train loss:0.8365292362489163\n",
      "train loss:0.9265222818521314\n",
      "train loss:1.0436499824797087\n",
      "train loss:0.8863044966983772\n",
      "train loss:0.9820421670485082\n",
      "train loss:0.9089748847472551\n",
      "train loss:0.9163317316399199\n",
      "train loss:0.6994366185815112\n",
      "train loss:0.9314941453756282\n",
      "train loss:0.868493645760635\n",
      "train loss:0.7859474364523138\n",
      "train loss:0.7677266354575307\n",
      "train loss:0.8214162843241453\n",
      "train loss:0.8673576581309769\n",
      "train loss:0.86219787171418\n",
      "train loss:0.8631244765585264\n",
      "train loss:0.9194105662389462\n",
      "train loss:0.9298661433591097\n",
      "train loss:0.9759858318899362\n",
      "train loss:0.9286093003869325\n",
      "train loss:0.8228894543458045\n",
      "train loss:0.837424992047909\n",
      "train loss:0.9262060203205403\n",
      "train loss:0.8407883808773253\n",
      "train loss:0.7796328701786202\n",
      "train loss:0.7825212590414955\n",
      "train loss:0.7714870940993305\n",
      "train loss:0.8122979361233266\n",
      "train loss:0.7158973546376615\n",
      "train loss:0.8320646456713482\n",
      "train loss:0.8165306624075518\n",
      "train loss:0.8268798648511063\n",
      "train loss:0.8264968074738358\n",
      "train loss:0.8194508481478898\n",
      "train loss:0.8795020817822017\n",
      "train loss:0.9711254182234615\n",
      "train loss:1.0260187046769575\n",
      "train loss:0.8678786326350449\n",
      "train loss:0.9145758417812029\n",
      "train loss:0.8118437382489994\n",
      "train loss:0.8618352310425342\n",
      "train loss:0.7098478595237186\n",
      "train loss:0.9393581339605401\n",
      "train loss:0.8335567216611015\n",
      "train loss:1.0275543312166158\n",
      "train loss:0.9763751894431019\n",
      "train loss:0.9081085052316318\n",
      "train loss:0.8813491625417721\n",
      "train loss:0.7332217066038134\n",
      "train loss:0.7660474921187601\n",
      "train loss:0.7900586149772135\n",
      "train loss:0.9823135760830184\n",
      "train loss:0.8919016604213843\n",
      "train loss:0.9250387853335091\n",
      "train loss:0.812332889504921\n",
      "train loss:0.859437239197686\n",
      "train loss:0.828780120381094\n",
      "train loss:0.821104296672494\n",
      "train loss:0.8346416914002787\n",
      "train loss:1.0202263621883618\n",
      "train loss:0.766536017145992\n",
      "train loss:0.8288641185778411\n",
      "train loss:1.0042535932937613\n",
      "train loss:0.8244762953821362\n",
      "train loss:0.7945164783232973\n",
      "train loss:0.8223905841972009\n",
      "train loss:0.9504467400221143\n",
      "train loss:0.8314281765756266\n",
      "train loss:0.7392021782746115\n",
      "train loss:0.7467214326249207\n",
      "train loss:0.9427104772813293\n",
      "train loss:0.9549970311301549\n",
      "train loss:1.0836936024540162\n",
      "train loss:0.9001286801653966\n",
      "train loss:0.7796415346234384\n",
      "train loss:0.819528017268469\n",
      "train loss:0.8258105422947534\n",
      "train loss:0.8654643142159951\n",
      "train loss:0.9477339339036182\n",
      "train loss:0.8673930396832782\n",
      "train loss:0.7991021400903489\n",
      "train loss:0.9037592287234288\n",
      "train loss:0.9881159092081352\n",
      "train loss:0.7930547502564125\n",
      "train loss:0.785923098212748\n",
      "train loss:0.7741164169676021\n",
      "train loss:0.9594106780993034\n",
      "train loss:0.9442481994332134\n",
      "train loss:0.8973022447027695\n",
      "train loss:0.8413440079411393\n",
      "train loss:0.8798994129520912\n",
      "train loss:0.8355485876913291\n",
      "train loss:0.9254289411544854\n",
      "train loss:0.7674901553265431\n",
      "train loss:0.8813336762374903\n",
      "train loss:0.9494375866955542\n",
      "train loss:0.8500764113132222\n",
      "train loss:1.0116688508625125\n",
      "train loss:0.8459390609865509\n",
      "train loss:0.8181078777857688\n",
      "train loss:0.8774376543174977\n",
      "train loss:0.8096663884257729\n",
      "train loss:0.6917284356180938\n",
      "train loss:0.8537070456191518\n",
      "train loss:0.759811707156512\n",
      "train loss:0.8128776009730171\n",
      "train loss:0.913447897059116\n",
      "train loss:0.8993081175234954\n",
      "train loss:0.840249532517983\n",
      "train loss:0.7492995688174294\n",
      "train loss:0.7340647072471698\n",
      "train loss:0.7553820759873884\n",
      "train loss:0.8202110526410143\n",
      "train loss:1.0810487312598396\n",
      "train loss:0.8738078788209899\n",
      "train loss:0.8201520948312528\n",
      "train loss:0.8931529555647224\n",
      "train loss:0.9164891351195213\n",
      "train loss:0.8900121453211337\n",
      "train loss:0.8333756988832011\n",
      "train loss:0.8206524906493691\n",
      "train loss:0.77481396481564\n",
      "train loss:0.761710566536051\n",
      "train loss:0.9215296069109814\n",
      "train loss:0.842236198079162\n",
      "train loss:0.8981112537815537\n",
      "train loss:0.9799571912959409\n",
      "train loss:0.9610668546987656\n",
      "train loss:0.9188458275145929\n",
      "train loss:0.7553712323592124\n",
      "train loss:0.8768791397232389\n",
      "train loss:0.9523399235543285\n",
      "train loss:1.05471160325386\n",
      "train loss:0.6414895301469872\n",
      "train loss:0.7546106966663598\n",
      "train loss:0.851043953224889\n",
      "train loss:1.000255614184607\n",
      "train loss:0.826862381159125\n",
      "train loss:0.8489402965739573\n",
      "train loss:0.9055837791756319\n",
      "train loss:0.709316672197271\n",
      "train loss:0.7768812622623138\n",
      "train loss:0.7048284980895164\n",
      "train loss:0.7005849067522816\n",
      "train loss:0.9372071423423048\n",
      "train loss:1.0986032573437203\n",
      "train loss:1.0256608543318189\n",
      "train loss:0.7899543430819124\n",
      "train loss:0.7973325186167949\n",
      "train loss:0.9800958583816888\n",
      "train loss:0.7886815260148983\n",
      "train loss:0.6974249502888975\n",
      "train loss:0.7999133015663409\n",
      "train loss:0.9717432864963181\n",
      "train loss:0.752620550476521\n",
      "train loss:0.7467001272652098\n",
      "train loss:0.7468832078981406\n",
      "train loss:0.8080303030824209\n",
      "train loss:0.8910516028685622\n",
      "train loss:0.8190765626118592\n",
      "train loss:0.8901247595593164\n",
      "train loss:0.7562188344886249\n",
      "train loss:0.9141753540910351\n",
      "train loss:0.8375492303974456\n",
      "train loss:0.7289524663968345\n",
      "train loss:0.7496257141123402\n",
      "train loss:0.9507520125142538\n",
      "train loss:1.0780122648168238\n",
      "train loss:1.0353811286388044\n",
      "train loss:0.8825774357808703\n",
      "train loss:0.6953997517117791\n",
      "train loss:0.8143562988276573\n",
      "train loss:0.8986359942116002\n",
      "train loss:0.7133018415544925\n",
      "train loss:0.8167191207633472\n",
      "train loss:0.9187367994340727\n",
      "train loss:0.7609536153762256\n",
      "train loss:0.8234878612963089\n",
      "train loss:0.7076232812760809\n",
      "train loss:0.8318361221368776\n",
      "train loss:0.8621334646127401\n",
      "train loss:0.8583174384990349\n",
      "train loss:0.8269863705267614\n",
      "train loss:1.0113553264846467\n",
      "train loss:0.8812828065607744\n",
      "train loss:0.8906069883895235\n",
      "train loss:0.8716178159401656\n",
      "train loss:0.8619013986050998\n",
      "train loss:0.972846583118553\n",
      "train loss:0.7855337547271403\n",
      "train loss:0.9047155200166671\n",
      "train loss:0.7859626665424545\n",
      "train loss:0.724416518895479\n",
      "train loss:0.7303930707722783\n",
      "train loss:0.8955882812002105\n",
      "train loss:1.005624933414839\n",
      "train loss:0.8857671239737389\n",
      "train loss:0.7858173567759152\n",
      "train loss:0.9096443142816071\n",
      "train loss:0.8323914455127476\n",
      "train loss:0.851269017011943\n",
      "train loss:0.9273753389566547\n",
      "train loss:0.9134705730540724\n",
      "train loss:0.861375569402705\n",
      "train loss:0.7748177616753362\n",
      "train loss:0.8624148199744903\n",
      "train loss:1.0005221755016234\n",
      "train loss:0.8435855428014257\n",
      "train loss:0.8565240189732937\n",
      "train loss:0.7910546599496752\n",
      "train loss:0.7590730984417879\n",
      "train loss:0.8553892562139847\n",
      "train loss:0.7097581808655599\n",
      "train loss:0.9248687664139067\n",
      "train loss:0.9902767587198287\n",
      "train loss:0.8327247805845207\n",
      "train loss:0.7479496495123109\n",
      "train loss:0.895781877932218\n",
      "train loss:0.8817372555825314\n",
      "train loss:0.8648760062951459\n",
      "train loss:0.9832260237604592\n",
      "train loss:0.7571266743621072\n",
      "train loss:0.868231479805105\n",
      "train loss:0.8161373333045043\n",
      "train loss:0.9190693511760063\n",
      "train loss:0.8973259532550284\n",
      "train loss:0.9557978532057382\n",
      "=== epoch:15, train acc:0.996, test acc:0.99 ===\n",
      "train loss:0.8366046642681668\n",
      "train loss:0.8869230640395657\n",
      "train loss:0.8383786469841952\n",
      "train loss:0.8802233300151419\n",
      "train loss:0.8521526051212136\n",
      "train loss:0.8192954153668258\n",
      "train loss:0.8418904212972511\n",
      "train loss:0.8148774781171155\n",
      "train loss:0.9853386744408694\n",
      "train loss:0.7390929537058598\n",
      "train loss:0.998347994194304\n",
      "train loss:0.949976252609543\n",
      "train loss:0.8377061002457075\n",
      "train loss:0.885592251912781\n",
      "train loss:0.7851113604879939\n",
      "train loss:0.7997827060794481\n",
      "train loss:0.8080113058470725\n",
      "train loss:0.9022504778218422\n",
      "train loss:1.005636738182294\n",
      "train loss:0.808157012735751\n",
      "train loss:0.9327868839187097\n",
      "train loss:0.9125241233104227\n",
      "train loss:0.7992225859490094\n",
      "train loss:0.9133551779492083\n",
      "train loss:0.820156895803179\n",
      "train loss:0.7139871589298258\n",
      "train loss:0.8026633833391738\n",
      "train loss:0.851950430655545\n",
      "train loss:0.8148914353873812\n",
      "train loss:0.8214026139171702\n",
      "train loss:0.8396962958308621\n",
      "train loss:0.8698188233879104\n",
      "train loss:0.7393807290604996\n",
      "train loss:0.8864471067701616\n",
      "train loss:0.9221963794705289\n",
      "train loss:1.016029001804282\n",
      "train loss:0.8960544007311977\n",
      "train loss:0.858299590313507\n",
      "train loss:0.9603471026464441\n",
      "train loss:0.7685974062120688\n",
      "train loss:1.139698784154498\n",
      "train loss:0.8214292462427101\n",
      "train loss:0.9112125391234316\n",
      "train loss:0.7568101068978831\n",
      "train loss:0.8671142710092786\n",
      "train loss:0.7946412572920228\n",
      "train loss:0.7633482244776091\n",
      "train loss:0.8123202528443136\n",
      "train loss:0.872862710714998\n",
      "train loss:0.8794421049434084\n",
      "train loss:0.886234830534768\n",
      "train loss:0.9024439136781851\n",
      "train loss:0.7489525372340742\n",
      "train loss:0.8625931882390971\n",
      "train loss:0.8484538808782027\n",
      "train loss:0.9395440746139783\n",
      "train loss:0.8487301565581375\n",
      "train loss:0.790870651527333\n",
      "train loss:0.8348534581296798\n",
      "train loss:0.9194305262622915\n",
      "train loss:0.8082037508057398\n",
      "train loss:0.8751266802855934\n",
      "train loss:0.8539478236851449\n",
      "train loss:0.8508819559814405\n",
      "train loss:0.8699840375162844\n",
      "train loss:0.7736683641297156\n",
      "train loss:0.8403629871340182\n",
      "train loss:0.8117610495437103\n",
      "train loss:0.8350135120851019\n",
      "train loss:0.7785079974455651\n",
      "train loss:0.8097544255531415\n",
      "train loss:0.7082851735020306\n",
      "train loss:0.8813423634078451\n",
      "train loss:0.965410435869714\n",
      "train loss:0.7848572706283824\n",
      "train loss:0.8209537445779885\n",
      "train loss:0.9141864906942588\n",
      "train loss:0.8110981252843428\n",
      "train loss:0.8914866031379723\n",
      "train loss:0.9455317735127763\n",
      "train loss:0.9044744944034917\n",
      "train loss:0.9840965427400189\n",
      "train loss:0.9812084516254252\n",
      "train loss:0.7254877540848362\n",
      "train loss:0.888224350215223\n",
      "train loss:0.801750990569695\n",
      "train loss:0.853323222126418\n",
      "train loss:0.863050972585277\n",
      "train loss:0.8684378081797138\n",
      "train loss:0.9137896517480972\n",
      "train loss:0.8768267937831119\n",
      "train loss:0.9753189771471825\n",
      "train loss:0.8669573453592966\n",
      "train loss:1.0039299216257223\n",
      "train loss:0.7104992105085235\n",
      "train loss:0.927663564777458\n",
      "train loss:0.8206704615621375\n",
      "train loss:0.9328831984638296\n",
      "train loss:1.0316758618405844\n",
      "train loss:0.6611945493986147\n",
      "train loss:0.8583597845305843\n",
      "train loss:0.9565435040611173\n",
      "train loss:0.8311009939821018\n",
      "train loss:0.85418635677593\n",
      "train loss:0.8871138379087078\n",
      "train loss:0.7460763801589947\n",
      "train loss:0.9798080439994895\n",
      "train loss:0.7632504233032862\n",
      "train loss:0.7492120554617057\n",
      "train loss:0.6873486911818985\n",
      "train loss:0.7814456725745829\n",
      "train loss:0.9442275104200064\n",
      "train loss:0.8348425464919812\n",
      "train loss:0.9182224033817394\n",
      "train loss:1.1218731577770171\n",
      "train loss:0.9747413828758126\n",
      "train loss:0.8812019827160467\n",
      "train loss:0.9829366331911881\n",
      "train loss:0.7037223991067966\n",
      "train loss:0.8601896082647942\n",
      "train loss:0.9217922418771934\n",
      "train loss:1.0344417634089618\n",
      "train loss:0.8365990865921374\n",
      "train loss:0.8208659808510957\n",
      "train loss:0.8910276535476699\n",
      "train loss:1.0454768986031635\n",
      "train loss:0.8774508694249187\n",
      "train loss:0.698799123945857\n",
      "train loss:0.8708309568596099\n",
      "train loss:0.9676073447333464\n",
      "train loss:0.8566241418002172\n",
      "train loss:0.8989753890965049\n",
      "train loss:0.7010268598607342\n",
      "train loss:0.9830564275344789\n",
      "train loss:0.6805828058425627\n",
      "train loss:0.7733466416449688\n",
      "train loss:0.7035094295240836\n",
      "train loss:0.8686095406311377\n",
      "train loss:0.8103904831455508\n",
      "train loss:0.793334932975099\n",
      "train loss:0.9570196969561002\n",
      "train loss:0.9652406084052393\n",
      "train loss:0.8482250842843158\n",
      "train loss:0.9083162756057781\n",
      "train loss:1.0012098055178742\n",
      "train loss:0.8887296047344365\n",
      "train loss:1.028908932352786\n",
      "train loss:1.0135757599890898\n",
      "train loss:1.0235775741914865\n",
      "train loss:1.0366339378224234\n",
      "train loss:0.8320226982514843\n",
      "train loss:0.7797979293709492\n",
      "train loss:0.8076682728740843\n",
      "train loss:0.9112739798205274\n",
      "train loss:0.8311697982604455\n",
      "train loss:0.8963836957466684\n",
      "train loss:0.8939936452090796\n",
      "train loss:1.0171135595904526\n",
      "train loss:0.9115165938409188\n",
      "train loss:0.7446037701172586\n",
      "train loss:0.7951874560791811\n",
      "train loss:0.6525261371270663\n",
      "train loss:0.7994475796240699\n",
      "train loss:0.872650336608325\n",
      "train loss:0.9137119849957656\n",
      "train loss:0.8492272893496995\n",
      "train loss:0.8370475271880065\n",
      "train loss:0.9640431143729628\n",
      "train loss:0.7372918734808519\n",
      "train loss:0.8510851801139028\n",
      "train loss:0.9866359212414877\n",
      "train loss:0.6499982121504445\n",
      "train loss:0.7197908898317423\n",
      "train loss:0.6702454434520214\n",
      "train loss:0.9795684306617874\n",
      "train loss:0.9396925566604374\n",
      "train loss:0.9548912541694782\n",
      "train loss:1.1013858934052208\n",
      "train loss:0.8329568459289401\n",
      "train loss:0.9110654861238597\n",
      "train loss:0.8153156636890819\n",
      "train loss:0.8489603235365777\n",
      "train loss:0.933409091473959\n",
      "train loss:0.7427018127755093\n",
      "train loss:0.8595085745555922\n",
      "train loss:0.9132303439775921\n",
      "train loss:0.8562107024669915\n",
      "train loss:0.9391483481778472\n",
      "train loss:0.9565987464505109\n",
      "train loss:0.9426883590292675\n",
      "train loss:0.8271598168990992\n",
      "train loss:0.774786725088348\n",
      "train loss:0.8618175622470331\n",
      "train loss:0.7286652416459097\n",
      "train loss:0.6759030265878068\n",
      "train loss:0.812615947309246\n",
      "train loss:0.824057221292357\n",
      "train loss:1.0193529586490013\n",
      "train loss:0.8922509135538629\n",
      "train loss:0.8585846187592643\n",
      "train loss:0.831416447189708\n",
      "train loss:0.8565463252242286\n",
      "train loss:0.8318112736333895\n",
      "train loss:0.9594415297305525\n",
      "train loss:0.9017579561686161\n",
      "train loss:0.8599054935331364\n",
      "train loss:0.8774386335170504\n",
      "train loss:0.8332382492789522\n",
      "train loss:0.829862776035711\n",
      "train loss:0.8228883724713276\n",
      "train loss:0.8645703840925623\n",
      "train loss:0.8801540552454601\n",
      "train loss:0.8155624498139455\n",
      "train loss:0.8380177264729208\n",
      "train loss:0.7572905263154142\n",
      "train loss:0.7508079961164136\n",
      "train loss:0.919072043735709\n",
      "train loss:0.9431956999218508\n",
      "train loss:0.8618671609720616\n",
      "train loss:0.9309448166333698\n",
      "train loss:0.7823114076329288\n",
      "train loss:0.9445071135036259\n",
      "train loss:0.8970339962941932\n",
      "train loss:0.8514905623351717\n",
      "train loss:0.9790912697111095\n",
      "train loss:0.9171855607637452\n",
      "train loss:0.9163930606776178\n",
      "train loss:0.9676535783346216\n",
      "train loss:0.9006595069228891\n",
      "train loss:0.7591186742720457\n",
      "train loss:0.9302610161787167\n",
      "train loss:0.9242195109915059\n",
      "train loss:0.9194998860257203\n",
      "train loss:0.8505993346950466\n",
      "train loss:0.8155798153579339\n",
      "train loss:0.8381064781300492\n",
      "train loss:0.8162302912228037\n",
      "train loss:0.8600994397239081\n",
      "train loss:0.8778761098788739\n",
      "train loss:0.8487460628532203\n",
      "train loss:1.0403593911967688\n",
      "train loss:0.7499489286795742\n",
      "train loss:1.0516563482950125\n",
      "train loss:0.9095924758090255\n",
      "train loss:0.8524754986319446\n",
      "train loss:0.8898608102358361\n",
      "train loss:0.9256835324527276\n",
      "train loss:0.765703428231016\n",
      "train loss:0.8549974106558542\n",
      "train loss:0.7525542198579009\n",
      "train loss:0.9495249149890127\n",
      "train loss:0.8244188111045352\n",
      "train loss:0.7927617839664876\n",
      "train loss:0.8936047495327942\n",
      "train loss:0.7179423319737935\n",
      "train loss:0.8066762762441122\n",
      "train loss:0.910575497175245\n",
      "train loss:0.9776745232840297\n",
      "train loss:0.9916904067131503\n",
      "train loss:0.8184989382664096\n",
      "train loss:0.8167259030929261\n",
      "train loss:0.7886771942345457\n",
      "train loss:0.7733852502431634\n",
      "train loss:0.7918697456193193\n",
      "train loss:0.8168899912966063\n",
      "train loss:0.871516953758167\n",
      "train loss:0.9480171224244881\n",
      "train loss:0.9019929782965026\n",
      "train loss:0.857707276258606\n",
      "train loss:0.8441557131402856\n",
      "train loss:0.8807596421567451\n",
      "train loss:0.8150689158227175\n",
      "train loss:0.8571493504266612\n",
      "train loss:0.7562615176301256\n",
      "train loss:0.7674765007996359\n",
      "train loss:0.9743587361094589\n",
      "train loss:0.7221122382058612\n",
      "train loss:0.7279449853359092\n",
      "train loss:0.8753547799513914\n",
      "train loss:0.9195591800366951\n",
      "train loss:0.9035803690274955\n",
      "train loss:1.1268181521082783\n",
      "train loss:0.9315697598398326\n",
      "train loss:0.8201375741892442\n",
      "train loss:0.9242111461539742\n",
      "train loss:0.7941446642608626\n",
      "train loss:0.8473717846071847\n",
      "train loss:0.861006503701824\n",
      "train loss:0.8587815751923871\n",
      "train loss:0.6752052673927531\n",
      "train loss:0.8796054403705608\n",
      "train loss:0.6945038668492532\n",
      "train loss:0.8919895032384807\n",
      "train loss:0.7780544019666561\n",
      "train loss:0.8864652440285008\n",
      "train loss:0.8574655457795997\n",
      "train loss:0.75886392500947\n",
      "train loss:0.7937718622408286\n",
      "train loss:0.772793931351036\n",
      "train loss:0.8243073485537243\n",
      "train loss:0.8179552470205013\n",
      "train loss:0.9131576416056832\n",
      "train loss:1.042703357765868\n",
      "train loss:0.8952592334423728\n",
      "train loss:0.7709675276322216\n",
      "train loss:0.9714284778667271\n",
      "train loss:0.9173942435465845\n",
      "train loss:0.8408282672430807\n",
      "train loss:0.9335789849473421\n",
      "train loss:0.8963630102910268\n",
      "train loss:0.8717462919742179\n",
      "train loss:0.8655587071212372\n",
      "train loss:0.8329114607747098\n",
      "train loss:0.8983155301729855\n",
      "train loss:0.9436393499476785\n",
      "train loss:0.8652742138011875\n",
      "train loss:0.9486464058207649\n",
      "train loss:0.7729007144883984\n",
      "train loss:0.852344068694046\n",
      "train loss:0.9464376387323286\n",
      "train loss:0.8401055840743088\n",
      "train loss:0.8539590868223803\n",
      "train loss:0.9829756942235028\n",
      "train loss:0.8688497937482487\n",
      "train loss:0.7238308715540979\n",
      "train loss:0.9557749879847955\n",
      "train loss:0.9397234238208124\n",
      "train loss:0.9594022817484968\n",
      "train loss:0.9402487181514364\n",
      "train loss:0.9193766136896037\n",
      "train loss:0.9509838975578917\n",
      "train loss:0.9844315474526973\n",
      "train loss:0.9858881577127668\n",
      "train loss:0.7256817293622433\n",
      "train loss:0.8901530080331763\n",
      "train loss:0.7358824620966392\n",
      "train loss:0.7741900996764773\n",
      "train loss:0.947629270531024\n",
      "train loss:0.8254258909666925\n",
      "train loss:0.7739927827044149\n",
      "train loss:1.068114831822224\n",
      "train loss:0.9633838813952061\n",
      "train loss:0.9541760993965434\n",
      "train loss:1.0550112452464937\n",
      "train loss:0.709193917546537\n",
      "train loss:0.8859879158798936\n",
      "train loss:0.8646232199171021\n",
      "train loss:0.9787870508815133\n",
      "train loss:0.930136001670761\n",
      "train loss:0.8114503403430418\n",
      "train loss:0.8825584111632174\n",
      "train loss:0.9507268883190971\n",
      "train loss:0.9153405102538801\n",
      "train loss:0.9882715982152557\n",
      "train loss:0.7788236652845724\n",
      "train loss:0.7315322642321975\n",
      "train loss:0.7538403851396602\n",
      "train loss:0.8332662892454085\n",
      "train loss:0.8541408424184955\n",
      "train loss:0.8317755945455463\n",
      "train loss:0.7912713521109582\n",
      "train loss:1.0109038903149477\n",
      "train loss:0.7428027777252957\n",
      "train loss:0.8588142048908302\n",
      "train loss:0.6815486042864295\n",
      "train loss:0.7940965064218645\n",
      "train loss:0.9567185693574735\n",
      "train loss:0.8894716990041523\n",
      "train loss:0.8678875416410681\n",
      "train loss:0.8083808543751797\n",
      "train loss:0.9924151546953669\n",
      "train loss:0.8195724399714388\n",
      "train loss:0.8212246238350309\n",
      "train loss:0.7803686307929141\n",
      "train loss:0.7518116064850686\n",
      "train loss:0.8765362460220786\n",
      "train loss:0.8260704649740007\n",
      "train loss:0.8102076638529447\n",
      "train loss:0.8645023689776633\n",
      "train loss:0.7394519380481807\n",
      "train loss:1.016272532929554\n",
      "train loss:0.8382197441278697\n",
      "train loss:0.746675460496297\n",
      "train loss:0.9424358732285654\n",
      "train loss:0.7946553949645859\n",
      "train loss:0.7308172976062122\n",
      "train loss:0.6462583827009489\n",
      "train loss:0.937958146445736\n",
      "train loss:0.8523124289365\n",
      "train loss:0.8258949382723202\n",
      "train loss:0.7542117992207387\n",
      "train loss:0.71648433609439\n",
      "train loss:0.9815897105326424\n",
      "train loss:0.8582336570378944\n",
      "train loss:0.9080421679121552\n",
      "train loss:0.8998157938040983\n",
      "train loss:0.9554311431722954\n",
      "train loss:0.755130855195957\n",
      "train loss:0.7800233879193932\n",
      "train loss:0.9665707389394597\n",
      "train loss:0.958869398073742\n",
      "train loss:0.9037906363662188\n",
      "train loss:0.8892123662084361\n",
      "train loss:0.9992702296787519\n",
      "train loss:0.8493584511519436\n",
      "train loss:0.9035889189040753\n",
      "train loss:0.7036049752575114\n",
      "train loss:0.9425767777066295\n",
      "train loss:0.8453864086049321\n",
      "train loss:0.8711538157629244\n",
      "train loss:0.9527885960910016\n",
      "train loss:0.9585842455543279\n",
      "train loss:0.9117417206711661\n",
      "train loss:0.7770574015483993\n",
      "train loss:0.8428260289080113\n",
      "train loss:0.7931825662029253\n",
      "train loss:0.7453641973832993\n",
      "train loss:1.0002563969248803\n",
      "train loss:0.9837718808971075\n",
      "train loss:0.9040805009192807\n",
      "train loss:0.8880725134661169\n",
      "train loss:0.8374313594685703\n",
      "train loss:1.159605956978608\n",
      "train loss:0.828594464920525\n",
      "train loss:0.7871604948144979\n",
      "train loss:0.8851235613945776\n",
      "train loss:0.8542712775706112\n",
      "train loss:0.7523429775259622\n",
      "train loss:1.137615335771538\n",
      "train loss:0.9763411125516532\n",
      "train loss:0.9795123464357864\n",
      "train loss:0.8278932616035368\n",
      "train loss:0.8864179812696769\n",
      "train loss:0.804255750366666\n",
      "train loss:1.0338023195291803\n",
      "train loss:0.8135197451453757\n",
      "train loss:1.0448384415471414\n",
      "train loss:1.0079859521428787\n",
      "train loss:0.7626116500944066\n",
      "train loss:0.8221774733412817\n",
      "train loss:1.0067700261225934\n",
      "train loss:0.8946098163107696\n",
      "train loss:0.9120365072667269\n",
      "train loss:0.8688867848699185\n",
      "train loss:0.8190104513024637\n",
      "train loss:0.7858183836817371\n",
      "train loss:0.8851384807630036\n",
      "train loss:0.9234200181095831\n",
      "train loss:0.7310698490622529\n",
      "train loss:0.7775508979228364\n",
      "train loss:0.7909539617529517\n",
      "train loss:0.6888647934630312\n",
      "train loss:0.9873441564017499\n",
      "train loss:0.8571086442067397\n",
      "train loss:0.8860875518787569\n",
      "train loss:0.9105211520031828\n",
      "train loss:0.8831718684536272\n",
      "train loss:0.7528028210162223\n",
      "train loss:0.8820507488259672\n",
      "train loss:0.8837747186714802\n",
      "train loss:0.7508920151556291\n",
      "train loss:0.7534593292715764\n",
      "train loss:0.695742181642975\n",
      "train loss:0.8814337228943717\n",
      "train loss:0.8620801282190595\n",
      "train loss:0.5948121060222007\n",
      "train loss:0.9108284282605722\n",
      "train loss:0.7970606951737033\n",
      "train loss:0.8922220868755082\n",
      "train loss:0.7491540067828862\n",
      "train loss:0.8137488955350277\n",
      "train loss:0.892902164332479\n",
      "train loss:0.7456333909955971\n",
      "train loss:1.076469941009642\n",
      "train loss:0.8232112044643253\n",
      "train loss:0.6478743365941123\n",
      "train loss:0.9535129797415322\n",
      "train loss:0.7895630128949995\n",
      "train loss:0.9321483359297822\n",
      "train loss:0.8396184235872042\n",
      "train loss:1.0169568611780624\n",
      "train loss:0.7835907840717509\n",
      "train loss:0.9559719144341827\n",
      "train loss:0.8680285781877789\n",
      "train loss:0.9957400578998226\n",
      "train loss:0.8810200321521594\n",
      "train loss:0.8755260054293729\n",
      "train loss:1.0437926163856155\n",
      "train loss:0.9375794802233517\n",
      "train loss:0.8863067829700865\n",
      "train loss:0.6825544500545773\n",
      "train loss:0.9136844271153138\n",
      "train loss:0.7351815877429732\n",
      "train loss:0.6922482358673746\n",
      "train loss:0.961073653487866\n",
      "train loss:0.8025591789397217\n",
      "train loss:0.8825243736339222\n",
      "train loss:0.804138759454237\n",
      "train loss:0.9525192026945526\n",
      "train loss:0.755054017938822\n",
      "train loss:0.8644549868836096\n",
      "train loss:0.9115395987341429\n",
      "train loss:0.9264983873036647\n",
      "train loss:0.8921446389675343\n",
      "train loss:0.9622930197163236\n",
      "train loss:0.8051081330629017\n",
      "train loss:0.7545807112761609\n",
      "train loss:0.7651562008886086\n",
      "train loss:0.8720283904955035\n",
      "train loss:0.9595680793438511\n",
      "train loss:0.9893261144082414\n",
      "train loss:0.8886046195435005\n",
      "train loss:0.90039448171565\n",
      "train loss:0.8082529951012012\n",
      "train loss:0.8075631393187912\n",
      "train loss:0.8324232134815382\n",
      "train loss:0.8228308497641842\n",
      "train loss:0.7371101863952026\n",
      "train loss:1.0145687415531484\n",
      "train loss:0.9345958866012214\n",
      "train loss:0.8224125723004377\n",
      "train loss:0.8101275691806751\n",
      "train loss:0.9172950934714601\n",
      "train loss:0.8834100129308703\n",
      "train loss:0.885776671963939\n",
      "train loss:1.0641725204474992\n",
      "train loss:0.8380730589024747\n",
      "train loss:0.8933652752020176\n",
      "train loss:1.0135409255970702\n",
      "train loss:0.9324463484904801\n",
      "train loss:0.8784332993837133\n",
      "train loss:0.8253288650740329\n",
      "train loss:0.743198718772159\n",
      "train loss:0.8095008204221301\n",
      "train loss:0.7826851800704326\n",
      "train loss:0.8311224255679274\n",
      "train loss:0.8905444466268267\n",
      "train loss:0.6621662633566071\n",
      "train loss:0.6586101593808233\n",
      "train loss:0.933372830081265\n",
      "train loss:0.9364620929709884\n",
      "train loss:1.0484807747707088\n",
      "train loss:0.7046584948968018\n",
      "train loss:0.7405077389578325\n",
      "train loss:0.8712927854505698\n",
      "train loss:0.7259574287501512\n",
      "train loss:0.984279567840529\n",
      "train loss:0.8044155377845112\n",
      "train loss:0.8203058310387593\n",
      "train loss:0.8648495943425303\n",
      "train loss:0.8917890201479709\n",
      "train loss:0.7549617949993739\n",
      "train loss:0.9059794859261747\n",
      "train loss:0.9097826310071612\n",
      "train loss:0.7197056657698302\n",
      "train loss:0.796686777720712\n",
      "train loss:0.9799142209985742\n",
      "train loss:0.6289091319776844\n",
      "train loss:0.8433081789821485\n",
      "train loss:0.7659468682057345\n",
      "train loss:0.885321552195946\n",
      "train loss:0.8474615511295047\n",
      "train loss:0.9572832159032604\n",
      "train loss:0.8145646349693236\n",
      "train loss:0.915203513847123\n",
      "train loss:0.8485671871044549\n",
      "train loss:0.9286556219760327\n",
      "train loss:0.874161954751813\n",
      "train loss:0.7875905418990259\n",
      "train loss:0.8747093601408653\n",
      "train loss:0.8761182104257615\n",
      "train loss:0.9699319257587176\n",
      "train loss:0.8059670604525776\n",
      "train loss:0.7837140524904526\n",
      "train loss:0.8608077239573003\n",
      "train loss:0.7499184647390754\n",
      "train loss:0.9909875559097532\n",
      "train loss:0.8163066723984989\n",
      "train loss:0.8842362172525258\n",
      "train loss:0.7794333932241096\n",
      "train loss:0.9663437462202087\n",
      "train loss:1.0018342605508281\n",
      "train loss:0.6943796214354911\n",
      "train loss:0.7943787588433112\n",
      "train loss:1.002232593333117\n",
      "train loss:0.8423762218521225\n",
      "train loss:0.8147317440905328\n",
      "train loss:1.0474334577656725\n",
      "train loss:0.7678700506120548\n",
      "train loss:0.8306643776148525\n",
      "train loss:0.7270700798490362\n",
      "train loss:0.6992033752166293\n",
      "train loss:0.8400627737676782\n",
      "train loss:0.9984483202544113\n",
      "train loss:0.9903906196043079\n",
      "train loss:0.9570154061474558\n",
      "train loss:0.8041873458035176\n",
      "train loss:0.9699387284315616\n",
      "train loss:0.7315315548548798\n",
      "train loss:0.9849677325253141\n",
      "=== epoch:16, train acc:0.997, test acc:0.988 ===\n",
      "train loss:0.7125208001956111\n",
      "train loss:0.7302704385729665\n",
      "train loss:0.865668770796718\n",
      "train loss:0.8993067634606859\n",
      "train loss:0.7834314773259721\n",
      "train loss:0.9639290055400994\n",
      "train loss:0.8820127189947362\n",
      "train loss:0.8670414846885681\n",
      "train loss:0.8690806704973728\n",
      "train loss:0.8057718035624916\n",
      "train loss:1.0002980902789635\n",
      "train loss:0.9616055714840958\n",
      "train loss:0.8502597155677867\n",
      "train loss:0.777656028969907\n",
      "train loss:0.9394386918518627\n",
      "train loss:0.7632730094892145\n",
      "train loss:0.9149856001694335\n",
      "train loss:0.865572568021274\n",
      "train loss:1.0011143223273027\n",
      "train loss:0.9735751261741583\n",
      "train loss:0.8967717384943706\n",
      "train loss:0.7357447551732963\n",
      "train loss:0.8690215815818132\n",
      "train loss:1.0662273370483313\n",
      "train loss:0.8119178574045091\n",
      "train loss:0.9029382407415292\n",
      "train loss:0.9339303955102046\n",
      "train loss:0.7147661490154991\n",
      "train loss:0.8719319207456496\n",
      "train loss:0.780063855649758\n",
      "train loss:0.9223346314015253\n",
      "train loss:0.9213861192367961\n",
      "train loss:0.8930204462278567\n",
      "train loss:0.8991055832638754\n",
      "train loss:0.7694684205948225\n",
      "train loss:0.9323728931547085\n",
      "train loss:0.9196374942798918\n",
      "train loss:0.9885912160758619\n",
      "train loss:0.7686302769106185\n",
      "train loss:0.853818378977859\n",
      "train loss:0.9953297342553068\n",
      "train loss:0.9139751566513472\n",
      "train loss:0.9642066039639385\n",
      "train loss:0.8772885632833365\n",
      "train loss:1.0065644758098313\n",
      "train loss:0.9406136215562099\n",
      "train loss:0.7890502005584912\n",
      "train loss:0.821559286181524\n",
      "train loss:0.932830629671994\n",
      "train loss:0.9499297545556733\n",
      "train loss:0.9544492733139534\n",
      "train loss:0.9816386115744428\n",
      "train loss:0.898443250341882\n",
      "train loss:0.708163582163034\n",
      "train loss:1.0006339829408726\n",
      "train loss:0.9142942540338629\n",
      "train loss:0.9491037753240912\n",
      "train loss:0.7999630563489086\n",
      "train loss:0.9183637671862936\n",
      "train loss:0.7977383238302679\n",
      "train loss:0.7109189966229909\n",
      "train loss:0.7638807568803968\n",
      "train loss:0.9642387181523122\n",
      "train loss:0.8995928556227242\n",
      "train loss:0.8802121080964771\n",
      "train loss:0.8917703967891331\n",
      "train loss:0.7166676720150046\n",
      "train loss:0.865460336037419\n",
      "train loss:1.0644846676591413\n",
      "train loss:0.8726043770789957\n",
      "train loss:0.8044293257184489\n",
      "train loss:0.7402133934844674\n",
      "train loss:0.8381336303978979\n",
      "train loss:0.9456643785810082\n",
      "train loss:0.861524195295939\n",
      "train loss:0.6913059178054095\n",
      "train loss:0.9843790321901575\n",
      "train loss:0.8874598686594607\n",
      "train loss:0.7912685106242391\n",
      "train loss:0.8298562742042792\n",
      "train loss:0.8146880829728452\n",
      "train loss:0.8362507503266202\n",
      "train loss:0.8146224652831134\n",
      "train loss:0.8945765091427398\n",
      "train loss:0.8762060635398561\n",
      "train loss:0.8774931528402147\n",
      "train loss:0.7890234469266045\n",
      "train loss:0.8426729044204757\n",
      "train loss:0.9035207185519741\n",
      "train loss:0.8189952799803631\n",
      "train loss:0.8133871467625301\n",
      "train loss:0.9383560090267671\n",
      "train loss:0.8538260998405626\n",
      "train loss:0.7951234264758356\n",
      "train loss:0.8536888060008496\n",
      "train loss:0.8259111825097084\n",
      "train loss:0.8130779826563497\n",
      "train loss:0.9375042706983595\n",
      "train loss:0.8104492637273415\n",
      "train loss:0.9110963272809472\n",
      "train loss:0.8962378006494973\n",
      "train loss:0.965146607935809\n",
      "train loss:0.7909981351766495\n",
      "train loss:0.9583105211944938\n",
      "train loss:0.9256640616986977\n",
      "train loss:0.863320516656549\n",
      "train loss:0.9604422411877374\n",
      "train loss:1.0331175941736956\n",
      "train loss:0.9009790345688745\n",
      "train loss:0.8680321394159602\n",
      "train loss:0.824852244464951\n",
      "train loss:0.9494850727004005\n",
      "train loss:0.9417023309035563\n",
      "train loss:0.7005999456964572\n",
      "train loss:0.7565462854969371\n",
      "train loss:0.8465232484145695\n",
      "train loss:0.8588189254730287\n",
      "train loss:0.8828690932772986\n",
      "train loss:0.826744266858697\n",
      "train loss:0.9131486018599431\n",
      "train loss:0.900877455774218\n",
      "train loss:0.9202777108261962\n",
      "train loss:0.9722150827379861\n",
      "train loss:0.736949423564824\n",
      "train loss:0.8770216665130489\n",
      "train loss:0.944070275901201\n",
      "train loss:0.924845766178047\n",
      "train loss:0.7544244849354159\n",
      "train loss:0.802741371029808\n",
      "train loss:0.8628564032972906\n",
      "train loss:0.8538665431173947\n",
      "train loss:0.8669104725158674\n",
      "train loss:0.9137396081319192\n",
      "train loss:0.8319398240042949\n",
      "train loss:0.9365521374915964\n",
      "train loss:0.9062625765995342\n",
      "train loss:0.9672895670680763\n",
      "train loss:0.7844885779811501\n",
      "train loss:0.8466106494026847\n",
      "train loss:0.7194583066725848\n",
      "train loss:0.7574176035377636\n",
      "train loss:0.9059585728942348\n",
      "train loss:0.8445094977575529\n",
      "train loss:0.9067209270563016\n",
      "train loss:0.8042245644603466\n",
      "train loss:0.8048578639130501\n",
      "train loss:0.9182518224164806\n",
      "train loss:0.9209657558458392\n",
      "train loss:0.7305450541597577\n",
      "train loss:0.6924796187040614\n",
      "train loss:0.9381452635154395\n",
      "train loss:0.8315810733614529\n",
      "train loss:0.971071777011549\n",
      "train loss:0.8080074064122517\n",
      "train loss:0.7381398698746326\n",
      "train loss:0.9575861522509281\n",
      "train loss:0.917493204279083\n",
      "train loss:0.9055065582571429\n",
      "train loss:0.8526956562737138\n",
      "train loss:0.7775776624455527\n",
      "train loss:0.8052834505326854\n",
      "train loss:0.9835846499898213\n",
      "train loss:0.9450260550325641\n",
      "train loss:0.8006026207691365\n",
      "train loss:0.7715998272796228\n",
      "train loss:0.6654581355092585\n",
      "train loss:0.9545713204323861\n",
      "train loss:0.8821107292211461\n",
      "train loss:0.9133120373978258\n",
      "train loss:0.8818366823487247\n",
      "train loss:0.9216728250340178\n",
      "train loss:0.8740769424397237\n",
      "train loss:1.0288460144696705\n",
      "train loss:0.8439008239211792\n",
      "train loss:0.920637570666568\n",
      "train loss:0.8093841143758647\n",
      "train loss:0.8376171066512706\n",
      "train loss:0.9082396993623276\n",
      "train loss:0.647540627104334\n",
      "train loss:0.9576989241175462\n",
      "train loss:0.8473193090237656\n",
      "train loss:0.7259210681192242\n",
      "train loss:0.8002570325695271\n",
      "train loss:0.861125992673698\n",
      "train loss:0.7852912414934238\n",
      "train loss:0.9623869266753635\n",
      "train loss:0.8649775589388129\n",
      "train loss:0.7919143433963457\n",
      "train loss:0.9246206121214254\n",
      "train loss:0.9264686640884412\n",
      "train loss:0.758206896298359\n",
      "train loss:0.8384591735977096\n",
      "train loss:0.9345770453651397\n",
      "train loss:0.9551488247249884\n",
      "train loss:0.7310072738715118\n",
      "train loss:0.7710652755531703\n",
      "train loss:0.8955488803631451\n",
      "train loss:0.7445665795391109\n",
      "train loss:0.8821440820740194\n",
      "train loss:0.6549686115129567\n",
      "train loss:0.8166867118587188\n",
      "train loss:0.7812203278393731\n",
      "train loss:0.8791513049940768\n",
      "train loss:0.9141409851128115\n",
      "train loss:0.9415562039176091\n",
      "train loss:0.7590989199050554\n",
      "train loss:0.8474562052161174\n",
      "train loss:0.9523634453088472\n",
      "train loss:0.8580384022944485\n",
      "train loss:0.9633452076371205\n",
      "train loss:0.8060863042925132\n",
      "train loss:0.7291093517237007\n",
      "train loss:0.7539362769575239\n",
      "train loss:0.7535637241078351\n",
      "train loss:0.7848517646520706\n",
      "train loss:0.8705775845714931\n",
      "train loss:0.90186441191225\n",
      "train loss:0.753514182406954\n",
      "train loss:0.9962378675743588\n",
      "train loss:0.876113693294682\n",
      "train loss:0.861005110266553\n",
      "train loss:0.7400673827307079\n",
      "train loss:0.8267370699853537\n",
      "train loss:0.9499987932487027\n",
      "train loss:0.9934433868347652\n",
      "train loss:0.8850560080590897\n",
      "train loss:0.9022678800306239\n",
      "train loss:0.8894330016928934\n",
      "train loss:0.7339550947013518\n",
      "train loss:0.9366079706993774\n",
      "train loss:0.8619504611353399\n",
      "train loss:0.9308037306851706\n",
      "train loss:0.7986709685224497\n",
      "train loss:0.8407276344303979\n",
      "train loss:0.9709524513510516\n",
      "train loss:0.9300771500733872\n",
      "train loss:0.7850304650944971\n",
      "train loss:0.8339018699571557\n",
      "train loss:0.8866925538034102\n",
      "train loss:0.7697491578958758\n",
      "train loss:0.8888412204711094\n",
      "train loss:0.880070690447644\n",
      "train loss:0.782405653541653\n",
      "train loss:0.8005595593274561\n",
      "train loss:0.8028436097644603\n",
      "train loss:1.032749868151052\n",
      "train loss:0.7714536683121519\n",
      "train loss:0.9416316082838406\n",
      "train loss:0.8078768470467148\n",
      "train loss:0.8304474509543174\n",
      "train loss:0.711776963224797\n",
      "train loss:0.8590578913085807\n",
      "train loss:0.9786131006847224\n",
      "train loss:0.9112788328969832\n",
      "train loss:0.8249230327442016\n",
      "train loss:0.9914095256412305\n",
      "train loss:0.8861207980525456\n",
      "train loss:0.9439183301884617\n",
      "train loss:0.8927355913783552\n",
      "train loss:0.855429568883634\n",
      "train loss:0.935018268421352\n",
      "train loss:0.6360846278520456\n",
      "train loss:1.1394048379904234\n",
      "train loss:0.8166686079548005\n",
      "train loss:0.7423424645718676\n",
      "train loss:0.8062519211364864\n",
      "train loss:1.0623619071240917\n",
      "train loss:0.885144277895509\n",
      "train loss:0.8943296582770485\n",
      "train loss:1.0317387310240638\n",
      "train loss:0.8084786856333269\n",
      "train loss:0.8504160093499371\n",
      "train loss:0.9296649724786828\n",
      "train loss:0.823077728605973\n",
      "train loss:0.9175689058425164\n",
      "train loss:0.9386806515665402\n",
      "train loss:0.8793286000980451\n",
      "train loss:0.8492107650257895\n",
      "train loss:0.815322774922352\n",
      "train loss:0.8558635665003033\n",
      "train loss:0.8976523613971037\n",
      "train loss:0.8030048002955661\n",
      "train loss:0.7971792661798461\n",
      "train loss:0.9806631399558181\n",
      "train loss:0.8208911020788032\n",
      "train loss:0.7501472464146446\n",
      "train loss:0.8984131206845077\n",
      "train loss:0.9392223181990577\n",
      "train loss:0.7379862743346108\n",
      "train loss:0.7498916125025649\n",
      "train loss:0.8470266289812821\n",
      "train loss:0.926320223017106\n",
      "train loss:0.9727902402057047\n",
      "train loss:0.8684074928472926\n",
      "train loss:0.9083369933094549\n",
      "train loss:0.8474855987495971\n",
      "train loss:0.9034416289088414\n",
      "train loss:0.9115922912495819\n",
      "train loss:0.846331248727695\n",
      "train loss:0.870775111411337\n",
      "train loss:0.7810912341528509\n",
      "train loss:0.869192647677382\n",
      "train loss:0.9377615911055855\n",
      "train loss:0.7459687168767113\n",
      "train loss:0.9305100276363638\n",
      "train loss:0.847099060256708\n",
      "train loss:0.9413900792409063\n",
      "train loss:0.7345672159190593\n",
      "train loss:0.7676470150694662\n",
      "train loss:0.9749943933004992\n",
      "train loss:0.9263191635440099\n",
      "train loss:0.7648482979397734\n",
      "train loss:0.8471346972056206\n",
      "train loss:0.9498283472565907\n",
      "train loss:1.0311917909302295\n",
      "train loss:0.927076936602571\n",
      "train loss:0.8903306953121054\n",
      "train loss:0.9470037624504323\n",
      "train loss:0.9100688071163259\n",
      "train loss:0.8648084991185694\n",
      "train loss:0.8667135886340833\n",
      "train loss:0.8306681274900329\n",
      "train loss:0.9347317583918854\n",
      "train loss:0.7625267772914254\n",
      "train loss:0.9051162519572251\n",
      "train loss:0.8250825873646705\n",
      "train loss:0.8734524726620436\n",
      "train loss:0.703860304471893\n",
      "train loss:0.7245003555231342\n",
      "train loss:0.8884795015400815\n",
      "train loss:0.8562064843954944\n",
      "train loss:0.6136013031716898\n",
      "train loss:0.7989364730528301\n",
      "train loss:0.8220690230275344\n",
      "train loss:0.9894756939956183\n",
      "train loss:0.8915727255561187\n",
      "train loss:0.9094443050036181\n",
      "train loss:0.8516097202651433\n",
      "train loss:0.8586611087343163\n",
      "train loss:0.7648120034906408\n",
      "train loss:0.7358448548027718\n",
      "train loss:0.9600841863165797\n",
      "train loss:0.9281726360989238\n",
      "train loss:0.7502493847646196\n",
      "train loss:0.9666388947682998\n",
      "train loss:0.8675372194964798\n",
      "train loss:0.7941000054743221\n",
      "train loss:0.9957715913350748\n",
      "train loss:0.8392608468810654\n",
      "train loss:0.7640324553870683\n",
      "train loss:1.0086384982093468\n",
      "train loss:0.8352738194001477\n",
      "train loss:0.8304700639931102\n",
      "train loss:0.9387586583573588\n",
      "train loss:0.8567069516084669\n",
      "train loss:0.7367896825808544\n",
      "train loss:0.9015771646731815\n",
      "train loss:0.838433491249448\n",
      "train loss:0.7721632904312662\n",
      "train loss:0.7178624678491589\n",
      "train loss:0.9437083402082745\n",
      "train loss:0.8469757890382319\n",
      "train loss:0.9666546379686138\n",
      "train loss:0.8177601454945317\n",
      "train loss:0.7643617449188439\n",
      "train loss:0.8729086924465232\n",
      "train loss:0.9977339222787082\n",
      "train loss:0.9410387895885619\n",
      "train loss:0.8628263748444353\n",
      "train loss:0.8775584088819112\n",
      "train loss:0.9864322826144815\n",
      "train loss:0.8402321910837703\n",
      "train loss:0.7399383709961158\n",
      "train loss:0.8530635051546795\n",
      "train loss:0.8263846266182422\n",
      "train loss:0.8196745875420275\n",
      "train loss:0.8403342320537992\n",
      "train loss:0.7677555314185324\n",
      "train loss:1.00557338196649\n",
      "train loss:0.8231597431015097\n",
      "train loss:0.7156562256411949\n",
      "train loss:0.8121925672913483\n",
      "train loss:0.8937801676067723\n",
      "train loss:1.013284047450909\n",
      "train loss:0.9211808864792814\n",
      "train loss:0.8835924389004333\n",
      "train loss:0.838309989992176\n",
      "train loss:0.8701775000711772\n",
      "train loss:0.956523323843704\n",
      "train loss:0.913424393092325\n",
      "train loss:0.8356828129713729\n",
      "train loss:0.8502562762129113\n",
      "train loss:0.8480555397818006\n",
      "train loss:0.89355566901861\n",
      "train loss:0.9729329138615579\n",
      "train loss:0.8930379223180445\n",
      "train loss:0.968198375607939\n",
      "train loss:0.9473492796332025\n",
      "train loss:0.8623874808576018\n",
      "train loss:0.8145999401254777\n",
      "train loss:0.7887684949261417\n",
      "train loss:0.9177815297733213\n",
      "train loss:0.8154134507139041\n",
      "train loss:0.8057648944576443\n",
      "train loss:0.8424852393098525\n",
      "train loss:0.8895296492421704\n",
      "train loss:1.1045869119674123\n",
      "train loss:0.8243401505302356\n",
      "train loss:0.7979294753046361\n",
      "train loss:0.8359652537815463\n",
      "train loss:0.8021150974910627\n",
      "train loss:0.8178151259885699\n",
      "train loss:0.7216790137454268\n",
      "train loss:0.869494457984283\n",
      "train loss:0.9159720540412435\n",
      "train loss:0.9425916676395778\n",
      "train loss:0.9058501018735098\n",
      "train loss:0.872780059781745\n",
      "train loss:0.7726645978872065\n",
      "train loss:0.8827188876772621\n",
      "train loss:0.8050647322172495\n",
      "train loss:0.8024223356950024\n",
      "train loss:0.8232994274050337\n",
      "train loss:0.893527836522347\n",
      "train loss:0.8339135089702847\n",
      "train loss:0.9483944710014478\n",
      "train loss:0.8955245564612094\n",
      "train loss:0.8430939429151502\n",
      "train loss:0.8553109418948498\n",
      "train loss:0.9571012725214488\n",
      "train loss:0.8735270199862484\n",
      "train loss:0.7770006385230499\n",
      "train loss:0.8264721563762193\n",
      "train loss:0.9606478251816287\n",
      "train loss:1.0436478983686523\n",
      "train loss:0.8945241463559949\n",
      "train loss:0.9724909232774928\n",
      "train loss:0.9516063180265927\n",
      "train loss:0.9535372082980086\n",
      "train loss:0.6472681961723324\n",
      "train loss:0.9128869709020695\n",
      "train loss:0.8560280276762318\n",
      "train loss:0.9296129835553499\n",
      "train loss:0.7933605493211171\n",
      "train loss:0.9215205132295443\n",
      "train loss:0.8431333626088235\n",
      "train loss:0.7746370354693438\n",
      "train loss:0.9187698062216206\n",
      "train loss:0.9096191640903413\n",
      "train loss:0.8433046305354422\n",
      "train loss:0.8464327726110358\n",
      "train loss:0.929935365428758\n",
      "train loss:0.800033009687274\n",
      "train loss:0.8606549229932224\n",
      "train loss:0.887669992136519\n",
      "train loss:0.8642740760540191\n",
      "train loss:0.9189160732973249\n",
      "train loss:0.9397729609941843\n",
      "train loss:0.8963651553677685\n",
      "train loss:0.9630782861465929\n",
      "train loss:0.8041896548433242\n",
      "train loss:1.0010281107835606\n",
      "train loss:0.8685726983698886\n",
      "train loss:0.9375383824173639\n",
      "train loss:0.96338227384266\n",
      "train loss:0.9440927348370252\n",
      "train loss:0.7841471265208517\n",
      "train loss:0.8560895474264456\n",
      "train loss:0.7856842404830795\n",
      "train loss:0.7688460762262582\n",
      "train loss:0.895568735072878\n",
      "train loss:0.7830902136917406\n",
      "train loss:0.9105790193109174\n",
      "train loss:0.849562723621818\n",
      "train loss:0.8297877644135552\n",
      "train loss:0.8896402223898103\n",
      "train loss:0.7218016767184916\n",
      "train loss:0.730854873874767\n",
      "train loss:0.8339376123294542\n",
      "train loss:0.8391263899853232\n",
      "train loss:0.83153989371034\n",
      "train loss:0.9467051499459019\n",
      "train loss:0.7303880582998029\n",
      "train loss:0.9340346437595144\n",
      "train loss:0.8553663750288049\n",
      "train loss:1.0284798038999865\n",
      "train loss:0.8221792360163822\n",
      "train loss:1.0255895383077895\n",
      "train loss:0.9082522527283169\n",
      "train loss:0.8855058140622506\n",
      "train loss:0.9929725582860156\n",
      "train loss:0.7783669208047884\n",
      "train loss:0.953994197858025\n",
      "train loss:0.9146388062412831\n",
      "train loss:0.9812226893416951\n",
      "train loss:0.8377110621442596\n",
      "train loss:0.8215535177304477\n",
      "train loss:0.7925562648132731\n",
      "train loss:1.0020333871485\n",
      "train loss:0.7061446541789387\n",
      "train loss:0.7808677289209982\n",
      "train loss:0.756941949634442\n",
      "train loss:0.8501545545365533\n",
      "train loss:0.92991401874359\n",
      "train loss:0.8617621289276137\n",
      "train loss:0.77718694993393\n",
      "train loss:0.950890171133327\n",
      "train loss:0.8691385214758311\n",
      "train loss:0.8228514188722719\n",
      "train loss:0.965151383661081\n",
      "train loss:0.9268514150728845\n",
      "train loss:0.860368116656693\n",
      "train loss:0.9708473927271852\n",
      "train loss:0.9965446790493637\n",
      "train loss:0.7317560487086763\n",
      "train loss:0.7632198580749203\n",
      "train loss:0.9193902279679107\n",
      "train loss:0.8729966359143216\n",
      "train loss:0.9407745799649553\n",
      "train loss:0.8521670880227923\n",
      "train loss:0.9394715614810729\n",
      "train loss:0.9095728823643295\n",
      "train loss:1.0123666570237722\n",
      "train loss:0.8364898560223526\n",
      "train loss:0.7283893858391799\n",
      "train loss:0.8817671612077812\n",
      "train loss:0.8467474910521042\n",
      "train loss:0.8953372782863922\n",
      "train loss:0.840883595601853\n",
      "train loss:0.799549489001801\n",
      "train loss:0.9298789446688552\n",
      "train loss:0.9207807622572973\n",
      "train loss:0.8557299888167617\n",
      "train loss:0.8736545035807914\n",
      "train loss:0.834167786813577\n",
      "train loss:0.9525214261339228\n",
      "train loss:0.7089641092432862\n",
      "train loss:0.8196460762805216\n",
      "train loss:0.8927519426611912\n",
      "train loss:0.9391555211459561\n",
      "train loss:0.8557580573508495\n",
      "train loss:0.8078736343054973\n",
      "train loss:0.5926559197749796\n",
      "train loss:0.7123348142101631\n",
      "train loss:1.0119716787514823\n",
      "train loss:0.921819358951197\n",
      "train loss:0.8976102424048372\n",
      "train loss:0.900414061930649\n",
      "train loss:0.8745581838637658\n",
      "train loss:1.046358017678792\n",
      "train loss:0.858426236377539\n",
      "train loss:1.0030019425945353\n",
      "train loss:0.9272105405229202\n",
      "train loss:0.8702358672789308\n",
      "train loss:0.9047024347755556\n",
      "train loss:0.8594588758234675\n",
      "train loss:0.9749081947480062\n",
      "train loss:0.9584147192136213\n",
      "train loss:0.8816789544664367\n",
      "train loss:0.8364166096800807\n",
      "train loss:0.8376413174248317\n",
      "train loss:0.9400617086798485\n",
      "train loss:0.9385709580771139\n",
      "train loss:0.7625500628625701\n",
      "train loss:1.06927454765307\n",
      "train loss:0.8156905390325302\n",
      "train loss:0.8995615353134302\n",
      "train loss:0.7759251400393122\n",
      "train loss:0.8095397702947822\n",
      "train loss:0.952610490693036\n",
      "train loss:0.8711892215061762\n",
      "train loss:0.9100380838830947\n",
      "train loss:0.8810502067881285\n",
      "train loss:0.9483078813040418\n",
      "train loss:0.7883148532454881\n",
      "train loss:0.7508166712228924\n",
      "train loss:0.7755876903147364\n",
      "train loss:0.6669139138066612\n",
      "train loss:0.8512487149125318\n",
      "train loss:0.7373699702301398\n",
      "train loss:0.9015922078044647\n",
      "train loss:0.913541337328146\n",
      "train loss:0.9300168456478012\n",
      "train loss:0.8119953061258594\n",
      "train loss:0.7691047577946541\n",
      "train loss:0.7715516945919022\n",
      "train loss:0.866892316976295\n",
      "train loss:0.8810636515000236\n",
      "train loss:0.8179574660943371\n",
      "train loss:0.872801953257546\n",
      "train loss:0.8141046209135502\n",
      "train loss:0.9484109714318396\n",
      "train loss:0.6605846803470469\n",
      "train loss:1.075331838527543\n",
      "train loss:0.9318565256314225\n",
      "train loss:1.015969040441938\n",
      "train loss:0.8673633371877688\n",
      "train loss:0.8685254387378428\n",
      "train loss:0.9696642831698226\n",
      "train loss:0.9004353648225124\n",
      "=== epoch:17, train acc:0.996, test acc:0.993 ===\n",
      "train loss:0.8951290273813158\n",
      "train loss:0.9745684210257065\n",
      "train loss:0.829609516545849\n",
      "train loss:0.8396300753089413\n",
      "train loss:0.847944706590339\n",
      "train loss:0.7747779090348308\n",
      "train loss:0.9022728751709781\n",
      "train loss:0.6617557011854406\n",
      "train loss:0.8895749816448274\n",
      "train loss:0.9711185387960961\n",
      "train loss:0.9062742284959561\n",
      "train loss:0.9619328885950189\n",
      "train loss:0.8304591120909832\n",
      "train loss:0.8602715103673357\n",
      "train loss:1.065186827266996\n",
      "train loss:0.8511631636183875\n",
      "train loss:0.8129096852574592\n",
      "train loss:0.847126640607395\n",
      "train loss:0.8924612863065228\n",
      "train loss:0.8593945199206275\n",
      "train loss:1.0875399924153295\n",
      "train loss:0.9630709737298554\n",
      "train loss:0.7531566867869114\n",
      "train loss:0.920162421367507\n",
      "train loss:0.8736869138171869\n",
      "train loss:0.7649214992430806\n",
      "train loss:0.8784557517588927\n",
      "train loss:0.8524446921848119\n",
      "train loss:0.7157208108556299\n",
      "train loss:0.8173716936700139\n",
      "train loss:0.7295664840637127\n",
      "train loss:0.8117902848386558\n",
      "train loss:0.8619281169865816\n",
      "train loss:0.8961135048410704\n",
      "train loss:1.0008857046354427\n",
      "train loss:0.8645079350247952\n",
      "train loss:0.9918096580943104\n",
      "train loss:0.874172467596517\n",
      "train loss:0.9058117834223794\n",
      "train loss:0.8288214941829295\n",
      "train loss:1.0179476603028133\n",
      "train loss:0.857135072814082\n",
      "train loss:0.7562086831949031\n",
      "train loss:0.9116243669254933\n",
      "train loss:0.8355490466618647\n",
      "train loss:0.9266724119917229\n",
      "train loss:0.7879855994249988\n",
      "train loss:0.6145861570820603\n",
      "train loss:0.8571243776813624\n",
      "train loss:0.86074557096961\n",
      "train loss:0.8166565389558714\n",
      "train loss:1.0297059662379349\n",
      "train loss:1.0000066994599384\n",
      "train loss:0.8543579120118139\n",
      "train loss:1.0672103326139455\n",
      "train loss:0.9160635544177037\n",
      "train loss:1.00657451388564\n",
      "train loss:0.7733893004112007\n",
      "train loss:0.9065474046310483\n",
      "train loss:0.9687077201958191\n",
      "train loss:0.9024586445454186\n",
      "train loss:0.9315408218900622\n",
      "train loss:0.7046717297735234\n",
      "train loss:1.0199776817308825\n",
      "train loss:0.7763299685979412\n",
      "train loss:0.8467964400168393\n",
      "train loss:0.9805299413535192\n",
      "train loss:0.9036565047077267\n",
      "train loss:0.823079228594508\n",
      "train loss:0.8909334504739725\n",
      "train loss:0.9803835524375488\n",
      "train loss:0.7311335179785331\n",
      "train loss:0.924513081640383\n",
      "train loss:0.810693926225303\n",
      "train loss:0.9150774304217135\n",
      "train loss:0.8686146413300528\n",
      "train loss:0.824054290001385\n",
      "train loss:0.9214113095496625\n",
      "train loss:0.6676377084210366\n",
      "train loss:1.118162988222818\n",
      "train loss:0.9428017480941222\n",
      "train loss:0.9209736505180429\n",
      "train loss:0.8664288421801429\n",
      "train loss:0.8276304545952984\n",
      "train loss:1.0567497624644697\n",
      "train loss:1.0084307079250074\n",
      "train loss:0.8912118127601556\n",
      "train loss:0.9621350007534231\n",
      "train loss:0.7658341086448454\n",
      "train loss:0.8673615826810753\n",
      "train loss:0.9309979622898544\n",
      "train loss:0.9913865485806101\n",
      "train loss:0.9045468448763863\n",
      "train loss:0.8684396356647757\n",
      "train loss:0.7427492553401969\n",
      "train loss:0.8692591943840628\n",
      "train loss:0.8370163292918127\n",
      "train loss:0.7525093452598469\n",
      "train loss:1.0023215521225073\n",
      "train loss:0.8273783647913894\n",
      "train loss:0.7915591770000079\n",
      "train loss:0.8726600344768437\n",
      "train loss:0.8196475748953705\n",
      "train loss:0.6987122909667824\n",
      "train loss:1.0655477274706995\n",
      "train loss:0.8959967344314098\n",
      "train loss:1.1026245539945752\n",
      "train loss:1.007461515176478\n",
      "train loss:0.941708722036946\n",
      "train loss:0.7151239496109748\n",
      "train loss:0.8081136761655888\n",
      "train loss:0.8816591829976792\n",
      "train loss:0.841715244637388\n",
      "train loss:0.8482988139559123\n",
      "train loss:0.9963161732666489\n",
      "train loss:0.9901337165471287\n",
      "train loss:0.8477788194107577\n",
      "train loss:0.8801649299738473\n",
      "train loss:0.6391459283419136\n",
      "train loss:0.8049779866216562\n",
      "train loss:0.93715423233131\n",
      "train loss:0.7140094228501391\n",
      "train loss:0.7237536782762335\n",
      "train loss:0.9420866934651647\n",
      "train loss:0.7963369029271568\n",
      "train loss:0.9171520221757432\n",
      "train loss:0.8809286343365847\n",
      "train loss:0.9043216523565387\n",
      "train loss:0.851399423495366\n",
      "train loss:1.0712037250005195\n",
      "train loss:0.8804578812926223\n",
      "train loss:0.7692416239616032\n",
      "train loss:0.7735116631578728\n",
      "train loss:0.7695709564628055\n",
      "train loss:0.8022888987702647\n",
      "train loss:0.9362061845649685\n",
      "train loss:0.9525630560502252\n",
      "train loss:0.8770780532910656\n",
      "train loss:1.0152711563924166\n",
      "train loss:0.8830436052795578\n",
      "train loss:0.8585886352328622\n",
      "train loss:0.835815727804\n",
      "train loss:0.8089785211949259\n",
      "train loss:0.8525188286005148\n",
      "train loss:0.8842783386518757\n",
      "train loss:0.8444925440248299\n",
      "train loss:0.8187546630561593\n",
      "train loss:0.9273324040735906\n",
      "train loss:1.053908758726665\n",
      "train loss:0.8337448293243032\n",
      "train loss:0.7527750673774775\n",
      "train loss:0.7470528719225222\n",
      "train loss:0.7331923928721349\n",
      "train loss:0.8084597385809862\n",
      "train loss:0.895783831412845\n",
      "train loss:0.78651076877\n",
      "train loss:0.9510864363167539\n",
      "train loss:0.9465943041527589\n",
      "train loss:0.7550640599685352\n",
      "train loss:0.8410114571408341\n",
      "train loss:0.6307887587146329\n",
      "train loss:0.8960120353872437\n",
      "train loss:0.7751915136391674\n",
      "train loss:0.9105998862724566\n",
      "train loss:0.8291754623951652\n",
      "train loss:1.0061249366794542\n",
      "train loss:0.9804003150511379\n",
      "train loss:0.889950141031151\n",
      "train loss:0.7788655634621058\n",
      "train loss:0.8757577640845122\n",
      "train loss:0.7390728673674326\n",
      "train loss:0.975722499649489\n",
      "train loss:0.8956679299555045\n",
      "train loss:0.9027662980113308\n",
      "train loss:0.7812358629551431\n",
      "train loss:0.9210830690850156\n",
      "train loss:0.8326776170388963\n",
      "train loss:0.8938195097534185\n",
      "train loss:0.8352280901236846\n",
      "train loss:1.1190278761693824\n",
      "train loss:1.0222629686952178\n",
      "train loss:0.8050314402512083\n",
      "train loss:0.8794801192560949\n",
      "train loss:0.8559190058716243\n",
      "train loss:0.8263475156940262\n",
      "train loss:0.9841622952016196\n",
      "train loss:0.9035951054771035\n",
      "train loss:1.0783259493851416\n",
      "train loss:0.786653411460264\n",
      "train loss:0.8316098111678255\n",
      "train loss:0.9268680126719819\n",
      "train loss:0.8755870137270592\n",
      "train loss:0.871422011777919\n",
      "train loss:0.9228174505798401\n",
      "train loss:0.7527494827905384\n",
      "train loss:1.0157744734490157\n",
      "train loss:0.9421714027715078\n",
      "train loss:0.8479323537633299\n",
      "train loss:1.098175153001785\n",
      "train loss:0.8444614019115099\n",
      "train loss:0.8621948776535997\n",
      "train loss:0.907507479672647\n",
      "train loss:0.6727457380346948\n",
      "train loss:0.6971269728145439\n",
      "train loss:0.8812031844854031\n",
      "train loss:0.9199179743344282\n",
      "train loss:0.7845697225568631\n",
      "train loss:0.7653872899959137\n",
      "train loss:0.8437641238891405\n",
      "train loss:0.976737966860916\n",
      "train loss:0.8878924420161945\n",
      "train loss:0.7544790220491525\n",
      "train loss:0.8038185505259863\n",
      "train loss:0.6390886045255018\n",
      "train loss:0.9477246966259993\n",
      "train loss:0.9164944889061942\n",
      "train loss:0.7904528777165831\n",
      "train loss:0.9000920822245095\n",
      "train loss:0.8513429043289134\n",
      "train loss:0.9153002891926277\n",
      "train loss:1.030332969394128\n",
      "train loss:0.9485300850692288\n",
      "train loss:0.8440634489038139\n",
      "train loss:0.9269267977717961\n",
      "train loss:0.8760255872890113\n",
      "train loss:0.7274223246738108\n",
      "train loss:0.826201117836274\n",
      "train loss:0.8949760871356431\n",
      "train loss:0.8550715925098938\n",
      "train loss:1.027311749132019\n",
      "train loss:0.6839744745964339\n",
      "train loss:0.7715073498975106\n",
      "train loss:1.0001607669313466\n",
      "train loss:0.8771809716125627\n",
      "train loss:0.9737741571470283\n",
      "train loss:0.8777158519845152\n",
      "train loss:0.7895848425213228\n",
      "train loss:0.7106963581837753\n",
      "train loss:1.0230126429585211\n",
      "train loss:1.035985596778099\n",
      "train loss:0.8953377613354011\n",
      "train loss:0.9762592421744908\n",
      "train loss:0.9445204885993497\n",
      "train loss:0.8406142630169668\n",
      "train loss:0.7955199217737244\n",
      "train loss:0.9848599183252328\n",
      "train loss:0.9083478787506135\n",
      "train loss:0.9185792797510267\n",
      "train loss:0.8118873832225275\n",
      "train loss:0.7545561337174861\n",
      "train loss:0.8346968764895568\n",
      "train loss:0.6857485705969631\n",
      "train loss:0.6487445560012374\n",
      "train loss:0.867897207568364\n",
      "train loss:0.913823735378631\n",
      "train loss:0.875197421043438\n",
      "train loss:1.019378087877119\n",
      "train loss:0.7805398685590493\n",
      "train loss:0.8135723395708636\n",
      "train loss:0.8091301600749509\n",
      "train loss:0.8972739983175779\n",
      "train loss:0.8010359017258533\n",
      "train loss:0.8795120535597718\n",
      "train loss:0.9584051880034816\n",
      "train loss:0.9300943586875857\n",
      "train loss:0.9336850814424098\n",
      "train loss:0.8753858770408118\n",
      "train loss:0.8521774724558646\n",
      "train loss:0.921006810170685\n",
      "train loss:1.0084606425836622\n",
      "train loss:1.0551862064971096\n",
      "train loss:0.9614187404849001\n",
      "train loss:0.7491229046425896\n",
      "train loss:0.7572800396259217\n",
      "train loss:0.9290049342914278\n",
      "train loss:0.9315308103759419\n",
      "train loss:0.6468714839778742\n",
      "train loss:0.872510121292552\n",
      "train loss:0.9195124445445945\n",
      "train loss:0.8347038341795031\n",
      "train loss:0.9286560874165827\n",
      "train loss:0.8659593316691498\n",
      "train loss:0.7757367636359895\n",
      "train loss:0.8801583373405114\n",
      "train loss:1.0027055281175838\n",
      "train loss:0.8348649310243167\n",
      "train loss:0.8222933744588211\n",
      "train loss:0.7799278785921249\n",
      "train loss:0.7976674237822244\n",
      "train loss:0.8188258403745103\n",
      "train loss:0.8186397581167131\n",
      "train loss:0.8266974085451884\n",
      "train loss:0.9074681273092611\n",
      "train loss:0.9276145176580777\n",
      "train loss:0.7117007400648565\n",
      "train loss:0.9311097303865045\n",
      "train loss:0.8475251004267699\n",
      "train loss:1.0121153434620844\n",
      "train loss:0.8874445728628487\n",
      "train loss:0.8603702452817995\n",
      "train loss:0.8163124634848\n",
      "train loss:0.7198609927365607\n",
      "train loss:0.9811889523066563\n",
      "train loss:0.8628593785860572\n",
      "train loss:1.0199641231216774\n",
      "train loss:0.8723958800553895\n",
      "train loss:0.7673483416289444\n",
      "train loss:0.8784880660846224\n",
      "train loss:0.7044481311291151\n",
      "train loss:0.6605205738790927\n",
      "train loss:0.9608302903382294\n",
      "train loss:0.8979530359212471\n",
      "train loss:0.820326832034096\n",
      "train loss:0.9204620700154718\n",
      "train loss:0.7345216103801063\n",
      "train loss:0.8422512805454474\n",
      "train loss:0.7614906586285086\n",
      "train loss:0.9114430518779101\n",
      "train loss:0.9707212131595899\n",
      "train loss:0.8897085731868849\n",
      "train loss:0.7895345703329301\n",
      "train loss:1.089258440141044\n",
      "train loss:0.8382388012114436\n",
      "train loss:0.8942945830221697\n",
      "train loss:0.9102432401411076\n",
      "train loss:0.9424233155051005\n",
      "train loss:0.9398162772301952\n",
      "train loss:0.9035639654326616\n",
      "train loss:0.7167947251806578\n",
      "train loss:0.9204355948502417\n",
      "train loss:0.9109603556728425\n",
      "train loss:1.0381722661287467\n",
      "train loss:1.0882182275815024\n",
      "train loss:0.834297940311629\n",
      "train loss:0.8735013364943282\n",
      "train loss:0.9890682251902528\n",
      "train loss:0.891644709312369\n",
      "train loss:0.7660666363750727\n",
      "train loss:0.9731531364313726\n",
      "train loss:0.6938113980764514\n",
      "train loss:0.9885626499876692\n",
      "train loss:0.8749159916684736\n",
      "train loss:0.88722249824584\n",
      "train loss:0.6830611309128406\n",
      "train loss:0.8623393630902372\n",
      "train loss:0.7792177792849724\n",
      "train loss:0.7996520927937253\n",
      "train loss:0.8097960237435118\n",
      "train loss:0.8943774849065069\n",
      "train loss:0.9027228384626543\n",
      "train loss:0.8988268813238786\n",
      "train loss:0.9812196446821756\n",
      "train loss:0.982781954029068\n",
      "train loss:0.8677660065454289\n",
      "train loss:0.8800211396806431\n",
      "train loss:0.7934927811401674\n",
      "train loss:0.842407083103131\n",
      "train loss:0.956896420058318\n",
      "train loss:0.8695087529925722\n",
      "train loss:0.9072226524644306\n",
      "train loss:0.9801656641177228\n",
      "train loss:0.7498305120165034\n",
      "train loss:0.983945102952736\n",
      "train loss:0.8406453751673001\n",
      "train loss:0.891212809450692\n",
      "train loss:0.7337588341980016\n",
      "train loss:0.8625297615024948\n",
      "train loss:0.8981678618152081\n",
      "train loss:0.9105122640656483\n",
      "train loss:0.9342859558430168\n",
      "train loss:0.9607105240672115\n",
      "train loss:0.8627755920172029\n",
      "train loss:0.829437712585397\n",
      "train loss:0.8186770986773406\n",
      "train loss:0.8029007596134362\n",
      "train loss:0.8460800881029423\n",
      "train loss:0.8943666517761969\n",
      "train loss:0.8964062892215474\n",
      "train loss:0.8407381327024861\n",
      "train loss:0.8062881119619567\n",
      "train loss:0.7029481179667301\n",
      "train loss:0.8241951843373488\n",
      "train loss:0.7464154647885323\n",
      "train loss:0.9233310661048231\n",
      "train loss:0.8930657136496127\n",
      "train loss:0.8117761313622283\n",
      "train loss:0.9463375458925453\n",
      "train loss:0.8129642442175072\n",
      "train loss:0.9141281071040009\n",
      "train loss:0.9626773464484678\n",
      "train loss:0.8379412907044618\n",
      "train loss:0.8431519422688766\n",
      "train loss:0.732015258767731\n",
      "train loss:0.9600302394701181\n",
      "train loss:0.7801435191827167\n",
      "train loss:0.8169955552152262\n",
      "train loss:1.0590249635910753\n",
      "train loss:0.9412221528843797\n",
      "train loss:0.8561406790938362\n",
      "train loss:0.8240546239323825\n",
      "train loss:0.8313992192976714\n",
      "train loss:0.8789442663217608\n",
      "train loss:0.7985653345558688\n",
      "train loss:0.8660069538551706\n",
      "train loss:0.6655221891674603\n",
      "train loss:0.8680983671264816\n",
      "train loss:0.7926882167286934\n",
      "train loss:0.7985287504438813\n",
      "train loss:0.80363468427636\n",
      "train loss:0.8608871857188423\n",
      "train loss:0.8815883723419272\n",
      "train loss:0.918537250719323\n",
      "train loss:0.8463432208524929\n",
      "train loss:0.8574614656004244\n",
      "train loss:0.8844929809193842\n",
      "train loss:0.8967487828619807\n",
      "train loss:0.9230900296452542\n",
      "train loss:0.803649855933619\n",
      "train loss:0.7292833929527275\n",
      "train loss:0.7103224660773034\n",
      "train loss:0.804314192697309\n",
      "train loss:0.7758029456434926\n",
      "train loss:0.8632375663377054\n",
      "train loss:0.941674279461745\n",
      "train loss:0.9557588041065729\n",
      "train loss:0.8229613262094739\n",
      "train loss:0.9572816747764675\n",
      "train loss:0.7936078024905282\n",
      "train loss:0.9642049889757277\n",
      "train loss:0.7448123655223762\n",
      "train loss:0.8373450932520963\n",
      "train loss:0.8040532486727282\n",
      "train loss:0.8307424646355658\n",
      "train loss:0.9221889003113488\n",
      "train loss:0.8390072109617873\n",
      "train loss:0.7180522907844697\n",
      "train loss:0.8033088709406926\n",
      "train loss:0.9078014895404775\n",
      "train loss:0.6720373930529413\n",
      "train loss:0.9210379503914002\n",
      "train loss:0.8033571432050773\n",
      "train loss:0.886624023389019\n",
      "train loss:0.8992672685921549\n",
      "train loss:0.9593166564306678\n",
      "train loss:0.7512691962091993\n",
      "train loss:0.9182975885192901\n",
      "train loss:0.9566634789628305\n",
      "train loss:0.8188469577316205\n",
      "train loss:0.8631233685280598\n",
      "train loss:1.071634003450325\n",
      "train loss:0.87660305907484\n",
      "train loss:0.9199294808579078\n",
      "train loss:0.9163409433356788\n",
      "train loss:0.8946023654146849\n",
      "train loss:0.7635839359947022\n",
      "train loss:0.8769756985502251\n",
      "train loss:0.8387150292785469\n",
      "train loss:0.8494867382478186\n",
      "train loss:0.9882017486862523\n",
      "train loss:0.9042949331233303\n",
      "train loss:0.8256185130599907\n",
      "train loss:0.8492729363433547\n",
      "train loss:0.985955113089573\n",
      "train loss:0.8962309140129986\n",
      "train loss:0.8810771443940563\n",
      "train loss:0.877296545204638\n",
      "train loss:0.7721493544682717\n",
      "train loss:0.9415464162341189\n",
      "train loss:0.7719958864420101\n",
      "train loss:0.8709660388743182\n",
      "train loss:0.7413059569654957\n",
      "train loss:0.8228028673241873\n",
      "train loss:0.781637273219261\n",
      "train loss:0.8046214680089873\n",
      "train loss:0.7668733963241059\n",
      "train loss:0.7081490662353341\n",
      "train loss:0.8220205757496943\n",
      "train loss:0.8330485058266395\n",
      "train loss:1.0630436006246442\n",
      "train loss:0.6791543070619399\n",
      "train loss:0.7673820216461587\n",
      "train loss:0.8099732245852131\n",
      "train loss:0.7864381651754053\n",
      "train loss:0.8136284095849352\n",
      "train loss:0.929420897345439\n",
      "train loss:0.8482277122524609\n",
      "train loss:0.8530891597413863\n",
      "train loss:0.8364799523192326\n",
      "train loss:0.9946963338840346\n",
      "train loss:0.8701176929552439\n",
      "train loss:0.9298559913508413\n",
      "train loss:0.9347422553674908\n",
      "train loss:0.765567731239912\n",
      "train loss:0.9422274770105241\n",
      "train loss:0.9345909366796034\n",
      "train loss:0.8299278539557183\n",
      "train loss:1.0168838376245142\n",
      "train loss:0.8685778636097862\n",
      "train loss:0.8432024435347245\n",
      "train loss:0.9536981793352142\n",
      "train loss:0.8362785728431362\n",
      "train loss:0.8396075645598391\n",
      "train loss:1.088884764908081\n",
      "train loss:0.8083337239381122\n",
      "train loss:0.9355890473339631\n",
      "train loss:0.9229467023999941\n",
      "train loss:0.8575089304192625\n",
      "train loss:0.8998114908000858\n",
      "train loss:0.8996989472676189\n",
      "train loss:0.8823388397877467\n",
      "train loss:0.9593221197536004\n",
      "train loss:0.8465653227719927\n",
      "train loss:0.8575023593707747\n",
      "train loss:0.957360945039338\n",
      "train loss:0.7361318313642754\n",
      "train loss:0.8998930242813244\n",
      "train loss:0.7999095020942947\n",
      "train loss:0.8370056267674844\n",
      "train loss:0.8929482465153317\n",
      "train loss:0.7582816193875768\n",
      "train loss:0.8717773681001542\n",
      "train loss:0.69764890509214\n",
      "train loss:0.7016293445166539\n",
      "train loss:0.8977854932177598\n",
      "train loss:1.0063898763254187\n",
      "train loss:0.8424227707060018\n",
      "train loss:0.7951473437246787\n",
      "train loss:0.8491728112089687\n",
      "train loss:0.9476779758747976\n",
      "train loss:0.7627844068151353\n",
      "train loss:0.9083397956770901\n",
      "train loss:0.8570068878599238\n",
      "train loss:1.0157638189609932\n",
      "train loss:0.8995996873906946\n",
      "train loss:0.9846319548076606\n",
      "train loss:0.7671861849604472\n",
      "train loss:0.9127054273377004\n",
      "train loss:0.9089869622722273\n",
      "train loss:0.7614751228725989\n",
      "train loss:0.9270372553005458\n",
      "train loss:0.9541421225901859\n",
      "train loss:0.8440056309898261\n",
      "train loss:0.8773310558392167\n",
      "train loss:0.848346268141034\n",
      "train loss:0.8145626731126536\n",
      "train loss:0.8720757759504941\n",
      "train loss:0.7143152603071353\n",
      "train loss:0.772515588331672\n",
      "train loss:0.7903282522007357\n",
      "train loss:0.789761723618166\n",
      "train loss:0.8477213466518632\n",
      "train loss:0.7985840603854696\n",
      "train loss:0.8259557010788463\n",
      "train loss:0.9852207178842831\n",
      "train loss:0.804869026733319\n",
      "train loss:0.8431080751833617\n",
      "train loss:0.8271860954631027\n",
      "train loss:0.856004411386233\n",
      "train loss:0.8785616608529954\n",
      "train loss:0.8655145863631464\n",
      "train loss:0.7551867143759157\n",
      "train loss:0.8036624413522238\n",
      "train loss:0.7861869825660263\n",
      "train loss:0.8609471615617389\n",
      "train loss:0.9904540428709936\n",
      "train loss:0.9194924829501503\n",
      "train loss:0.8287306772897978\n",
      "train loss:0.7285313202155208\n",
      "train loss:0.7476722460106886\n",
      "train loss:0.7217759387534651\n",
      "train loss:0.8804003253635068\n",
      "train loss:0.9610149773312824\n",
      "train loss:0.9596829048778729\n",
      "train loss:0.7295714842300254\n",
      "train loss:0.8945419672549503\n",
      "train loss:0.9564703162224698\n",
      "train loss:0.7265169894551233\n",
      "train loss:0.883871009467022\n",
      "train loss:0.7745268263277818\n",
      "train loss:0.7375902318096191\n",
      "train loss:0.946695655106124\n",
      "train loss:0.7488767647406079\n",
      "train loss:0.8665008907120801\n",
      "train loss:0.9635731823550772\n",
      "train loss:1.0040073216573304\n",
      "train loss:0.8834138355846366\n",
      "train loss:1.2086108844674939\n",
      "train loss:1.0436284624641865\n",
      "train loss:0.7870833099233465\n",
      "train loss:0.8620487219578551\n",
      "train loss:0.7014419892571108\n",
      "train loss:0.888390189753025\n",
      "train loss:0.8340501068915702\n",
      "train loss:0.9353284330341226\n",
      "train loss:0.981632870197234\n",
      "train loss:0.8779039406460359\n",
      "train loss:0.7416329725395798\n",
      "train loss:0.8575907033576828\n",
      "train loss:1.1133480656217478\n",
      "train loss:0.9950428348993674\n",
      "=== epoch:18, train acc:0.998, test acc:0.992 ===\n",
      "train loss:0.9486785887174218\n",
      "train loss:0.9804445368337176\n",
      "train loss:0.708568463116005\n",
      "train loss:0.9464049963062778\n",
      "train loss:0.7940968521199444\n",
      "train loss:1.070361146773074\n",
      "train loss:0.9150388860927984\n",
      "train loss:0.884176350236189\n",
      "train loss:0.8763907399644595\n",
      "train loss:0.9048224738555867\n",
      "train loss:0.9691341504048724\n",
      "train loss:1.0545592203183511\n",
      "train loss:0.8710769959428716\n",
      "train loss:0.7653019635040254\n",
      "train loss:0.9092138693128308\n",
      "train loss:0.7481520172213096\n",
      "train loss:0.9324677229750713\n",
      "train loss:0.9036603940034976\n",
      "train loss:1.087567004988937\n",
      "train loss:0.8752221815900408\n",
      "train loss:0.9058004825433329\n",
      "train loss:0.8003452002338703\n",
      "train loss:0.9867250177135898\n",
      "train loss:0.7373964200129137\n",
      "train loss:0.9532939454639989\n",
      "train loss:0.8837582199415881\n",
      "train loss:0.9184211560343989\n",
      "train loss:0.8886621577013334\n",
      "train loss:0.8357457790037024\n",
      "train loss:0.9792326281140972\n",
      "train loss:0.8045363977030457\n",
      "train loss:0.869435315773033\n",
      "train loss:0.914733804905126\n",
      "train loss:0.840349536659484\n",
      "train loss:0.9822892449662352\n",
      "train loss:1.0698010717629949\n",
      "train loss:0.8429607058216255\n",
      "train loss:0.9014711435070535\n",
      "train loss:0.9091914010710131\n",
      "train loss:1.0041869307127762\n",
      "train loss:0.8423518377749124\n",
      "train loss:0.6983708214943405\n",
      "train loss:0.8317518549174959\n",
      "train loss:0.9344637712722361\n",
      "train loss:0.8106098547753426\n",
      "train loss:0.9714924884561742\n",
      "train loss:0.9694999480949085\n",
      "train loss:1.106363115425945\n",
      "train loss:0.8246123185780511\n",
      "train loss:0.8257931964468955\n",
      "train loss:0.8789492344939096\n",
      "train loss:0.8465212032126748\n",
      "train loss:0.8948219115013996\n",
      "train loss:0.8601109761822602\n",
      "train loss:0.9125622284028669\n",
      "train loss:0.7529587571880525\n",
      "train loss:0.798649237678503\n",
      "train loss:0.8208953059303684\n",
      "train loss:0.7984875665576368\n",
      "train loss:0.8106344612981252\n",
      "train loss:0.7929184486455764\n",
      "train loss:0.9422237163388203\n",
      "train loss:0.8257622584806614\n",
      "train loss:0.926731459776543\n",
      "train loss:0.6501609691396335\n",
      "train loss:0.8908546837159609\n",
      "train loss:0.8241809634654993\n",
      "train loss:0.9491211876396309\n",
      "train loss:0.8447353931729354\n",
      "train loss:0.6322437710834277\n",
      "train loss:0.765900103322918\n",
      "train loss:0.8484575099017471\n",
      "train loss:0.8656447903011154\n",
      "train loss:0.7848315024481519\n",
      "train loss:0.7534998334294462\n",
      "train loss:0.8433929638283262\n",
      "train loss:0.8024991504454804\n",
      "train loss:0.7160448700344593\n",
      "train loss:0.7406387991514758\n",
      "train loss:0.8301922780136108\n",
      "train loss:0.8054860021134493\n",
      "train loss:0.8569721158802078\n",
      "train loss:0.8967879997582814\n",
      "train loss:0.65699683580808\n",
      "train loss:0.8854467649428568\n",
      "train loss:0.7086470134938652\n",
      "train loss:0.6160664407743865\n",
      "train loss:0.7628661899283259\n",
      "train loss:1.0508842802163243\n",
      "train loss:0.9770373961700003\n",
      "train loss:0.8864812670018573\n",
      "train loss:0.9517307779856048\n",
      "train loss:0.7915785874632247\n",
      "train loss:0.9005435376336881\n",
      "train loss:0.9165275621874387\n",
      "train loss:1.050087727586464\n",
      "train loss:1.0157644720626549\n",
      "train loss:0.8484478822431121\n",
      "train loss:0.8169848075345996\n",
      "train loss:0.8949397942181083\n",
      "train loss:0.7891644193926216\n",
      "train loss:0.7727891376084015\n",
      "train loss:0.9054473286553163\n",
      "train loss:0.7674943578596652\n",
      "train loss:0.7659389723689917\n",
      "train loss:0.8917521521721911\n",
      "train loss:0.8447763791426626\n",
      "train loss:0.7692757149203545\n",
      "train loss:0.9794396876026612\n",
      "train loss:0.7491041967927313\n",
      "train loss:0.9594036233323994\n",
      "train loss:0.7839939046023281\n",
      "train loss:0.774321664674725\n",
      "train loss:1.0366640053726344\n",
      "train loss:0.9539426574335791\n",
      "train loss:0.7049507882619974\n",
      "train loss:0.714358188097089\n",
      "train loss:0.9239188089482135\n",
      "train loss:0.7191204600561982\n",
      "train loss:0.848052329635255\n",
      "train loss:0.8601856936304625\n",
      "train loss:0.768669463120449\n",
      "train loss:0.9978749248776699\n",
      "train loss:0.9601133927574408\n",
      "train loss:0.7861605134073727\n",
      "train loss:0.8554684658954536\n",
      "train loss:0.7098840020097816\n",
      "train loss:0.9202293330123292\n",
      "train loss:1.0392025188356573\n",
      "train loss:0.742287241786468\n",
      "train loss:0.9130446619919823\n",
      "train loss:0.7909289074120983\n",
      "train loss:0.8277594342294562\n",
      "train loss:0.9724200750071834\n",
      "train loss:0.9596159081332423\n",
      "train loss:0.7650663904895971\n",
      "train loss:0.8794007364207616\n",
      "train loss:1.0354653152435394\n",
      "train loss:0.9812981633910222\n",
      "train loss:0.9468858562942977\n",
      "train loss:0.8522387325122288\n",
      "train loss:0.7709485031672508\n",
      "train loss:0.8449567262854365\n",
      "train loss:0.7983096246011031\n",
      "train loss:0.96016832349208\n",
      "train loss:0.9524507956106077\n",
      "train loss:0.8102162668044427\n",
      "train loss:0.9268128518895823\n",
      "train loss:0.9506660806257301\n",
      "train loss:0.6991351615958701\n",
      "train loss:0.6878280085021606\n",
      "train loss:0.9445909914387863\n",
      "train loss:0.9788927217056488\n",
      "train loss:0.9246817973782008\n",
      "train loss:0.7770899338514892\n",
      "train loss:0.8300976381818758\n",
      "train loss:0.957972803015834\n",
      "train loss:0.8339829327440331\n",
      "train loss:0.9769900083460926\n",
      "train loss:0.765001988351605\n",
      "train loss:0.9043188370435594\n",
      "train loss:0.8241209473378218\n",
      "train loss:0.8087536103722768\n",
      "train loss:0.7932089374914361\n",
      "train loss:0.895992080785177\n",
      "train loss:0.9799746573794388\n",
      "train loss:0.7188362608674562\n",
      "train loss:0.8672181170894829\n",
      "train loss:0.879083843163271\n",
      "train loss:0.946962058282434\n",
      "train loss:0.7917850029316077\n",
      "train loss:0.8629802759418191\n",
      "train loss:0.7471583784466728\n",
      "train loss:0.6581963956311037\n",
      "train loss:0.904163160807892\n",
      "train loss:0.9497034041495495\n",
      "train loss:0.8346207838226295\n",
      "train loss:0.8609294144123006\n",
      "train loss:0.8920250122935809\n",
      "train loss:0.9502205386846456\n",
      "train loss:0.8112616786132847\n",
      "train loss:0.870103366561911\n",
      "train loss:0.7689313093149072\n",
      "train loss:0.9205496503689012\n",
      "train loss:0.8017137435778379\n",
      "train loss:0.78108323253514\n",
      "train loss:0.8167302972969547\n",
      "train loss:0.6700071925927442\n",
      "train loss:0.7717733928782219\n",
      "train loss:0.9362477168285714\n",
      "train loss:0.9587443033129968\n",
      "train loss:0.8776495887699771\n",
      "train loss:0.755389457925067\n",
      "train loss:0.9618350960295103\n",
      "train loss:1.1304477273878932\n",
      "train loss:0.9845433244676637\n",
      "train loss:0.7193361422219092\n",
      "train loss:0.8887316329849952\n",
      "train loss:0.792376499655707\n",
      "train loss:0.9377037915770842\n",
      "train loss:0.8546556333517707\n",
      "train loss:0.9861455161402825\n",
      "train loss:0.9153105714778562\n",
      "train loss:1.02058653564436\n",
      "train loss:0.9143306195411219\n",
      "train loss:0.9450073306657589\n",
      "train loss:0.9499996841270986\n",
      "train loss:0.8488378046505051\n",
      "train loss:0.7933546980165292\n",
      "train loss:0.7908876797131991\n",
      "train loss:1.015276923840668\n",
      "train loss:0.9800982020970003\n",
      "train loss:0.977339116371575\n",
      "train loss:0.8599272334715695\n",
      "train loss:0.8169511453640463\n",
      "train loss:0.8493162437698162\n",
      "train loss:0.7163544479249928\n",
      "train loss:0.8177568217444521\n",
      "train loss:0.8330107190464163\n",
      "train loss:0.837401720937747\n",
      "train loss:0.7706299236602931\n",
      "train loss:0.7321424980630615\n",
      "train loss:0.7882791144550707\n",
      "train loss:0.9002970704776097\n",
      "train loss:1.0221305695426082\n",
      "train loss:0.9274911556452095\n",
      "train loss:0.7836998655314314\n",
      "train loss:0.8595128391595653\n",
      "train loss:0.7382568848178659\n",
      "train loss:0.896877359083891\n",
      "train loss:0.8165542174556427\n",
      "train loss:1.038396393264482\n",
      "train loss:0.9539726048466748\n",
      "train loss:0.7122855828958164\n",
      "train loss:0.8361907379155396\n",
      "train loss:0.8629288369474333\n",
      "train loss:0.9792346970254237\n",
      "train loss:1.1153988951889031\n",
      "train loss:0.9904356720374373\n",
      "train loss:1.0270389975394212\n",
      "train loss:0.6088597660133513\n",
      "train loss:0.7086257045547112\n",
      "train loss:0.9191326554865165\n",
      "train loss:1.0377537961963237\n",
      "train loss:0.8708883724937757\n",
      "train loss:0.7444674908495315\n",
      "train loss:0.7662174976925482\n",
      "train loss:0.9508024146228674\n",
      "train loss:0.8604179656290326\n",
      "train loss:0.9001973118259357\n",
      "train loss:0.9313114552359693\n",
      "train loss:0.8186316259738411\n",
      "train loss:0.9780101944835389\n",
      "train loss:0.7010678921507376\n",
      "train loss:0.7798540817200729\n",
      "train loss:0.830363318375582\n",
      "train loss:0.838080382324641\n",
      "train loss:1.0254759408993481\n",
      "train loss:0.9615515713409123\n",
      "train loss:0.8734001336213173\n",
      "train loss:0.7527014212258142\n",
      "train loss:0.8205609971325591\n",
      "train loss:0.7924850743997999\n",
      "train loss:0.8702057036098588\n",
      "train loss:0.7972791669132548\n",
      "train loss:0.9845156036675291\n",
      "train loss:0.825320292528738\n",
      "train loss:0.8521467207553954\n",
      "train loss:0.9024170131633926\n",
      "train loss:0.9113683122999319\n",
      "train loss:1.0709248105590634\n",
      "train loss:0.7260614978140648\n",
      "train loss:0.8871493211618043\n",
      "train loss:0.9355599164237642\n",
      "train loss:0.8771958087612483\n",
      "train loss:0.8347391940280124\n",
      "train loss:0.8354844364918779\n",
      "train loss:1.0281533337435984\n",
      "train loss:0.8790894095809477\n",
      "train loss:0.9157372632083001\n",
      "train loss:0.8268055039815959\n",
      "train loss:0.8652741061251089\n",
      "train loss:0.9187089318321978\n",
      "train loss:0.8202393545745068\n",
      "train loss:0.8372095098906503\n",
      "train loss:0.980540458339928\n",
      "train loss:0.6943101021720058\n",
      "train loss:0.792876972903695\n",
      "train loss:0.8243296282465116\n",
      "train loss:0.9261464369081079\n",
      "train loss:0.9025920639503471\n",
      "train loss:0.9759135906773118\n",
      "train loss:0.6919726213778559\n",
      "train loss:0.8794304123843807\n",
      "train loss:0.9155345578687372\n",
      "train loss:0.8703438273957796\n",
      "train loss:1.0191405231443789\n",
      "train loss:0.9208131894573316\n",
      "train loss:0.8865974221186547\n",
      "train loss:0.8108496805553266\n",
      "train loss:0.8787997448041035\n",
      "train loss:0.8979807290596793\n",
      "train loss:0.8679431657399641\n",
      "train loss:0.8262322223950416\n",
      "train loss:0.7923944555893025\n",
      "train loss:0.9049625652328049\n",
      "train loss:0.994791595843911\n",
      "train loss:0.8931533886280149\n",
      "train loss:1.072372869222061\n",
      "train loss:0.9697761733982798\n",
      "train loss:0.8929619540576867\n",
      "train loss:0.9254652708961385\n",
      "train loss:0.9669830078297267\n",
      "train loss:0.7566414448862265\n",
      "train loss:0.9648831114586867\n",
      "train loss:0.8964003011837874\n",
      "train loss:0.7092419314074532\n",
      "train loss:0.6431429294190655\n",
      "train loss:0.9123146650508065\n",
      "train loss:0.8832231432581014\n",
      "train loss:0.6720695350765193\n",
      "train loss:0.7703736629604464\n",
      "train loss:0.8506315494420577\n",
      "train loss:0.8635316202982187\n",
      "train loss:0.9365877100537939\n",
      "train loss:0.945248253216538\n",
      "train loss:0.9308723813276216\n",
      "train loss:0.8883567576510244\n",
      "train loss:0.7863385076076298\n",
      "train loss:0.9069349157882114\n",
      "train loss:0.6978744074113665\n",
      "train loss:0.8084361772993442\n",
      "train loss:0.9027862889467319\n",
      "train loss:0.8809101485056449\n",
      "train loss:0.9558572617560465\n",
      "train loss:0.9681958667289965\n",
      "train loss:0.8640011563581512\n",
      "train loss:0.8885360673498799\n",
      "train loss:0.7459429322931298\n",
      "train loss:0.9278042375948828\n",
      "train loss:0.9630855591115798\n",
      "train loss:0.8529972444523614\n",
      "train loss:0.7394483391000469\n",
      "train loss:0.9641576769367852\n",
      "train loss:0.9198450643903437\n",
      "train loss:0.8318534613524727\n",
      "train loss:0.9140148431987263\n",
      "train loss:0.8399436842243237\n",
      "train loss:0.9112114432956275\n",
      "train loss:0.9057624901238036\n",
      "train loss:0.8546106543065639\n",
      "train loss:0.7413134847771546\n",
      "train loss:0.7012921807451982\n",
      "train loss:0.9014830851844468\n",
      "train loss:0.8218741817359\n",
      "train loss:0.9024812240497462\n",
      "train loss:0.9465781459766067\n",
      "train loss:0.8938885982052963\n",
      "train loss:0.7902719200636288\n",
      "train loss:0.7547470783096841\n",
      "train loss:0.6304297871475619\n",
      "train loss:0.7187012518014022\n",
      "train loss:0.7679920947097116\n",
      "train loss:0.8142084148752363\n",
      "train loss:0.9073260653409669\n",
      "train loss:0.8995918141246199\n",
      "train loss:0.7610944540808022\n",
      "train loss:0.9844197326455191\n",
      "train loss:1.0491399263761234\n",
      "train loss:0.870046203472937\n",
      "train loss:0.7594022186628596\n",
      "train loss:0.9367548234588893\n",
      "train loss:0.9097873381418262\n",
      "train loss:0.9052414589058503\n",
      "train loss:0.7644775820358594\n",
      "train loss:0.9461292303663162\n",
      "train loss:0.6796834765347234\n",
      "train loss:0.8909378572100591\n",
      "train loss:0.9531825644990046\n",
      "train loss:0.7888007090555164\n",
      "train loss:0.8862470436781814\n",
      "train loss:0.903582678743944\n",
      "train loss:0.7981004455852709\n",
      "train loss:0.7622307502090518\n",
      "train loss:0.8488879861079631\n",
      "train loss:0.9719122474648869\n",
      "train loss:0.9044776557109167\n",
      "train loss:0.9602243388449463\n",
      "train loss:0.9503152481922146\n",
      "train loss:0.8602994375995806\n",
      "train loss:0.8325726689140532\n",
      "train loss:1.021921662950941\n",
      "train loss:0.8618877868682582\n",
      "train loss:0.9941277422145133\n",
      "train loss:0.8264086794170555\n",
      "train loss:0.7037592272032984\n",
      "train loss:0.8441430663607578\n",
      "train loss:0.87291896320742\n",
      "train loss:0.7955784044017358\n",
      "train loss:0.9143553066522284\n",
      "train loss:0.9580334146008924\n",
      "train loss:0.8023873296566612\n",
      "train loss:0.8101267711730449\n",
      "train loss:0.822543107779449\n",
      "train loss:0.9715591082010139\n",
      "train loss:0.9285298273076661\n",
      "train loss:0.8867421303519331\n",
      "train loss:0.984949899671204\n",
      "train loss:0.7351789113802321\n",
      "train loss:0.9698610168722759\n",
      "train loss:0.8866054638320553\n",
      "train loss:0.8799812139920806\n",
      "train loss:0.9453302219721706\n",
      "train loss:0.916046071490847\n",
      "train loss:0.8510401180298124\n",
      "train loss:1.018955656333017\n",
      "train loss:0.7412637633093639\n",
      "train loss:0.8993813381848241\n",
      "train loss:0.7565994100146978\n",
      "train loss:0.8381008087386086\n",
      "train loss:0.9231597326871566\n",
      "train loss:0.6486354367475627\n",
      "train loss:0.832102319775752\n",
      "train loss:0.6996956207013285\n",
      "train loss:0.8971594743971647\n",
      "train loss:0.8321748547764345\n",
      "train loss:0.8191727851534215\n",
      "train loss:0.8493279777773768\n",
      "train loss:0.8834417654247378\n",
      "train loss:0.6250827642236751\n",
      "train loss:0.9660965755287145\n",
      "train loss:0.7245112260080027\n",
      "train loss:0.866989894119828\n",
      "train loss:0.8575523723458844\n",
      "train loss:0.7908361979607321\n",
      "train loss:0.8141730350853311\n",
      "train loss:0.7794195347030479\n",
      "train loss:0.8964815168209047\n",
      "train loss:0.8721981630053125\n",
      "train loss:0.8311441351841599\n",
      "train loss:0.8376463941274049\n",
      "train loss:0.8615555987451665\n",
      "train loss:0.8962761831591091\n",
      "train loss:1.0277910803801635\n",
      "train loss:0.894628750390792\n",
      "train loss:0.9791805562677528\n",
      "train loss:0.8149824339331865\n",
      "train loss:0.8487619132056197\n",
      "train loss:0.9837354773341773\n",
      "train loss:1.0562865430647452\n",
      "train loss:0.7788434630950108\n",
      "train loss:0.8701599422349166\n",
      "train loss:0.8335159952600794\n",
      "train loss:0.940375719883789\n",
      "train loss:0.8375134610370638\n",
      "train loss:0.8228868932511203\n",
      "train loss:0.7644976161469589\n",
      "train loss:0.820097176483611\n",
      "train loss:0.9464233853435904\n",
      "train loss:0.8582059265599281\n",
      "train loss:0.9021292068781516\n",
      "train loss:0.9662518443478476\n",
      "train loss:0.787858155063847\n",
      "train loss:1.0070506515225761\n",
      "train loss:0.8128302433226006\n",
      "train loss:0.8104326789408957\n",
      "train loss:0.9038923210105714\n",
      "train loss:0.731848847750912\n",
      "train loss:0.7367910952107121\n",
      "train loss:0.8281693941555297\n",
      "train loss:0.8800866629915919\n",
      "train loss:0.8063304808905475\n",
      "train loss:0.8863644937105591\n",
      "train loss:0.8409949799347983\n",
      "train loss:0.884348327290709\n",
      "train loss:0.7904317799086036\n",
      "train loss:0.8383044868201505\n",
      "train loss:0.8957837386357353\n",
      "train loss:0.7860042967306362\n",
      "train loss:0.8988327544849475\n",
      "train loss:0.912330131724239\n",
      "train loss:0.9389295198590681\n",
      "train loss:0.8886709210928012\n",
      "train loss:0.7305004670830626\n",
      "train loss:0.7969557956201784\n",
      "train loss:0.9869137916013508\n",
      "train loss:0.8754946725633918\n",
      "train loss:0.8067592024513565\n",
      "train loss:1.073325572025788\n",
      "train loss:0.8569292453987406\n",
      "train loss:0.7582412463820031\n",
      "train loss:0.8509960917369647\n",
      "train loss:0.9626143123867127\n",
      "train loss:1.054861870545914\n",
      "train loss:0.9541749760929139\n",
      "train loss:0.8247479418361785\n",
      "train loss:0.8285482521209695\n",
      "train loss:0.8341057871424408\n",
      "train loss:0.7597981197984093\n",
      "train loss:0.7443526241478685\n",
      "train loss:0.7704514735300444\n",
      "train loss:1.0007803436464109\n",
      "train loss:0.9759979971635215\n",
      "train loss:0.9653748842897785\n",
      "train loss:0.7792454522014645\n",
      "train loss:0.7680055331187419\n",
      "train loss:0.9369786092313268\n",
      "train loss:0.8693199605897847\n",
      "train loss:0.7782872041122622\n",
      "train loss:0.8655556597724032\n",
      "train loss:0.9214465803120003\n",
      "train loss:0.8303086717029824\n",
      "train loss:0.8458040880478451\n",
      "train loss:0.8443666717934122\n",
      "train loss:0.7601549487676338\n",
      "train loss:0.8186831314065721\n",
      "train loss:0.9029477400637411\n",
      "train loss:0.829306075963665\n",
      "train loss:0.8618937767925101\n",
      "train loss:0.9095835932256132\n",
      "train loss:0.8897387808844731\n",
      "train loss:0.9019814803924348\n",
      "train loss:0.8456247946762268\n",
      "train loss:1.0234468955083385\n",
      "train loss:0.8022381072395421\n",
      "train loss:0.8263240372172282\n",
      "train loss:0.8030504562868309\n",
      "train loss:0.9053761683132645\n",
      "train loss:0.7133595930674244\n",
      "train loss:0.773310082578302\n",
      "train loss:0.9761335398025236\n",
      "train loss:0.7572864692867478\n",
      "train loss:0.9743142337511256\n",
      "train loss:0.8294780047435186\n",
      "train loss:0.792571376564029\n",
      "train loss:0.7709857294491904\n",
      "train loss:0.848640476690108\n",
      "train loss:0.6935323844767582\n",
      "train loss:0.6973672028793336\n",
      "train loss:0.8982925721330552\n",
      "train loss:0.9749140983455925\n",
      "train loss:0.727863893662023\n",
      "train loss:0.8002262230825139\n",
      "train loss:0.9257577174350787\n",
      "train loss:0.9742509356075828\n",
      "train loss:0.7567379827058726\n",
      "train loss:0.9957766301207295\n",
      "train loss:0.8995857871184622\n",
      "train loss:0.8483579389870701\n",
      "train loss:0.9608261650275525\n",
      "train loss:0.897315377171444\n",
      "train loss:0.8328553626452136\n",
      "train loss:0.8786694854411863\n",
      "train loss:0.8977016079741393\n",
      "train loss:0.8433278239210028\n",
      "train loss:0.7420537846752508\n",
      "train loss:0.8264088612498469\n",
      "train loss:0.7741032045145768\n",
      "train loss:0.8061339123201796\n",
      "train loss:0.9287775465111868\n",
      "train loss:0.8873326535791874\n",
      "train loss:0.6576478676399756\n",
      "train loss:0.9287208400981817\n",
      "train loss:0.8587827970092538\n",
      "train loss:0.878390675446593\n",
      "train loss:0.8161628722585739\n",
      "train loss:0.8830719949829866\n",
      "train loss:0.8948955718400078\n",
      "train loss:0.8349547718745302\n",
      "train loss:0.8141474910256887\n",
      "train loss:0.9286800083767183\n",
      "train loss:0.7770514460821158\n",
      "train loss:0.9819162760902053\n",
      "train loss:0.8448151938070647\n",
      "train loss:0.7816033731957878\n",
      "train loss:0.8248203764483342\n",
      "train loss:0.8320974365035839\n",
      "train loss:0.9067742270381206\n",
      "train loss:0.9710764559119162\n",
      "train loss:0.8425967761723595\n",
      "train loss:0.8037116251487215\n",
      "train loss:0.8464806906189903\n",
      "train loss:0.8582567463140468\n",
      "train loss:0.704052800910293\n",
      "train loss:0.7396610882387488\n",
      "train loss:0.9388386955396872\n",
      "train loss:0.8584969471748762\n",
      "train loss:0.9129908186996297\n",
      "train loss:0.8800717939512063\n",
      "train loss:0.8972071785620528\n",
      "train loss:0.8139237288950081\n",
      "train loss:0.8064822416759667\n",
      "train loss:0.9101710978743385\n",
      "train loss:0.7342165318554268\n",
      "train loss:0.8029245762758711\n",
      "train loss:0.8485274761004675\n",
      "train loss:0.9614224032101343\n",
      "train loss:0.8876319379460162\n",
      "train loss:0.8196417814778627\n",
      "train loss:0.7898066136424323\n",
      "=== epoch:19, train acc:1.0, test acc:0.99 ===\n",
      "train loss:0.8581384765680588\n",
      "train loss:0.8050538167608936\n",
      "train loss:0.86456199761311\n",
      "train loss:0.8011839559825878\n",
      "train loss:0.6417192656786925\n",
      "train loss:0.7184489420400663\n",
      "train loss:0.918236836419481\n",
      "train loss:1.0316158313659785\n",
      "train loss:0.8605091379029483\n",
      "train loss:0.9780662304377746\n",
      "train loss:0.7590187474132086\n",
      "train loss:0.8617596251328594\n",
      "train loss:0.9287527993475042\n",
      "train loss:0.9073694434598688\n",
      "train loss:1.0253877901244872\n",
      "train loss:0.8819760546631354\n",
      "train loss:0.7498449783496217\n",
      "train loss:0.8925661560466484\n",
      "train loss:0.9440768959106381\n",
      "train loss:0.9327470898671691\n",
      "train loss:0.8637444797997695\n",
      "train loss:0.9275531240817103\n",
      "train loss:0.8957504146752789\n",
      "train loss:0.8106591412395122\n",
      "train loss:0.929311563961834\n",
      "train loss:0.8504148941880204\n",
      "train loss:0.9798989671632492\n",
      "train loss:0.849139783443257\n",
      "train loss:0.7987827714084759\n",
      "train loss:0.7843323757844245\n",
      "train loss:1.1145810374263534\n",
      "train loss:0.9079405230126804\n",
      "train loss:0.869096235762445\n",
      "train loss:0.8176420276064446\n",
      "train loss:0.9815814169257508\n",
      "train loss:0.6938041899865323\n",
      "train loss:0.9839484062821469\n",
      "train loss:0.9143879299014998\n",
      "train loss:0.6778679936398819\n",
      "train loss:0.8257525939883833\n",
      "train loss:0.902669667588645\n",
      "train loss:1.0135860496891516\n",
      "train loss:0.8897876773374488\n",
      "train loss:0.7077452035107339\n",
      "train loss:0.963332906365154\n",
      "train loss:0.8902672483323691\n",
      "train loss:0.7857911621591076\n",
      "train loss:0.9369161083993098\n",
      "train loss:0.8924719732168505\n",
      "train loss:0.7991180502362498\n",
      "train loss:0.8095171980160365\n",
      "train loss:0.8549735908124947\n",
      "train loss:0.8147606665651967\n",
      "train loss:0.9136749228124152\n",
      "train loss:0.8527675382256761\n",
      "train loss:0.8039750553436339\n",
      "train loss:0.7534289474433415\n",
      "train loss:0.6928868096737059\n",
      "train loss:0.8005738357438484\n",
      "train loss:0.9859701869503446\n",
      "train loss:0.7164695973865928\n",
      "train loss:0.90462071811657\n",
      "train loss:0.8518891530545568\n",
      "train loss:0.9771429896347875\n",
      "train loss:0.8719515857085135\n",
      "train loss:0.9066415360920402\n",
      "train loss:0.6903279866692782\n",
      "train loss:0.8493539485664793\n",
      "train loss:0.844269178438728\n",
      "train loss:0.695790406822919\n",
      "train loss:0.8560200753728772\n",
      "train loss:0.8216992434205745\n",
      "train loss:0.9075562449040614\n",
      "train loss:0.8049440159405299\n",
      "train loss:0.7505348993008744\n",
      "train loss:0.8567566710992918\n",
      "train loss:0.8200821113114689\n",
      "train loss:0.8250351845006204\n",
      "train loss:0.9926544468990413\n",
      "train loss:0.9198162982806456\n",
      "train loss:0.7316064643503648\n",
      "train loss:0.8054469468158828\n",
      "train loss:0.8609159940271394\n",
      "train loss:0.7969493714145212\n",
      "train loss:0.8987743776115888\n",
      "train loss:0.687929484415136\n",
      "train loss:0.7519466034236194\n",
      "train loss:1.02801771160047\n",
      "train loss:0.8996666253470563\n",
      "train loss:0.8762708552475746\n",
      "train loss:1.0309437918276476\n",
      "train loss:0.8108759967770968\n",
      "train loss:0.9220717454927861\n",
      "train loss:1.0386042511070586\n",
      "train loss:0.992624623906473\n",
      "train loss:1.0321063253953324\n",
      "train loss:0.8676195967623717\n",
      "train loss:0.7359792129472141\n",
      "train loss:0.7742781880437037\n",
      "train loss:1.0707851535095965\n",
      "train loss:0.8841583609026682\n",
      "train loss:0.8861536346301092\n",
      "train loss:0.7574140208695441\n",
      "train loss:0.8731731911805903\n",
      "train loss:0.7284095071438391\n",
      "train loss:0.8888131213729169\n",
      "train loss:0.8526040874483417\n",
      "train loss:0.8368940544738811\n",
      "train loss:0.8204389032676711\n",
      "train loss:0.9826568313469747\n",
      "train loss:0.9586490649368106\n",
      "train loss:0.9501542569681806\n",
      "train loss:0.841560733027329\n",
      "train loss:0.8048791519116087\n",
      "train loss:0.7984415402539013\n",
      "train loss:0.820574371766101\n",
      "train loss:0.8823297007808496\n",
      "train loss:0.818683258859679\n",
      "train loss:0.8932185127751289\n",
      "train loss:0.8322164433395859\n",
      "train loss:0.8331334802322161\n",
      "train loss:0.8850167887895222\n",
      "train loss:1.054066808499841\n",
      "train loss:0.7735782150662882\n",
      "train loss:1.034921310543447\n",
      "train loss:0.9018529428854879\n",
      "train loss:0.8878601217633809\n",
      "train loss:0.894049064497818\n",
      "train loss:0.9564972495366761\n",
      "train loss:0.71552422768591\n",
      "train loss:0.8646286542701865\n",
      "train loss:0.694104704325819\n",
      "train loss:0.7585294148257592\n",
      "train loss:1.027013847968121\n",
      "train loss:0.7337914772952697\n",
      "train loss:0.9280270019825828\n",
      "train loss:0.8443470511500952\n",
      "train loss:0.9043365821177862\n",
      "train loss:0.9351622635991511\n",
      "train loss:0.9614311975295504\n",
      "train loss:0.9162520055239594\n",
      "train loss:0.8230954315391223\n",
      "train loss:1.0494236658527265\n",
      "train loss:0.8861792657864531\n",
      "train loss:0.8784750016601675\n",
      "train loss:0.7411736512982853\n",
      "train loss:0.7316723600817976\n",
      "train loss:0.8045633675675703\n",
      "train loss:0.8485906680357364\n",
      "train loss:1.0099222866604523\n",
      "train loss:0.9062493473770037\n",
      "train loss:0.7711138615590742\n",
      "train loss:0.732018523486904\n",
      "train loss:0.9282691399558511\n",
      "train loss:0.848636325996654\n",
      "train loss:0.9400583945698509\n",
      "train loss:0.7313358268235948\n",
      "train loss:0.8493109331234246\n",
      "train loss:0.9230475377907542\n",
      "train loss:0.888560655283494\n",
      "train loss:0.8742030021047191\n",
      "train loss:0.8497773400579081\n",
      "train loss:0.8282973253120639\n",
      "train loss:0.9876678807379052\n",
      "train loss:0.876165931460972\n",
      "train loss:0.8846436866503095\n",
      "train loss:0.972581038557007\n",
      "train loss:0.7277035679014248\n",
      "train loss:0.8261177493769778\n",
      "train loss:0.7861387004063944\n",
      "train loss:0.9222878159009794\n",
      "train loss:0.9304288980487978\n",
      "train loss:0.9167846230257495\n",
      "train loss:0.9406301325125308\n",
      "train loss:0.815363045709706\n",
      "train loss:0.8475230827143464\n",
      "train loss:0.9115842448649059\n",
      "train loss:0.9048408616410094\n",
      "train loss:0.7816513998890815\n",
      "train loss:0.8560623553426729\n",
      "train loss:0.9444182637709956\n",
      "train loss:0.7297206139814711\n",
      "train loss:0.6066300332580066\n",
      "train loss:0.9246494143699465\n",
      "train loss:0.9706504070135192\n",
      "train loss:0.7352400069159657\n",
      "train loss:0.8863640982733736\n",
      "train loss:0.877121841449337\n",
      "train loss:0.8347625278322387\n",
      "train loss:0.8493981844935764\n",
      "train loss:0.9250627334732363\n",
      "train loss:0.7837906856834763\n",
      "train loss:0.8201903437053558\n",
      "train loss:0.7868886265053066\n",
      "train loss:0.9934767221416071\n",
      "train loss:0.6943521954872429\n",
      "train loss:0.9560822345662338\n",
      "train loss:0.9779757753668314\n",
      "train loss:0.776739387550169\n",
      "train loss:0.964759437519519\n",
      "train loss:0.821122285042234\n",
      "train loss:0.8849458328547897\n",
      "train loss:0.9572611678724988\n",
      "train loss:0.9548869936981376\n",
      "train loss:0.9428434445638118\n",
      "train loss:0.7638443328128284\n",
      "train loss:0.944496878607178\n",
      "train loss:0.8064631325193239\n",
      "train loss:0.7113586211998882\n",
      "train loss:0.8838057722293307\n",
      "train loss:0.6629134487036685\n",
      "train loss:0.7477460596045272\n",
      "train loss:0.860017190304778\n",
      "train loss:0.7919971943294841\n",
      "train loss:0.8021104655297596\n",
      "train loss:0.779375052447439\n",
      "train loss:0.8719164921732216\n",
      "train loss:0.8866859639189318\n",
      "train loss:0.9158871698030999\n",
      "train loss:0.9489965344341132\n",
      "train loss:0.8531034113375355\n",
      "train loss:0.7060278180004699\n",
      "train loss:0.9554949896573949\n",
      "train loss:0.7703627912646117\n",
      "train loss:0.8435335401047567\n",
      "train loss:0.8021325732897006\n",
      "train loss:0.863862842593727\n",
      "train loss:0.955519792736801\n",
      "train loss:0.9173213642332629\n",
      "train loss:0.8127476455985061\n",
      "train loss:0.8939467311562901\n",
      "train loss:0.7998465305947857\n",
      "train loss:0.7790052274367832\n",
      "train loss:0.7895035058024178\n",
      "train loss:0.9015262120176327\n",
      "train loss:0.8523166959261982\n",
      "train loss:0.7099960290949215\n",
      "train loss:0.8394990143885862\n",
      "train loss:0.6814006860388244\n",
      "train loss:1.0925392524088033\n",
      "train loss:0.8595797087777669\n",
      "train loss:0.9297523302148744\n",
      "train loss:0.7388164162432118\n",
      "train loss:0.9004345879368536\n",
      "train loss:0.9065502342094477\n",
      "train loss:0.9590633909533033\n",
      "train loss:1.1211323123666501\n",
      "train loss:0.8929454922197085\n",
      "train loss:0.8394604720287181\n",
      "train loss:0.8146087701478144\n",
      "train loss:0.8697308950550147\n",
      "train loss:0.7601253873491132\n",
      "train loss:0.9024868625077036\n",
      "train loss:0.8288086991591956\n",
      "train loss:0.9309003242340443\n",
      "train loss:0.771073694901983\n",
      "train loss:0.9448491724667426\n",
      "train loss:0.8278335413394856\n",
      "train loss:0.8619547234769454\n",
      "train loss:0.6721735866260309\n",
      "train loss:0.8547543231797076\n",
      "train loss:0.633390644699347\n",
      "train loss:0.7525495933719932\n",
      "train loss:0.8165456520376247\n",
      "train loss:0.6772872899000052\n",
      "train loss:0.921496460878058\n",
      "train loss:0.7838708514792404\n",
      "train loss:0.6211003540936362\n",
      "train loss:0.7160552146150856\n",
      "train loss:0.8278022583420116\n",
      "train loss:0.9851832647247909\n",
      "train loss:0.8132964589690996\n",
      "train loss:1.0531579791353525\n",
      "train loss:0.865801339517953\n",
      "train loss:0.6937592656503255\n",
      "train loss:0.8825695333512944\n",
      "train loss:0.9450746779388495\n",
      "train loss:0.7553377139863031\n",
      "train loss:0.8545924335894979\n",
      "train loss:0.8672937338985892\n",
      "train loss:0.7398869319506862\n",
      "train loss:0.8431964240262936\n",
      "train loss:0.9189774575011173\n",
      "train loss:0.8022589188285629\n",
      "train loss:0.8092759740156988\n",
      "train loss:0.8757751587575109\n",
      "train loss:0.8847082387298356\n",
      "train loss:0.7874607596983833\n",
      "train loss:0.7331571498865059\n",
      "train loss:0.8770354489663249\n",
      "train loss:0.8909471679821769\n",
      "train loss:0.9540940415592655\n",
      "train loss:0.9363845972933064\n",
      "train loss:0.874299001957841\n",
      "train loss:0.6556155948394049\n",
      "train loss:0.94958860285088\n",
      "train loss:0.7371706978514192\n",
      "train loss:0.7364814326645913\n",
      "train loss:0.8752613200855838\n",
      "train loss:0.7546586030375205\n",
      "train loss:0.7987774047546776\n",
      "train loss:0.8433392967118045\n",
      "train loss:0.8278917977662279\n",
      "train loss:0.847493891220616\n",
      "train loss:0.7515612152515139\n",
      "train loss:0.7341435260816211\n",
      "train loss:0.8394465944975518\n",
      "train loss:0.9676756515188768\n",
      "train loss:1.076900783745247\n",
      "train loss:0.8416448959981507\n",
      "train loss:0.8382595908223274\n",
      "train loss:0.979996318834982\n",
      "train loss:0.9678655001711796\n",
      "train loss:0.9364496216387056\n",
      "train loss:0.7671060773996753\n",
      "train loss:0.8551071251383193\n",
      "train loss:0.8475912151501046\n",
      "train loss:0.8749959158780432\n",
      "train loss:0.8911740815246758\n",
      "train loss:0.7061557260494239\n",
      "train loss:0.670798753699736\n",
      "train loss:0.7509309560118146\n",
      "train loss:0.8712669311969343\n",
      "train loss:0.7721052415419888\n",
      "train loss:0.7845693006313924\n",
      "train loss:0.8902497384492523\n",
      "train loss:0.8681023746232005\n",
      "train loss:0.8936991012811987\n",
      "train loss:0.8722501278226332\n",
      "train loss:0.7957238021648944\n",
      "train loss:0.7967485560853063\n",
      "train loss:0.8238197973559103\n",
      "train loss:0.7516000702865672\n",
      "train loss:0.7806296378689646\n",
      "train loss:0.8563054168710532\n",
      "train loss:0.9316842460180388\n",
      "train loss:0.8996903266300681\n",
      "train loss:0.8694428082456784\n",
      "train loss:0.8578493089465113\n",
      "train loss:0.7235527534795281\n",
      "train loss:0.7036530507424621\n",
      "train loss:0.836358116395619\n",
      "train loss:1.021423247811289\n",
      "train loss:0.8890287944249223\n",
      "train loss:0.7706726157783065\n",
      "train loss:0.7661253025640785\n",
      "train loss:0.7557985033788617\n",
      "train loss:0.7107029748176353\n",
      "train loss:0.6331619757705955\n",
      "train loss:0.8412109647097068\n",
      "train loss:0.7521686633192368\n",
      "train loss:0.8013066755612445\n",
      "train loss:0.9570454844850613\n",
      "train loss:0.7847844076312889\n",
      "train loss:0.8109250803577253\n",
      "train loss:0.9914258046796732\n",
      "train loss:0.8026980630737509\n",
      "train loss:0.9849879882892096\n",
      "train loss:0.8344269040190109\n",
      "train loss:0.9740247759401519\n",
      "train loss:0.9721282472009943\n",
      "train loss:0.8264538506228134\n",
      "train loss:0.8186368262063495\n",
      "train loss:0.7071049554943352\n",
      "train loss:0.9208043949623839\n",
      "train loss:0.7705744391437485\n",
      "train loss:0.7789177529511511\n",
      "train loss:0.9914561230735557\n",
      "train loss:0.9244647364644035\n",
      "train loss:0.7398155272361676\n",
      "train loss:0.9678610212126846\n",
      "train loss:0.9426753492161052\n",
      "train loss:0.7991841424907684\n",
      "train loss:0.7598944999503544\n",
      "train loss:0.9357319215073159\n",
      "train loss:0.8591329720696389\n",
      "train loss:0.697169427229772\n",
      "train loss:0.838503911824125\n",
      "train loss:0.7384507212418601\n",
      "train loss:0.9217816347349133\n",
      "train loss:0.7601980649504845\n",
      "train loss:0.9185485794798117\n",
      "train loss:0.8245775501813496\n",
      "train loss:1.0719409176829473\n",
      "train loss:0.8158848411089761\n",
      "train loss:0.789627388161279\n",
      "train loss:0.8226949240476666\n",
      "train loss:0.7129852410471491\n",
      "train loss:0.8570285346480067\n",
      "train loss:0.8547326694634073\n",
      "train loss:1.0135180241786965\n",
      "train loss:0.9566156210424493\n",
      "train loss:0.8343435323300582\n",
      "train loss:0.7961890395549451\n",
      "train loss:0.8847116345070235\n",
      "train loss:0.7841335960866919\n",
      "train loss:0.6826478541662603\n",
      "train loss:0.8944596710247491\n",
      "train loss:0.8263211062523023\n",
      "train loss:0.9648012541153937\n",
      "train loss:0.8002078465500878\n",
      "train loss:0.9624630003365029\n",
      "train loss:0.9369813943930216\n",
      "train loss:0.7707820020918521\n",
      "train loss:1.0166277398652594\n",
      "train loss:0.7297727396873023\n",
      "train loss:0.9146428624404592\n",
      "train loss:0.8659773584634971\n",
      "train loss:0.8724062065478215\n",
      "train loss:0.8151656774312925\n",
      "train loss:0.8401901178464729\n",
      "train loss:0.9639848008383857\n",
      "train loss:0.7397460929741481\n",
      "train loss:0.9787232629282449\n",
      "train loss:0.8324447978568376\n",
      "train loss:0.898430555893213\n",
      "train loss:0.811394195711141\n",
      "train loss:0.8667712587447644\n",
      "train loss:0.9264430597883414\n",
      "train loss:0.8167666487058624\n",
      "train loss:0.854096709176368\n",
      "train loss:0.741690498247863\n",
      "train loss:0.8832383056815499\n",
      "train loss:0.8328527929636657\n",
      "train loss:0.8461496218457759\n",
      "train loss:0.9448496491737279\n",
      "train loss:0.7681916518880516\n",
      "train loss:0.79130935875538\n",
      "train loss:0.9012489396594167\n",
      "train loss:0.9535002949393053\n",
      "train loss:0.8749127576189103\n",
      "train loss:0.9417165085773236\n",
      "train loss:0.9653347287962571\n",
      "train loss:0.9020136522799919\n",
      "train loss:0.9335153529910488\n",
      "train loss:0.7933147581440074\n",
      "train loss:0.8157567578671856\n",
      "train loss:0.7148710807732273\n",
      "train loss:0.9329083142851795\n",
      "train loss:0.9556155506925604\n",
      "train loss:0.8228442360416729\n",
      "train loss:0.9138108428276799\n",
      "train loss:0.790012070097242\n",
      "train loss:0.7675835768884882\n",
      "train loss:1.0491955413950667\n",
      "train loss:0.8876027410450054\n",
      "train loss:0.8737197723401857\n",
      "train loss:0.9042894516371682\n",
      "train loss:0.8248496016002016\n",
      "train loss:0.7199520067828838\n",
      "train loss:0.7440801246847983\n",
      "train loss:0.7350564495502389\n",
      "train loss:0.7677733084994571\n",
      "train loss:0.8146482373416378\n",
      "train loss:0.9315347308946417\n",
      "train loss:0.793427655681541\n",
      "train loss:0.6916672676451153\n",
      "train loss:0.8593102383829513\n",
      "train loss:0.9227842236317159\n",
      "train loss:0.830036904064404\n",
      "train loss:0.7957662354255894\n",
      "train loss:0.8669351602694181\n",
      "train loss:0.9598542880068943\n",
      "train loss:0.9294800682857719\n",
      "train loss:0.7821608379757362\n",
      "train loss:0.8719786429370169\n",
      "train loss:0.9122334282061604\n",
      "train loss:0.8213378465522148\n",
      "train loss:0.7812151529641588\n",
      "train loss:0.8829766588557559\n",
      "train loss:0.7947078353390528\n",
      "train loss:0.7608442799601214\n",
      "train loss:0.9599319980870454\n",
      "train loss:0.8211291883095625\n",
      "train loss:1.0078016910488659\n",
      "train loss:0.7557183740064982\n",
      "train loss:0.8875551536161366\n",
      "train loss:1.0221175193401497\n",
      "train loss:0.8572282170918575\n",
      "train loss:0.77892932969176\n",
      "train loss:0.7950093730919268\n",
      "train loss:0.921585738315176\n",
      "train loss:0.8779103118870678\n",
      "train loss:0.86593956576293\n",
      "train loss:0.8833303866531069\n",
      "train loss:0.799230945346487\n",
      "train loss:0.7077745679198647\n",
      "train loss:0.8318193906166143\n",
      "train loss:0.8389410671523252\n",
      "train loss:0.7622161293730889\n",
      "train loss:0.8317498359988882\n",
      "train loss:0.8656831132750483\n",
      "train loss:0.9649613592274922\n",
      "train loss:0.8435249706144207\n",
      "train loss:0.7924117072735649\n",
      "train loss:0.8648990506875005\n",
      "train loss:0.9622093040346337\n",
      "train loss:0.7578050171331142\n",
      "train loss:0.9288848310592509\n",
      "train loss:0.9086626504350768\n",
      "train loss:0.7914352918632287\n",
      "train loss:0.9489070593471561\n",
      "train loss:0.7451417577794446\n",
      "train loss:0.9347346739741822\n",
      "train loss:0.7209526833049296\n",
      "train loss:0.7068777360742382\n",
      "train loss:0.9073543752449141\n",
      "train loss:0.8633291391564447\n",
      "train loss:0.8612702174196205\n",
      "train loss:0.9574212033905907\n",
      "train loss:0.9184034009238968\n",
      "train loss:0.8374025660382837\n",
      "train loss:0.8541312230614513\n",
      "train loss:1.005868511012978\n",
      "train loss:0.7825046589371227\n",
      "train loss:0.9962391974999197\n",
      "train loss:0.9501496343250387\n",
      "train loss:0.9533967457576422\n",
      "train loss:0.7539680335514062\n",
      "train loss:0.9781553067030299\n",
      "train loss:0.9149241833460358\n",
      "train loss:0.8309681820726209\n",
      "train loss:0.9137583029146221\n",
      "train loss:0.7963524184156092\n",
      "train loss:0.7949566495231766\n",
      "train loss:0.951934403066833\n",
      "train loss:0.8507834693136301\n",
      "train loss:0.883666864250209\n",
      "train loss:0.8496901549716068\n",
      "train loss:0.8944969127790074\n",
      "train loss:0.8592543354275298\n",
      "train loss:0.6939141402689537\n",
      "train loss:0.8448266755608614\n",
      "train loss:0.8373609944129734\n",
      "train loss:0.9260074560405654\n",
      "train loss:0.7469929517594324\n",
      "train loss:0.8858936323052313\n",
      "train loss:0.9329552158907276\n",
      "train loss:0.9828933005998377\n",
      "train loss:1.0083667725016874\n",
      "train loss:0.8140446149406556\n",
      "train loss:0.8502020052513213\n",
      "train loss:0.7545338283066856\n",
      "train loss:0.984071741516549\n",
      "train loss:0.960492637350552\n",
      "train loss:0.9327458086945098\n",
      "train loss:0.8111823167439997\n",
      "train loss:0.772492387394057\n",
      "train loss:0.7639269249608109\n",
      "train loss:0.8514199276285972\n",
      "train loss:0.9399517303020366\n",
      "train loss:0.8059631384969097\n",
      "train loss:0.8804524330833885\n",
      "train loss:0.8529463612680214\n",
      "train loss:0.8216189846257265\n",
      "train loss:0.7841495673783082\n",
      "train loss:0.7150212207350767\n",
      "train loss:0.8967312021674745\n",
      "train loss:0.7574212726072421\n",
      "train loss:0.7152489273965713\n",
      "train loss:0.9082761602357229\n",
      "train loss:0.6783737103890798\n",
      "train loss:0.8567141420273753\n",
      "train loss:0.8928195516911503\n",
      "train loss:0.9917362383438926\n",
      "train loss:0.7915151213552791\n",
      "train loss:0.9038929343478783\n",
      "train loss:0.7685284489374632\n",
      "train loss:0.7877082390301825\n",
      "train loss:1.0356188384384757\n",
      "train loss:0.8981321184832305\n",
      "train loss:0.8330699103705951\n",
      "train loss:0.8335724557063332\n",
      "train loss:0.9293675357810268\n",
      "train loss:0.8795433232215809\n",
      "train loss:1.0198791315803704\n",
      "train loss:0.7694942630036423\n",
      "train loss:0.8473404527233632\n",
      "train loss:0.8756886391157837\n",
      "train loss:0.8728139822952014\n",
      "train loss:1.0883494813097083\n",
      "train loss:0.9501099521929904\n",
      "train loss:0.8559414181301388\n",
      "train loss:0.7495724805541706\n",
      "train loss:0.8385176028759683\n",
      "train loss:0.7770280214862693\n",
      "train loss:0.8660053877828097\n",
      "train loss:0.9132751576139316\n",
      "train loss:0.8853313248737561\n",
      "train loss:0.9327040436402995\n",
      "train loss:0.9973748118573786\n",
      "train loss:0.8549631379439857\n",
      "train loss:0.9123085342279939\n",
      "train loss:0.8201326580105217\n",
      "train loss:0.7398737215057278\n",
      "train loss:0.8516820678587312\n",
      "train loss:0.9453407432678795\n",
      "train loss:0.9449621318002964\n",
      "train loss:0.9814812572798723\n",
      "train loss:0.8102255040163078\n",
      "=== epoch:20, train acc:0.998, test acc:0.99 ===\n",
      "train loss:0.7427199612223983\n",
      "train loss:0.8792072505951098\n",
      "train loss:0.9047469590892641\n",
      "train loss:0.8409350086516703\n",
      "train loss:0.9023120214989436\n",
      "train loss:0.931936472222728\n",
      "train loss:0.9286860139379172\n",
      "train loss:0.8188707567380287\n",
      "train loss:0.8887016257800964\n",
      "train loss:0.8992263203101172\n",
      "train loss:0.8770718272015492\n",
      "train loss:0.8149861103503069\n",
      "train loss:0.9218545748556872\n",
      "train loss:0.8906783548656904\n",
      "train loss:0.7007281209204903\n",
      "train loss:0.7200063359322288\n",
      "train loss:0.9437268930255723\n",
      "train loss:0.8288041208296919\n",
      "train loss:0.8054476052731319\n",
      "train loss:0.9436266524323615\n",
      "train loss:0.9206901409409574\n",
      "train loss:0.867273177488427\n",
      "train loss:0.8450547894647289\n",
      "train loss:0.98924737815773\n",
      "train loss:0.8406952384203962\n",
      "train loss:0.7549143171739446\n",
      "train loss:0.777229781188228\n",
      "train loss:0.9226026831854232\n",
      "train loss:0.9629725339944786\n",
      "train loss:0.8125354796839962\n",
      "train loss:0.9845917039591586\n",
      "train loss:0.8226466855056037\n",
      "train loss:0.8625641004086197\n",
      "train loss:0.8787571147309409\n",
      "train loss:0.8017302396493539\n",
      "train loss:0.8993857238278209\n",
      "train loss:0.7529868014805483\n",
      "train loss:0.9815113584132322\n",
      "train loss:0.9144442314232937\n",
      "train loss:0.8555633113647132\n",
      "train loss:0.9451589330731918\n",
      "train loss:0.9654144158502733\n",
      "train loss:1.0109528828362064\n",
      "train loss:0.9748573851208536\n",
      "train loss:0.861882132180419\n",
      "train loss:0.8032359602460458\n",
      "train loss:0.8149840301405288\n",
      "train loss:0.8178001793346218\n",
      "train loss:0.8621955992572303\n",
      "train loss:0.8835816277304734\n",
      "train loss:0.7571984464471225\n",
      "train loss:0.9393392324204747\n",
      "train loss:0.707918636196909\n",
      "train loss:0.9021666299344201\n",
      "train loss:0.593280178740518\n",
      "train loss:0.8730876332231975\n",
      "train loss:0.9773399705469916\n",
      "train loss:0.6887866016064944\n",
      "train loss:0.8940076240905802\n",
      "train loss:0.9066151696865251\n",
      "train loss:0.9544528543166987\n",
      "train loss:0.7903340581568412\n",
      "train loss:0.8796782615800598\n",
      "train loss:0.8644131665692619\n",
      "train loss:0.9237608206312189\n",
      "train loss:0.8695879381027356\n",
      "train loss:1.0548597240841129\n",
      "train loss:0.8346015771945052\n",
      "train loss:0.8641813589646796\n",
      "train loss:0.756396166937636\n",
      "train loss:0.9971868063448199\n",
      "train loss:0.8441315052246684\n",
      "train loss:0.7923317818569008\n",
      "train loss:0.7344985067848087\n",
      "train loss:0.7797855011679928\n",
      "train loss:0.6875905983660863\n",
      "train loss:0.8482772064912577\n",
      "train loss:1.0020641627322906\n",
      "train loss:0.8420045605448435\n",
      "train loss:0.9345516320400314\n",
      "train loss:0.8237282315290818\n",
      "train loss:0.8709917838379319\n",
      "train loss:0.9162794202237196\n",
      "train loss:1.059103761669502\n",
      "train loss:0.9774430501388964\n",
      "train loss:0.8362835780975683\n",
      "train loss:0.7916228335591842\n",
      "train loss:0.9242297915232645\n",
      "train loss:0.7574358715517863\n",
      "train loss:0.7536017432743874\n",
      "train loss:0.9274053008799125\n",
      "train loss:0.8513192383889444\n",
      "train loss:0.9749605856818345\n",
      "train loss:0.5696438012358896\n",
      "train loss:0.803659623367716\n",
      "train loss:0.8616794032761854\n",
      "train loss:0.8621184361082131\n",
      "train loss:0.8050487099883263\n",
      "train loss:0.7308645641677797\n",
      "train loss:0.9334879260206173\n",
      "train loss:0.9469003246017265\n",
      "train loss:0.7538169446891486\n",
      "train loss:0.7958493683046739\n",
      "train loss:0.819629049830783\n",
      "train loss:0.8548606518737398\n",
      "train loss:0.7360775286865171\n",
      "train loss:0.934448219036455\n",
      "train loss:0.8519543137706691\n",
      "train loss:0.9138002666446916\n",
      "train loss:0.8173069401249353\n",
      "train loss:0.8241264256782589\n",
      "train loss:0.865083264705642\n",
      "train loss:0.9614289087423806\n",
      "train loss:0.7967521182058216\n",
      "train loss:0.7488461578305315\n",
      "train loss:0.9248380640915841\n",
      "train loss:0.9819112075481934\n",
      "train loss:0.6641266122484574\n",
      "train loss:0.7892787700692354\n",
      "train loss:0.8991972130907384\n",
      "train loss:0.9014258753981953\n",
      "train loss:0.8364249921709203\n",
      "train loss:0.9943488829677307\n",
      "train loss:0.9029640214926138\n",
      "train loss:0.9214525196303842\n",
      "train loss:0.9329672168544587\n",
      "train loss:0.6815700632675288\n",
      "train loss:0.9562288351058139\n",
      "train loss:1.0687802701658307\n",
      "train loss:0.8579863508716093\n",
      "train loss:0.9184562551181551\n",
      "train loss:0.7425772515257377\n",
      "train loss:0.7999256492642101\n",
      "train loss:0.8864110548056009\n",
      "train loss:0.5688669479014692\n",
      "train loss:0.7897239090482604\n",
      "train loss:0.8625279400991388\n",
      "train loss:0.8589328219842168\n",
      "train loss:0.8435382498431211\n",
      "train loss:0.7688682345545078\n",
      "train loss:0.897944167186527\n",
      "train loss:0.7564706635174074\n",
      "train loss:0.9245357972793748\n",
      "train loss:0.7532251200695189\n",
      "train loss:0.9798628001993528\n",
      "train loss:0.9522139800581735\n",
      "train loss:0.9016591713556845\n",
      "train loss:0.988582380107494\n",
      "train loss:1.0795593502851857\n",
      "train loss:0.8347991070498277\n",
      "train loss:0.893385302048579\n",
      "train loss:0.8672407307262436\n",
      "train loss:0.8289995485757735\n",
      "train loss:0.8261395060695449\n",
      "train loss:0.8839530905857554\n",
      "train loss:0.9532513199713604\n",
      "train loss:0.8484297744964273\n",
      "train loss:0.8452889464170451\n",
      "train loss:0.935365641762574\n",
      "train loss:0.8868808009937713\n",
      "train loss:1.0381703793094277\n",
      "train loss:0.7055768876979341\n",
      "train loss:0.7860969709420569\n",
      "train loss:0.9068722670076599\n",
      "train loss:0.8649618466817388\n",
      "train loss:0.9446850093633976\n",
      "train loss:0.8266455124378704\n",
      "train loss:0.8388666467615132\n",
      "train loss:0.8441365656782963\n",
      "train loss:1.0252996584782226\n",
      "train loss:0.7577321773434009\n",
      "train loss:0.8028464856294785\n",
      "train loss:0.9683463933860691\n",
      "train loss:0.7015672086528074\n",
      "train loss:0.8285081375770628\n",
      "train loss:0.9251816497996369\n",
      "train loss:0.7293596318263572\n",
      "train loss:0.779723183104085\n",
      "train loss:0.8540371288901868\n",
      "train loss:0.7805337064146438\n",
      "train loss:0.922646424827754\n",
      "train loss:0.7430698488759389\n",
      "train loss:0.8090464074085757\n",
      "train loss:0.8705226985886664\n",
      "train loss:0.7406539231562281\n",
      "train loss:0.8605708396445176\n",
      "train loss:0.9577964619462002\n",
      "train loss:0.8928819080696292\n",
      "train loss:0.8904266568701285\n",
      "train loss:1.120685380912315\n",
      "train loss:0.9110403776932244\n",
      "train loss:0.7657076362531466\n",
      "train loss:0.8702716334310354\n",
      "train loss:0.815757448168931\n",
      "train loss:0.8277831814180684\n",
      "train loss:0.8832203922622835\n",
      "train loss:0.6957673719945265\n",
      "train loss:0.8277084734396408\n",
      "train loss:0.763555412222696\n",
      "train loss:0.7634522956178994\n",
      "train loss:0.8400989540832456\n",
      "train loss:0.728797639109643\n",
      "train loss:0.8974281112732395\n",
      "train loss:0.8237434611944923\n",
      "train loss:0.7083300447530908\n",
      "train loss:0.7043397750547328\n",
      "train loss:0.8818083129583415\n",
      "train loss:0.839506482487647\n",
      "train loss:0.7297805929919281\n",
      "train loss:0.7715598534299016\n",
      "train loss:0.9563267704683811\n",
      "train loss:0.9259705706905964\n",
      "train loss:0.8135981885118957\n",
      "train loss:0.8996422072941372\n",
      "train loss:0.9654367669293449\n",
      "train loss:0.7995881475682489\n",
      "train loss:0.9497479031200973\n",
      "train loss:0.7852170801732757\n",
      "train loss:0.9558282393445388\n",
      "train loss:0.9975032132321593\n",
      "train loss:0.7978042611873878\n",
      "train loss:0.7478042395799784\n",
      "train loss:0.8094524662666038\n",
      "train loss:0.8150985820799427\n",
      "train loss:0.8534028110972807\n",
      "train loss:0.7392867925387092\n",
      "train loss:0.924941211168657\n",
      "train loss:0.6601734581957688\n",
      "train loss:0.873308795391787\n",
      "train loss:0.8906013255857643\n",
      "train loss:0.8075600850994453\n",
      "train loss:0.7399983006418096\n",
      "train loss:0.9230730401673058\n",
      "train loss:0.9237398800580447\n",
      "train loss:0.8012561175720556\n",
      "train loss:0.8972391895573115\n",
      "train loss:0.9674198092655122\n",
      "train loss:1.0324899441197408\n",
      "train loss:0.865202679992501\n",
      "train loss:0.8935421841560885\n",
      "train loss:0.9329382046648955\n",
      "train loss:0.919448274470539\n",
      "train loss:0.927447829586772\n",
      "train loss:0.8502950187076173\n",
      "train loss:0.8019342570464947\n",
      "train loss:0.954947325148051\n",
      "train loss:0.7415542050163099\n",
      "train loss:0.8234422240416626\n",
      "train loss:0.8489480655702651\n",
      "train loss:0.9577179423843388\n",
      "train loss:0.9396352076583561\n",
      "train loss:0.9981684972865981\n",
      "train loss:0.7791510630605155\n",
      "train loss:0.813112049967229\n",
      "train loss:0.73471370442428\n",
      "train loss:0.7810373365365897\n",
      "train loss:0.7965664613626819\n",
      "train loss:0.8617769553235243\n",
      "train loss:0.9244337144185127\n",
      "train loss:0.919288701813969\n",
      "train loss:0.7876833827930179\n",
      "train loss:0.7926859331468886\n",
      "train loss:0.8537300973569075\n",
      "train loss:0.908488470737237\n",
      "train loss:0.8142956301412344\n",
      "train loss:0.9024115353305134\n",
      "train loss:1.0474932726573256\n",
      "train loss:0.7891596543616832\n",
      "train loss:0.7177280938843726\n",
      "train loss:0.9721634089193387\n",
      "train loss:0.8555673843130437\n",
      "train loss:1.018259809869027\n",
      "train loss:0.8489820284529648\n",
      "train loss:0.9859271806947121\n",
      "train loss:0.7831466378063083\n",
      "train loss:1.0305898105014415\n",
      "train loss:0.874154081980384\n",
      "train loss:0.8059073253812307\n",
      "train loss:0.8752201564689479\n",
      "train loss:0.9193054059058522\n",
      "train loss:0.7406746238933632\n",
      "train loss:0.9448362549590483\n",
      "train loss:0.7787555163938019\n",
      "train loss:0.9598497175444416\n",
      "train loss:0.7673984881294688\n",
      "train loss:0.8008409535588632\n",
      "train loss:0.7197966102026504\n",
      "train loss:0.8312304084420863\n",
      "train loss:0.9114772470591835\n",
      "train loss:0.8963655500755294\n",
      "train loss:0.961694220855753\n",
      "train loss:0.7660659736403933\n",
      "train loss:0.9190661029640127\n",
      "train loss:0.8316993650272917\n",
      "train loss:0.8686115634021894\n",
      "train loss:0.9116871782279261\n",
      "train loss:0.6971238562624484\n",
      "train loss:0.8396828965085739\n",
      "train loss:0.7036705792601\n",
      "train loss:0.9086258844681658\n",
      "train loss:0.8562551052211949\n",
      "train loss:0.7583503358178062\n",
      "train loss:0.7978236469394602\n",
      "train loss:0.8264954465757015\n",
      "train loss:1.0046620806699555\n",
      "train loss:0.8721055326023297\n",
      "train loss:0.8601111168614979\n",
      "train loss:0.8131182987636147\n",
      "train loss:0.800419238542411\n",
      "train loss:0.7974890492005057\n",
      "train loss:0.8250062804821802\n",
      "train loss:0.9816573207901885\n",
      "train loss:0.8775880320775872\n",
      "train loss:0.8491598591332852\n",
      "train loss:0.7268243525102608\n",
      "train loss:0.8430288653662139\n",
      "train loss:0.75529154041413\n",
      "train loss:0.938610943183414\n",
      "train loss:0.7257196285786938\n",
      "train loss:0.8967611581761438\n",
      "train loss:1.059094285922415\n",
      "train loss:0.8981273035360827\n",
      "train loss:0.8636453737165692\n",
      "train loss:0.6900723658122871\n",
      "train loss:0.698366152869854\n",
      "train loss:0.9212193987989743\n",
      "train loss:0.7963502705492536\n",
      "train loss:0.7933223039331915\n",
      "train loss:0.9133910421030762\n",
      "train loss:0.8654848259071758\n",
      "train loss:1.0076346825774192\n",
      "train loss:0.959618017380894\n",
      "train loss:0.9495649624847518\n",
      "train loss:0.893617091141602\n",
      "train loss:0.9319160918097247\n",
      "train loss:0.775684623879962\n",
      "train loss:0.9374418943268706\n",
      "train loss:0.7892299550350629\n",
      "train loss:0.9404673866533745\n",
      "train loss:0.9057431506774476\n",
      "train loss:0.9827480207834409\n",
      "train loss:0.7983378212434583\n",
      "train loss:0.7627874995323567\n",
      "train loss:0.8380206325637606\n",
      "train loss:0.727753874058794\n",
      "train loss:0.9680146876877981\n",
      "train loss:1.0215855961496887\n",
      "train loss:0.9057294103003437\n",
      "train loss:0.9593521541544284\n",
      "train loss:0.8546884120226609\n",
      "train loss:0.8261244910596452\n",
      "train loss:0.7769452407291935\n",
      "train loss:0.9151102155369989\n",
      "train loss:0.841496734222434\n",
      "train loss:0.9484543684225356\n",
      "train loss:0.7714539806084386\n",
      "train loss:0.7818406446132848\n",
      "train loss:0.9211958666045189\n",
      "train loss:0.7896506991485659\n",
      "train loss:0.812226370928079\n",
      "train loss:0.8932074891090945\n",
      "train loss:0.822225367381141\n",
      "train loss:0.9316353684314447\n",
      "train loss:0.8331811093138153\n",
      "train loss:1.003041289158211\n",
      "train loss:0.8789889643761915\n",
      "train loss:0.9215207210660273\n",
      "train loss:0.8841360904525534\n",
      "train loss:0.8875486618146279\n",
      "train loss:0.8234522676024961\n",
      "train loss:0.6171041912217743\n",
      "train loss:0.8732563396570842\n",
      "train loss:0.9378915324456962\n",
      "train loss:0.8917813656458178\n",
      "train loss:0.9396319533763225\n",
      "train loss:0.9088535035767288\n",
      "train loss:0.691832829570577\n",
      "train loss:0.8523622392837622\n",
      "train loss:0.8873651204566328\n",
      "train loss:0.8488421126357629\n",
      "train loss:1.0290816564266705\n",
      "train loss:0.7457441065226432\n",
      "train loss:0.9519482872309254\n",
      "train loss:0.9090976579219191\n",
      "train loss:0.7521073861623903\n",
      "train loss:0.7684739705168007\n",
      "train loss:1.001466114046358\n",
      "train loss:0.82036950284106\n",
      "train loss:0.8659433343971492\n",
      "train loss:0.7481986939597154\n",
      "train loss:0.8437500283689807\n",
      "train loss:0.7884556600219084\n",
      "train loss:0.8501907364131798\n",
      "train loss:0.8708277933010902\n",
      "train loss:0.9482542433176101\n",
      "train loss:0.8407605824923917\n",
      "train loss:0.8697209334195317\n",
      "train loss:0.866712579597174\n",
      "train loss:0.7535639839694461\n",
      "train loss:0.8835528440633285\n",
      "train loss:0.8608425071240536\n",
      "train loss:0.8481160736699098\n",
      "train loss:0.828621544303819\n",
      "train loss:0.8480246665826736\n",
      "train loss:0.9584209793923912\n",
      "train loss:0.7724600761953504\n",
      "train loss:0.9186138813628258\n",
      "train loss:0.9455226564649345\n",
      "train loss:0.9769463455110102\n",
      "train loss:0.869828942100111\n",
      "train loss:0.76481400844917\n",
      "train loss:0.8477680997267146\n",
      "train loss:0.8756137552278944\n",
      "train loss:0.8377910202189822\n",
      "train loss:1.0686943990888287\n",
      "train loss:0.8209562288356385\n",
      "train loss:0.6902569253591909\n",
      "train loss:0.8770246889995369\n",
      "train loss:0.7726995754863392\n",
      "train loss:1.0667980618242061\n",
      "train loss:0.8830760902669365\n",
      "train loss:0.8026719582432069\n",
      "train loss:0.9140877212054428\n",
      "train loss:0.8270467483883095\n",
      "train loss:0.8902146683440507\n",
      "train loss:0.8579925610053775\n",
      "train loss:0.8596679881082739\n",
      "train loss:0.8854703803153968\n",
      "train loss:0.9468962279315888\n",
      "train loss:0.9300476182118571\n",
      "train loss:0.7294037624695479\n",
      "train loss:0.7841413285913359\n",
      "train loss:0.8302575237332345\n",
      "train loss:0.9390064752817405\n",
      "train loss:0.7242724713660759\n",
      "train loss:0.7237282243391521\n",
      "train loss:0.8660240777852386\n",
      "train loss:0.7298911174421769\n",
      "train loss:0.7952908053631629\n",
      "train loss:0.8006419464090284\n",
      "train loss:0.91497491174473\n",
      "train loss:0.8511996316484044\n",
      "train loss:0.9037962714032639\n",
      "train loss:0.9299770228062141\n",
      "train loss:0.8449928814878143\n",
      "train loss:0.8849576551125038\n",
      "train loss:0.9004556838762505\n",
      "train loss:0.981630167587367\n",
      "train loss:0.913143555637986\n",
      "train loss:0.8968988619276514\n",
      "train loss:0.8284471968136193\n",
      "train loss:0.737229570898905\n",
      "train loss:0.7728154376564318\n",
      "train loss:0.8430099562035419\n",
      "train loss:0.9616435338624594\n",
      "train loss:0.7577632255497371\n",
      "train loss:0.6520933829773787\n",
      "train loss:0.8852232170049598\n",
      "train loss:0.8964695910829302\n",
      "train loss:0.8769456504714\n",
      "train loss:0.7027428566783996\n",
      "train loss:0.7474845163891318\n",
      "train loss:0.964587563898873\n",
      "train loss:0.8174415549757386\n",
      "train loss:0.7957343667829258\n",
      "train loss:0.843231264948383\n",
      "train loss:0.7952819984941708\n",
      "train loss:0.8122328478614119\n",
      "train loss:0.8747483371363888\n",
      "train loss:0.9724001429128944\n",
      "train loss:0.9298495640805912\n",
      "train loss:0.7193010813075031\n",
      "train loss:0.9439586513192864\n",
      "train loss:0.8271778823933527\n",
      "train loss:0.7665295033639196\n",
      "train loss:0.752275022134992\n",
      "train loss:0.8850248395684795\n",
      "train loss:0.9829272241218032\n",
      "train loss:0.6975235102239294\n",
      "train loss:0.8161000523988688\n",
      "train loss:0.8473245620799904\n",
      "train loss:0.8478624264647289\n",
      "train loss:0.8563469706764657\n",
      "train loss:0.8056775005328032\n",
      "train loss:0.8690174656567469\n",
      "train loss:0.7328487255050058\n",
      "train loss:0.8235402960973975\n",
      "train loss:0.882057863587387\n",
      "train loss:0.9186732859265737\n",
      "train loss:1.017210817136807\n",
      "train loss:0.8507549616082062\n",
      "train loss:0.8208991223115842\n",
      "train loss:0.9348472977334815\n",
      "train loss:0.8234319593700369\n",
      "train loss:0.7715804210412466\n",
      "train loss:0.8664542022461057\n",
      "train loss:0.9047852691703071\n",
      "train loss:0.7801684970735343\n",
      "train loss:0.9331654404915013\n",
      "train loss:0.6834301687664157\n",
      "train loss:0.8344764673882663\n",
      "train loss:0.8202667471357401\n",
      "train loss:0.9355639016846051\n",
      "train loss:0.7814074427059126\n",
      "train loss:0.7943587136897142\n",
      "train loss:0.8986690920853293\n",
      "train loss:0.7880457088642152\n",
      "train loss:0.8106077768888575\n",
      "train loss:0.7702105330280732\n",
      "train loss:0.9013286569396074\n",
      "train loss:0.8317065086736161\n",
      "train loss:0.8065393566288354\n",
      "train loss:0.8468454046263858\n",
      "train loss:0.8016240664248877\n",
      "train loss:0.9222456866550729\n",
      "train loss:0.8367500692546295\n",
      "train loss:0.8497461285991483\n",
      "train loss:0.7999165437319194\n",
      "train loss:0.7343320441412533\n",
      "train loss:1.0321990355980513\n",
      "train loss:0.9225243064921383\n",
      "train loss:0.8621299672269316\n",
      "train loss:0.9318311529880375\n",
      "train loss:0.8285063596864559\n",
      "train loss:0.8419771303874883\n",
      "train loss:0.7976673196020494\n",
      "train loss:0.9164235092559445\n",
      "train loss:0.7275873972848262\n",
      "train loss:0.9695285933170473\n",
      "train loss:0.7800400772831516\n",
      "train loss:0.9050012278404632\n",
      "train loss:0.9809425365000811\n",
      "train loss:1.0370888613178137\n",
      "train loss:0.9228694619451165\n",
      "train loss:0.9210433369409428\n",
      "train loss:0.7784008137827289\n",
      "train loss:0.9966792751806937\n",
      "train loss:0.9890775634051462\n",
      "train loss:0.9023060780154591\n",
      "train loss:0.836122132785777\n",
      "train loss:0.7903413436135871\n",
      "train loss:0.893978196466791\n",
      "train loss:0.956355757227046\n",
      "train loss:0.8412423950874053\n",
      "train loss:0.8296806949829977\n",
      "train loss:0.9641404938306857\n",
      "train loss:0.8443419499096142\n",
      "train loss:0.7951476376777229\n",
      "train loss:0.85569969023585\n",
      "train loss:0.8629253181038736\n",
      "train loss:0.850406253750227\n",
      "train loss:0.8968296842520246\n",
      "train loss:0.7321269858856492\n",
      "train loss:0.9117116044619104\n",
      "train loss:0.8567308852721552\n",
      "train loss:0.9798427593441568\n",
      "train loss:0.8909164655578037\n",
      "train loss:0.8227950068513943\n",
      "train loss:0.801201203900342\n",
      "train loss:0.9557050203552923\n",
      "train loss:0.7005462180767351\n",
      "train loss:0.966915772773093\n",
      "train loss:0.8584288336567748\n",
      "train loss:0.7372248341337108\n",
      "train loss:0.9785154863026441\n",
      "train loss:0.7964229021295333\n",
      "train loss:0.9275692235952064\n",
      "train loss:0.7241079421262298\n",
      "train loss:0.7210355867875708\n",
      "train loss:0.6479846993899839\n",
      "train loss:0.8073749313093056\n",
      "train loss:0.852301389072471\n",
      "train loss:1.0341841623573758\n",
      "train loss:0.9489716223698786\n",
      "train loss:0.9154878665050148\n",
      "train loss:0.8279207560219151\n",
      "train loss:0.9408083586815501\n",
      "train loss:0.9077581203309686\n",
      "train loss:0.8513966631408215\n",
      "train loss:0.8722637479967846\n",
      "train loss:0.9609046894532053\n",
      "train loss:0.7746335096584432\n",
      "train loss:0.946731088191977\n",
      "train loss:0.8037119830438695\n",
      "train loss:0.9124541910838653\n",
      "train loss:0.9535776957606857\n",
      "train loss:0.9441370624603969\n",
      "train loss:0.8739665232320829\n",
      "train loss:0.7389215806792541\n",
      "train loss:1.017698527688261\n",
      "train loss:0.7951844605665608\n",
      "train loss:0.7789233245761339\n",
      "train loss:0.7578442699203756\n",
      "train loss:0.6768890332078378\n",
      "train loss:0.8495043308846482\n",
      "train loss:0.8137597605588188\n",
      "train loss:0.7281841047650949\n",
      "train loss:0.8115724526402828\n",
      "train loss:0.8290626688822569\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9922\n",
      "Saved Network Parameters!\n",
      "CPU times: user 17h 23min 15s, sys: 1h 48min 37s, total: 19h 11min 52s\n",
      "Wall time: 12h 34min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "########\n",
    "# train DeepConvNet\n",
    "# 참고: ch08/train_deepnet.py\n",
    "# (시간 관계상 실행은 생략)\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src.dataset.mnist import load_mnist\n",
    "#from deep_convnet import DeepConvNet\n",
    "from src.common.trainer import Trainer\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()  \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=20, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr':0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보관\n",
    "network.save_params(\"deep_convnet_params2.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9935\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (6, 0), 2: (3, 5), 3: (3, 5), 4: (8, 3), 5: (7, 3), 6: (1, 3), 7: (8, 9), 8: (6, 0), 9: (6, 5), 10: (7, 2), 11: (9, 4), 12: (7, 1), 13: (5, 3), 14: (1, 3), 15: (0, 6), 16: (9, 4), 17: (7, 9), 18: (6, 0), 19: (9, 8), 20: (4, 9)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######\n",
    "# DeepConvNet이 인식에 실패한 예\n",
    "# 참고: ch08/misclassified_mnist.py\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from deep_convnet import DeepConvNet\n",
    "from src.dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating test accuracy ... \n",
      "test accuracy:0.9922\n",
      "======= misclassified result =======\n",
      "{view index: (label, inference), ...}\n",
      "{1: (9, 5), 2: (6, 0), 3: (5, 3), 4: (4, 8), 5: (6, 0), 6: (3, 5), 7: (2, 7), 8: (4, 8), 9: (3, 5), 10: (8, 9), 11: (6, 0), 12: (6, 0), 13: (6, 5), 14: (9, 4), 15: (7, 1), 16: (4, 8), 17: (4, 8), 18: (2, 7), 19: (8, 2), 20: (9, 4)}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#######\n",
    "# DeepConvNet이 인식에 실패한 예\n",
    "# 참고: ch08/misclassified_mnist.py\n",
    "\n",
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from deep_convnet import DeepConvNet\n",
    "from src.dataset.mnist import load_mnist\n",
    "\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params2.pkl\")\n",
    "\n",
    "print(\"calculating test accuracy ... \")\n",
    "#sampled = 1000\n",
    "#x_test = x_test[:sampled]\n",
    "#t_test = t_test[:sampled]\n",
    "\n",
    "classified_ids = []\n",
    "\n",
    "acc = 0.0\n",
    "batch_size = 100\n",
    "\n",
    "for i in range(int(x_test.shape[0] / batch_size)):\n",
    "    tx = x_test[i*batch_size:(i+1)*batch_size]\n",
    "    tt = t_test[i*batch_size:(i+1)*batch_size]\n",
    "    y = network.predict(tx, train_flg=False)\n",
    "    y = np.argmax(y, axis=1)\n",
    "    classified_ids.append(y)\n",
    "    acc += np.sum(y == tt)\n",
    "    \n",
    "acc = acc / x_test.shape[0]\n",
    "print(\"test accuracy:\" + str(acc))\n",
    "\n",
    "classified_ids = np.array(classified_ids)\n",
    "classified_ids = classified_ids.flatten()\n",
    " \n",
    "max_view = 20\n",
    "current_view = 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.2, wspace=0.2)\n",
    "\n",
    "mis_pairs = {}\n",
    "for i, val in enumerate(classified_ids == t_test):\n",
    "    if not val:\n",
    "        ax = fig.add_subplot(4, 5, current_view, xticks=[], yticks=[])\n",
    "        ax.imshow(x_test[i].reshape(28, 28), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        mis_pairs[current_view] = (t_test[i], classified_ids[i])\n",
    "            \n",
    "        current_view += 1\n",
    "        if current_view > max_view:\n",
    "            break\n",
    "\n",
    "print(\"======= misclassified result =======\")\n",
    "print(\"{view index: (label, inference), ...}\")\n",
    "print(mis_pairs)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3.4 연산 정밀도와 비트 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caluculate accuracy (float64) ... \n",
      "0.9935\n",
      "caluculate accuracy (float16) ... \n",
      "0.9935\n"
     ]
    }
   ],
   "source": [
    "########\n",
    "# 딥러닝은 높은 수치 정밀도를 요구하지 않는 것이 특징\n",
    "\n",
    "# ch08/half_float_network.py\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "network = DeepConvNet()\n",
    "network.load_params(\"deep_convnet_params.pkl\")\n",
    "\n",
    "sampled = 10000 # 고속화를 위한 표본추출\n",
    "x_test = x_test[:sampled]\n",
    "t_test = t_test[:sampled]\n",
    "\n",
    "print(\"caluculate accuracy (float64) ... \")\n",
    "print(network.accuracy(x_test, t_test))\n",
    "\n",
    "# float16(반정밀도)로 형변환\n",
    "x_test = x_test.astype(np.float16)\n",
    "for param in network.params.values():\n",
    "    param[...] = param.astype(np.float16)\n",
    "\n",
    "print(\"caluculate accuracy (float16) ... \")\n",
    "print(network.accuracy(x_test, t_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
